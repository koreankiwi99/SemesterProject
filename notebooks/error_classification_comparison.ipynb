{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Classification Comparison (v1, v2, v3)\n",
    "\n",
    "Compare error classifications across three prompt versions for GPT-5 FOLIO baseline false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load all three classification results\n",
    "v1 = pd.read_csv('../results/error_analysis/gpt-5_folio_baseline_20251223_011844_v1.csv')\n",
    "v2 = pd.read_csv('../results/error_analysis/gpt-5_folio_baseline_20251223_011844_v2.csv')\n",
    "v3 = pd.read_csv('../results/error_analysis/gpt-5_folio_baseline_20251223_011844_v3.csv')\n",
    "\n",
    "print(f\"v1: {len(v1)} cases, v2: {len(v2)} cases, v3: {len(v3)} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Category Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"V1 Categories:\")\n",
    "print(v1['root_cause_category'].value_counts())\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"V2 Categories:\")\n",
    "print(v2['root_cause_category'].value_counts())\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"V3 Categories:\")\n",
    "print(v3['root_cause_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all three\n",
    "comparison = v1[['case_idx', 'example_id', 'pattern', 'root_cause_category']].copy()\n",
    "comparison.columns = ['case_idx', 'example_id', 'pattern', 'v1']\n",
    "comparison['v2'] = v2['root_cause_category']\n",
    "comparison['v3'] = v3['root_cause_category']\n",
    "\n",
    "# Show all cases\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. V3 Cases by Category (with actual Lean code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses for detailed view\n",
    "responses_dir = Path('../results/simplelean/gpt-5_folio_baseline_20251223_011844/responses')\n",
    "\n",
    "def get_response(case_idx):\n",
    "    \"\"\"Load response file for a case.\"\"\"\n",
    "    path = responses_dir / f'case_{case_idx}.txt'\n",
    "    if path.exists():\n",
    "        return path.read_text()\n",
    "    return 'Not found'\n",
    "\n",
    "# Add response to v3\n",
    "v3['lean_response'] = v3['case_idx'].apply(get_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cases by V3 category\n",
    "for category in v3['root_cause_category'].unique():\n",
    "    cases = v3[v3['root_cause_category'] == category]\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"CATEGORY: {category} ({len(cases)} cases)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for _, row in cases.iterrows():\n",
    "        print(f\"\\n--- Case {row['case_idx']} | {row['pattern']} ---\")\n",
    "        print(f\"Conclusion: {row['conclusion'][:100]}...\")\n",
    "        print(f\"Error: {row['error_description']}\")\n",
    "        print(f\"Problematic: {row.get('problematic_axiom', 'N/A')}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detailed View: Gaming Categories (AXIOMATIZE_*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_cats = ['AXIOMATIZE_CONCLUSION', 'AXIOMATIZE_CONTRADICTION', 'AXIOMATIZE_FABRICATION']\n",
    "gaming_cases = v3[v3['root_cause_category'].isin(gaming_cats)]\n",
    "\n",
    "print(f\"Gaming cases: {len(gaming_cases)}\")\n",
    "print()\n",
    "\n",
    "for _, row in gaming_cases.iterrows():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Case {row['case_idx']} | {row['root_cause_category']} | {row['pattern']}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nConclusion: {row['conclusion']}\")\n",
    "    print(f\"\\nError: {row['error_description']}\")\n",
    "    print(f\"\\n--- Lean Code ---\")\n",
    "    print(row['lean_response'][:2000])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Disagreements Between Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cases where v1, v2, v3 disagree\n",
    "def normalize_category(cat):\n",
    "    \"\"\"Map similar categories across versions.\"\"\"\n",
    "    mappings = {\n",
    "        'REASONING_FAILURE': 'REASONING',\n",
    "        'REASONING_GAP': 'REASONING',\n",
    "        'PROOF_INCOMPLETE': 'REASONING',\n",
    "        'AXIOMATIZES_CONCLUSION': 'AXIOM_CONCLUSION',\n",
    "        'AXIOMATIZE_CONCLUSION': 'AXIOM_CONCLUSION',\n",
    "        'AXIOMATIZES_CONTRADICTION': 'AXIOM_CONTRADICTION',\n",
    "        'AXIOMATIZE_CONTRADICTION': 'AXIOM_CONTRADICTION',\n",
    "        'AXIOMATIZES_UNMENTIONED': 'AXIOM_FABRICATION',\n",
    "        'FABRICATES_ENTITY_FACT': 'AXIOM_FABRICATION',\n",
    "        'AXIOMATIZE_FABRICATION': 'AXIOM_FABRICATION',\n",
    "        'INCORRECT_FORMALIZATION': 'FORMALIZATION',\n",
    "        'FORMALIZE_INCORRECTLY': 'FORMALIZATION',\n",
    "        'FORMALIZE_INCOMPLETE': 'FORMALIZATION',\n",
    "    }\n",
    "    return mappings.get(cat, cat)\n",
    "\n",
    "comparison['v1_norm'] = comparison['v1'].apply(normalize_category)\n",
    "comparison['v2_norm'] = comparison['v2'].apply(normalize_category)\n",
    "comparison['v3_norm'] = comparison['v3'].apply(normalize_category)\n",
    "\n",
    "comparison['all_agree'] = (comparison['v1_norm'] == comparison['v2_norm']) & (comparison['v2_norm'] == comparison['v3_norm'])\n",
    "\n",
    "print(f\"Agreement: {comparison['all_agree'].sum()}/{len(comparison)} cases\")\n",
    "print()\n",
    "print(\"Disagreements:\")\n",
    "comparison[~comparison['all_agree']][['case_idx', 'pattern', 'v1', 'v2', 'v3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category Mapping Summary:\")\n",
    "print()\n",
    "print(\"Gaming (AXIOMATIZE_*):\")\n",
    "print(f\"  v1: {(v1['root_cause_category'].str.startswith('AXIOM')).sum()}\")\n",
    "print(f\"  v2: {(v2['root_cause_category'].str.startswith('AXIOM')).sum()}\")\n",
    "print(f\"  v3: {(v3['root_cause_category'].str.startswith('AXIOM')).sum()}\")\n",
    "print()\n",
    "print(\"Reasoning/Proof Issues:\")\n",
    "print(f\"  v1 (REASONING_FAILURE): {(v1['root_cause_category'] == 'REASONING_FAILURE').sum()}\")\n",
    "print(f\"  v2 (REASONING_GAP): {(v2['root_cause_category'] == 'REASONING_GAP').sum()}\")\n",
    "print(f\"  v3 (PROOF_INCOMPLETE): {(v3['root_cause_category'] == 'PROOF_INCOMPLETE').sum()}\")\n",
    "print()\n",
    "print(\"Formalization Issues:\")\n",
    "print(f\"  v1 (INCORRECT_FORMALIZATION): {(v1['root_cause_category'] == 'INCORRECT_FORMALIZATION').sum()}\")\n",
    "print(f\"  v2 (INCORRECT_FORMALIZATION): {(v2['root_cause_category'] == 'INCORRECT_FORMALIZATION').sum()}\")\n",
    "print(f\"  v3 (FORMALIZE_*): {v3['root_cause_category'].str.startswith('FORMALIZE').sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
