{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# V6 Classification Manual Verification\n",
    "\n",
    "Verify GPT-4o's classification of GPT-5 FOLIO baseline false negatives (27 cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load v6 classification results\n",
    "df = pd.read_csv('../results/error_analysis/gpt-5_folio_baseline_v6.csv')\n",
    "\n",
    "# Load FOLIO data\n",
    "with open('../data/folio/original/folio-validation.json') as f:\n",
    "    folio_data = json.load(f)\n",
    "\n",
    "# Load baseline results\n",
    "with open('../results/simplelean/gpt-5_folio_baseline/results.jsonl') as f:\n",
    "    baseline = {r['case_idx']: r for r in [json.loads(l) for l in f]}\n",
    "\n",
    "print(f'Loaded {len(df)} classifications')\n",
    "print(f'\\nCategory distribution:')\n",
    "print(df['root_cause_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_case(case_idx):\n",
    "    \"\"\"Display full details for a case.\"\"\"\n",
    "    row = df[df['case_idx'] == case_idx].iloc[0]\n",
    "    folio = folio_data[case_idx]\n",
    "    result = baseline[case_idx]\n",
    "    \n",
    "    print('=' * 70)\n",
    "    print(f'CASE {case_idx}')\n",
    "    print('=' * 70)\n",
    "    print(f'Ground Truth: {row[\"ground_truth\"]}')\n",
    "    print(f'Prediction: {row[\"prediction\"]}')\n",
    "    print(f'V6 Category: {row[\"root_cause_category\"]}')\n",
    "    print(f'V6 Explanation: {row[\"error_description\"]}')\n",
    "    print(f'Problematic Element: {row[\"problematic_axiom\"]}')\n",
    "    print()\n",
    "    print('--- PREMISES ---')\n",
    "    print(folio['premises'])\n",
    "    print()\n",
    "    print('--- CONCLUSION ---')\n",
    "    print(folio['conclusion'])\n",
    "    print()\n",
    "    print('--- LEAN CODE ---')\n",
    "    print(result.get('lean_code', 'N/A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## AXIOM_FABRICATION Cases (11)\n",
    "\n",
    "Model invented facts not in premises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fab_cases = df[df['root_cause_category'] == 'AXIOM_FABRICATION']['case_idx'].tolist()\n",
    "print(f'AXIOM_FABRICATION cases: {fab_cases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 70 - Known gaming case\n",
    "show_case(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "**Case 70 Verdict:** CORRECT - Model added `axiom A5_stock : Stock KO` but premises only say \"KO is a mature stock\", not that KO is a stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 89 - Questionable classification\n",
    "show_case(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": "**Case 89 Verdict:** WRONG CLASSIFICATION\n\nV6 says AXIOM_FABRICATION because K1 \"all books contain knowledge\" vs premise \"books contain tons of knowledge\".\n\nBUT the proof doesn't use K1! The proof chain is:\n1. Harry read Walden (H3)\n2. Walden is a book (H2), Harry is a person (H1)\n3. Person reads book → gains knowledge (R1) → Harry gains knowledge\n4. Gains knowledge → smarter (R2) → Harry is smarter\n5. Therefore ∃p. Person p ∧ Smarter p ∧ GainsKnowledge p\n\n**Should be: FAITHFUL** (model's reasoning is correct, GT may be wrong)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 36\n",
    "show_case(36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": "**Case 36 Verdict:** PARTIALLY CORRECT\n\nV6 says AXIOM_FABRICATION for R2 \"conductors leading orchestras\".\n\nActual issues:\n1. R2: Premise \"Orchestras are led by conductors\" → `Leads l o → Conductor l` is **wrong direction**\n   - Premise says: Conductor → LeadsOrchestra  \n   - Axiom says: LeadsOrchestra → Conductor\n2. R1: Premise \"Composers write music pieces\" → `Composer x → MusicPiece y → Wrote x y` \n   - This says every composer wrote every piece!\n   - Should be: `Wrote x y ∧ MusicPiece y → Composer x`\n\n**Better classification: FORMALIZATION_ERROR** (wrong implication direction)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 46\n",
    "show_case(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "**Case 46 Verdict:** ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 118\n",
    "show_case(118)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "**Case 118 Verdict:** ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show remaining AXIOM_FABRICATION cases\n",
    "for case_idx in [5, 29, 41, 77, 92, 141]:\n",
    "    show_case(case_idx)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## FAITHFUL Cases (8)\n",
    "\n",
    "V6 says formalization is correct - implies potential GT issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "faithful_cases = df[df['root_cause_category'] == 'FAITHFUL']['case_idx'].tolist()\n",
    "print(f'FAITHFUL cases: {faithful_cases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 202 - Known potential GT error\n",
    "show_case(202)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "**Case 202 Verdict:** CORRECT - Model's reasoning is valid: Ailton = Ailton Silva, loaned to Braga, Braga is football club => loaned to football club."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show remaining FAITHFUL cases\n",
    "for case_idx in [102, 122, 123, 127, 128, 130, 196]:\n",
    "    show_case(case_idx)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## DATASET_BUG Cases (2)\n",
    "\n",
    "Premises contain contradictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 75 and 159 - Known bad stories (368, 435)\n",
    "show_case(75)\n",
    "print('\\n')\n",
    "show_case(159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "**Cases 75, 159 Verdict:** CORRECT - These are from stories 368 and 435 which have contradictory premises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Other Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VACUOUS_TRUTH - Case 83\n",
    "show_case(83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "**Case 83 Verdict:** CORRECT - Model proved via vacuous truth (antecedent is impossible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL_MISMATCH cases\n",
    "goal_cases = df[df['root_cause_category'] == 'GOAL_MISMATCH']['case_idx'].tolist()\n",
    "print(f'GOAL_MISMATCH cases: {goal_cases}')\n",
    "for case_idx in goal_cases:\n",
    "    show_case(case_idx)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REASONING_ERROR - Case 119\n",
    "show_case(119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSING_PREMISE - Case 99\n",
    "show_case(99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": "## Summary\n\n| Category | Cases | V6 Correct | Issues Found |\n|----------|-------|------------|--------------|\n| AXIOM_FABRICATION | 11 | ~8/11 | Case 89: should be FAITHFUL (proof doesn't use fabricated axiom). Case 36: should be FORMALIZATION_ERROR. |\n| FAITHFUL | 8 | 8/8 | Case 202 confirmed correct |\n| DATASET_BUG | 2 | 2/2 | Known bad stories (368, 435) |\n| VACUOUS_TRUTH | 1 | 1/1 | Case 83 correct |\n| GOAL_MISMATCH | 3 | ? | Need verification |\n| REASONING_ERROR | 1 | ? | Need verification |\n| MISSING_PREMISE | 1 | ? | Need verification |\n\n**Key Findings:**\n1. V6 sometimes classifies as AXIOM_FABRICATION when the actual issue is FORMALIZATION_ERROR (wrong implication direction)\n2. V6 may miss that a fabricated axiom isn't actually used in the proof (Case 89)\n3. FAITHFUL cases appear to be genuine GT issues where model's reasoning is correct"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}