[
  {
    "story_id": 380,
    "premises": "People in this club who perform in school talent shows often attend and are very engaged with school events.\nPeople in this club either perform in school talent shows often or are inactive and disinterested community members.\nPeople in this club who chaperone high school dances are not students who attend the school.\nAll people in this club who are inactive and disinterested members of their community chaperone high school dances.\nAll young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \nBonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school.",
    "model_response": "Reasoning:\nLet C=\u201cin club\u201d, P=\u201cperforms often\u201d, A=\u201cattends and is very engaged with school events\u201d, I=\u201cinactive/disinterested\u201d, H=\u201cchaperones dances\u201d, S=\u201cstudent at the school\u201d, YW=\u201cyoung child or teenager who wishes to further academic opportunities.\u201d\n\nGiven for club members: \n- P \u2192 A.\n- I \u2192 H and H \u2192 \u00acS, so I \u2192 \u00acS.\n- P \u2228 I.\n- YW \u2192 S.\n\nBonnie: C and either (A \u2227 S) or (\u00acA \u2227 \u00acS), i.e., A \u2194 S.\n\nFrom P \u2228 I and the above:\n- If I, then \u00acS, hence \u00acA (by A \u2194 S), hence \u00acP (since P \u2192 A). So with I: I true, H true, S false, A false, P false.\n- If \u00acI, then P (from P \u2228 I), hence A, and thus S (by A \u2194 S). Also H must be false (since H \u2192 \u00acS). So with \u00acI: P true, A true, S true, H false, I false.\n\nQuestion 1:\nP is true in the \u00acI case and false in the I case. Undetermined.\nAnswer: Unknown.\n\nQuestion 2:\nStatement antecedent: (YW \u2227 H) \u2228 \u00acYW \u2261 H \u2228 \u00acYW.\n- If I: H true, antecedent true; consequent S \u2228 I true (I true).\n- If \u00acI: S true, so consequent true regardless of antecedent.\nThus the implication holds.\nAnswer: True.\n\nQuestion 3:\nAntecedent: H \u2228 (\u00acH \u2192 P) \u2261 H \u2228 (H \u2228 P) \u2261 H \u2228 P. For any club member, P \u2228 I and I \u2192 H imply H \u2228 P is always true. Consequent: YW \u2227 I is impossible for club members because I \u2192 H \u2192 \u00acS while YW \u2192 S. So antecedent always true and consequent always false, making the implication false.\nAnswer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1014,
        "conclusion": "Bonnie performs in school talent shows often.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1015,
        "conclusion": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1016,
        "conclusion": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 426,
    "premises": "All employees who schedule a meeting with their customers will go to the company building today. \nEveryone who has lunch in the company building schedules meetings with their customers. \nEmployees have lunch either in the company building or at home.\nIf an employee has lunch at home, they are working remotely from home.\nAll employees who are in other countries work remotely from home. \nNo managers work remotely from home. \nJames will appear in the company today if and only if he is a manager.",
    "model_response": "Reasoning:\n\nGiven:\n- Lunch in building -> schedules meeting -> goes to building today.\n- Lunch at home -> remote.\n- In other countries -> remote.\n- Manager -> not remote (so not lunch at home; hence lunch in building by the either-or).\n- Not remote -> not in other countries.\n- James goes to the company today iff he is a manager.\n\nCase analysis for James:\n- If James is a manager: not remote -> not lunch at home -> lunch in building.\n- If James is not a manager: he does not appear at the company; thus cannot have lunch in the building (that would force appearing), so he has lunch at home and is remote. Whether he is in other countries is undetermined.\n\nQuestion 1:\n- Lunch in building iff James is a manager. We don\u2019t know if he is a manager. Unknown.\n\nQuestion 2:\n- The negation of Q1; since Q1 is unknown, this is also unknown.\n\nQuestion 3:\n- The statement is (M or O) -> not(H or R), and its contrapositive (H or R) -> (not M and not O).\n- In the non-manager case, James is remote and has lunch at home. He may or may not be in other countries; both are consistent with the premises. If he is in other countries, the statement becomes false; if he is not, it becomes true. Therefore the truth is not determined. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1208,
        "conclusion": "James has lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1209,
        "conclusion": "James does not have lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1210,
        "conclusion": "If James is either a manager or in other countries,  then James does not either has lunch at home or work remotely from home. If James either has lunch at home or works remotely from home, then he is neither a manager nor does he work in other countries. [contrapositive is more natural]",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 198,
    "premises": "When the Monkeypox virus occurs in a being, it may get Monkeypox. \nMonkeypox virus can occur in certain animals.\nHumans are mammals.\nMammals are animals.\nSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness. \nPeople feel tired when they get the flu.",
    "model_response": "Reasoning:\n\nQuestion 1:\n- Premise: Monkeypox virus can occur in certain animals. This implies the existence of animals (since \"certain animals\" refers to some animals).\n- Therefore, it follows that there is at least one animal.\n- Conclusion: True.\n\nQuestion 2:\n- Premise: People feel tired when they get the flu. This is a conditional about what happens if someone gets the flu, not whether anyone does.\n- No information is given that no one gets the flu or that someone does.\n- Conclusion: Unknown.\n\nQuestion 3:\n- Premise: Symptoms of Monkeypox include fever, headache, muscle pains, and tiredness.\n- The list uses \"include,\" which is not necessarily exhaustive. Coughing is not mentioned, but it is not ruled out either.\n- Conclusion: Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 563,
        "conclusion": "There is an animal.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 564,
        "conclusion": "No one gets the flu.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 565,
        "conclusion": "Symptoms of Monkeypox include coughing.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 20,
    "premises": "A Japanese game company created the game the Legend of Zelda.\nAll games on the Top 10 list are made by Japanese game companies.\nIf a game sells more than one million copies, then it will be included in the Top 10 list.\nThe Legend of Zelda sold more than one million copies.",
    "model_response": "Reasoning:\n1) The Legend of Zelda sold more than one million copies. By the rule, any game that sells more than one million copies will be included in the Top 10 list. Therefore, The Legend of Zelda is on the Top 10 list.\n2) We know only that all games on the Top 10 list are made by Japanese game companies. We have no information about whether FIFA 22 is on the Top 10 list or its sales. Therefore, we cannot determine whether FIFA 22 is made by a Japanese company.\n3) From (1), The Legend of Zelda is on the Top 10 list. Therefore, the statement that it is not on the Top 10 list is false.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 57,
        "conclusion": "The Legend of Zelda is on the Top 10 list.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 58,
        "conclusion": "FIFA 22 is made by a Japanese video game company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 59,
        "conclusion": "The Legend of Zelda is not on the Top 10 list.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 282,
    "premises": "All squares are four-sided.\nAll four-sided things are shapes. ",
    "model_response": "Reasoning for Question 1:\n- From \"All squares are four-sided\" and \"All four-sided things are shapes,\" we can apply transitivity: if A \u2286 B and B \u2286 C, then A \u2286 C.\n- Therefore, all squares are shapes.\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 726,
        "conclusion": "All squares are shapes.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 471,
    "premises": "All rabbits that can be spotted near the campus are cute. \nSome turtles can be spotted near the campus. \nThe only animals that can be spotted near the campus are rabbits and squirrels.\nIf something is skittish, then it is not calm.\nAll the squirrels that can be spotted near the campus are skittish.\nRockie can be spotted near the campus, and it is calm.",
    "model_response": "Reasoning:\n- From \"Rockie can be spotted near the campus\" and \"The only animals that can be spotted near the campus are rabbits and squirrels,\" we get Rabbit(Rockie) or Squirrel(Rockie).\n- From \"If something is skittish, then it is not calm\" and Rockie is calm, we infer Rockie is not skittish.\n- From \"All the squirrels that can be spotted near the campus are skittish\" and Rockie is near but not skittish, we infer Rockie is not a squirrel.\n- Therefore, Rockie is a rabbit. From \"All rabbits that can be spotted near the campus are cute,\" Rockie is cute.\n- Nothing ties Rockie to being a turtle; \"Some turtles can be spotted near the campus\" does not specify Rockie. Given the premises, Rockie\u2019s turtle status is undetermined.\n\nQuestion 1: Rockie is a turtle.\n- Undetermined from the premises. Answer: Unknown.\n\nQuestion 2: Rockie is not a turtle.\n- Also undetermined. Answer: Unknown.\n\nQuestion 3: Rockie is a turtle or cute.\n- Rockie is cute, so the disjunction is true. Answer: True.\n\nQuestion 4: If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.\n- Rockie is not a squirrel, so the antecedent holds. Rockie is cute, so the consequent holds. Answer: True.\n\nQuestion 5: If Rockie is cute and calm, then Rockie is a skittish turtle.\n- Rockie is cute and calm (antecedent true), but Rockie is not skittish (consequent false), so the implication is false. Answer: False.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1361,
        "conclusion": "Rockie is a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1362,
        "conclusion": "Rockie is not a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1363,
        "conclusion": "Rockie is a turtle or cute.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1364,
        "conclusion": "If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1365,
        "conclusion": "If Rockie is cute and calm, then Rockie is a skittish turtle.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 184,
    "premises": "\"Stranger Things\" is a popular Netflix show.\nIf a Netflix show is popular, Karen will binge-watch it.\nIf and only if Karen binge-watches a Netflix show, she will download it.\nKaren does not download \"Black Mirror.\"\n\"Black Mirror\" is a Netflix show.\nIf Karen binge-watches a Netflix show, she will share it with Lisa.",
    "model_response": "Reasoning:\n\n- Premises:\n  - Stranger Things (ST) is a popular Netflix show.\n  - If a Netflix show is popular, Karen will binge-watch it. (Popular \u2192 Binge)\n  - Karen will download a Netflix show if and only if she binge-watches it. (Binge \u2194 Download)\n  - Karen does not download Black Mirror (BM).\n  - BM is a Netflix show.\n  - If Karen binge-watches a Netflix show, she will share it with Lisa. (Binge \u2192 Share)\n\nQuestion 1:\n- ST is popular and a Netflix show \u21d2 Karen binge-watches ST.\n- Binge(ST) \u21d2 Share(ST).\n- Conclusion: True.\n\nQuestion 2:\n- Not Download(BM) and Binge \u2194 Download \u21d2 Not Binge(BM).\n- For Netflix shows, Popular \u2192 Binge, so contrapositive gives Not Binge \u21d2 Not Popular.\n- BM is a Netflix show, so Not Popular(BM).\n- The statement \u201cBM is popular\u201d is False.\n\nQuestion 3:\n- We have Not Binge(BM).\n- Only rule connecting share is Binge \u2192 Share; there is no rule Share \u2192 Binge or Not Binge \u2192 Not Share.\n- Cannot conclude either Share(BM) or Not Share(BM).\n- Conclusion: Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 530,
        "conclusion": "Karen will share \"Stranger Things\" with Lisa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 531,
        "conclusion": "\"Black Mirror\" is popular.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 532,
        "conclusion": "Karen will share \"Black Mirror\" with Lisa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 232,
    "premises": "Beijing is the capital of the People's Republic of China. \nBeijing is the capital city of the world's most populous nation.\nBeijing is located in Northern China.\nBeijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nBeijing has hosted the Summer and Winter Olympics and the Summer and Winter Paralympics.\nMany of Beijing's 91 universities consistently rank among the best universities in the world.",
    "model_response": "Reasoning:\n1. The context states Beijing hosted the 2008 Summer Olympics and that it has hosted both the Summer and Winter Olympics. Therefore, it hosted the 2008 Summer Olympics and also a Winter Olympics.\n2. The context explicitly says Beijing is located in Northern China, which contradicts \u201csouthern China.\u201d\n3. The context provides no information about Beijing\u2019s size ranking among Chinese cities.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 657,
        "conclusion": "Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 658,
        "conclusion": "Beijing is located in southern China.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 659,
        "conclusion": "Beijing is the second largest Chinese city.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 452,
    "premises": "All aliens are extraterrestrials.\nIf someone is from Mars, then they are an alien.\nNo extraterrestrials are human.\nAll highly intelligent beings from Earth are humans.\nMarvin is a highly intelligent being.\nMarvin is either from Earth and from Mars, or he is from neither.\nIf Marvin is not from Earth, then Marvin is an extraterrestrial.",
    "model_response": "Reasoning:\n- From \u201ceither (from Earth and from Mars) or (from neither),\u201d consider the two cases:\n  - If Marvin is from Earth and from Mars: From Mars \u2192 alien \u2192 extraterrestrial \u2192 not human. Also, highly intelligent and from Earth \u2192 human. Contradiction (human and not human). So this case is impossible.\n  - Therefore Marvin is not from Earth and not from Mars.\n- From not from Earth \u2192 extraterrestrial, and extraterrestrial \u2192 not human. Hence Marvin is not human and not from Mars.\n- Alien status: From Mars \u2192 alien, but Marvin is not from Mars. Also, extraterrestrial does not imply alien. So alien status is undetermined.\n\nQuestion 1: Marvin is an alien.\n- We cannot conclude alien from the premises (he\u2019s extraterrestrial but that doesn\u2019t imply alien). Unknown.\n\nQuestion 2: Marvin is neither a human nor from Mars.\n- We derived not human and not from Mars. True.\n\nQuestion 3: If Marvin is not from Mars, then Marvin is a human.\n- We have not from Mars true and human false, so the conditional is false. False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1301,
        "conclusion": "Marvin is an alien.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1302,
        "conclusion": "Marvin is neither a human nor from Mars.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1303,
        "conclusion": "If Marvin is not from Mars, then Marvin is a human.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 340,
    "premises": "Everyone at the mixer is a Grand Slam champion or an Oscar-nominated actor.\nEvery Grand Slam champion at the mixer is a professional tennis player.\nAll Oscar-nominated actors at the mixer are celebrities.\nAll professional tennis players at the mixer are athletes.\nIf a person at the mixer is a celebrity, then they are well paid.\nIf a person at the mixer is an athlete, then they are famous.\nAll well-paid people at the mixer live in tax havens.\nDjokovic is at the mixer: if Djokovic is a famous athlete, then Djokovic is well-paid.",
    "model_response": "Reasoning:\n\n- From \u201cEveryone at the mixer is a Grand Slam champion or an Oscar-nominated actor\u201d and \u201cDjokovic is at the mixer,\u201d we know Djokovic is G or O.\n- G -> professional tennis player -> athlete (A); and A -> famous (F).\n- O -> celebrity (C) -> well-paid (W).\n- W -> lives in tax havens (L).\n- Special for Djokovic: if he is a famous athlete (A and F), then he is well-paid (W).\n\nQuestion 1:\n- We only know Djokovic is G or O; nothing forces G specifically. So it\u2019s not entailed that he is G.\n- Answer: Unknown.\n\nQuestion 2:\n- Case 1: If Djokovic is O, then C -> W -> L, so he lives in a tax haven.\n- Case 2: If Djokovic is G, then G -> A and A -> F; by the special rule (A and F) -> W, so W -> L. Thus he lives in a tax haven.\n- In all cases, Djokovic lives in a tax haven.\n- Answer: True.\n\nQuestion 3:\n- This is the negation of Question 2\u2019s conclusion, which is true.\n- Answer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 893,
        "conclusion": "Djokovic is a Grand Slam champion.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 894,
        "conclusion": "Djokovic lives in a tax haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 895,
        "conclusion": "Djokovic does not live in a tax haven.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 96,
    "premises": "Diamond Mine is a professional wrestling stable formed in WWE.\nRoderick Strong leads Diamond Mine.\nDiamond Mine includes the Creed Brothers and Ivy Nile.\nImperium has a feud with Diamond Mine.",
    "model_response": "Reasoning:\n1. Diamond Mine is a professional wrestling stable, and Roderick Strong leads Diamond Mine. Therefore, he leads a professional wrestling stable.\n2. The Creed Brothers are members of Diamond Mine, which Roderick Strong leads. Leading the stable entails leading its members, including the Creed Brothers.\n3. Imperium has a feud with Diamond Mine, a professional wrestling stable that includes Ivy Nile. Therefore, the claim that Imperium does not have such a feud is false.\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 289,
        "conclusion": "Roderick Strong leads a professional wrestling stable.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 290,
        "conclusion": "Roderick Strong leads the Creed Brothers.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 291,
        "conclusion": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 219,
    "premises": "Symphony No. 9 is a music piece.\nComposers write music pieces.\nBeethoven wrote Symphony No. 9.\nVienna Music Society premiered Symphony No. 9.\nVienna Music Society is an orchestra.\nBeethoven leads the Vienna Music Society.\nOrchestras are led by conductors.",
    "model_response": "Reasoning:\n1) We know: Composers write music pieces. Beethoven wrote a music piece (Symphony No. 9). From \u201cComposers write music pieces\u201d we cannot infer the converse that everyone who writes a music piece is a composer. So we cannot conclude Beethoven is a composer from the given statements alone.\n\n2) Vienna Music Society is an orchestra and premiered Symphony No. 9, which is a music piece. Therefore, at least one orchestra premiered a music piece.\n\n3) Beethoven leads the Vienna Music Society. Orchestras are led by conductors. Therefore, the leader of an orchestra is a conductor; hence Beethoven is a conductor. So \u201cBeethoven is not a conductor\u201d is false.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 621,
        "conclusion": "Beethoven is a composer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 622,
        "conclusion": "Some orchestras premiered music pieces.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 623,
        "conclusion": "Beethoven is not a conductor.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 350,
    "premises": "All of Zaha Hadid's design styles that Max adores have interesting geometries.\nNo brutalist buildings that Max adores have interesting geometries.\nEvery style that Max adores is either Zaha Hadid's design style or Kelly Wearstler's design style. \nAll of Kelly Wearstler's design styles that Max adores are evocative.\nAll of Kelly Wearstler's design styles that Max adores are dreamy.\nIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative.",
    "model_response": "Reasoning:\n\n- The statements distinguish between \u201cdesign styles that Max adores\u201d (Zaha or Kelly) and \u201cdesigns by Max.\u201d The only rule linking properties of designs by Max is: if a design by Max that he adores has interesting geometries, then it is a brutalist building and evocative. Combined with \u201cNo brutalist buildings that Max adores have interesting geometries,\u201d this implies there cannot be any design by Max that he adores which also has interesting geometries. However, none of the premises assert that any particular design by Max is adored, interesting, brutalist, evocative, or dreamy; nor do they link designs by Max to Kelly styles (which would yield evocative/dreamy).\n\nQuestion 1:\n- To conclude a design by Max is brutalist, we would need it to be adored and have interesting geometries (to trigger the conditional). But that combination is impossible by the \u201cno adored brutalist is interesting\u201d rule, and there is no other route to infer brutalism. No existence of any such design is given. Therefore Unknown.\n\nQuestion 2:\n- Evocative and dreamy are guaranteed only for Kelly Wearstler\u2019s design styles that Max adores. That concerns styles, not designs by Max. The only way to get evocative for a design by Max is via the impossible combination (adored and interesting), and there is no way given to get dreamy for a design by Max. Therefore Unknown.\n\nQuestion 3:\n- Same issue: no basis to assert that any design by Max is evocative or dreamy absent a link between designs by Max and adored Kelly styles or the impossible \u201cadored and interesting\u201d case. Therefore Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 927,
        "conclusion": "A design by Max is a brutalist building.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 928,
        "conclusion": "A design by Max is evocative and dreamy.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 929,
        "conclusion": "A design by Max is either evocative or dreamy.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 385,
    "premises": "If someone is ranked highly by the Women's Tennis Association, then they are one of the most active players in major tennis. \nEveryone who lost to Iga \u015awi\u0105tek at Roland Garros 2022 is ranked highly by the Women's Tennis Association.\nAll female tennis players at Roland Garros 2022 lost to Iga \u015awi\u0105tek.\nAll tennis players at Roland Garros 2022 are either female or male.\nAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal.\nIf Coco Gauff is ranked highly by the Women's Tennis Association or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nCoco Gauff is at Roland Garros 2022.",
    "model_response": "Reasoning:\n\n- From \u201cCoco Gauff is at Roland Garros 2022\u201d and \u201cAll tennis players at Roland Garros 2022 are either female or male,\u201d Coco is either female or male at RG22.\n- Assume Coco is male. Then by \u201cAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal,\u201d she lost to Nadal. Then by \u201cIf Coco Gauff is ranked highly by the WTA or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022,\u201d it follows she is not male\u2014a contradiction. Hence Coco is not male. Therefore, by the female-or-male dichotomy, Coco is female.\n- Being female at RG22 implies she lost to Iga \u015awi\u0105tek. Those who lost to Iga at RG22 are ranked highly by the WTA, and those ranked highly by the WTA are among the most active players in major tennis. Thus Coco is among the most active players in major tennis and also lost to Iga.\n\nQuestion 1:\n- As shown, Coco is ranked highly by the WTA, hence among the most active players in major tennis. True.\n\nQuestion 2:\n- We only know male players lost to Nadal; we have no rule that female players lost to Nadal. Coco is female, so we cannot conclude she lost to Nadal, nor can we conclude she did not. Unknown.\n\nQuestion 3:\n- We established Coco both lost to Iga and is among the most active players in major tennis. Therefore the statement \u201cCoco is not both \u2026\u201d is false. False.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1029,
        "conclusion": "Coco Gauff is among the most active Grand-Slam players.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1030,
        "conclusion": "Coco Gauff has lost to Rafael Nadal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1031,
        "conclusion": "Coco Gauff is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 256,
    "premises": "All cats are mammals.\nSome pets are not mammals.",
    "model_response": "- All cats are mammals, so any cat is a mammal.\n- Some pets are not mammals, so at least one pet is definitely not a cat.\n- However, this does not rule out that some other pets could be mammals and possibly cats.\n- Both scenarios are consistent with the premises: some pets being cats, or none being cats.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 700,
        "conclusion": "No pets are cats.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 159,
    "premises": "There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.",
    "model_response": "Reasoning for Question 1:\n- Rule: If a student wants a long vacation, then their favorite season is summer.\n- James wants to have a long vacation.\n- Therefore, James\u2019s favorite season is summer.\n- Conclusion: True.\n\nReasoning for Question 2:\n- Emma\u2019s favorite season is summer.\n- Mia\u2019s favorite season is not the same as Emma\u2019s, so Mia\u2019s favorite is not summer.\n- The remaining possibilities for Mia are spring, fall, or winter.\n- We cannot determine which one specifically.\n- Conclusion: Unknown.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 456,
        "conclusion": "James's favorite season is summer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 457,
        "conclusion": "Mia's favorite season is spring.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 343,
    "premises": "No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.",
    "model_response": "First, derive a global fact about 1984:\n- Streaming service \u2192 digital (S \u2192 D).\n- No digital are analog: D \u2192 \u00acA (equivalently, A \u2192 \u00acD).\n- Printed text \u2192 analog (P \u2192 A).\n- Hardcover book \u2192 printed text (H \u2192 P).\n- If 1984 is a streaming service, then it is a hardcover book: S(1984) \u2192 H(1984).\n\nAssume 1984 is a streaming service. Then:\n- S(1984) \u2192 D(1984).\n- S(1984) \u2192 H(1984) \u2192 P(1984) \u2192 A(1984).\nSo 1984 would be both digital and analog, contradicting D \u2192 \u00acA. Hence \u00acS(1984): 1984 is not a streaming service.\n\nQuestion 1: 1984 is printed text.\n- The only route provided to printed text is via S(1984) \u2192 H(1984) \u2192 P(1984), but we have \u00acS(1984). No other premises imply P(1984) or \u00acP(1984). So this is not determined.\nAnswer: Unknown.\n\nQuestion 2: 1984 is a streaming service.\n- From the derivation above, \u00acS(1984).\nAnswer: False.\n\nQuestion 3: 1984 is not a streaming service.\n- As derived, \u00acS(1984).\nAnswer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 904,
        "conclusion": "1984 is printed text.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 905,
        "conclusion": "1984 is a streaming service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 906,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 213,
    "premises": "All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.",
    "model_response": "Question 1 reasoning:\n- French and Spanish are Romance languages, so the Romance family has multiple members.\n- All languages within a language family are related to each other.\n- Basque is not related to any other language.\n- If Basque were a Romance language, it would be related to other Romance languages (e.g., French, Spanish), contradicting that Basque is not related to any other language.\n- Therefore, Basque is not a Romance language. The statement is false.\n\nQuestion 2 reasoning:\n- German is related to Spanish, and Spanish is a Romance language.\n- We know that being in the same family implies relatedness, but we are not told that relatedness implies being in the same family.\n- Therefore, from \u201cGerman is related to Spanish,\u201d we cannot conclude that German is a Romance language, nor can we rule it out.\n- The statement is uncertain based on the given information.\n\nQuestion 3 reasoning:\n- French is a Romance language.\n- All Romance languages are Indo-European.\n- Therefore, French is Indo-European. The statement is true.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 608,
        "conclusion": "Basque is a Romance language.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 609,
        "conclusion": "German is a Romance language.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 610,
        "conclusion": "French is an Indo-European language.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 79,
    "premises": "Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.",
    "model_response": "Question 1 reasoning:\n- Given: Robert Lewandowski is a striker.\n- Given: Strikers are soccer players.\n- Therefore, Robert Lewandowski is a soccer player.\nConclusion: True.\n\nQuestion 2 reasoning:\n- Given: Robert Lewandowski left Bayern Munchen.\n- Rule: If a player leaves a team, they no longer play for that team.\n- Therefore, he does not play for Bayern Munchen.\nConclusion: False.\n\nQuestion 3 reasoning:\n- There is no information connecting being a striker or leaving a team to being a \"star.\"\n- No explicit statement that he is a star.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 240,
        "conclusion": "Robert Lewandowski is a soccer player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 241,
        "conclusion": "Robert Lewandowski plays for Bayern Munchen.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 242,
        "conclusion": "Robert Lewandowski is a star.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 2,
    "premises": "Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.",
    "model_response": "Question 1 reasoning:\n- Butte is in Montana.\n- St Pierre is not in Montana.\n- A city can only be in one state (none of these cities are exceptions).\n- Therefore, they cannot be in the same state. Statement is false.\n\nQuestion 2 reasoning:\n- We know St Pierre is not in Montana.\n- We have no information about which state Bismarck is in.\n- It\u2019s possible they are in the same non-Montana state, or not. Insufficient information. Statement is unknown.\n\nQuestion 3 reasoning:\n- The text states Montana includes Missoula.\n- Therefore, Montana is home to Missoula. Statement is true.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 4,
        "conclusion": "Butte and St Pierre are in the same state.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 5,
        "conclusion": "St Pierre and Bismarck are in the same state.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 6,
        "conclusion": "Montana is home to the city of Missoula.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 192,
    "premises": "International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.",
    "model_response": "- We know: If someone is an international student in the US, then they have either an F1 or J1 visa. We are not told Mike is in the US.\n- We know: If an international student in the US has an F1 visa and wants to work in the US, they must apply for CPT or OPT. Mike \u201cneeds to apply for CPT if he wants to work in the US.\u201d This is consistent with having an F1 visa, but the rule is only one-way; needing CPT does not imply F1 based on the given information.\n- No information links J1 status to CPT or forbids it in the given context. Thus Mike\u2019s CPT requirement does not rule out J1.\n- Therefore, we cannot determine whether Mike has F1 or J1 from the provided statements.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 548,
        "conclusion": "Mike has an F1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 549,
        "conclusion": "Mike has a J1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 442,
    "premises": "All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.",
    "model_response": "Reasoning:\n- From All Brown Swiss cattle are cows and All cows are domesticated animals, we get: All Brown Swiss cattle are domesticated animals.\n- From Alligators are not domesticated animals and Ted is an alligator, we get: Ted is not domesticated.\n- By modus tollens on All Brown Swiss cattle are domesticated animals, Ted is not Brown Swiss cattle.\n\nQuestion 1:\n- Nothing in the premises links being an alligator or being non-domesticated to not being a pet. We cannot conclude whether Ted is a pet.\n- Answer: Unknown.\n\nQuestion 2:\n- The statement requires Ted to be both a pet and Brown Swiss cattle. We have deduced Ted is not Brown Swiss cattle, so the conjunction is false regardless of pet status.\n- Answer: False.\n\nQuestion 3:\n- Since Ted is not Brown Swiss cattle, the antecedent is false; the conditional is therefore true (vacuously) given the premises.\n- Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1271,
        "conclusion": "Ted is a pet.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1272,
        "conclusion": "Ted is a pet and Brown Swiss cattle",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1273,
        "conclusion": "If Ted is a Brown Swiss cattle, then Ted is not a pet.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 234,
    "premises": "Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.",
    "model_response": "Reasoning:\n1. The context states Yale University is a private Ivy League research university and that it moved to New Haven in 1716. Therefore, the statement that a private Ivy League research university moved to New Haven is supported.\n2. The context provides Yale\u2019s endowment value ($42.3 billion) but does not compare it to other institutions. Thus, we cannot conclude it is the largest based solely on the given information.\n3. The context lists Pierson College among Yale\u2019s residential colleges, so the statement is supported.\n\nANSWERS:\n1: True\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 663,
        "conclusion": "A private Ivy League research university moved to New Haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 664,
        "conclusion": "Yale University has the largest university endowment of any educational institution.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 665,
        "conclusion": "Pierson College is a residential college at Yale.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 120,
    "premises": "Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.",
    "model_response": "Reasoning:\n- Q1: Badults used the working title \"The Secret Dude Society,\" and Andrew Collins was the script editor for Badults. Therefore, he was the script editor for a series with that working title. True.\n- Q2: Badults starred members of Pappy's and was piloted on BBC Three. This contradicts the claim that no members of Pappy's have starred in a show piloting on BBC Two or BBC Three. False.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 360,
        "conclusion": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 361,
        "conclusion": "No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 322,
    "premises": "All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.",
    "model_response": "Reasoning:\n\n- Let G(x): x is a growth stock. B(x): x is bought to earn rapid appreciation. S(x): x is suitable for a retirement fund. Stock(x): x is a stock. Mature(x): x is a mature stock.\n- Premises:\n  1) \u2200x (G(x) -> B(x))\n  2) \u2200x (B(x) -> \u00acS(x))\n  3) \u2203x (Stock(x) \u2227 G(x))\n  4) \u2200x (Mature(x) -> S(x))\n  5) Mature(KO)\n\nFrom 4 and 5: S(KO). From 2, if B(KO) then \u00acS(KO); contradiction with S(KO), so \u00acB(KO). From 1, if G(KO) then B(KO); but \u00acB(KO), so \u00acG(KO).\n\nQuestion 1:\n\"KO is a mature stock\" implies KO is a stock. So True.\n\nQuestion 2:\nWe have KO is a stock, but \u00acG(KO). So \u201cKO is a stock and a growth stock\u201d is False.\n\nQuestion 3:\nAntecedent is G(KO) \u2228 B(KO), both disjuncts are false (\u00acG(KO) and \u00acB(KO)), so the conditional is vacuously True regardless of the consequent.\n\nANSWERS:\n1: True\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 819,
        "conclusion": "KO is a stock.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 820,
        "conclusion": "KO is a stock and a growth stock.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 821,
        "conclusion": "If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 83,
    "premises": "All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.",
    "model_response": "Reasoning:\nQuestion 1:\n- Joe's plate is from Istanbul.\n- All plates from Istanbul begin with 34.\n- Therefore, Joe's plate begins with 34. The statement is True.\n\nQuestion 2:\n- Tom's plate begins with 35.\n- If a plate begins with 35, it does not begin with 34.\n- Plates that do not begin with 34 are not from Istanbul.\n- Therefore, Tom's plate is not from Istanbul. The statement is False.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 253,
        "conclusion": "Joe's license plate begins with the number 34.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 254,
        "conclusion": "Tom's license plate is from Istanbul.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 368,
    "premises": "If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.",
    "model_response": "Reasoning:\n\n- From \u201cHannah is at Mary\u2019s school\u201d and \u201cHannah works in student jobs on campus\u201d with the rule \u201cIf people at Mary\u2019s school work in student jobs on campus, then they need to earn money,\u201d we derive that Hannah needs to earn money.\n- From \u201cIf Hannah needs to earn money, then she is neither picky nor needs to earn money,\u201d together with the derived need, we get both that Hannah is not picky and that she does not need to earn money. Thus we have both Need and \u00acNeed for Hannah, creating a direct conflict about whether she needs money.\n\nQuestion 1:\n- Since we have both Need and \u00acNeed, the status of \u201cHannah needs to earn money\u201d is uncertain.\n\nQuestion 2:\n- AtSchool(Hannah) is true and \u00acPicky(Hannah) is derivable as above.\n- \u201cSpends a lot of time eating and catching up with friends in the campus dining halls\u201d follows only if she enjoys the dining hall meals. We only know she either orders takeout or enjoys dining hall meals; we can\u2019t conclude she enjoys them. So we cannot conclude the dining-hall-time part, and the whole conjunction is uncertain.\n\nQuestion 3:\n- AtSchool(Hannah) is true.\n- We derived \u00acPicky(Hannah), so the disjunction \u201cnot picky or, if picky, then spends a lot of time in dining halls\u201d is satisfied by the first disjunct. Therefore the whole statement is true.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 979,
        "conclusion": "Hannah needs to earn money to help pay for her college tuition.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 980,
        "conclusion": "Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 981,
        "conclusion": "Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 319,
    "premises": "No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.",
    "model_response": "Reasoning:\n- From \u201cNo baked sweets are spicy,\u201d we get Spicy -> not BakedSweet (and BakedSweet -> not Spicy).\n- All cupcakes are baked sweets; all Baked by Melissa products are cupcakes; thus MelissaProduct -> Cupcake -> BakedSweet -> not Spicy.\n- All mala hotpots are spicy; hence MalaHotpot -> Spicy -> not BakedSweet.\n- Dried Thai chilies are (Spicy or MalaHotpot or not BakedSweet). Each disjunct implies not BakedSweet, so Dried Thai chilies are not BakedSweet. Therefore they are not Cupcakes and not MelissaProducts.\n\nQuestion 1: Being a MelissaProduct would imply being a baked sweet, but Dried Thai chilies are not baked sweets. So False.\n\nQuestion 2: As above, they are not MelissaProducts. True.\n\nQuestion 3: The disjunction allows they might be spicy without being mala hotpots, or just not baked sweets. Cannot conclude they are mala hotpots. Unknown.\n\nQuestion 4: We established they are not baked sweets and not MelissaProducts. True.\n\nQuestion 5: They cannot be cupcakes (since not baked sweets), nor MelissaProducts. False.\n\nANSWERS:\n1: False\n2: True\n3: Unknown\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 805,
        "conclusion": "Dried Thai chilies are products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 806,
        "conclusion": "Dried Thai chilies are not products of Baked by Melissa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 807,
        "conclusion": "Dried Thai chilies are a mala hotpot.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 808,
        "conclusion": "Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 809,
        "conclusion": "Dried Thai chilies are cupcakes and products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 306,
    "premises": "If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.",
    "model_response": "Reasoning:\n\n- From \u201cAll popular restaurants have ratings >4\u201d and \u201cHPS has rating >4 or is popular,\u201d it follows that HPS (Hamden Plaza Subway) has rating >4.\n- From \u201cAll rating >4 are listed in Yelp\u2019s recommendations\u201d and \u201cListed implies not many negative reviews,\u201d it follows that HPS does not receive many negative reviews.\n- No premise determines whether HPS provides take-out service.\n\nQuestion 1:\n- Antecedent requires HPS receives many negative reviews, but we derived that HPS does not. The antecedent cannot hold, so the conditional is vacuously true.\nAnswer: True.\n\nQuestion 2:\n- Disjunction \u201cprovides take-out or does not receive many negative reviews\u201d is true because we have \u201cdoes not receive many negative reviews.\u201d\nAnswer: True.\n\nQuestion 3:\n- We have no information fixing whether HPS provides take-out; the existential statement about some no-take-out restaurants does not apply to HPS (and does not determine T(HPS)).\nAnswer: Unknown.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 754,
        "conclusion": "If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 755,
        "conclusion": "The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 756,
        "conclusion": "The Hamden Plaza store does not provide take-out service.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 245,
    "premises": "In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.",
    "model_response": "Reasoning:\n- The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\n- It is named after Sir Digby; therefore Sir Digby is a good guy and is in the movie.\n- In superhero movies, the good guys always win; thus Sir Digby wins.\n- Sir Digby fights his nemesis; therefore he wins that fight.\n- If somebody wins a fight, the person they are fighting does not win; hence Sir Digby\u2019s nemesis does not win.\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 688,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 58,
    "premises": "Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.",
    "model_response": "Reasoning:\n1) All books contain knowledge. Walden is a book. Therefore, Walden contains knowledge.\n2) Harry read a book. Readers gain knowledge. Gaining knowledge makes a person smarter. Therefore, Harry is smarter than before.\n3) We only know that gaining knowledge implies becoming smarter, not that being smarter implies having gained knowledge. The converse is not established.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 171,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 172,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 173,
        "conclusion": "A smarter person has gained knowledge.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 191,
    "premises": "A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.",
    "model_response": "Reasoning:\n- Given: If an NLP task outputs a text sequence, then it is a language generation task. Machine translation is an NLP task whose output is a text sequence. Therefore, machine translation is a language generation task.\n- Given: An NLP task can be categorized as either a language generation task or a language understanding task (interpreted as mutually exclusive categories). Since machine translation is a language generation task, it is not a language understanding task.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 546,
        "conclusion": "Machine translation is a language generation task.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 547,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 166,
    "premises": "Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. ",
    "model_response": "Reasoning:\n\nQuestion 1:\n- Tom will rent if both: (a) he is allowed to move in with Fluffy, and (b) the security deposit is no more than $1500.\n- The Olive Garden is a managed building with monthly rent $2000.\n- The security deposit at a managed building is either equal to the monthly rent or more, so at The Olive Garden it is at least $2000, which is more than $1500. Thus condition (b) is not satisfied.\n- We do not know whether The Olive Garden allows pets, so we cannot confirm (a).\n- The given condition is sufficient, not necessary; failing it does not imply Tom will not rent. Therefore we cannot conclude whether he will rent.\nConclusion: Unknown.\n\nQuestion 2:\n- Cats are pets; Fluffy is Tom\u2019s cat, so Fluffy is a pet.\n- If a managed building allows pets, then people are allowed to move in with a pet.\n- We only know that some managed buildings allow pets; we do not know whether The Olive Garden allows pets.\nConclusion: Unknown.\n\nQuestion 3:\n- The security deposit at a managed building is either equal to the monthly rent or more.\n- The Olive Garden\u2019s monthly rent is $2000.\n- Therefore, the security deposit at The Olive Garden is either $2000 or more.\nConclusion: True.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 476,
        "conclusion": "Tom will rent an apartment in The Olive Garden.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 477,
        "conclusion": "Tom is allowed to move into an apartment in The Olive Garden with Fluffy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 478,
        "conclusion": "The security deposit at the Olive Garden is either $2000 or more.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 352,
    "premises": "All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. ",
    "model_response": "Reasoning:\n\n- From the premises: Private company \u2192 Company \u2192 Business organization \u2192 Legal entity. And every legal entity is created under law and has legal obligations. So for any x: PC(x) \u2192 LE(x), LE(x) \u2192 CL(x) and LE(x) \u2192 LO(x). Hence PC(x) implies both CL(x) and LO(x).\n- Given: For H (the Harvard Weekly Book Club), CL(H) \u2192 \u00acPC(H). Combining with PC(H) \u2192 CL(H) yields PC(H) \u2192 \u00acPC(H), so \u00acPC(H).\n\nQuestion 1:\n- To conclude H has legal obligations (LO(H)), we would need H to be a legal entity. Nothing establishes that H is a legal entity or created under law. So LO(H) cannot be concluded.\n- Answer: Unknown.\n\nQuestion 2:\n- The statement asserts LO(H) and PC(H). We have shown \u00acPC(H), so the conjunction is false regardless of LO(H).\n- Answer: False.\n\nQuestion 3:\n- If PC(H), then H is a legal entity, hence both LO(H) and CL(H) hold. Therefore (LO(H) \u2228 CL(H)) holds under the assumption.\n- Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 933,
        "conclusion": "The Harvard Weekly Book club has legal obligations.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 934,
        "conclusion": "The Harvard Weekly Book club has legal obligations and is a private company.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 935,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 472,
    "premises": "Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.",
    "model_response": "Reasoning:\n\n- Facts we have:\n  - Animals are either invertebrates or vertebrates. (If Animal then Invertebrate or Vertebrate)\n  - Animals with backbones reproduce by male-and-female mating.\n  - Vertebrate animals have a backbone.\n  - Bees do not reproduce by male-and-female mating.\n  - All queen bees are bees.\n  - Harry is a bee.\n- From \u201cbees do not reproduce by male-and-female mating\u201d and \u201canimals with backbones reproduce by male-and-female mating,\u201d we can infer that Harry is not an animal with a backbone. However, we are not told that bees are animals, so we cannot conclude Harry is an animal, nor whether he is a vertebrate or invertebrate.\n\nQuestion 1:\n- We know all queen bees are bees, and Harry is a bee. This does not imply he is a queen bee. No information says all bees are queen bees or that Harry specifically is a queen bee.\n- Conclusion: Unknown.\n\nQuestion 2:\n- \u201cHarry is an invertebrate or a queen bee.\u201d We cannot conclude he is an invertebrate (we don\u2019t know he\u2019s an animal), and we cannot conclude he is a queen bee.\n- Conclusion: Unknown.\n\nQuestion 3:\n- Harry is not an animal with a backbone (as argued above).\n- The antecedent simplifies to: either (vertebrate and animal-with-backbone) or (not vertebrate and not animal-with-backbone). Since animal-with-backbone is false, the antecedent reduces to \u201cnot vertebrate.\u201d\n- There is no information linking \u201cnot vertebrate\u201d to \u201cneither invertebrate nor queen bee.\u201d In fact, it is consistent with the premises that Harry could be an animal without a backbone (hence an invertebrate), making the consequent false while the antecedent holds. It is also consistent that we don\u2019t know whether he\u2019s a queen bee.\n- Therefore, the truth of the conditional cannot be determined from the given facts.\n- Conclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1366,
        "conclusion": "Harry is a queen bee.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1367,
        "conclusion": "Harry is an invertebrate or a queen bee.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1368,
        "conclusion": "If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 379,
    "premises": "People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers",
    "model_response": "Reasoning:\n- From the rules: Born-in-multiple \u2192 Spend-time-with-siblings \u2192 Live-at-home \u2192 Not-live-with-strangers. So Born-in-multiple implies Not-live-with-strangers.\n- Luke\u2019s given disjunction: (Born-in-multiple AND Live-with-strangers) OR (Not-born-in-multiple AND Not-live-with-strangers). The first disjunct contradicts the derived implication, so it cannot be true. Therefore, the second disjunct must be true: Luke is not born in a multiple birth and does not live with strangers.\n- Q1: From Not-born-in-multiple we cannot infer whether he spends a lot of time with siblings. No rule gives Spend from the negation, so this is unknown.\n- Q2: If someone complains often about annoying siblings, then they have siblings born together, hence were born in a multiple birth. Given Luke is not born in a multiple birth, by modus tollens, Luke does not complain often about annoying siblings. So the statement is false.\n- Q3: We have both Not-born-in-multiple and Not-complain (from above), so the conjunction is true.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1011,
        "conclusion": "Luke spends a lot of time hanging out and playing with his siblings.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1012,
        "conclusion": "Luke complains often about annoying siblings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1013,
        "conclusion": "Luke is neither born in a multiple birth nor complains often about annoying siblings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 197,
    "premises": "It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.",
    "model_response": "Reasoning:\n\nQuestion 1:\n- Policy: ETS provides aid to GRE applicants who prove economic hardship.\n- Criteria: Those in single-parent families or with few resources can prove economic hardship.\n- Tom: Is a GRE applicant; lives in a single-parent family; has few resources.\n- However, \u201ccan prove\u201d does not entail that Tom actually did prove hardship or that he applied for aid. Therefore, we cannot conclude that ETS provides financial aid to Tom.\nConclusion: Unknown.\n\nQuestion 2:\n- Given: It costs $205 to take the GRE, which is cheaper than $300.\n- Therefore, the cost is below $300.\nConclusion: True.\n\nQuestion 3:\n- Claim: No one taking the GRE has financial aid provided to them by something.\n- Policy: ETS provides aid to any GRE applicant who proves economic hardship.\n- We do not know if any specific GRE applicant actually proved hardship (even Tom only \u201ccan\u201d prove).\n- Thus we cannot confirm the universal negative nor refute it with a concrete counterexample.\nConclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 560,
        "conclusion": "ETS provides financial aid to Tom.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 561,
        "conclusion": "It costs below US $300 to take the GRE test.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 562,
        "conclusion": "No one taking the GRE test has financial aid provided to them by something.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 361,
    "premises": "If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly",
    "model_response": "Reasoning:\n\n- From S -> not T and C -> T, S and C cannot both hold. So not (S and C).\n- Given (S and C) or (not S and not C), and not (S and C), we conclude not S and not C for Peter.\n- From not S and (G -> S), infer not G (Modus Tollens).\n- From F -> V and V -> C, we have F -> C. With not C, infer not F (Modus Tollens).\n\nQuestion 1:\n- We have not C and not S. C -> T gives no info about T from not C, and S -> not T gives no info from not S. So whether Peter is notably tidy is undetermined.\n\nQuestion 2:\n- We have not G and not F. Therefore G or F is false.\n\nQuestion 3:\n- We have not G and not F, so (G and F) is false and (not G and not F) is true. The disjunction is true.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 958,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 959,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 960,
        "conclusion": "Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 262,
    "premises": "All fir trees are evergreens.\nSome objects of worship are fir trees.",
    "model_response": "Step-by-step reasoning:\n- All fir trees are evergreens means every fir is an evergreen.\n- Some objects of worship are fir trees means there exists at least one thing that is both a fir tree and an object of worship; thus some evergreens are objects of worship.\n- The statement to evaluate claims there exist evergreens that are not objects of worship. The premises do not specify anything about non-fir evergreens or about whether all evergreens are objects of worship.\n- It is consistent with the premises that all evergreens are objects of worship (making the statement false) and also consistent that some evergreens are not objects of worship (making it true). Therefore, the truth of the statement cannot be determined.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 706,
        "conclusion": "Some evergreens are not objects of worship.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 124,
    "premises": "The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.",
    "model_response": "Reasoning:\n- The Picuris Mountains are stated to be in New Mexico or Texas. The Harding Pegmatite Mine is located in the Picuris Mountains and was donated. It is also stated that there are no mountain ranges in Texas that have mines that have been donated. Therefore, the Picuris Mountains cannot be in Texas; they must be in New Mexico.\n- Juan de O\u00f1ate visited the Picuris Mountains.\n\nQuestion 1:\n- Since Picuris Mountains are in New Mexico and Juan de O\u00f1ate visited them, he visited a mountain range in New Mexico.\n- Answer: True\n\nQuestion 2:\n- Since Picuris Mountains are not in Texas, he did not visit a mountain range in Texas.\n- Answer: False\n\nQuestion 3:\n- The Harding Pegmatite Mine is located in the Picuris Mountains, which are in New Mexico; thus it is located in a mountain range in New Mexico. The statement says it is not, which is incorrect.\n- Answer: False\n\nANSWERS:\n1: True\n2: False\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 370,
        "conclusion": "Juan de Onate visited a mountain range in New Mexico.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 371,
        "conclusion": "Juan de Onate visited a mountain range in Texas.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 372,
        "conclusion": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 183,
    "premises": "If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.",
    "model_response": "Question 1 reasoning:\n- Michael is taller than everyone else in his class.\n- Peter is taller than Michael.\n- By transitivity, Peter is taller than everyone in Michael\u2019s class.\n- Therefore, there is no man in Michael\u2019s class taller than Peter, so the statement is false.\n\nQuestion 2 reasoning:\n- If a person does not jump when shooting, Michael can block their shooting.\n- Michael cannot block Windy\u2019s shooting.\n- Therefore, Windy must jump when shooting.\n- Anyone who can jump when shooting is a great shooter. Since Windy jumps when shooting, she can jump when shooting, so she is a great shooter.\n\nQuestion 3 reasoning:\n- We know Windy jumps when shooting.\n- The only general blocking rule given (taller man can block another man) requires both to be men and a known taller-than relation.\n- We don\u2019t know Windy\u2019s gender or any height relation between Peter and Windy, and we have no rule that Peter can block jump shooters.\n- Therefore, we cannot conclude whether Peter can block Windy\u2019s shooting.\n\nANSWERS:\n1: False\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 527,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 528,
        "conclusion": "Windy is a great shooter.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 529,
        "conclusion": "Peter can block Windy's shooting.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 151,
    "premises": "Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.",
    "model_response": "Reasoning:\n1) We are told Barutin Cove is named after the Bulgarian settlement of Barutin. There is no indication it is named after all islands in Antarctica; that claim conflicts with the given specific eponym.\n2) We know Barutin Cove is named after a Bulgarian place and is on Snow Island, which is in the South Shetland Islands. We are told Antarctica is located on the South Shetland Islands (not that the South Shetland Islands are in Antarctica). Using the given transitivity, we can place Barutin Cove in the South Shetland Islands, but we cannot place it in Antarctica. So we cannot conclude there exists a cove in Antarctica named after a Bulgarian place.\n3) As above, we cannot determine whether Barutin Cove is in Antarctica or not; we only know it is in the South Shetland Islands. Thus we cannot assert it is not in Antarctica.\n\nANSWERS:\n1: False\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 439,
        "conclusion": "Barutin Cove is named after all islands in Antarctica.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 440,
        "conclusion": "There is at least one cove in Antarctica named after a place in Bulgaria.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 441,
        "conclusion": "Barutin Cove is not located in Antarctica.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 295,
    "premises": "Some affection is love.\nSome love is positive.",
    "model_response": "Reasoning:\n- Let A = the set of things that are affection, L = the set of things that are love, P = the set of things that are positive.\n- Premises:\n  - Some A are L: \u2203x (A(x) \u2227 L(x)).\n  - Some L are P: \u2203x (L(x) \u2227 P(x)).\n- These two existential statements could refer to different individuals within L. It\u2019s possible that one individual is in A \u2229 L and a different individual is in L \u2229 P, with no individual in A \u2229 P.\n- Therefore, the conclusion \u201cSome affection is positive\u201d (\u2203x (A(x) \u2227 P(x))) is not guaranteed.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 739,
        "conclusion": "Some affection is positive.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 315,
    "premises": "If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. ",
    "model_response": "Reasoning:\n- From the premises: TM3 \u21d2 transports multiple passengers \u21d2 not a one-seater. Solo EV \u21d2 single-seat electric car \u21d2 one-seater \u21d2 not transporting multiple passengers. Therefore, TM3 and Solo EV are mutually exclusive.\n- The statement \u201cIf John\u2019s car is not a TM3, then John\u2019s car is not a TM3 or a single-seat electric car\u201d is a tautology of the form A \u2192 (A \u2228 B), so it gives no information about John\u2019s car.\n\nQuestion 1:\n- No premise asserts John\u2019s car is a TM3. The tautology provides no evidence. Conclusion: Unknown.\n\nQuestion 2:\n- No premise asserts John\u2019s car is a Solo EV. Conclusion: Unknown.\n\nQuestion 3:\n- We could conclude not Solo EV if we knew John\u2019s car is a TM3, but we don\u2019t. The tautology gives no help. Conclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 786,
        "conclusion": "John's car is a Tesla Model 3.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 787,
        "conclusion": "John's car is a Solo EV.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 788,
        "conclusion": "John's car is not a Solo EV.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 467,
    "premises": "All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. ",
    "model_response": "Reasoning:\n\nQuestion 1:\n- From \"Rock is Peter's pet\" and \"Peter's pets are all either monkeys or birds,\" Rock is a monkey or a bird.\n- Nothing else forces Rock specifically to be a monkey or rules it out. Therefore, it is uncertain whether Rock is a monkey.\n\nQuestion 2:\n- We have the disjunction: Rock can fly, or Rock is a bird, or Rock cannot breathe.\n- Case 1: If Rock can fly, then since Rock is Peter's pet, Rock has wings.\n- Case 2: If Rock is a bird, then as Peter's bird Rock can fly; being Peter's pet that can fly, Rock has wings.\n- Case 3: If Rock cannot breathe, then Rock cannot be a monkey (since monkey \u21d2 mammal; Peter\u2019s mammal-pets are animals; Peter\u2019s animal-pets can breathe). Thus Rock must be a bird; then as Peter's bird Rock can fly; hence Rock has wings.\n- In all cases, Rock has wings. So the statement is true.\n\nQuestion 3:\n- This is the negation of Question 2\u2019s conclusion. Since Rock has wings is true, Rock does not have wings is false.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1348,
        "conclusion": "Rock is a monkey.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1349,
        "conclusion": "Rock has wings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1350,
        "conclusion": "Rock does not have wings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 330,
    "premises": "All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. ",
    "model_response": "Reasoning:\n\nGiven rules:\n- W \u2192 I \u2192 P \u2192 E (well-attended \u21d2 invites others \u21d2 makes plans \u21d2 engaged).\n- From E \u2192 \u00ac(F \u2227 P), and P \u2192 E, we get P \u2192 \u00acF, hence F \u2192 \u00acP, and since I \u2192 P, also I \u2192 \u00acF and F \u2192 \u00acI.\n- The only statement about larger families is L(John) \u2192 (W(John) \u2228 F(John)); it does not assert L(John).\n\nQuestion 1: Whether John has a larger family (L). No premise determines L(John). Unknown.\n\nQuestion 2: Whether John does not have a larger family (\u00acL). No premise determines \u00acL(John). Unknown.\n\nQuestion 3: Whether John is engaged (E). E would follow if W or I or P were known, but none are established. Also no premise forces \u00acE. Unknown.\n\nQuestion 4: Whether John neither has a larger family nor invites others (\u00acL \u2227 \u00acI). Neither \u00acL nor \u00acI is entailed by the premises. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown\n4: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 846,
        "conclusion": "John has a larger family.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 847,
        "conclusion": "John does not have a larger family.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 848,
        "conclusion": "John is engaged.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 849,
        "conclusion": "John neither has a larger family nor does he invite others to his wedding.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.25
  },
  {
    "story_id": 26,
    "premises": "Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.",
    "model_response": "Reasoning:\n1. We are told: Platypuses have no teeth, and Platypuses are mammals. Therefore, it directly follows that Platypuses are mammals with no teeth. True.\n\n2. We are told: Platypuses are mammals. Nothing in the given information states that mammals are not reptiles or that platypuses are reptiles. Based solely on the provided information, we cannot conclude they are reptiles or not. Unknown.\n\n3. We are told: Humans have teeth, and some mammals have teeth. From this we cannot infer that humans are mammals (having teeth does not imply being a mammal). The text does not state that humans are mammals. Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 74,
        "conclusion": "Platypuses are mammals with no teeth.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 75,
        "conclusion": "Platypuses are reptiles.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 76,
        "conclusion": "Humans are mammals.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 203,
    "premises": "Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.",
    "model_response": "Reasoning:\n1. Given: Vacuums suck. Given: Space is a vacuum. Therefore, by modus ponens, Space sucks. So the statement \"Space sucks\" is true.\n2. Given: Vampires suck. From \"Space sucks\" we cannot infer \"Space is a vampire,\" because sucking is not unique to vampires (plungers and vacuums also suck). No information says Space is a vampire. So this is unknown.\n3. The statement claims all household appliances suck. Given: A duster is a household appliance that doesn't suck. This is a counterexample, so the universal claim is false.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 578,
        "conclusion": "Space sucks.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 579,
        "conclusion": "Space is a vampire.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 580,
        "conclusion": "If something is a household appliance, it sucks.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 131,
    "premises": "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.",
    "model_response": "Reasoning:\n- Categories of ML: supervised, unsupervised, reinforcement learning.\n- Unsupervised algorithms do not require labeled data.\n- The SOTA text summarization model is trained with ML algorithms, and reinforcement learning is not used.\n- The ML algorithm for training text summarization models requires labeled data.\n- Therefore, the training algorithm cannot be unsupervised (since it requires labels) and, with RL excluded, it must be supervised.\n\nQuestion 1:\n- Since the algorithm used requires labeled data and RL is not used, supervised learning is used. True.\n\nQuestion 2:\n- Unsupervised learning does not require labeled data, but the training algorithm requires labeled data, so unsupervised is not used. False.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 388,
        "conclusion": "Supervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 389,
        "conclusion": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 460,
    "premises": "If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. ",
    "model_response": "Reasoning:\n- From \u201cAll family-friendly animated films are rated General Audience\u201d and \u201cIf a film is rated General Audience, then it is appropriate for people of all ages,\u201d we have F(x) -> G(x) -> A(x), hence F(x) -> A(x).\n- Given \u201cHachi is either a family-friendly animated film or is appropriate for people of all ages\u201d (F(h) \u2228 A(h)) and F(h) -> A(h), we conclude A(h).\n- From \u201cIf a film is appropriate for people of all ages, then children can watch it without guidance,\u201d A(h) -> C(h), so C(h).\n- From \u201cIf a film contains excessive erotic and violent content, children cannot watch it without guidance,\u201d E(h) -> \u00acC(h). By contrapositive with C(h), we get \u00acE(h).\n\nQuestion 1:\n- We know A(h), but G(h) -> A(h) does not allow A(h) -> G(h). We do not know F(h) either. So G(h) is not determined. Answer: Unknown.\n\nQuestion 2:\n- The statement is E(h) \u2228 Z(h). Since \u00acE(h), this reduces to Z(h), which is not determined by the premises. Answer: Unknown.\n\nQuestion 3:\n- The statement (E(h) \u2227 Z(h)) \u2228 (\u00acE(h) \u2227 \u00acZ(h)) is equivalent to E(h) \u2194 Z(h). With \u00acE(h), it reduces to \u00acZ(h), which is not determined. Answer: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1327,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1328,
        "conclusion": "\"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1329,
        "conclusion": "\"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 46,
    "premises": "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.",
    "model_response": "Reasoning:\n\nQuestion 1:\n- Breeding back is defined as a form of artificial selection.\n- Heck cattle were bred back in the 1920s.\n- Therefore, Heck cattle are the result of artificial selection; thus at least some Heck cattle are artificially selected.\nConclusion: True.\n\nQuestion 2:\n- We know aurochs are animals and Heck cattle were bred back to resemble them.\n- We also know some animals bred back resemble extinct animals, but this does not specify that aurochs are extinct.\n- No explicit statement says aurochs are extinct, and the \u201csome\u201d statement doesn\u2019t entail it.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 133,
        "conclusion": "Some Heck cattle are artificially selected.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 134,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 483,
    "premises": "Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.",
    "model_response": "Reasoning:\n- From \"A person either has US or Taiwanese citizenship\" and \"Vladimir neither holds Taiwanese citizenship,\" Vladimir must have US citizenship. By \"US citizenship -> can register\" and \"can register -> can participate,\" Vladimir can participate in the 2024 election.\n- From \"Ekaterina can register OR is a Russian federation official\":\n  - If she can register, then she can participate.\n  - If she is an official, then she does not have Taiwanese citizenship; by the citizenship disjunction she then has US citizenship, hence can register and can participate.\n  Therefore, Ekaterina can register and can participate.\n\nQuestion 1:\n- Knowing only that not having Taiwanese citizenship does not imply being a Russian official, we cannot conclude Vladimir is an official. Unknown.\n\nQuestion 2:\n- We also cannot conclude Vladimir is not an official. Unknown.\n\nQuestion 3:\n- Ekaterina can participate (as shown), so \u201cparticipate or manager at Gazprom\u201d is true. True.\n\nQuestion 4:\n- Ekaterina can participate, so \u201cEkaterina can participate or Vladimir is a manager at Gazprom\u201d is true regardless of Vladimir\u2019s status (and we also know Vladimir is not a manager). True.\n\nQuestion 5:\n- Ekaterina can register, and Vladimir can participate. So the statement \u201cIt is not true that [Ekaterina can register and Vladimir can participate]\u201d is false. False.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1410,
        "conclusion": "Vladimir is a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1411,
        "conclusion": "Vladimir is not a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1412,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1413,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1414,
        "conclusion": "It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 80,
    "premises": "New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.",
    "model_response": "Question 1 reasoning:\n- All of New Vessel Press\u2019s published books are in English.\n- Neapolitan Chronicles is published by New Vessel Press.\n- Therefore, Neapolitan Chronicles is in English.\nAnswer: True.\n\nQuestion 2 reasoning:\n- The context mentions only Neapolitan Chronicles and Palace of Flies as New Vessel Press titles.\n- There is no information about Harry Potter being published by New Vessel Press.\nAnswer: Unknown.\n\nQuestion 3 reasoning:\n- Palace of Flies is published by New Vessel Press, which specializes in translating foreign literature into English.\n- Specializing does not mean every book is a translation, and no source language is specified.\n- No information states Palace of Flies was translated from Italian.\nAnswer: Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 243,
        "conclusion": "Neapolitan Chronicles is an English book.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 244,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 245,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 363,
    "premises": "All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. ",
    "model_response": "Reasoning:\n\n- From \u201cNo chemical compounds contain only one element\u201d and \u201cThe mixture either both is a chemical compound and contains only one element, or neither,\u201d it follows the \u201cboth\u201d case is impossible; thus the mixture is neither a chemical compound nor a one-element substance (\u00acC \u2227 \u00acE).\n- From All alkanes \u2192 hydrocarbons \u2192 organic compounds \u2192 chemical compounds, we get Alkane \u2192 Chemical. By contraposition, \u00acChemical \u2192 \u00acAlkane. Hence the mixture is not an alkane.\n- Only organic compounds are guaranteed to contain carbon, but the mixture is not a chemical compound, hence not necessarily organic; so we cannot conclude it contains carbon.\n\nQuestion 1: We cannot infer whether the mixture contains carbon. Unknown.\n\nQuestion 2: The mixture is not an alkane, so the conjunction \u201calkane and contains carbon\u201d is false. False.\n\nQuestion 3: The consequent \u201cneither a chemical compound nor an alkane\u201d is true for the mixture, so the conditional is true regardless of the antecedent. True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 964,
        "conclusion": "The mixture contains carbon.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 965,
        "conclusion": "The mixture is an alkane and contains carbon.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 966,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 258,
    "premises": "All humans are mortal.\nAll Greeks are humans.",
    "model_response": "Reasoning:\n- From \"All Greeks are humans\" and \"All humans are mortal,\" we can deduce \"All Greeks are mortal.\"\n- The statement \"Some Greeks are mortal\" asserts existence of at least one Greek. The premises do not guarantee that any Greeks exist.\n- Therefore, the truth of \"Some Greeks are mortal\" is not determined by the given information.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 702,
        "conclusion": "Some Greeks are mortal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 435,
    "premises": "None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.",
    "model_response": "Reasoning:\n- From \u201cAll students working in the lab are taking a class with Professor David\u201d and \u201cAll of the students taking a class with Professor David are taking the database course,\u201d and \u201cAll of the students who are taking the database course are from the computer science department,\u201d plus \u201cJames is a student working in the lab,\u201d we get: James takes a class with David \u2192 takes the database course \u2192 is in CS.\n- The statement \u201cJames doesn't work in the lab or have a part-time job offered by the university\u201d is naturally read as: James does not work in the lab and does not have a university part-time job. This contradicts \u201cJames is a student working in the lab,\u201d but it still explicitly states he does not have a part-time job. There is no statement asserting that he does have such a job.\n- Therefore:\n  - Q1: \u201cJames has a part-time job\u201d is contradicted by the explicit negation, so False.\n  - Q2: \u201cJames does not have a part-time job\u201d follows directly, so True.\n  - Q3: \u201cJames either takes the database course or has a part-time job\u201d is True because we derived that he takes the database course.\n  - Q4: \u201cJames takes the database course\u201d is True via the lab \u2192 David \u2192 database chain.\n\nANSWERS:\n1: False\n2: True\n3: True\n4: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1244,
        "conclusion": "James has a part-time job offered by the university.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1245,
        "conclusion": "James does not have a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1246,
        "conclusion": "James either takes the database course or has a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1247,
        "conclusion": "James takes the database course.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.75
  },
  {
    "story_id": 217,
    "premises": "If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.",
    "model_response": "Reasoning:\n\nQuestion 1:\n- From \"If George likes music, he wants to compose\": L -> W.\n- From \"If George has access to a program, he can compose\": A -> C.\n- From \"If George can compose and wants to compose, he will compose\": (C \u2227 W) -> P.\n- Given L \u2227 A, we get W and C, hence C \u2227 W, so P. Therefore the statement is true.\n\nQuestion 2:\n- From (C \u2227 W) -> P, contraposition yields \u00acP -> (\u00acC \u2228 \u00acW).\n- This does not entail \u00acP -> \u00acC; George might fail to compose because he doesn\u2019t want to, even if he can.\n- A consistent scenario: C true, W false, P false satisfies all premises. So the implication \u00acP -> \u00acC is not entailed. It\u2019s not forced false either, so it\u2019s unknown based on given info.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 618,
        "conclusion": "If George likes music and has access to a program, he will compose.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 619,
        "conclusion": "If George will not compose, George can not compose.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 292,
    "premises": "A hawk never swims. \nSome birds are hawks.",
    "model_response": "Step-by-step reasoning:\n- \"A hawk never swims\" means no hawk swims.\n- \"Some birds are hawks\" means there exists at least one bird that is a hawk.\n- Therefore, there exists at least one bird that does not swim.\n- Hence, the statement \"All birds swim\" is contradicted.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 736,
        "conclusion": "All birds swim.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 318,
    "premises": "Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.",
    "model_response": "Reasoning:\n\n- From the context: Some show at 8 pm on Monday gives out roses. Any show that gives out roses is an episode of The Bachelor. The Bachelor portrays the lives of real people, and all shows portraying real lives are reality TV. Therefore, any rose-giving show is reality TV. Breaking Bad is a show and is not reality TV, so Breaking Bad cannot be a rose-giving show.\n\nQuestion 1:\n- We only know that some show at Monday 8 pm gives roses (and thus is reality TV). Breaking Bad is not reality TV, so it\u2019s not that show. But nothing rules out Breaking Bad also airing at that time without giving roses. So we cannot determine its timeslot.\n- Conclusion: Unknown.\n\nQuestion 2:\n- The claim requires that Breaking Bad gives out roses (at Monday 8 pm). But if it gave out roses, it would be an episode of The Bachelor and thus reality TV, contradicting that Breaking Bad is not reality TV. So the claim is false.\n- Conclusion: False.\n\nQuestion 3:\n- Since roses are not given out during Breaking Bad, the antecedent \u201croses are given out during Breaking Bad\u201d is false. A conditional with a false antecedent is true.\n- Conclusion: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 802,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 803,
        "conclusion": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 804,
        "conclusion": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 107,
    "premises": "Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.",
    "model_response": "Question 1 reasoning:\nThe statement uses an inclusive \u201cor.\u201d Since Heinrich Schmidt was German, \u201cGerman or Russian or both\u201d is satisfied regardless of whether he was Russian. Therefore, the statement is true.\n\nQuestion 2 reasoning:\nHeinrich Schmidt is a German politician and was a member of both the Prussian State Parliament and the Nazi Reichstag. This provides a concrete example satisfying \u201csome German politician.\u201d Therefore, the statement is true.\n\nQuestion 3 reasoning:\nThe context states that Heinrich Schmidt, a politician, was part of the Nazi Reichstag. This contradicts \u201cNo politicians are part of the Nazi Reichstag.\u201d Therefore, the statement is false.\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 323,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 324,
        "conclusion": "Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 325,
        "conclusion": "No politicians are part of the Nazi Reichstag.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 386,
    "premises": "If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.",
    "model_response": "Reasoning:\n- From the premises: deadly -> low survival. Severe -> deadly. Bile duct cancer -> severe -> deadly -> low survival. Cholangiocarcinoma -> bile duct cancer. Therefore, bile duct cancer -> low survival.\n- Given: Not (colorectal is bile duct cancer AND colorectal has low survival). Since bile duct cancer implies low survival, if colorectal were bile duct cancer, it would have low survival, contradicting the given. Hence colorectal is not a bile duct cancer. Therefore, colorectal is also not cholangiocarcinoma (as that would imply bile duct cancer). Whether colorectal has low survival or is severe remains undetermined. Mild flu implies low survival, but no link to colorectal cancer is given.\n\nQuestion 1:\n- We have no information implying colorectal cancer is severe, nor that it isn\u2019t. So Unknown.\n\nQuestion 2:\n- Antecedent: \u201ccolorectal is bile duct cancer or cholangiocarcinoma\u201d is false (both disjuncts are false). A material implication with a false antecedent is true. So True.\n\nQuestion 3:\n- The statement effectively requires colorectal to be cholangiocarcinoma and (a mild flu or a bile duct cancer), or \u201call of the above.\u201d But colorectal is neither cholangiocarcinoma nor a bile duct cancer, so the whole statement is False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1032,
        "conclusion": "Colorectal cancer is a kind of severe cancer",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1033,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1034,
        "conclusion": "Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 355,
    "premises": "All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.",
    "model_response": "Reasoning:\n- From S -> C, H -> S, so H -> C. Also D -> \u00acC. Therefore H and D cannot both be true.\n- The given exclusive scenario for Taylor is (H \u2227 D) or (\u00acH \u2227 \u00acD). Since H \u2227 D is impossible, it must be \u00acH \u2227 \u00acD.\n- From G -> N -> H, we get G -> H. With \u00acH, contrapositive gives \u00acG.\n\nQuestion 1:\n- We have \u00acH, but H -> S does not allow inferring \u00acS. So whether Taylor eats salads is not determined.\n- Answer: Unknown.\n\nQuestion 2:\n- From \u00acH and G -> H, we conclude \u00acG.\n- Answer: False.\n\nQuestion 3:\n- We have \u00acH and \u00acG, so the statement holds.\n- Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 941,
        "conclusion": "Taylor eats salads regularly.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 942,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 943,
        "conclusion": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 51,
    "premises": "The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. ",
    "model_response": "Reasoning:\n1. The context only states that the summer Olympic games is a sporting event. It provides no information about the world championships. Therefore, we cannot determine this from the given information.\n2. The context explicitly states that the last summer Olympic games was in Tokyo. The statement claims the opposite, so it is contradicted by the context.\n3. The context states that the last summer Olympic games was in Tokyo and that the United States won the most medals in Tokyo. Therefore, it follows that the United States won the most medals in the last summer Olympic games.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 147,
        "conclusion": "The world championships is a sporting event.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 148,
        "conclusion": "The last summer Olympic games were not in Tokyo.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 149,
        "conclusion": "The United States won the most medals in the last summer Olympic games.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 259,
    "premises": "All horses have hooves.\nNo humans have hooves.",
    "model_response": "Reasoning:\n- Premises: All horses have hooves. No humans have hooves.\n- If any human were a horse, they would have hooves (from \"all horses have hooves\"), but humans do not have hooves (from \"no humans have hooves\"). Contradiction.\n- Therefore, no humans are horses, so the statement \"Some humans are horses\" is false.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 703,
        "conclusion": "Some humans are horses.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 152,
    "premises": "Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.",
    "model_response": "Question 1 reasoning:\n- Susan flies to LGA, so her arrival airport is LGA.\n- Departure and arrival cannot be the same.\n- Therefore, Susan\u2019s departure is not LGA. The statement that she flies from LGA is false.\n\nQuestion 2 reasoning:\n- John flies from LGA, so his departure airport is LGA.\n- Departure and arrival cannot be the same.\n- Therefore, John\u2019s arrival is not LGA. The statement that he flies to LGA is false.\n\nANSWERS:\n1: False\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 442,
        "conclusion": "Susan flies from LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 443,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 441,
    "premises": "No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.",
    "model_response": "Reasoning:\n- From Tom is a pet owner and all pet owners love animals, Tom loves animals.\n- From all animal lovers are nice to animals, Tom is nice to animals.\n- From no one nice to animals is also mean to animals, Tom is not mean to animals.\n\nQuestion 1:\n- Nothing links being nice or loving animals to not being grumpy; Tom could be grumpy or not. Unknown.\n\nQuestion 2:\n- Since Tom is not mean, he cannot be both grumpy and mean. True.\n\nQuestion 3:\n- Antecedent \u201cTom is not both grumpy and mean\u201d is true (since Tom is not mean).\n- Consequent \u201cTom is neither grumpy nor an animal lover\u201d is false because Tom is an animal lover.\n- Hence the implication is false. False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1268,
        "conclusion": "Tom is a grumpy person.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1269,
        "conclusion": "Tom is not both a grumpy person and mean to animals.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1270,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 64,
    "premises": "A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.",
    "model_response": "Question 1 reasoning:\n- Family History is a novel and is written by Dani Shapiro.\n- Rule: If a book is a novel and it is written by a person, then the person is a novel writer.\n- Therefore, Dani Shapiro is a novel writer.\nConclusion: True.\n\nQuestion 2 reasoning:\n- Dani Shapiro created a podcast called Family Secrets, so Family Secrets is a podcast.\n- Rule: A podcast is not a novel.\n- Therefore, Family Secrets is not a novel.\nConclusion: False.\n\nQuestion 3 reasoning:\n- Boston is an American city, and being born in an American city implies being American.\n- Dani Shapiro is American, but there is no information that she was born in Boston.\n- Being American does not imply being born in Boston.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 189,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 190,
        "conclusion": "Family Secrets is a novel.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 191,
        "conclusion": "Dani Shapiro was born in Boston.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 456,
    "premises": "Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.",
    "model_response": "Reasoning:\n- From the chain PB \u2192 JS \u2192 Leap \u2192 Activate, we have PB \u2192 Activate.\n- Given \u00acActivate(Yuri), by contraposition of Leap \u2192 Activate we get \u00acLeap(Yuri), and by contraposition of PB \u2192 Activate we get \u00acPB(Yuri).\n- Nothing in the premises constrains Yuri\u2019s nationality.\n\nQuestion 1: No information links Yuri to being American or not. Unknown.\nQuestion 2: \u201cNot an American professional basketball player\u201d means \u00ac(American \u2227 PB). Since \u00acPB(Yuri), this is true. True.\nQuestion 3: Requires PB(Yuri), but we have \u00acPB(Yuri). False.\nQuestion 4: Antecedent \u00acLeap(Yuri) is true; consequent (American \u2227 PB) is false due to \u00acPB(Yuri). Implication is false. False.\nQuestion 5: Antecedent \u00ac(American \u2227 PB) is true (since \u00acPB); consequent PB is false. Implication is false. False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False\n4: False\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1313,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1314,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1315,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1316,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1317,
        "conclusion": "If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 280,
    "premises": "Events are either happy or sad.\nAt least one event is happy. ",
    "model_response": "Given that every event is either happy or sad (mutually exclusive categories) and at least one event is happy, it cannot be the case that all events are sad. Therefore, the statement \"All events are sad\" is false.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 724,
        "conclusion": "All events are sad.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 140,
    "premises": "The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.",
    "model_response": "Reasoning:\n1. It is explicitly stated that the winner of the 1992 du Maurier Classic was Steinhauer. Therefore, the statement that Steinhauer was not the winner contradicts the given information.\n2. We know there was a six-way tie on the leaderboard with at least one Belgian in that tie. We also know Descampe is Belgian and on the leaderboard. However, it is not stated that Descampe is the Belgian in the six-way tie; there could be other Belgian players on the leaderboard, and Descampe might not be in the tie. Thus, this cannot be concluded from the given information.\n\nANSWERS:\n1: False\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 411,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 412,
        "conclusion": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 459,
    "premises": "Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.",
    "model_response": "Reasoning:\n- From (\u00acJumps(KiKi) \u2227 \u00acLegs(KiKi)) \u2192 (Terricolous(KiKi) \u2228 Legs(KiKi)), if \u00acJumps and \u00acLegs held, then with \u00acLegs we\u2019d have Terricolous, which by Terricolous \u2192 Legs contradicts \u00acLegs. So \u00ac(\u00acJumps \u2227 \u00acLegs), hence Jumps(KiKi) \u2228 Legs(KiKi). If Legs, then by Legs \u2192 Jumps we get Jumps anyway. Therefore Jumps(KiKi) is true.\n- Jane likes all animals that jump, so Jane likes KiKi.\n- Jane does not like any animals that bark. Since KiKi is an animal and Jane likes KiKi, KiKi does not bark.\n- All dogs bark, so if KiKi does not bark, KiKi is not a dog.\n- Nothing entails Terricolous(KiKi); it remains undetermined.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1324,
        "conclusion": "KiKi is terricolous.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1325,
        "conclusion": "KiKi is a barking dog.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1326,
        "conclusion": "KiKi does not bark and he is not a dog.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 101,
    "premises": "Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.",
    "model_response": "Reasoning:\n1. The context states Ailton Silva is Brazilian and plays for N\u00e1utico, so it is not true that no one at N\u00e1utico is Brazilian.\n2. The context says Ailton Silva plays for N\u00e1utico, which is a football club, so the statement is false.\n3. Ailton was loaned out to Braga, and Braga is a football club, so the statement is false.\n4. The context provides no information linking Ailton Silva to Fluminense; only that Fluminense is a football club. Therefore, we cannot determine this.\n5. Ailton was loaned out to Braga, which is a football club, so this is true.\n\nANSWERS:\n1: False\n2: False\n3: False\n4: Unknown\n5: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 304,
        "conclusion": "No one playing for Nautico is Brazilian.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 305,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 306,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 307,
        "conclusion": "Ailton Silva played for Fluminense.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 308,
        "conclusion": "Ailton Silva was loaned out to a football club.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.8
  }
]