[
  {
    "story_id": 380,
    "premises": "Matthew Gray (born 24 June 1973) is an Australian archer. W\u0142adys\u0142aw III of Poland may refer to:\n\nW\u0142adys\u0142aw III of Poland (1424-1444), also known as W\u0142adys\u0142aw III of Varna, King of Poland\nW\u0142adys\u0142aw III Spindleshanks (1165?-1231), High Duke of Poland. People in this club who perform in school talent shows often attend and are very engaged with school events.\nPeople in this club either perform in school talent shows often or are inactive and disinterested community members.\nPeople in this club who chaperone high school dances are not students who attend the school.\nAll people in this club who are inactive and disinterested members of their community chaperone high school dances.\nAll young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \nBonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Matthew Gray (born 24 June 1973) is an Australian archer. W\u0142adys\u0142aw III of Poland may refer to:\n\nW\u0142adys\u0142aw III of Poland (1424-1444), also known as W\u0142adys\u0142aw III of Varna, King of Poland\nW\u0142adys\u0142aw III Spindleshanks (1165?-1231), High Duke of Poland. People in this club who perform in school talent shows often attend and are very engaged with school events.\nPeople in this club either perform in school talent shows often or are inactive and disinterested community members.\nPeople in this club who chaperone high school dances are not students who attend the school.\nAll people in this club who are inactive and disinterested members of their community chaperone high school dances.\nAll young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \nBonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Bonnie performs in school talent shows often.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n\nSet up predicates for club members:\n- P: performs in school talent shows often\n- G: attends and is very engaged with school events\n- S: student who attends the school\n- I: inactive and disinterested community member\n- C: chaperones high school dances\n- Y: young child or teenager\n- W: wishes to further academic career/educational opportunities\n\nGiven rules (for people in this club):\n1) P -> G\n2) P \u2228 I\n3) C -> \u00acS\n4) I -> C (so I -> \u00acS)\n5) (Y \u2227 W) -> S\n6) For Bonnie: (G \u2227 S) \u2228 (\u00acG \u2227 \u00acS), i.e., S \u2194 G\n\nFrom these, Bonnie has two consistent cases:\n- Case A: G \u2227 S. Then I is false (else I -> \u00acS), so by (2) P is true. Also C is false (since C -> \u00acS). Y and W are unconstrained.\n- Case B: \u00acG \u2227 \u00acS. Then P is false (else P -> G), so by (2) I is true, hence C is true. Also Y \u2227 W must be false (else (5) would force S).\n\nQuestion 1: Is \u201cBonnie performs in school talent shows often\u201d true?\n- Case A: P true. Case B: P false. Not determined uniquely. Answer: Unknown.\n\nQuestion 2: Antecedent: \u201ceither (Y \u2227 W \u2227 C) or not (Y \u2227 W)\u201d which is equivalent to C \u2228 \u00ac(Y \u2227 W). Consequent: S \u2228 I.\n- Case A: C is false, so antecedent is \u00ac(Y \u2227 W) (could be true or false). If true, consequent S \u2228 I is true (S true). If false, conditional is vacuously true.\n- Case B: Y \u2227 W is false, so antecedent true; consequent S \u2228 I is true (I true).\nThus the conditional holds in all models. Answer: True.\n\nQuestion 3: Antecedent: \u201ceither C or, if not C, then P\u201d simplifies to C \u2228 P. By (2) and I -> C, for Bonnie either P or C holds in all models, so the antecedent is always true (Case A: P true; Case B: C true). Consequent: (Y \u2227 W) \u2227 I.\n- Case A: I is false, so the consequent is false. Since the antecedent is true here, the conditional is false in at least one consistent model. Answer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1014,
        "conclusion": "Bonnie performs in school talent shows often.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1015,
        "conclusion": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1016,
        "conclusion": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 426,
    "premises": "p\u0254. No pursuit was attempted because Wellesley was superseded by Sir Harry Burrard and then Sir Hew Dalrymple (one having arrived during the battle, the second soon after). All employees who schedule a meeting with their customers will go to the company building today. \nEveryone who has lunch in the company building schedules meetings with their customers. \nEmployees have lunch either in the company building or at home.\nIf an employee has lunch at home, they are working remotely from home.\nAll employees who are in other countries work remotely from home. \nNo managers work remotely from home. \nJames will appear in the company today if and only if he is a manager.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: p\u0254. No pursuit was attempted because Wellesley was superseded by Sir Harry Burrard and then Sir Hew Dalrymple (one having arrived during the battle, the second soon after). All employees who schedule a meeting with their customers will go to the company building today. \nEveryone who has lunch in the company building schedules meetings with their customers. \nEmployees have lunch either in the company building or at home.\nIf an employee has lunch at home, they are working remotely from home.\nAll employees who are in other countries work remotely from home. \nNo managers work remotely from home. \nJames will appear in the company today if and only if he is a manager.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? James has lunch in the company.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? James does not have lunch in the company.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If James is either a manager or in other countries,  then James does not either has lunch at home or work remotely from home. If James either has lunch at home or works remotely from home, then he is neither a manager nor does he work in other countries. [contrapositive is more natural]\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nLet:\n- Lc = James has lunch in the company building.\n- H = James has lunch at home.\n- R = James works remotely from home.\n- M = James is a manager.\n- C = James is in other countries.\n- A = James appears in the company today.\n\nGiven:\n- Lc -> schedules -> goes to company building -> A.\n- A iff M.\n- H -> R.\n- C -> R.\n- No managers work remotely: M -> \u00acR, hence by contrapositive R -> \u00acM.\n- From H -> R, contrapositive gives \u00acR -> \u00acH.\n- Lunch is either in the building or at home (exclusive), so exactly one of Lc, H holds.\n\nFrom these:\n- Lc -> A -> M, so Lc -> M.\n- M -> \u00acR -> \u00acH, and by exclusivity of lunch locations, \u00acH -> Lc. Thus M -> Lc.\n- Therefore Lc iff M. Also, if \u00acM then \u00acA, hence \u00acLc (since Lc -> A), so H is true and R is true. So two consistent branches remain:\n  - M true: Lc true, H false, R false, C false.\n  - M false: Lc false, H true, R true, and C may be either true or false (if C true, still consistent).\n\nQuestion 1: Is \u201cJames has lunch in the company\u201d true?\n- Since Lc iff M and we do not know whether M holds, Lc is undetermined.\nAnswer: Unknown.\n\nQuestion 2: Is \u201cJames does not have lunch in the company\u201d true?\n- As above, since Lc is undetermined, its negation is also undetermined.\nAnswer: Unknown.\n\nQuestion 3: The statement is the conjunction of:\n- (M or C) -> not (H or R), and\n- (H or R) -> (not M and not C).\n\nNote H or R is equivalent to R (because H -> R and \u00acR -> \u00acH).\nSo these become:\n- (M or C) -> \u00acR, and\n- R -> (\u00acM \u2227 \u00acC).\n\nWe know M -> \u00acR, but C -> R, so if C is true then the first implication fails. Since C can be true in a model consistent with the premises (non-manager, remote), the overall statement is not entailed. In other models (e.g., M true, C false; or M false, C false) the statement holds. Hence its truth is undetermined.\nAnswer: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1208,
        "conclusion": "James has lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1209,
        "conclusion": "James does not have lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1210,
        "conclusion": "If James is either a manager or in other countries,  then James does not either has lunch at home or work remotely from home. If James either has lunch at home or works remotely from home, then he is neither a manager nor does he work in other countries. [contrapositive is more natural]",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 198,
    "premises": "She was a speaker at dozens of events over her lifetime, including the first national convention of the Amalgamated Flying Saucer Clubs of America on July 11 and 12, 1959 at the Statler-Hilton Hotel in Los Angeles, California. The couple planned to live in Philadelphia during the summer months and would winter in Greenwood, South Carolina. When the Monkeypox virus occurs in a being, it may get Monkeypox. \nMonkeypox virus can occur in certain animals.\nHumans are mammals.\nMammals are animals.\nSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness. \nPeople feel tired when they get the flu.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: She was a speaker at dozens of events over her lifetime, including the first national convention of the Amalgamated Flying Saucer Clubs of America on July 11 and 12, 1959 at the Statler-Hilton Hotel in Los Angeles, California. The couple planned to live in Philadelphia during the summer months and would winter in Greenwood, South Carolina. When the Monkeypox virus occurs in a being, it may get Monkeypox. \nMonkeypox virus can occur in certain animals.\nHumans are mammals.\nMammals are animals.\nSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness. \nPeople feel tired when they get the flu.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? There is an animal.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? No one gets the flu.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Symptoms of Monkeypox include coughing.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1) The text states \"Monkeypox virus can occur in certain animals,\" which implies that some animals exist. Therefore, there is at least one animal.\n2) The text says \"People feel tired when they get the flu,\" which is a conditional statement and does not assert whether anyone actually gets the flu. So we cannot conclude \"No one gets the flu.\"\n3) The text lists Monkeypox symptoms as \"fever, headache, muscle pains, and tiredness.\" Coughing is not mentioned, and the list may not be exhaustive. We cannot conclude that coughing is included.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 563,
        "conclusion": "There is an animal.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 564,
        "conclusion": "No one gets the flu.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 565,
        "conclusion": "Symptoms of Monkeypox include coughing.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 20,
    "premises": "Locomotive 2711 currently holds the world record for the longest passenger train ever pulled by a single locomotive. The Antiochian Orthodox Archdiocese of Mexico, Venezuela, Central America and the Caribbean (Spanish: Arquidi\u00f3cesis Ortodoxa Antioquena de M\u00e9xico, Venezuela, Centroam\u00e9rica y El Caribe; Arabic: \u0623\u0628\u0631\u0634\u064a\u0629 \u0627\u0644\u0645\u0643\u0633\u064a\u0643\u060c \u0641\u0646\u0632\u0648\u064a\u0644\u0627\u060c \u0623\u0645\u0631\u064a\u0643\u0627 \u0627\u0644\u0648\u0633\u0637\u0649 \u0648\u062c\u0632\u0631 \u0627\u0644\u0643\u0627\u0631\u064a\u0628\u064a \u0644\u0644\u0623\u0631\u062b\u0648\u0630\u0643\u0633 \u0627\u0644\u0623\u0646\u0637\u0627\u0643\u064a\u064a\u0646 \u02bcamabrashiyya almaks\u012bk, finizwayl\u0101, \u02bcam\u012brk\u0101 alw\u016bs\u1e6d\u0101 wajazr alk\u0101r\u012bb\u012b lil\u02bcurth\u016bdhuks al\u02bcan\u1e6d\u0101k\u012byin) is a jurisdiction of the Greek Orthodox Church of Antioch. A Japanese game company created the game the Legend of Zelda.\nAll games on the Top 10 list are made by Japanese game companies.\nIf a game sells more than one million copies, then it will be included in the Top 10 list.\nThe Legend of Zelda sold more than one million copies.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Locomotive 2711 currently holds the world record for the longest passenger train ever pulled by a single locomotive. The Antiochian Orthodox Archdiocese of Mexico, Venezuela, Central America and the Caribbean (Spanish: Arquidi\u00f3cesis Ortodoxa Antioquena de M\u00e9xico, Venezuela, Centroam\u00e9rica y El Caribe; Arabic: \u0623\u0628\u0631\u0634\u064a\u0629 \u0627\u0644\u0645\u0643\u0633\u064a\u0643\u060c \u0641\u0646\u0632\u0648\u064a\u0644\u0627\u060c \u0623\u0645\u0631\u064a\u0643\u0627 \u0627\u0644\u0648\u0633\u0637\u0649 \u0648\u062c\u0632\u0631 \u0627\u0644\u0643\u0627\u0631\u064a\u0628\u064a \u0644\u0644\u0623\u0631\u062b\u0648\u0630\u0643\u0633 \u0627\u0644\u0623\u0646\u0637\u0627\u0643\u064a\u064a\u0646 \u02bcamabrashiyya almaks\u012bk, finizwayl\u0101, \u02bcam\u012brk\u0101 alw\u016bs\u1e6d\u0101 wajazr alk\u0101r\u012bb\u012b lil\u02bcurth\u016bdhuks al\u02bcan\u1e6d\u0101k\u012byin) is a jurisdiction of the Greek Orthodox Church of Antioch. A Japanese game company created the game the Legend of Zelda.\nAll games on the Top 10 list are made by Japanese game companies.\nIf a game sells more than one million copies, then it will be included in the Top 10 list.\nThe Legend of Zelda sold more than one million copies.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The Legend of Zelda is on the Top 10 list.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? FIFA 22 is made by a Japanese video game company.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The Legend of Zelda is not on the Top 10 list.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Q1: The Legend of Zelda sold more than one million copies. By the rule \u201cIf a game sells more than one million copies, then it will be included in the Top 10 list,\u201d it follows that The Legend of Zelda is on the Top 10 list. Therefore, the statement is True.\n- Q2: We are told only that all games on the Top 10 list are made by Japanese companies, and that The Legend of Zelda was made by a Japanese company. There is no information about FIFA 22\u2019s sales or inclusion in the Top 10 list. We cannot conclude whether FIFA 22 is made by a Japanese company. Therefore, Unknown.\n- Q3: From Q1, The Legend of Zelda is on the Top 10 list, so the statement that it is not on the Top 10 list is False.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 57,
        "conclusion": "The Legend of Zelda is on the Top 10 list.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 58,
        "conclusion": "FIFA 22 is made by a Japanese video game company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 59,
        "conclusion": "The Legend of Zelda is not on the Top 10 list.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 282,
    "premises": "Compulsory Heterosexuality and Lesbian Existence is a 1980 essay by Adrienne Rich, which was also published in her 1986 book Blood, Bread, and Poetry: Selected Prose 1979-1985. Top floor: Expresso Tiradentes station\nMezzanine: ticketing office, ATMs, cafeteria, operational control center, health and other services. All squares are four-sided.\nAll four-sided things are shapes. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: Compulsory Heterosexuality and Lesbian Existence is a 1980 essay by Adrienne Rich, which was also published in her 1986 book Blood, Bread, and Poetry: Selected Prose 1979-1985. Top floor: Expresso Tiradentes station\nMezzanine: ticketing office, ATMs, cafeteria, operational control center, health and other services. All squares are four-sided.\nAll four-sided things are shapes. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? All squares are shapes.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "The essay and station details are irrelevant to the logical claim.\n\n- Given: All squares are four-sided.\n- Given: All four-sided things are shapes.\n- Therefore: All squares are shapes (transitivity of subset relations).\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 726,
        "conclusion": "All squares are shapes.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 471,
    "premises": "With no fish passage facilities, the dam blocked passage of anadromous Pacific Salmon from the upper 50+ miles of the Elwha watershed located within Olympic National Park. His state mainly comprised the town of Radhanpur in Gujarat with some adjoining areas. All rabbits that can be spotted near the campus are cute. \nSome turtles can be spotted near the campus. \nThe only animals that can be spotted near the campus are rabbits and squirrels.\nIf something is skittish, then it is not calm.\nAll the squirrels that can be spotted near the campus are skittish.\nRockie can be spotted near the campus, and it is calm.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: With no fish passage facilities, the dam blocked passage of anadromous Pacific Salmon from the upper 50+ miles of the Elwha watershed located within Olympic National Park. His state mainly comprised the town of Radhanpur in Gujarat with some adjoining areas. All rabbits that can be spotted near the campus are cute. \nSome turtles can be spotted near the campus. \nThe only animals that can be spotted near the campus are rabbits and squirrels.\nIf something is skittish, then it is not calm.\nAll the squirrels that can be spotted near the campus are skittish.\nRockie can be spotted near the campus, and it is calm.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Rockie is a turtle.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Rockie is not a turtle.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Rockie is a turtle or cute.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? If Rockie is cute and calm, then Rockie is a skittish turtle.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Premises:\n  - All spotted rabbits are cute.\n  - Some turtles are spotted near the campus (existence).\n  - If an animal can be spotted near the campus, then it is a rabbit or a squirrel.\n  - Skittish -> not calm.\n  - All spotted squirrels are skittish.\n  - Rockie is spotted and calm.\n\n- From Rockie is calm and skittish -> not calm, we infer Rockie is not skittish.\n- If Rockie were a squirrel (and is spotted), then Rockie would be skittish; contradiction. So Rockie is not a squirrel.\n- Whether Rockie is a turtle is not determined. Whether Rockie is a rabbit (and thus cute) depends on whether Rockie is an animal; that is not given. Rockie could be a non-animal object that is spotted and calm.\n\nQuestion 1: Rockie is a turtle.\n- Not determined by the premises; existence of some spotted turtles does not entail Rockie is one.\nAnswer: Unknown\n\nQuestion 2: Rockie is not a turtle.\n- Also not determined; consistent models allow Rockie to be a turtle (e.g., also a rabbit) or not.\nAnswer: Unknown\n\nQuestion 3: Rockie is a turtle or cute.\n- Could be false in a consistent model where Rockie is a non-animal, hence neither turtle nor (guaranteed) cute. Not entailed true nor false.\nAnswer: Unknown\n\nQuestion 4: If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.\n- Antecedent is true (Rockie is not a squirrel). Consequent reduces to \u201cRockie is cute\u201d since Rockie is not skittish; that is undetermined. Hence the implication is not determined.\nAnswer: Unknown\n\nQuestion 5: If Rockie is cute and calm, then Rockie is a skittish turtle.\n- There is a consistent model where Rockie is a cute, calm rabbit (not a turtle, not skittish), making the implication false there; but other models make it vacuously true. So not determined.\nAnswer: Unknown\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown\n4: Unknown\n5: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1361,
        "conclusion": "Rockie is a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1362,
        "conclusion": "Rockie is not a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1363,
        "conclusion": "Rockie is a turtle or cute.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 4,
        "example_id": 1364,
        "conclusion": "If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 5,
        "example_id": 1365,
        "conclusion": "If Rockie is cute and calm, then Rockie is a skittish turtle.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.4
  },
  {
    "story_id": 184,
    "premises": "Since 1999, it has been situated in the Subcarpathian Voivodeship and is the capital of Le\u017cajsk County. Fotograf\u00edas de Joaqu\u00edn Blez. \"Stranger Things\" is a popular Netflix show.\nIf a Netflix show is popular, Karen will binge-watch it.\nIf and only if Karen binge-watches a Netflix show, she will download it.\nKaren does not download \"Black Mirror.\"\n\"Black Mirror\" is a Netflix show.\nIf Karen binge-watches a Netflix show, she will share it with Lisa.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Since 1999, it has been situated in the Subcarpathian Voivodeship and is the capital of Le\u017cajsk County. Fotograf\u00edas de Joaqu\u00edn Blez. \"Stranger Things\" is a popular Netflix show.\nIf a Netflix show is popular, Karen will binge-watch it.\nIf and only if Karen binge-watches a Netflix show, she will download it.\nKaren does not download \"Black Mirror.\"\n\"Black Mirror\" is a Netflix show.\nIf Karen binge-watches a Netflix show, she will share it with Lisa.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Karen will share \"Stranger Things\" with Lisa.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? \"Black Mirror\" is popular.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Karen will share \"Black Mirror\" with Lisa.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- \"Stranger Things\" is a popular Netflix show.\n- Rule: If a Netflix show is popular, Karen will binge-watch it \u21d2 Karen binge-watches Stranger Things.\n- Rule: If Karen binge-watches a Netflix show, she will share it with Lisa \u21d2 She shares Stranger Things with Lisa.\nConclusion: True.\n\nQuestion 2:\n- \"Black Mirror\" is a Netflix show and Karen does not download it.\n- Rule (iff): Karen binge-watches a Netflix show iff she will download it \u21d2 Not downloading Black Mirror implies she does not binge-watch it.\n- Rule: If a Netflix show is popular, Karen will binge-watch it. Contrapositive with known Netflix status: If she does not binge-watch it, then it is not popular.\n- Therefore, Black Mirror is not popular.\nConclusion: False.\n\nQuestion 3:\n- From above, Karen does not binge-watch Black Mirror.\n- Rule: If she binge-watches a Netflix show, she will share it with Lisa. This is one-way; it does not say she shares only if she binge-watches.\n- Therefore, we cannot conclude whether she shares Black Mirror.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 530,
        "conclusion": "Karen will share \"Stranger Things\" with Lisa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 531,
        "conclusion": "\"Black Mirror\" is popular.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 532,
        "conclusion": "Karen will share \"Black Mirror\" with Lisa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 232,
    "premises": "The winners of the two groups of the 2. C. Beijing is the capital of the People's Republic of China. \nBeijing is the capital city of the world's most populous nation.\nBeijing is located in Northern China.\nBeijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nBeijing has hosted the Summer and Winter Olympics and the Summer and Winter Paralympics.\nMany of Beijing's 91 universities consistently rank among the best universities in the world.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The winners of the two groups of the 2. C. Beijing is the capital of the People's Republic of China. \nBeijing is the capital city of the world's most populous nation.\nBeijing is located in Northern China.\nBeijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nBeijing has hosted the Summer and Winter Olympics and the Summer and Winter Paralympics.\nMany of Beijing's 91 universities consistently rank among the best universities in the world.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Beijing is located in southern China.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Beijing is the second largest Chinese city.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. The text says Beijing hosted the 2008 Summer Olympics and that it has hosted both the Summer and Winter Olympics. Therefore, it hosted the 2008 Summer Olympics and a Winter Olympics. True.\n2. The text explicitly states Beijing is located in Northern China. The statement says southern China, which contradicts the text. False.\n3. The text provides no information about Beijing\u2019s size ranking among Chinese cities. Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 657,
        "conclusion": "Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 658,
        "conclusion": "Beijing is located in southern China.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 659,
        "conclusion": "Beijing is the second largest Chinese city.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 452,
    "premises": "On January 1, 2006, Wasseiges had a total population of 2,517. The Bloodstone Lands is a module for the Forgotten Realms campaign setting for the 2nd edition of Advanced Dungeons & Dragons. All aliens are extraterrestrials.\nIf someone is from Mars, then they are an alien.\nNo extraterrestrials are human.\nAll highly intelligent beings from Earth are humans.\nMarvin is a highly intelligent being.\nMarvin is either from Earth and from Mars, or he is from neither.\nIf Marvin is not from Earth, then Marvin is an extraterrestrial.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: On January 1, 2006, Wasseiges had a total population of 2,517. The Bloodstone Lands is a module for the Forgotten Realms campaign setting for the 2nd edition of Advanced Dungeons & Dragons. All aliens are extraterrestrials.\nIf someone is from Mars, then they are an alien.\nNo extraterrestrials are human.\nAll highly intelligent beings from Earth are humans.\nMarvin is a highly intelligent being.\nMarvin is either from Earth and from Mars, or he is from neither.\nIf Marvin is not from Earth, then Marvin is an extraterrestrial.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Marvin is an alien.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Marvin is neither a human nor from Mars.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Marvin is not from Mars, then Marvin is a human.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n\n- Let E = Marvin is from Earth; M = Marvin is from Mars; A = Marvin is an alien; X = Marvin is an extraterrestrial; H = Marvin is human; I = Marvin is highly intelligent.\n\n- Given: A -> X; M -> A; X -> \u00acH; (I \u2227 E) -> H; I; (E \u2227 M) \u2228 (\u00acE \u2227 \u00acM); \u00acE -> X.\n\n- Consider the first disjunct E \u2227 M:\n  - From M -> A -> X -> \u00acH.\n  - From I \u2227 E and I true, we get H.\n  - Contradiction (H and \u00acH). So E \u2227 M is impossible.\n\n- Therefore, by the given (E \u2227 M) \u2228 (\u00acE \u2227 \u00acM), we must have \u00acE \u2227 \u00acM.\n\n- From \u00acE and \u00acE -> X, we get X. From X -> \u00acH, we get \u00acH.\n\nQuestion 1: Is Marvin an alien?\n- We have M false, so cannot use M -> A. We have X true, but only A -> X is given, not X -> A. So A is not determined.\n- Answer: Unknown.\n\nQuestion 2: Is Marvin neither a human nor from Mars?\n- We derived \u00acH and \u00acM.\n- Answer: True.\n\nQuestion 3: If Marvin is not from Mars, then Marvin is a human?\n- Antecedent \u00acM is true; consequent H is false. So the implication is false.\n- Answer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1301,
        "conclusion": "Marvin is an alien.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1302,
        "conclusion": "Marvin is neither a human nor from Mars.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1303,
        "conclusion": "If Marvin is not from Mars, then Marvin is a human.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 340,
    "premises": "Although the Mercedes-Benz M-Class was introduced more than a year prior to the X5, the X5 was the first to utilise a monocoque chassis. , and thereafter was interested in the construction of railroads and was active in the Republican politics of Missouri. Everyone at the mixer is a Grand Slam champion or an Oscar-nominated actor.\nEvery Grand Slam champion at the mixer is a professional tennis player.\nAll Oscar-nominated actors at the mixer are celebrities.\nAll professional tennis players at the mixer are athletes.\nIf a person at the mixer is a celebrity, then they are well paid.\nIf a person at the mixer is an athlete, then they are famous.\nAll well-paid people at the mixer live in tax havens.\nDjokovic is at the mixer: if Djokovic is a famous athlete, then Djokovic is well-paid.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Although the Mercedes-Benz M-Class was introduced more than a year prior to the X5, the X5 was the first to utilise a monocoque chassis. , and thereafter was interested in the construction of railroads and was active in the Republican politics of Missouri. Everyone at the mixer is a Grand Slam champion or an Oscar-nominated actor.\nEvery Grand Slam champion at the mixer is a professional tennis player.\nAll Oscar-nominated actors at the mixer are celebrities.\nAll professional tennis players at the mixer are athletes.\nIf a person at the mixer is a celebrity, then they are well paid.\nIf a person at the mixer is an athlete, then they are famous.\nAll well-paid people at the mixer live in tax havens.\nDjokovic is at the mixer: if Djokovic is a famous athlete, then Djokovic is well-paid.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Djokovic is a Grand Slam champion.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Djokovic lives in a tax haven.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Djokovic does not live in a tax haven.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Everyone at the mixer is either a Grand Slam champion or an Oscar-nominated actor.\n- Djokovic is at the mixer, so Djokovic is either a Grand Slam champion or an Oscar-nominated actor.\n- There is no information forcing which disjunct holds. Hence we cannot conclude he is a Grand Slam champion.\nAnswer: Unknown.\n\nQuestion 2:\n- From above, Djokovic is either a Grand Slam champion or an Oscar-nominated actor.\n- If Grand Slam champion: then professional tennis player \u2192 athlete \u2192 famous; with the given conditional for Djokovic (if famous athlete then well-paid), Djokovic is well-paid; all well-paid people at the mixer live in tax havens \u21d2 Djokovic lives in a tax haven.\n- If Oscar-nominated actor: then celebrity \u2192 well-paid \u2192 lives in a tax haven.\n- In either case, Djokovic lives in a tax haven.\nAnswer: True.\n\nQuestion 3:\n- This is the negation of Question 2\u2019s conclusion.\n- Since Djokovic lives in a tax haven is true, \u201cDjokovic does not live in a tax haven\u201d is false.\nAnswer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 893,
        "conclusion": "Djokovic is a Grand Slam champion.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 894,
        "conclusion": "Djokovic lives in a tax haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 895,
        "conclusion": "Djokovic does not live in a tax haven.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 96,
    "premises": "In 1945, he was returned to US-controlled Korea by the US military. Kabel may refer to:\n\nKabel (Haarlemmermeer), a hamlet in the Netherlands\nKabel (Heerhugowaard), a hamlet in the Netherlands\nKabel (typeface). Diamond Mine is a professional wrestling stable formed in WWE.\nRoderick Strong leads Diamond Mine.\nDiamond Mine includes the Creed Brothers and Ivy Nile.\nImperium has a feud with Diamond Mine.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: In 1945, he was returned to US-controlled Korea by the US military. Kabel may refer to:\n\nKabel (Haarlemmermeer), a hamlet in the Netherlands\nKabel (Heerhugowaard), a hamlet in the Netherlands\nKabel (typeface). Diamond Mine is a professional wrestling stable formed in WWE.\nRoderick Strong leads Diamond Mine.\nDiamond Mine includes the Creed Brothers and Ivy Nile.\nImperium has a feud with Diamond Mine.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Roderick Strong leads a professional wrestling stable.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Roderick Strong leads the Creed Brothers.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. Diamond Mine is a professional wrestling stable, and Roderick Strong leads Diamond Mine. Therefore, he leads a professional wrestling stable. True.\n2. Diamond Mine includes the Creed Brothers, and Roderick Strong leads Diamond Mine. Thus, he leads the group that includes the Creed Brothers, so he leads the Creed Brothers. True.\n3. Imperium has a feud with Diamond Mine, which is a professional wrestling stable that includes Ivy Nile. Therefore, the claim that Imperium doesn't have a feud with such a stable is false. False.\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 289,
        "conclusion": "Roderick Strong leads a professional wrestling stable.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 290,
        "conclusion": "Roderick Strong leads the Creed Brothers.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 291,
        "conclusion": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 219,
    "premises": "The municipality was formed on January 1, 1971, by merging the independent communities of Betzweiler and W\u00e4lde. The Ledger also regularly published some of the most popular mid-century women poets including Sarah M. Symphony No. 9 is a music piece.\nComposers write music pieces.\nBeethoven wrote Symphony No. 9.\nVienna Music Society premiered Symphony No. 9.\nVienna Music Society is an orchestra.\nBeethoven leads the Vienna Music Society.\nOrchestras are led by conductors.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The municipality was formed on January 1, 1971, by merging the independent communities of Betzweiler and W\u00e4lde. The Ledger also regularly published some of the most popular mid-century women poets including Sarah M. Symphony No. 9 is a music piece.\nComposers write music pieces.\nBeethoven wrote Symphony No. 9.\nVienna Music Society premiered Symphony No. 9.\nVienna Music Society is an orchestra.\nBeethoven leads the Vienna Music Society.\nOrchestras are led by conductors.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Beethoven is a composer.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Some orchestras premiered music pieces.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Beethoven is not a conductor.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Facts: Symphony No. 9 is a music piece. Composers write music pieces. Beethoven wrote Symphony No. 9. Vienna Music Society (VMS) premiered Symphony No. 9. VMS is an orchestra. Beethoven leads VMS. Orchestras are led by conductors.\n\nQuestion 1:\n- From \"Composers write music pieces\" we can only infer that being a composer implies writing music pieces, not the converse.\n- Beethoven wrote a music piece, but that alone does not prove he is a composer.\n- Conclusion: Unknown.\n\nQuestion 2:\n- VMS is an orchestra and it premiered Symphony No. 9, which is a music piece.\n- Therefore, at least one orchestra premiered a music piece.\n- Conclusion: True.\n\nQuestion 3:\n- Orchestras are led by conductors, and Beethoven leads VMS, an orchestra.\n- Therefore, Beethoven is a conductor.\n- The statement \"Beethoven is not a conductor\" is contradicted.\n- Conclusion: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 621,
        "conclusion": "Beethoven is a composer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 622,
        "conclusion": "Some orchestras premiered music pieces.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 623,
        "conclusion": "Beethoven is not a conductor.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 350,
    "premises": "S. However, due to the Greco-Turkish War during that period and the political instability that followed it soon became evident that the large telescope for the observatory would not materialise. All of Zaha Hadid's design styles that Max adores have interesting geometries.\nNo brutalist buildings that Max adores have interesting geometries.\nEvery style that Max adores is either Zaha Hadid's design style or Kelly Wearstler's design style. \nAll of Kelly Wearstler's design styles that Max adores are evocative.\nAll of Kelly Wearstler's design styles that Max adores are dreamy.\nIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: S. However, due to the Greco-Turkish War during that period and the political instability that followed it soon became evident that the large telescope for the observatory would not materialise. All of Zaha Hadid's design styles that Max adores have interesting geometries.\nNo brutalist buildings that Max adores have interesting geometries.\nEvery style that Max adores is either Zaha Hadid's design style or Kelly Wearstler's design style. \nAll of Kelly Wearstler's design styles that Max adores are evocative.\nAll of Kelly Wearstler's design styles that Max adores are dreamy.\nIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? A design by Max is a brutalist building.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? A design by Max is evocative and dreamy.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? A design by Max is either evocative or dreamy.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- The premises only give conditional statements about items Max adores (styles or designs). They do not assert that any design by Max exists, nor that any particular property (brutalist, evocative, dreamy) applies to any existing design by Max.\n- From \u201cIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative\u201d together with \u201cNo brutalist buildings that Max adores have interesting geometries,\u201d we can infer that no design by Max that he adores can have interesting geometries. This still does not establish the existence of any design by Max, nor that any is brutalist, evocative, or dreamy.\n\nQuestion 1: \u201cA design by Max is a brutalist building.\u201d\n- There is no existential guarantee of any design by Max being brutalist (or existing). Unknown.\n\nQuestion 2: \u201cA design by Max is evocative and dreamy.\u201d\n- Only adored Kelly Wearstler styles are guaranteed evocative and dreamy, but there\u2019s no existence claim tying this to a design by Max. Unknown.\n\nQuestion 3: \u201cA design by Max is either evocative or dreamy.\u201d\n- Same issue: no existential guarantee. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 927,
        "conclusion": "A design by Max is a brutalist building.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 928,
        "conclusion": "A design by Max is evocative and dreamy.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 929,
        "conclusion": "A design by Max is either evocative or dreamy.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 385,
    "premises": "Matthew Gray (born 24 June 1973) is an Australian archer. By placing the wood into water, the moisture and heat from the bending iron will reform the structure of the wood, reorganizing the fibers of the wood to prevent the wood from springing back to its original state. If someone is ranked highly by the Women's Tennis Association, then they are one of the most active players in major tennis. \nEveryone who lost to Iga \u015awi\u0105tek at Roland Garros 2022 is ranked highly by the Women's Tennis Association.\nAll female tennis players at Roland Garros 2022 lost to Iga \u015awi\u0105tek.\nAll tennis players at Roland Garros 2022 are either female or male.\nAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal.\nIf Coco Gauff is ranked highly by the Women's Tennis Association or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nCoco Gauff is at Roland Garros 2022.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Matthew Gray (born 24 June 1973) is an Australian archer. By placing the wood into water, the moisture and heat from the bending iron will reform the structure of the wood, reorganizing the fibers of the wood to prevent the wood from springing back to its original state. If someone is ranked highly by the Women's Tennis Association, then they are one of the most active players in major tennis. \nEveryone who lost to Iga \u015awi\u0105tek at Roland Garros 2022 is ranked highly by the Women's Tennis Association.\nAll female tennis players at Roland Garros 2022 lost to Iga \u015awi\u0105tek.\nAll tennis players at Roland Garros 2022 are either female or male.\nAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal.\nIf Coco Gauff is ranked highly by the Women's Tennis Association or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nCoco Gauff is at Roland Garros 2022.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Coco Gauff is among the most active Grand-Slam players.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Coco Gauff has lost to Rafael Nadal.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Coco Gauff is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \"Coco Gauff is at Roland Garros 2022\" and \"All tennis players at Roland Garros 2022 are either female or male,\" Coco is female or male.\n- Case analysis:\n  - If female: then she lost to Iga \u015awi\u0105tek; hence ranked highly; hence among the most active players in major tennis; thus by the conditional, she is not male.\n  - If male: then she lost to Rafael Nadal; by the conditional, she is not male.\n- Therefore, in all cases, Coco is not male. Using \"female or male\" and \"not male,\" we conclude she is female.\n- As female at Roland Garros 2022, she lost to Iga \u015awi\u0105tek; hence ranked highly; hence among the most active players in major tennis.\n\nQuestion 1: From above, Coco is among the most active players in major tennis. True.\n\nQuestion 2: We only know all male players lost to Nadal. Since Coco is not male (and we have no rule that only males lost to Nadal), whether she lost to Nadal is not determined. Unknown.\n\nQuestion 3: We established Coco both lost to Iga \u015awi\u0105tek and is among the most active players in major tennis. So the statement that she is not both is false. False.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1029,
        "conclusion": "Coco Gauff is among the most active Grand-Slam players.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1030,
        "conclusion": "Coco Gauff has lost to Rafael Nadal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1031,
        "conclusion": "Coco Gauff is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 256,
    "premises": "Aksana Miankova, also transliterated as Oksana Menkova, (Belarusian: \u0410\u043a\u0441\u0430\u043d\u0430 \u041c\u044f\u043d\u044c\u043a\u043e\u0432\u0430, born 28 March 1982) is a Belarusian former hammer thrower. Its length is up to 39 centimetres (15 in). All cats are mammals.\nSome pets are not mammals.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: Aksana Miankova, also transliterated as Oksana Menkova, (Belarusian: \u0410\u043a\u0441\u0430\u043d\u0430 \u041c\u044f\u043d\u044c\u043a\u043e\u0432\u0430, born 28 March 1982) is a Belarusian former hammer thrower. Its length is up to 39 centimetres (15 in). All cats are mammals.\nSome pets are not mammals.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? No pets are cats.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n- From \"All cats are mammals,\" every cat belongs to the set of mammals.\n- From \"Some pets are not mammals,\" there exists at least one pet that is not a mammal.\n- This does not rule out that some other pets could be mammals, and thus could be cats. Nor does it assert that any pet is a cat.\n- Therefore, the statement \"No pets are cats\" is not entailed or contradicted by the premises.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 700,
        "conclusion": "No pets are cats.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 159,
    "premises": "74) catalyzes the chemical reaction\n\n(3S)-3-hydroxyacyl-CoA \n  \n    \n      \n        \u21cc\n      \n    \n    {\\displaystyle \\rightleftharpoons }\n  \n trans-2-enoyl-CoA + H2O\nThis enzyme belongs to the family of lyases, specifically the hydro-lyases, which cleave carbon-oxygen bonds. Other notable artists to have worked on the character include Glenn Fabry, Simon Bisley, Clint Langley and Simon Davis. There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: 74) catalyzes the chemical reaction\n\n(3S)-3-hydroxyacyl-CoA \n  \n    \n      \n        \u21cc\n      \n    \n    {\\displaystyle \\rightleftharpoons }\n  \n trans-2-enoyl-CoA + H2O\nThis enzyme belongs to the family of lyases, specifically the hydro-lyases, which cleave carbon-oxygen bonds. Other notable artists to have worked on the character include Glenn Fabry, Simon Bisley, Clint Langley and Simon Davis. There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? James's favorite season is summer.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Mia's favorite season is spring.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\nQuestion 1:\n- Rule: All students who want a long vacation have summer as their favorite season.\n- Given: James wants to have a long vacation.\n- Missing: Whether James is a student.\n- Conclusion: The rule may not apply; James could still favor summer, but it\u2019s not entailed. Therefore, Unknown.\n\nQuestion 2:\n- Given: Emma's favorite season is summer. Mia's favorite is not the same as Emma's.\n- Therefore: Mia's favorite is not summer. Possible remaining favorites: spring, fall, or winter.\n- Conclusion: Insufficient information to assert spring specifically. Therefore, Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 456,
        "conclusion": "James's favorite season is summer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 457,
        "conclusion": "Mia's favorite season is spring.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 343,
    "premises": "He was subsequently re-elected in the redistricted Mayo-Tatchun in the 1992 election. Most commonly the more electronegative atom keeps the pair of electrons becoming anionic while the more electropositive atom becomes cationic. No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: He was subsequently re-elected in the redistricted Mayo-Tatchun in the 1992 election. Most commonly the more electronegative atom keeps the pair of electrons becoming anionic while the more electropositive atom becomes cationic. No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? 1984 is printed text.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? 1984 is a streaming service.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? 1984 is not a streaming service.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Premises:\n  - No digital media are analog: Digital -> not Analog.\n  - Every printed text is analog media: Printed -> Analog.\n  - All streaming services are digital media: Streaming -> Digital.\n  - Hardcover -> Printed.\n  - If 1984 is a streaming service, then 1984 is a hardcover book: Streaming(1984) -> Hardcover(1984).\n\n- From these, if Streaming(1984), then:\n  - Streaming(1984) -> Hardcover(1984) -> Printed(1984) -> Analog(1984).\n  - And Streaming(1984) -> Digital(1984).\n  - With Digital -> not Analog, we get Analog(1984) and not Analog(1984), a contradiction.\n  - Therefore, Streaming(1984) implies false, so not Streaming(1984).\n\nQuestion 1:\n- We only get Printed(1984) if Streaming(1984) holds, but we derived not Streaming(1984). No other premise asserts 1984 is printed. So this is unknown.\n\nQuestion 2:\n- From the contradiction argument above, not Streaming(1984). So the statement that 1984 is a streaming service is false.\n\nQuestion 3:\n- As established, not Streaming(1984) is true.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 904,
        "conclusion": "1984 is printed text.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 905,
        "conclusion": "1984 is a streaming service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 906,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 213,
    "premises": "Four daily rituals and three yearly festivals are held at the temple, of which the Vaikasi Visagam, Adipooram and Navarathri uthsavam, Annabishekam and Theerthavari are some of the prominent festivals celebrated. It is centred on the Waikato which consists of Waikato District, Matamata-Piako District, Waip\u0101 District, South Waikato District and Hamilton City. All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Four daily rituals and three yearly festivals are held at the temple, of which the Vaikasi Visagam, Adipooram and Navarathri uthsavam, Annabishekam and Theerthavari are some of the prominent festivals celebrated. It is centred on the Waikato which consists of Waikato District, Matamata-Piako District, Waip\u0101 District, South Waikato District and Hamilton City. All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Basque is a Romance language.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? German is a Romance language.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? French is an Indo-European language.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Romance languages form a language family, and all languages within a family are related to each other.\n- French and Spanish are Romance, so any Romance language would be related to them.\n- Basque is stated to be not related to any other language.\n- Therefore Basque cannot be a Romance language.\nConclusion: False.\n\nQuestion 2:\n- German is related to Spanish.\n- All members of a language family are related, but we are not told that being related implies being in the same family.\n- There is no explicit statement that German is in the Romance family.\nConclusion: Unknown.\n\nQuestion 3:\n- French is a Romance language.\n- All Romance languages are Indo-European.\n- Therefore French is Indo-European.\nConclusion: True.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 608,
        "conclusion": "Basque is a Romance language.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 609,
        "conclusion": "German is a Romance language.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 610,
        "conclusion": "French is an Indo-European language.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 79,
    "premises": "Jorma Ojaharju's style of writing has been compared with Colombian novelist Gabriel Garc\u00eda M\u00e1rquez who is widely considered the leading exponent of the literary style called magical realism. g. Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Jorma Ojaharju's style of writing has been compared with Colombian novelist Gabriel Garc\u00eda M\u00e1rquez who is widely considered the leading exponent of the literary style called magical realism. g. Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Robert Lewandowski is a soccer player.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Robert Lewandowski plays for Bayern Munchen.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Robert Lewandowski is a star.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. We are told Robert Lewandowski is a striker, and that strikers are soccer players. Therefore, Robert Lewandowski is a soccer player.\n2. We are told Robert Lewandowski left Bayern Munchen, and that if a player leaves a team, they no longer play for that team. Therefore, he does not play for Bayern Munchen.\n3. There is no information stating or implying that Robert Lewandowski is a star. Thus, we cannot conclude this.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 240,
        "conclusion": "Robert Lewandowski is a soccer player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 241,
        "conclusion": "Robert Lewandowski plays for Bayern Munchen.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 242,
        "conclusion": "Robert Lewandowski is a star.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 2,
    "premises": "There is a museum and tea shop on one side of the lake and a restaurant on the other. TAIP may refer to:\n\nTaiwan Independence Party, a left-wing political party in Taiwan\nTransportes A\u00e9reos da \u00cdndia Portuguesa\nTrimble ASCII Interface Protocol, a communications protocol for Global Positioning Systems\nYES (Lithuanian: TAIP), a political party in Lithuania. Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: There is a museum and tea shop on one side of the lake and a restaurant on the other. TAIP may refer to:\n\nTaiwan Independence Party, a left-wing political party in Taiwan\nTransportes A\u00e9reos da \u00cdndia Portuguesa\nTrimble ASCII Interface Protocol, a communications protocol for Global Positioning Systems\nYES (Lithuanian: TAIP), a political party in Lithuania. Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Butte and St Pierre are in the same state.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? St Pierre and Bismarck are in the same state.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Montana is home to the city of Missoula.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. Butte is explicitly stated to be in Montana. St Pierre is explicitly stated to not be in Montana. Since Butte is only in one state (and not an exception city), they cannot be in the same state. So the statement is false.\n2. The text gives no information about Bismarck\u2019s state, and only states that St Pierre is not in Montana. Without information on Bismarck, we cannot determine if they share a state. So it is unknown.\n3. The text explicitly says Montana includes Missoula. Therefore, Montana is home to Missoula. True.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 4,
        "conclusion": "Butte and St Pierre are in the same state.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 5,
        "conclusion": "St Pierre and Bismarck are in the same state.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 6,
        "conclusion": "Montana is home to the city of Missoula.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 192,
    "premises": "Common examples include strut seals, hydraulic pump seals, axle seals, power steering seals, and valve stem seals. Thaumogenesis is the seventh full-length album by drone doom band Nadja, it was released in January 2007 by aRCHIVE recordings. International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: Common examples include strut seals, hydraulic pump seals, axle seals, power steering seals, and valve stem seals. Thaumogenesis is the seventh full-length album by drone doom band Nadja, it was released in January 2007 by aRCHIVE recordings. International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Mike has an F1 visa.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Mike has a J1 visa.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- We know: International students in the US have either an F1 or J1 visa. But it\u2019s not stated that Mike is in the US; only that he is an international student.\n- We also know: If an international student in the US has an F1 visa and wants to work in the US, they need to apply for CPT or OPT.\n- The statement about Mike says he needs to apply for CPT if he wants to work in the US. This does not logically imply he has an F1 visa (it would be affirming the consequent), and the text does not specify requirements for J1. Therefore, we cannot conclude whether Mike has F1 or J1.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 548,
        "conclusion": "Mike has an F1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 549,
        "conclusion": "Mike has a J1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 442,
    "premises": "He was an above average athlete participating in various sports. Scientists classify diamonds into four main types according to the nature of crystallographic defects present. All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: He was an above average athlete participating in various sports. Scientists classify diamonds into four main types according to the nature of crystallographic defects present. All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Ted is a pet.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Ted is a pet and Brown Swiss cattle\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Ted is a Brown Swiss cattle, then Ted is not a pet.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From All Brown Swiss cattle are cows and All cows are domesticated animals, we get: All Brown Swiss cattle are domesticated.\n- From Alligators are not domesticated animals and Ted is an alligator, we get: Ted is not domesticated.\n- By modus tollens, since Brown Swiss cattle implies domesticated but Ted is not domesticated, Ted is not Brown Swiss cattle.\n\nQuestion 1:\n- We have no premise linking being a pet to being an alligator or to domestication. \u201cSome pets are Brown Swiss cattle\u201d does not involve Ted. So we cannot determine whether Ted is a pet. Answer: Unknown.\n\nQuestion 2:\n- The statement asserts Ted is both a pet and Brown Swiss cattle. We have established Ted is not Brown Swiss cattle, so the conjunction is false regardless of his pet status. Answer: False.\n\nQuestion 3:\n- The conditional \u201cIf Ted is a Brown Swiss cattle, then Ted is not a pet\u201d has a false antecedent (Ted is not Brown Swiss cattle) given the premises, making the implication vacuously true. Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1271,
        "conclusion": "Ted is a pet.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1272,
        "conclusion": "Ted is a pet and Brown Swiss cattle",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1273,
        "conclusion": "If Ted is a Brown Swiss cattle, then Ted is not a pet.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 234,
    "premises": "The destructive dilemma rule can be stated:\n\n  \n    \n      \n        \n          \n            \n              P\n              \u2192\n              Q\n              ,\n              R\n              \u2192\n              S\n              ,\n              \u00ac\n              Q\n              \u2228\n              \u00ac\n              S\n            \n            \n              \u2234\n              \u00ac\n              P\n              \u2228\n              \u00ac\n              R\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {P\\to Q,R\\to S,\\neg Q\\lor \\neg S}{\\therefore \\neg P\\lor \\neg R}}}\n  \n\nwhere the rule is that wherever instances of \"\n  \n    \n      \n        P\n        \u2192\n        Q\n      \n    \n    {\\displaystyle P\\to Q}\n  \n\", \"\n  \n    \n      \n        R\n        \u2192\n        S\n      \n    \n    {\\displaystyle R\\to S}\n  \n\", and \"\n  \n    \n      \n        \u00ac\n        Q\n        \u2228\n        \u00ac\n        S\n      \n    \n    {\\displaystyle \\neg Q\\lor \\neg S}\n  \n\" appear on lines of a proof, \"\n  \n    \n      \n        \u00ac\n        P\n        \u2228\n        \u00ac\n        R\n      \n    \n    {\\displaystyle \\neg P\\lor \\neg R}\n  \n\" can be placed on a subsequent line. The transmitter site is atop Sauratown Mountain near Pinnacle, North Carolina. Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The destructive dilemma rule can be stated:\n\n  \n    \n      \n        \n          \n            \n              P\n              \u2192\n              Q\n              ,\n              R\n              \u2192\n              S\n              ,\n              \u00ac\n              Q\n              \u2228\n              \u00ac\n              S\n            \n            \n              \u2234\n              \u00ac\n              P\n              \u2228\n              \u00ac\n              R\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {P\\to Q,R\\to S,\\neg Q\\lor \\neg S}{\\therefore \\neg P\\lor \\neg R}}}\n  \n\nwhere the rule is that wherever instances of \"\n  \n    \n      \n        P\n        \u2192\n        Q\n      \n    \n    {\\displaystyle P\\to Q}\n  \n\", \"\n  \n    \n      \n        R\n        \u2192\n        S\n      \n    \n    {\\displaystyle R\\to S}\n  \n\", and \"\n  \n    \n      \n        \u00ac\n        Q\n        \u2228\n        \u00ac\n        S\n      \n    \n    {\\displaystyle \\neg Q\\lor \\neg S}\n  \n\" appear on lines of a proof, \"\n  \n    \n      \n        \u00ac\n        P\n        \u2228\n        \u00ac\n        R\n      \n    \n    {\\displaystyle \\neg P\\lor \\neg R}\n  \n\" can be placed on a subsequent line. The transmitter site is atop Sauratown Mountain near Pinnacle, North Carolina. Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? A private Ivy League research university moved to New Haven.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Yale University has the largest university endowment of any educational institution.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Pierson College is a residential college at Yale.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. The text states that Yale University is a private Ivy League research university and that Yale University moved to New Haven in 1716. Therefore, a private Ivy League research university moved to New Haven.\n2. The text only provides Yale\u2019s endowment value ($42.3 billion) but does not compare it to other institutions. Thus, we cannot conclude it is the largest based on the given information.\n3. The text explicitly lists Pierson College among Yale\u2019s residential colleges.\n\nANSWERS:\n1: True\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 663,
        "conclusion": "A private Ivy League research university moved to New Haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 664,
        "conclusion": "Yale University has the largest university endowment of any educational institution.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 665,
        "conclusion": "Pierson College is a residential college at Yale.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 120,
    "premises": "FRCs were a major area of research in the 1960s and into the 1970s, but had problems scaling up into practical fusion triple products (target combinations of density, temperature and confinement time). By 1950, he and his team had produced some of the first high-quality X-ray diffraction images of DNA fibers. Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: FRCs were a major area of research in the 1960s and into the 1970s, but had problems scaling up into practical fusion triple products (target combinations of density, temperature and confinement time). By 1950, he and his team had produced some of the first high-quality X-ray diffraction images of DNA fibers. Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1) The working title \"The Secret Dude Society\" was used for Badults, and Andrew Collins was the script editor for Badults. Therefore, he was the script editor for a series with that working title.\n2) Badults stars members of Pappy's and was piloted on BBC Three. Therefore, there exists at least one instance of members of Pappy's starring in a show piloting on BBC Three, contradicting the statement.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 360,
        "conclusion": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 361,
        "conclusion": "No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 322,
    "premises": "Jakarta International Java Jazz Festival (JJF) is one of the largest jazz festivals in the world. Several ships of the French Navy have been named in honour of Anne Hilarion de Tourville. All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Jakarta International Java Jazz Festival (JJF) is one of the largest jazz festivals in the world. Several ships of the French Navy have been named in honour of Anne Hilarion de Tourville. All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? KO is a stock.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? KO is a stock and a growth stock.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Let G(x) = x is a growth stock; R(x) = x is bought for rapid price appreciation; S(x) = x is suitable for a retirement fund; M(x) = x is a mature stock; Stock(x) = x is a stock.\n- From \u201cAll growth stocks are bought to earn profits from rapid price appreciation\u201d: G(x) -> R(x).\n- From \u201cIf bought to earn profits from rapid price appreciation, then not suitable for a retirement fund\u201d: R(x) -> \u00acS(x). Hence G(x) -> \u00acS(x), and by contrapositive S(x) -> \u00acG(x) and S(x) -> \u00acR(x).\n- From \u201cAll mature stocks are suitable for a retirement fund\u201d and \u201cKO is a mature stock\u201d: M(KO) and thus S(KO). \u201cMature stock\u201d entails it is a stock, so Stock(KO). Also, from S(KO), we get \u00acG(KO) and \u00acR(KO).\n\nQuestion 1:\n- KO is a mature stock, hence a stock. True.\n\nQuestion 2:\n- KO is a stock, but not a growth stock (since S(KO) -> \u00acG(KO)). So the conjunction \u201cstock and growth stock\u201d is false.\n\nQuestion 3:\n- Antecedent \u201cKO is a growth stock or bought to earn profits from rapid price appreciation\u201d is false (\u00acG(KO) and \u00acR(KO)). A conditional with a false antecedent is true, regardless of the consequent (we also don\u2019t have information about price volatility). So the statement is true.\n\nANSWERS:\n1: True\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 819,
        "conclusion": "KO is a stock.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 820,
        "conclusion": "KO is a stock and a growth stock.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 821,
        "conclusion": "If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 159,
    "premises": "74) catalyzes the chemical reaction\n\n(3S)-3-hydroxyacyl-CoA \n  \n    \n      \n        \u21cc\n      \n    \n    {\\displaystyle \\rightleftharpoons }\n  \n trans-2-enoyl-CoA + H2O\nThis enzyme belongs to the family of lyases, specifically the hydro-lyases, which cleave carbon-oxygen bonds. Other notable artists to have worked on the character include Glenn Fabry, Simon Bisley, Clint Langley and Simon Davis. There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: 74) catalyzes the chemical reaction\n\n(3S)-3-hydroxyacyl-CoA \n  \n    \n      \n        \u21cc\n      \n    \n    {\\displaystyle \\rightleftharpoons }\n  \n trans-2-enoyl-CoA + H2O\nThis enzyme belongs to the family of lyases, specifically the hydro-lyases, which cleave carbon-oxygen bonds. Other notable artists to have worked on the character include Glenn Fabry, Simon Bisley, Clint Langley and Simon Davis. There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? James's favorite season is summer.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Mia's favorite season is spring.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: All students who want a long vacation have summer as their favorite season.\n- Given: James wants to have a long vacation.\n- Missing: Whether James is a student.\n- Conclusion: Since the rule applies only to students and we don't know if James is a student, we cannot conclude his favorite season is summer.\n\nQuestion 2:\n- Given: Emma's favorite season is summer.\n- Given: Mia's favorite season is not the same as Emma's, so Mia's is not summer.\n- Given: Seasons are Spring, Summer, Fall, Winter.\n- Conclusion: Mia could prefer Spring, Fall, or Winter; we cannot determine that it is Spring specifically.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 456,
        "conclusion": "James's favorite season is summer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 457,
        "conclusion": "Mia's favorite season is spring.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 343,
    "premises": "He was subsequently re-elected in the redistricted Mayo-Tatchun in the 1992 election. Most commonly the more electronegative atom keeps the pair of electrons becoming anionic while the more electropositive atom becomes cationic. No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: He was subsequently re-elected in the redistricted Mayo-Tatchun in the 1992 election. Most commonly the more electronegative atom keeps the pair of electrons becoming anionic while the more electropositive atom becomes cationic. No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? 1984 is printed text.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? 1984 is a streaming service.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? 1984 is not a streaming service.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- From premises: Hardcover \u2192 Printed, and (If 1984 is Streaming) \u2192 Hardcover. Thus, if 1984 were streaming, it would be printed.\n- However, we do not have any premise that asserts 1984 is streaming or hardcover outright.\n- Therefore, we cannot conclude 1984 is printed. Status: Unknown.\n\nQuestion 2:\n- Assume 1984 is a streaming service. Then:\n  - Streaming \u2192 Digital (all streaming services are digital).\n  - Digital \u2192 not Analog (no digital media are analog).\n  - Also, Streaming \u2192 Hardcover (given), and Hardcover \u2192 Printed, and Printed \u2192 Analog.\n  - Thus, Streaming implies both Analog and not Analog, a contradiction.\n- Therefore, 1984 is not a streaming service. The statement \"1984 is a streaming service\" is False.\n\nQuestion 3:\n- From the reasoning in Question 2, we derived not Streaming(1984).\n- Therefore, \"1984 is not a streaming service\" is True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 904,
        "conclusion": "1984 is printed text.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 905,
        "conclusion": "1984 is a streaming service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 906,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 213,
    "premises": "Four daily rituals and three yearly festivals are held at the temple, of which the Vaikasi Visagam, Adipooram and Navarathri uthsavam, Annabishekam and Theerthavari are some of the prominent festivals celebrated. It is centred on the Waikato which consists of Waikato District, Matamata-Piako District, Waip\u0101 District, South Waikato District and Hamilton City. All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Four daily rituals and three yearly festivals are held at the temple, of which the Vaikasi Visagam, Adipooram and Navarathri uthsavam, Annabishekam and Theerthavari are some of the prominent festivals celebrated. It is centred on the Waikato which consists of Waikato District, Matamata-Piako District, Waip\u0101 District, South Waikato District and Hamilton City. All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Basque is a Romance language.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? German is a Romance language.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? French is an Indo-European language.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Romance languages are a language family.\n- All languages within a language family are related to each other.\n- French and Spanish are Romance, so the Romance family has multiple members.\n- Basque is not related to any other language.\n- If Basque were Romance, it would be related to French/Spanish, contradicting the premise.\n- Therefore, the statement is false.\n\nQuestion 2:\n- German is related to Spanish, and Spanish is Romance.\n- We know: same family implies related, but we are not given that related implies same family.\n- Thus, German being related to a Romance language does not entail German is Romance.\n- Insufficient information to conclude; it could be either way.\n- Therefore, the statement is unknown.\n\nQuestion 3:\n- All Romance languages are Indo-European.\n- French is a Romance language.\n- Therefore, French is Indo-European.\n- The statement is true.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 608,
        "conclusion": "Basque is a Romance language.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 609,
        "conclusion": "German is a Romance language.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 610,
        "conclusion": "French is an Indo-European language.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 79,
    "premises": "Jorma Ojaharju's style of writing has been compared with Colombian novelist Gabriel Garc\u00eda M\u00e1rquez who is widely considered the leading exponent of the literary style called magical realism. g. Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Jorma Ojaharju's style of writing has been compared with Colombian novelist Gabriel Garc\u00eda M\u00e1rquez who is widely considered the leading exponent of the literary style called magical realism. g. Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Robert Lewandowski is a soccer player.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Robert Lewandowski plays for Bayern Munchen.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Robert Lewandowski is a star.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1: From \"Robert Lewandowski is a striker\" and \"Strikers are soccer players,\" it follows that Robert Lewandowski is a soccer player. Therefore, the statement is true.\n2: We are told \"Robert Lewandowski left Bayern Munchen\" and \"If a player leaves a team they no longer play for that team.\" Thus, he does not play for Bayern Munchen. Therefore, the statement that he plays for Bayern Munchen is false.\n3: There is no information stating or implying that Robert Lewandowski is a \"star.\" Being a striker or a soccer player does not entail being a star. Therefore, this is unknown based on the given information.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 240,
        "conclusion": "Robert Lewandowski is a soccer player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 241,
        "conclusion": "Robert Lewandowski plays for Bayern Munchen.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 242,
        "conclusion": "Robert Lewandowski is a star.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 2,
    "premises": "There is a museum and tea shop on one side of the lake and a restaurant on the other. TAIP may refer to:\n\nTaiwan Independence Party, a left-wing political party in Taiwan\nTransportes A\u00e9reos da \u00cdndia Portuguesa\nTrimble ASCII Interface Protocol, a communications protocol for Global Positioning Systems\nYES (Lithuanian: TAIP), a political party in Lithuania. Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: There is a museum and tea shop on one side of the lake and a restaurant on the other. TAIP may refer to:\n\nTaiwan Independence Party, a left-wing political party in Taiwan\nTransportes A\u00e9reos da \u00cdndia Portuguesa\nTrimble ASCII Interface Protocol, a communications protocol for Global Positioning Systems\nYES (Lithuanian: TAIP), a political party in Lithuania. Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Butte and St Pierre are in the same state.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? St Pierre and Bismarck are in the same state.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Montana is home to the city of Missoula.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: Butte is in Montana.\n- Given: St Pierre is not in Montana.\n- Since a city can only be in one state (and neither is listed as an exception), they cannot share the same state.\n- Conclusion: False.\n\nQuestion 2:\n- No information is provided about Bismarck\u2019s state.\n- We only know St Pierre is not in Montana; nothing else about its state.\n- Conclusion: Unknown.\n\nQuestion 3:\n- Given: The state of Montana includes Missoula.\n- Therefore, Montana is home to Missoula.\n- Conclusion: True.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 4,
        "conclusion": "Butte and St Pierre are in the same state.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 5,
        "conclusion": "St Pierre and Bismarck are in the same state.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 6,
        "conclusion": "Montana is home to the city of Missoula.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 192,
    "premises": "Common examples include strut seals, hydraulic pump seals, axle seals, power steering seals, and valve stem seals. Thaumogenesis is the seventh full-length album by drone doom band Nadja, it was released in January 2007 by aRCHIVE recordings. International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: Common examples include strut seals, hydraulic pump seals, axle seals, power steering seals, and valve stem seals. Thaumogenesis is the seventh full-length album by drone doom band Nadja, it was released in January 2007 by aRCHIVE recordings. International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Mike has an F1 visa.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Mike has a J1 visa.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cInternational students in the US have either an F1 visa or a J1 visa\u201d and \u201cMike is an international student,\u201d Mike has either F1 or J1.\n- The rule given: If an international student has an F1 visa and wants to work, they need to apply for CPT or OPT.\n- We are told: \u201cMike needs to apply for CPT if he wants to work in the US.\u201d This is consistent with F1, but the provided information does not state that only F1 students need CPT or that J1 students cannot also need CPT. The implication given is one-way (F1 \u21d2 needs CPT/OPT), not biconditional. Therefore, we cannot conclude whether Mike is F1 or J1.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 548,
        "conclusion": "Mike has an F1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 549,
        "conclusion": "Mike has a J1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 442,
    "premises": "He was an above average athlete participating in various sports. Scientists classify diamonds into four main types according to the nature of crystallographic defects present. All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: He was an above average athlete participating in various sports. Scientists classify diamonds into four main types according to the nature of crystallographic defects present. All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Ted is a pet.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Ted is a pet and Brown Swiss cattle\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Ted is a Brown Swiss cattle, then Ted is not a pet.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nGiven facts:\n- All Brown Swiss cattle are cows. So B(x) \u2192 C(x).\n- All cows are domesticated animals. So C(x) \u2192 D(x).\n- Therefore, all Brown Swiss cattle are domesticated. So B(x) \u2192 D(x).\n- Alligators are not domesticated animals. So A(x) \u2192 \u00acD(x).\n- Ted is an alligator. So A(Ted), hence \u00acD(Ted).\n- From B(x) \u2192 D(x) and \u00acD(Ted), we get \u00acB(Ted).\n\nQuestion 1:\nWe have no rule relating being a pet to domestication. The fact that some pets are Brown Swiss cattle doesn\u2019t imply anything about Ted. Thus whether Ted is a pet is not determined. Answer: Unknown.\n\nQuestion 2:\nThe statement asserts Ted is both a pet and Brown Swiss cattle. We have deduced \u00acB(Ted). Therefore the conjunction is false. Answer: False.\n\nQuestion 3:\nIf Ted is Brown Swiss cattle, then Ted is not a pet. Since \u00acB(Ted), the antecedent is false, making the implication true (vacuously). Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1271,
        "conclusion": "Ted is a pet.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1272,
        "conclusion": "Ted is a pet and Brown Swiss cattle",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1273,
        "conclusion": "If Ted is a Brown Swiss cattle, then Ted is not a pet.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 234,
    "premises": "The destructive dilemma rule can be stated:\n\n  \n    \n      \n        \n          \n            \n              P\n              \u2192\n              Q\n              ,\n              R\n              \u2192\n              S\n              ,\n              \u00ac\n              Q\n              \u2228\n              \u00ac\n              S\n            \n            \n              \u2234\n              \u00ac\n              P\n              \u2228\n              \u00ac\n              R\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {P\\to Q,R\\to S,\\neg Q\\lor \\neg S}{\\therefore \\neg P\\lor \\neg R}}}\n  \n\nwhere the rule is that wherever instances of \"\n  \n    \n      \n        P\n        \u2192\n        Q\n      \n    \n    {\\displaystyle P\\to Q}\n  \n\", \"\n  \n    \n      \n        R\n        \u2192\n        S\n      \n    \n    {\\displaystyle R\\to S}\n  \n\", and \"\n  \n    \n      \n        \u00ac\n        Q\n        \u2228\n        \u00ac\n        S\n      \n    \n    {\\displaystyle \\neg Q\\lor \\neg S}\n  \n\" appear on lines of a proof, \"\n  \n    \n      \n        \u00ac\n        P\n        \u2228\n        \u00ac\n        R\n      \n    \n    {\\displaystyle \\neg P\\lor \\neg R}\n  \n\" can be placed on a subsequent line. The transmitter site is atop Sauratown Mountain near Pinnacle, North Carolina. Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The destructive dilemma rule can be stated:\n\n  \n    \n      \n        \n          \n            \n              P\n              \u2192\n              Q\n              ,\n              R\n              \u2192\n              S\n              ,\n              \u00ac\n              Q\n              \u2228\n              \u00ac\n              S\n            \n            \n              \u2234\n              \u00ac\n              P\n              \u2228\n              \u00ac\n              R\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {P\\to Q,R\\to S,\\neg Q\\lor \\neg S}{\\therefore \\neg P\\lor \\neg R}}}\n  \n\nwhere the rule is that wherever instances of \"\n  \n    \n      \n        P\n        \u2192\n        Q\n      \n    \n    {\\displaystyle P\\to Q}\n  \n\", \"\n  \n    \n      \n        R\n        \u2192\n        S\n      \n    \n    {\\displaystyle R\\to S}\n  \n\", and \"\n  \n    \n      \n        \u00ac\n        Q\n        \u2228\n        \u00ac\n        S\n      \n    \n    {\\displaystyle \\neg Q\\lor \\neg S}\n  \n\" appear on lines of a proof, \"\n  \n    \n      \n        \u00ac\n        P\n        \u2228\n        \u00ac\n        R\n      \n    \n    {\\displaystyle \\neg P\\lor \\neg R}\n  \n\" can be placed on a subsequent line. The transmitter site is atop Sauratown Mountain near Pinnacle, North Carolina. Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? A private Ivy League research university moved to New Haven.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Yale University has the largest university endowment of any educational institution.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Pierson College is a residential college at Yale.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. The text states \u201cYale University is a private Ivy League research university\u201d and \u201cYale University moved to New Haven in 1716,\u201d so a private Ivy League research university moved to New Haven. True.\n2. The text only provides Yale\u2019s endowment value ($42.3 billion) and does not compare it to others. Therefore, we cannot conclude it is the largest from the given information. Unknown.\n3. The text lists Pierson College among Yale\u2019s residential colleges. True.\n\nANSWERS:\n1: True\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 663,
        "conclusion": "A private Ivy League research university moved to New Haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 664,
        "conclusion": "Yale University has the largest university endowment of any educational institution.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 665,
        "conclusion": "Pierson College is a residential college at Yale.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 120,
    "premises": "FRCs were a major area of research in the 1960s and into the 1970s, but had problems scaling up into practical fusion triple products (target combinations of density, temperature and confinement time). By 1950, he and his team had produced some of the first high-quality X-ray diffraction images of DNA fibers. Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: FRCs were a major area of research in the 1960s and into the 1970s, but had problems scaling up into practical fusion triple products (target combinations of density, temperature and confinement time). By 1950, he and his team had produced some of the first high-quality X-ray diffraction images of DNA fibers. Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. The working title \"The Secret Dude Society\" was used for Badults, and Andrew Collins was the script editor for Badults. Therefore, he was the script editor for a series with that working title. True.\n2. Badults starred members of Pappy's and was piloted on BBC Three. Thus, it is not true that no members of Pappy's have starred in a show piloting on BBC Two or BBC Three. False.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 360,
        "conclusion": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 361,
        "conclusion": "No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 322,
    "premises": "Jakarta International Java Jazz Festival (JJF) is one of the largest jazz festivals in the world. Several ships of the French Navy have been named in honour of Anne Hilarion de Tourville. All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Jakarta International Java Jazz Festival (JJF) is one of the largest jazz festivals in the world. Several ships of the French Navy have been named in honour of Anne Hilarion de Tourville. All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? KO is a stock.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? KO is a stock and a growth stock.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- Given: All growth stocks -> bought for rapid price appreciation.\n- Given: If something is bought for rapid price appreciation -> not suitable for a retirement fund.\n- Therefore: All growth stocks -> not suitable for a retirement fund.\n- Given: All mature stocks -> suitable for a retirement fund.\n- Given: KO is a mature stock -> KO is a stock and KO is suitable for a retirement fund.\n- Contraposition steps used:\n  - From (growth -> not suitable), we get (suitable -> not growth).\n  - From (bought-for-rapid -> not suitable), we get (suitable -> not bought-for-rapid).\n\nQuestion 1:\n- KO is a mature stock, hence KO is a stock. True.\n\nQuestion 2:\n- KO is a stock (True) but, as shown, KO is not a growth stock (since KO is suitable). So \u201cKO is a stock and a growth stock\u201d is False.\n\nQuestion 3:\n- Antecedent: \u201cKO is a growth stock or bought to earn profits from rapid price appreciation.\u201d\n- From suitability, KO is neither a growth stock nor bought for rapid price appreciation, so the antecedent is False.\n- A conditional with a false antecedent is True regardless of the consequent. Therefore the statement is True.\n\nANSWERS:\n1: True\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 819,
        "conclusion": "KO is a stock.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 820,
        "conclusion": "KO is a stock and a growth stock.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 821,
        "conclusion": "If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 83,
    "premises": "In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). Healy is a station on Metra's Milwaukee District North Line in the Hermosa community area of Chicago, Illinois. All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). Healy is a station on Metra's Milwaukee District North Line in the Hermosa community area of Chicago, Illinois. All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Joe's license plate begins with the number 34.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Tom's license plate is from Istanbul.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Facts: All plates from Istanbul begin with 34. If a plate does not begin with 34, it is not from Istanbul. If a plate begins with 35, then it does not begin with 34.\n- Joe: His plate is from Istanbul. Therefore, by \u201cfrom Istanbul -> begins with 34,\u201d Joe\u2019s plate begins with 34.\n- Tom: His plate begins with 35, so it does not begin with 34. By \u201cnot 34 -> not from Istanbul,\u201d Tom\u2019s plate is not from Istanbul.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 253,
        "conclusion": "Joe's license plate begins with the number 34.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 254,
        "conclusion": "Tom's license plate is from Istanbul.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 368,
    "premises": "They released an album on Crypt Records in 1994 and a sophomore effort on Au Go Go Records in 1996. It is ranked as a top university of Pakistan for Agriculture/Veterinary and is ranked among top ten Pakistani universities in general category. If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: They released an album on Crypt Records in 1994 and a sophomore effort on Au Go Go Records in 1996. It is ranked as a top university of Pakistan for Agriculture/Veterinary and is ranked among top ten Pakistani universities in general category. If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Hannah needs to earn money to help pay for her college tuition.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cHannah is at Mary's school\u201d and \u201cIf people at Mary's school work in student jobs on campus, then they need to earn money\u2026\u201d, plus \u201cHannah works in student jobs on campus,\u201d we infer: Hannah needs to earn money.\n- From \u201cIf she needs to earn money\u2026, then she is neither picky nor needs to earn money,\u201d and the above fact that she needs money, we infer both not picky and not needing money. So we have a contradiction: she both needs money and does not need money. We can, however, safely conclude she is not a picky eater.\n- About spending time in dining halls: that follows only if she enjoys the dining hall meals. We only know that at Mary's school each person either orders takeout or enjoys the dining hall; we cannot conclude she enjoys them, so we cannot conclude she spends a lot of time in dining halls.\n\nQuestion 1:\n- We derive both \u201cHannah needs money\u201d and \u201cHannah does not need money.\u201d Due to this inconsistency, the truth of \u201cHannah needs money\u201d is uncertain.\n\nQuestion 2:\n- \u201cHannah is at Mary's school\u201d is true; \u201cshe is not a picky eater\u201d is derivable; but \u201cshe spends a lot of her time in the dining halls\u201d is not established (nor refuted). The whole conjunction is therefore uncertain.\n\nQuestion 3:\n- \u201cHannah is at Mary's school\u201d is true. The disjunction \u201cnot picky or (if picky then spends)\u201d is satisfied because we have already derived \u201cnot picky.\u201d Hence the whole statement is true.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 979,
        "conclusion": "Hannah needs to earn money to help pay for her college tuition.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 980,
        "conclusion": "Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 981,
        "conclusion": "Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 319,
    "premises": "Harry Elliott Alger (April 8, 1924 \u2013 January 27, 2010) was a provincial level politician from Alberta, Canada. His works can be found in permanent collections of Fototeca de Cuba and at the Museo Nacional de Bellas Artes de La Habana. No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: Harry Elliott Alger (April 8, 1924 \u2013 January 27, 2010) was a provincial level politician from Alberta, Canada. His works can be found in permanent collections of Fototeca de Cuba and at the Museo Nacional de Bellas Artes de La Habana. No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are products of Baked by Melissa.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are not products of Baked by Melissa.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are a mala hotpot.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are cupcakes and products of Baked by Melissa.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Cupcake \u2192 Baked sweet, and no baked sweets are spicy, so Cupcake \u2192 \u00acSpicy.\n- Baked by Melissa product \u2192 Cupcake \u2192 Baked sweet \u2192 \u00acSpicy.\n- Mala hotpot \u2192 Spicy.\n- Dried Thai chilies: Spicy or Mala hotpot or \u00acBaked sweet. In any of these cases, \u00acBaked sweet holds (since Spicy or Mala hotpot implies \u00acBaked sweet). Therefore Dried Thai chilies are not baked sweets, hence not cupcakes (contrapositive), hence not Baked by Melissa products (contrapositive).\n\nQuestion 1: If they were Baked by Melissa products, they\u2019d be cupcakes and baked sweets, contradicting the established \u00acBaked sweet. So False.\n\nQuestion 2: From above, they are not Baked by Melissa products. True.\n\nQuestion 3: The premises allow that they could be spicy without being a mala hotpot, so we can\u2019t conclude they are a mala hotpot. Unknown.\n\nQuestion 4: We established they are neither Baked by Melissa products nor baked sweets. True.\n\nQuestion 5: They are not cupcakes and not Baked by Melissa products, so the conjunction is false. False.\n\nANSWERS:\n1: False\n2: True\n3: Unknown\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 805,
        "conclusion": "Dried Thai chilies are products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 806,
        "conclusion": "Dried Thai chilies are not products of Baked by Melissa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 807,
        "conclusion": "Dried Thai chilies are a mala hotpot.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 808,
        "conclusion": "Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 809,
        "conclusion": "Dried Thai chilies are cupcakes and products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 306,
    "premises": "Judith Ellen Retchin (born May 24, 1952) is a senior judge of the Superior Court of the District of Columbia. E. If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Judith Ellen Retchin (born May 24, 1952) is a senior judge of the Superior Court of the District of Columbia. E. If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The Hamden Plaza store does not provide take-out service.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations\u201d and \u201cIf listed, then not many negative reviews,\u201d we have: Rating>4(x) -> Listed(x) -> \u00acManyNeg(x).\n- From \u201cAll popular restaurants have ratings > 4\u201d and \u201cHamden Plaza Subway store has rating > 4 or is popular,\u201d we deduce Rating>4(H) (since Popular(H) implies Rating>4(H), so Rating>4(H) \u2228 Popular(H) entails Rating>4(H)).\n- Therefore, Listed(H) and hence \u00acManyNeg(H).\n- Nothing in the premises determines whether H provides take-out service.\n\nQuestion 1:\n- Antecedent requires ManyNeg(H), which is false. Therefore the implication is vacuously true.\n\nQuestion 2:\n- We know \u00acManyNeg(H). Hence TakeOut(H) \u2228 \u00acManyNeg(H) is true.\n\nQuestion 3:\n- No information determines whether H provides take-out service. The existential about some non-takeout restaurants getting many negatives does not constrain H. So it\u2019s undetermined.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 754,
        "conclusion": "If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 755,
        "conclusion": "The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 756,
        "conclusion": "The Hamden Plaza store does not provide take-out service.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 245,
    "premises": "S. The EU\u2013US Open Skies Agreement is an open skies air transport agreement between the European Union (EU) and the United States (US). In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: S. The EU\u2013US Open Skies Agreement is an open skies air transport agreement between the European Union (EU) and the United States (US). In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Sir Digby\u2019s nemesis does not win.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1) The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\n2) If a superhero movie is named after a character, that character is a good guy; the movie is named after Sir Digby, so Sir Digby is a good guy.\n3) In superhero movies, the good guys always win; therefore, Sir Digby wins.\n4) Sir Digby fights his nemesis.\n5) If somebody wins a fight, the person they are fighting does not win; thus, Sir Digby\u2019s nemesis does not win.\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 688,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 58,
    "premises": "KTH is ranked 73rd in the world among all universities in the 2024 QS World University Rankings, which is higher than any other university in the Nordic countries. Shahnaz Sheikh (born 21 March 1949) is a retired Pakistani field hockey player. Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: KTH is ranked 73rd in the world among all universities in the 2024 QS World University Rankings, which is higher than any other university in the Nordic countries. Shahnaz Sheikh (born 21 March 1949) is a retired Pakistani field hockey player. Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Walden contains knowledge.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Harry is smarter than before.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? A smarter person has gained knowledge.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Walden is explicitly stated to be a book.\n- Premise: Books contain tons of knowledge. Therefore, Walden contains knowledge.\nConclusion: True.\n\nQuestion 2:\n- Premise: When a person reads a book, that person gains knowledge.\n- Harry read Walden, so Harry gains knowledge.\n- Premise: If a person gains knowledge, they become smarter.\n- Therefore Harry becomes smarter than before.\nConclusion: True.\n\nQuestion 3:\n- Premise: If a person gains knowledge, they become smarter. This gives only one direction (gaining knowledge \u2192 smarter).\n- The statement claims the converse (smarter \u2192 has gained knowledge), which is not supported.\n- No information rules out other ways to become smarter.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 171,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 172,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 173,
        "conclusion": "A smarter person has gained knowledge.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 191,
    "premises": "He mixed to good effect his poetic studies and his religious work. S. A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: He mixed to good effect his poetic studies and his religious work. S. A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Machine translation is a language generation task.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Machine translation is a language understanding task.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning for Question 1:\n- Premise: If the output of an NLP task is a text sequence, then it is a language generation task.\n- Premise: Machine translation is an NLP task, and its output is a text sequence.\n- Therefore, by modus ponens, machine translation is a language generation task.\n- Conclusion: The statement is true.\n\nReasoning for Question 2:\n- Premise: A natural language processing task can be categorized as either a language generation task or a language understanding task (mutually exclusive categorization).\n- From Question 1, machine translation is a language generation task.\n- Therefore, under this categorization, it is not a language understanding task.\n- Conclusion: The statement is false.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 546,
        "conclusion": "Machine translation is a language generation task.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 547,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 166,
    "premises": "The breed can also be prone to skin disorders such as the breed-specific condition hyperplastic dermatosis. The complex features a central LED pillar and interactive floor which is prominent next to BAR36. Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The breed can also be prone to skin disorders such as the breed-specific condition hyperplastic dermatosis. The complex features a central LED pillar and interactive floor which is prominent next to BAR36. Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Tom will rent an apartment in The Olive Garden.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Tom is allowed to move into an apartment in The Olive Garden with Fluffy.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The security deposit at the Olive Garden is either $2000 or more.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Question 1 reasoning:\n- The Olive Garden is a managed building with monthly rent $2000.\n- In managed buildings, the security deposit is equal to or more than the monthly rent, so at least $2000 (> $1500).\n- Tom will rent if he is allowed to move in with Fluffy and the deposit is no more than $1500. The deposit condition is not met at The Olive Garden, and we also don\u2019t know if pets are allowed there.\n- Therefore, we cannot conclude that Tom will rent an apartment in The Olive Garden.\n\nQuestion 2 reasoning:\n- Fluffy is Tom\u2019s cat; cats are pets, so Fluffy is a pet.\n- People are allowed to move in with a pet if a managed building allows pets.\n- We have no information that The Olive Garden allows pets (only that some managed buildings do).\n- Therefore, it\u2019s uncertain whether Tom is allowed to move in with Fluffy at The Olive Garden.\n\nQuestion 3 reasoning:\n- The Olive Garden is a managed building with monthly rent $2000.\n- For managed buildings, the security deposit is either equal to the monthly rent or more, and a deposit is required.\n- Therefore, at The Olive Garden the security deposit is $2000 or more.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 476,
        "conclusion": "Tom will rent an apartment in The Olive Garden.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 477,
        "conclusion": "Tom is allowed to move into an apartment in The Olive Garden with Fluffy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 478,
        "conclusion": "The security deposit at the Olive Garden is either $2000 or more.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 352,
    "premises": "Some of Sellow's scientific collections from Uruguay and Brazil are divided between the Museum of Natural History of Berlin, the Ethnological Museum of Berlin, and the Museum of Natural History of Vienna. Before the 1970s, the idea of rolling luggage was shunned by the travel industry, who viewed it as much less masculine than traditional luggage. All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Some of Sellow's scientific collections from Uruguay and Brazil are divided between the Museum of Natural History of Berlin, the Ethnological Museum of Berlin, and the Museum of Natural History of Vienna. Before the 1970s, the idea of rolling luggage was shunned by the travel industry, who viewed it as much less masculine than traditional luggage. All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The Harvard Weekly Book club has legal obligations.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The Harvard Weekly Book club has legal obligations and is a private company.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nGiven:\n- All business organizations are legal entities.\n- All companies are business organizations.\n- All private companies are companies.\n- All legal entities are created under law.\n- All legal entities have legal obligations.\n- If the Harvard Weekly Book Club is created under law, then it is not a private company.\n\nFrom \"private company\" \u2192 company \u2192 business organization \u2192 legal entity \u2192 created under law, and \"created under law\" \u2192 not a private company, we get:\n- If the Club were a private company, then it would not be a private company. Hence, the Club is not a private company.\n\nQuestion 1:\nWe only know legal entities have legal obligations. We do not know the Club is a legal entity (we only know it is not a private company). Thus we cannot conclude it has legal obligations. Answer: Unknown.\n\nQuestion 2:\nThe statement asserts the Club has legal obligations and is a private company. We established it is not a private company, so the conjunction is false. Answer: False.\n\nQuestion 3:\nIf the Club is a private company, then by the chain it is created under law. Therefore the disjunction \u201chas legal obligations or is created under law\u201d holds (the second disjunct is true). Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 933,
        "conclusion": "The Harvard Weekly Book club has legal obligations.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 934,
        "conclusion": "The Harvard Weekly Book club has legal obligations and is a private company.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 935,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 472,
    "premises": "Wall Street is a street which runs through the Financial District of New York City, which due to many financial centers being located on the street is further a metonym for the Economy of the United States. The Howden Insurance Mile is a New Zealand Thoroughbred horse race run at Hastings Racecourse in Hawke's Bay. Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Wall Street is a street which runs through the Financial District of New York City, which due to many financial centers being located on the street is further a metonym for the Economy of the United States. The Howden Insurance Mile is a New Zealand Thoroughbred horse race run at Hastings Racecourse in Hawke's Bay. Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Harry is a queen bee.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Harry is an invertebrate or a queen bee.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: All queen bees are bees; Harry is a bee.\n- There is no statement saying all bees are queen bees or that Harry is a queen bee.\n- Therefore, we cannot conclude Harry is a queen bee.\n- Answer: Unknown.\n\nQuestion 2:\n- We need: Harry is an invertebrate or a queen bee.\n- We cannot conclude Harry is a queen bee (from Q1).\n- For invertebrate: \u201cAnimals are either invertebrates or vertebrates\u201d applies only if Harry is an animal, but we are not given that bees are animals.\n- From Harry is a bee and all bees do not reproduce by male-and-female mating, plus \u201cAll animals with backbones reproduce by male-and-female mating,\u201d we can conclude \u00ac(Animal \u2227 Backbone) for Harry. This does not imply he is an invertebrate.\n- Therefore, we cannot conclude either disjunct.\n- Answer: Unknown.\n\nQuestion 3:\n- Antecedent: (Vertebrate \u2227 Animal-with-backbone) or (\u00acVertebrate \u2227 \u00ac(Animal-with-backbone)).\n- From Harry being a bee and the reproduction rules, we have \u00ac(Animal \u2227 Backbone) for Harry. So the first disjunct (Vertebrate \u2227 Animal-with-backbone) is false, and the antecedent reduces to \u00acVertebrate.\n- The consequent says Harry is neither an invertebrate nor a queen bee. We have no information that would force either negation.\n- Thus, whether the conditional holds is undetermined.\n- Answer: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1366,
        "conclusion": "Harry is a queen bee.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1367,
        "conclusion": "Harry is an invertebrate or a queen bee.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1368,
        "conclusion": "If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 83,
    "premises": "In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). Healy is a station on Metra's Milwaukee District North Line in the Hermosa community area of Chicago, Illinois. All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). Healy is a station on Metra's Milwaukee District North Line in the Hermosa community area of Chicago, Illinois. All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Joe's license plate begins with the number 34.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Tom's license plate is from Istanbul.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Given: All plates from Istanbul begin with 34. Contrapositive given: If not 34, then not from Istanbul.\n- Joe\u2019s plate is from Istanbul, so it must begin with 34.\n- Tom\u2019s plate begins with 35. If begins with 35, then it does not begin with 34. If not 34, then not from Istanbul. So Tom\u2019s plate is not from Istanbul.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 253,
        "conclusion": "Joe's license plate begins with the number 34.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 254,
        "conclusion": "Tom's license plate is from Istanbul.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 368,
    "premises": "They released an album on Crypt Records in 1994 and a sophomore effort on Au Go Go Records in 1996. It is ranked as a top university of Pakistan for Agriculture/Veterinary and is ranked among top ten Pakistani universities in general category. If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: They released an album on Crypt Records in 1994 and a sophomore effort on Au Go Go Records in 1996. It is ranked as a top university of Pakistan for Agriculture/Veterinary and is ranked among top ten Pakistani universities in general category. If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Hannah needs to earn money to help pay for her college tuition.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Facts and rules: At(Hannah). W(Hannah). If At \u2227 W then N. If At then (O \u2228 E). If At \u2227 E then \u00acP and S. Also: If N then (\u00acP \u2227 \u00acN).\n- From At and W and (At \u2227 W -> N), we get N(Hannah).\n- From N(Hannah) and (N -> \u00acP \u2227 \u00acN), we get \u00acP(Hannah) and \u00acN(Hannah). So we have both N and \u00acN, creating a contradiction about N.\n\nQuestion 1:\n- We derived both N(Hannah) and \u00acN(Hannah). Therefore, whether she needs to earn money is not determinable. Answer: Unknown.\n\nQuestion 2:\n- Need At \u2227 \u00acP \u2227 S. We have At and \u00acP (from N -> \u00acP and the earlier derivation of N). But S requires E (since At \u2227 E -> S), and we only know O \u2228 E, not E itself. So S is not entailed nor refuted. Answer: Unknown.\n\nQuestion 3:\n- Need At \u2227 [\u00acP \u2228 (P -> S)]. At is true. \u00acP is derivable as above, so the disjunction holds. Hence the whole statement holds. Answer: True.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 979,
        "conclusion": "Hannah needs to earn money to help pay for her college tuition.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 980,
        "conclusion": "Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 981,
        "conclusion": "Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 319,
    "premises": "Harry Elliott Alger (April 8, 1924 \u2013 January 27, 2010) was a provincial level politician from Alberta, Canada. His works can be found in permanent collections of Fototeca de Cuba and at the Museo Nacional de Bellas Artes de La Habana. No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: Harry Elliott Alger (April 8, 1924 \u2013 January 27, 2010) was a provincial level politician from Alberta, Canada. His works can be found in permanent collections of Fototeca de Cuba and at the Museo Nacional de Bellas Artes de La Habana. No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are products of Baked by Melissa.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are not products of Baked by Melissa.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are a mala hotpot.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? Dried Thai chilies are cupcakes and products of Baked by Melissa.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From the rules: Cupcake -> Baked sweet; BBM product -> Cupcake -> Baked sweet; Baked sweet -> not Spicy, so Spicy -> not Baked sweet (contrapositive). Also Not Baked sweet -> Not Cupcake -> Not BBM product (via contrapositives).\n- Given: Dried Thai chilies (DTC) are Spicy or Mala hotpots or Not baked sweets. Since Mala hotpot -> Spicy, this reduces to DTC are Spicy or Not baked sweets. In either case, DTC are Not baked sweets (because Spicy -> Not baked sweets).\n- Therefore DTC are Not baked sweets, hence Not cupcakes, hence Not BBM products.\n\nQuestion 1: DTC are BBM products? From above, DTC are Not BBM products. So False.\n\nQuestion 2: DTC are not BBM products? True (as deduced).\n\nQuestion 3: DTC are a mala hotpot? The disjunction doesn\u2019t force mala hotpot; Unknown.\n\nQuestion 4: DTC are neither BBM products nor baked sweets? Both negations hold; True.\n\nQuestion 5: DTC are cupcakes and BBM products? Both are false; the conjunction is False.\n\nANSWERS:\n1: False\n2: True\n3: Unknown\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 805,
        "conclusion": "Dried Thai chilies are products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 806,
        "conclusion": "Dried Thai chilies are not products of Baked by Melissa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 807,
        "conclusion": "Dried Thai chilies are a mala hotpot.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 808,
        "conclusion": "Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 809,
        "conclusion": "Dried Thai chilies are cupcakes and products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 306,
    "premises": "Judith Ellen Retchin (born May 24, 1952) is a senior judge of the Superior Court of the District of Columbia. E. If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Judith Ellen Retchin (born May 24, 1952) is a senior judge of the Superior Court of the District of Columbia. E. If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The Hamden Plaza store does not provide take-out service.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \"All restaurants with a rating greater than four are listed in Yelp\u2019s recommendations\" and \"If listed, then not many negative reviews\": R(x) \u2192 L(x) \u2192 \u00acN(x).\n- From \"All popular among locals have ratings >4\": P(x) \u2192 R(x).\n- Given for Hamden Plaza Subway store: R(H) \u2228 P(H). With P(H) \u2192 R(H), we conclude R(H). Therefore L(H) and \u00acN(H).\n\nQuestion 1:\n- Antecedent: T(H) \u2227 N(H). But we have \u00acN(H). So the antecedent is false, making the implication true (vacuously).\n\nQuestion 2:\n- T(H) \u2228 \u00acN(H). Since \u00acN(H) is true, the disjunction is true.\n\nQuestion 3:\n- No information determines T(H) or \u00acT(H). So this is uncertain.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 754,
        "conclusion": "If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 755,
        "conclusion": "The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 756,
        "conclusion": "The Hamden Plaza store does not provide take-out service.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 245,
    "premises": "S. The EU\u2013US Open Skies Agreement is an open skies air transport agreement between the European Union (EU) and the United States (US). In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: S. The EU\u2013US Open Skies Agreement is an open skies air transport agreement between the European Union (EU) and the United States (US). In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Sir Digby\u2019s nemesis does not win.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n- The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\n- If a superhero movie is named after a character, that character is a good guy and is in the movie. The movie is named after Sir Digby, so Sir Digby is a good guy in the movie.\n- In superhero movies, the good guys always win. Therefore, Sir Digby (a good guy) wins.\n- Sir Digby fights his nemesis. If somebody wins a fight, the person they are fighting does not win.\n- Hence, Sir Digby\u2019s nemesis does not win.\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 688,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 58,
    "premises": "KTH is ranked 73rd in the world among all universities in the 2024 QS World University Rankings, which is higher than any other university in the Nordic countries. Shahnaz Sheikh (born 21 March 1949) is a retired Pakistani field hockey player. Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: KTH is ranked 73rd in the world among all universities in the 2024 QS World University Rankings, which is higher than any other university in the Nordic countries. Shahnaz Sheikh (born 21 March 1949) is a retired Pakistani field hockey player. Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Walden contains knowledge.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Harry is smarter than before.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? A smarter person has gained knowledge.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n1) Walden is explicitly called \u201cthe book \u2018Walden\u2019.\u201d Given \u201cBooks contain tons of knowledge,\u201d any book contains knowledge. Therefore, Walden contains knowledge. Conclusion: True.\n\n2) Harry read the book Walden. From \u201cWhen a person reads a book, that person gains knowledge,\u201d Harry gains knowledge. From \u201cIf a person gains knowledge, they become smarter,\u201d Harry becomes smarter than he was before reading. Conclusion: True.\n\n3) We are given only that gaining knowledge implies becoming smarter. The converse (\u201cif someone is smarter, then they have gained knowledge\u201d) is not entailed. So we cannot conclude it. Conclusion: Unknown.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 171,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 172,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 173,
        "conclusion": "A smarter person has gained knowledge.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 191,
    "premises": "He mixed to good effect his poetic studies and his religious work. S. A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: He mixed to good effect his poetic studies and his religious work. S. A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Machine translation is a language generation task.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Machine translation is a language understanding task.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Question 1 reasoning:\n- Machine translation is a natural language processing (NLP) task.\n- The output of machine translation is a text sequence.\n- If the output of an NLP task is a text sequence, then it is a language generation task.\n- Therefore, machine translation is a language generation task.\n\nQuestion 2 reasoning:\n- An NLP task can be categorized as either a language generation task or a language understanding task (mutually exclusive categorization).\n- From Question 1, machine translation is a language generation task.\n- Therefore, it is not a language understanding task.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 546,
        "conclusion": "Machine translation is a language generation task.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 547,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 166,
    "premises": "The breed can also be prone to skin disorders such as the breed-specific condition hyperplastic dermatosis. The complex features a central LED pillar and interactive floor which is prominent next to BAR36. Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The breed can also be prone to skin disorders such as the breed-specific condition hyperplastic dermatosis. The complex features a central LED pillar and interactive floor which is prominent next to BAR36. Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Tom will rent an apartment in The Olive Garden.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Tom is allowed to move into an apartment in The Olive Garden with Fluffy.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The security deposit at the Olive Garden is either $2000 or more.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Tom will rent a managed building apartment if: (a) he\u2019s allowed to move in with Fluffy, and (b) the security deposit is \u2264 $1500.\n- The Olive Garden is a managed building, but we don\u2019t know if it allows pets; \u201cPets are allowed in some managed buildings\u201d doesn\u2019t imply Olive Garden allows them.\n- The deposit amount at the Olive Garden is not specified. We only know it can be equal to rent or more in some cases; that\u2019s a possibility, not a certainty for this building.\n- The sufficient conditions for Tom renting are not established. Also, the statement is only an \u201cif\u201d (sufficient), not \u201ciff\u201d (necessary).\n- Conclusion: Unknown.\n\nQuestion 2:\n- If a managed building allows pets, then people are allowed to move in with a pet. Fluffy is a cat and cats are pets.\n- We do not know whether the Olive Garden allows pets; \u201csome managed buildings\u201d does not entail this one does.\n- Conclusion: Unknown.\n\nQuestion 3:\n- Monthly rent at the Olive Garden is $2000.\n- The rule: the security deposit can be equal to the monthly rent or more indicates possibilities, not the actual policy for this building.\n- Therefore we cannot conclude the deposit at the Olive Garden is $2000 or more; it might be, but it\u2019s not entailed.\n- Conclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 476,
        "conclusion": "Tom will rent an apartment in The Olive Garden.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 477,
        "conclusion": "Tom is allowed to move into an apartment in The Olive Garden with Fluffy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 478,
        "conclusion": "The security deposit at the Olive Garden is either $2000 or more.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 352,
    "premises": "Some of Sellow's scientific collections from Uruguay and Brazil are divided between the Museum of Natural History of Berlin, the Ethnological Museum of Berlin, and the Museum of Natural History of Vienna. Before the 1970s, the idea of rolling luggage was shunned by the travel industry, who viewed it as much less masculine than traditional luggage. All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Some of Sellow's scientific collections from Uruguay and Brazil are divided between the Museum of Natural History of Berlin, the Ethnological Museum of Berlin, and the Museum of Natural History of Vienna. Before the 1970s, the idea of rolling luggage was shunned by the travel industry, who viewed it as much less masculine than traditional luggage. All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The Harvard Weekly Book club has legal obligations.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The Harvard Weekly Book club has legal obligations and is a private company.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- From the universal rules: private company \u2192 company \u2192 business organization \u2192 legal entity. Legal entity \u2192 created under law and legal obligations.\n- Specific to H: If H is created under law, then H is not a private company.\n- Therefore, if H were a private company, then it would be a legal entity and hence created under law, which would imply it is not a private company. So private company(H) \u2192 not private company(H), which entails that H is not a private company.\n\nQuestion 1:\n- To conclude H has legal obligations, it would suffice to know H is a legal entity. We have no information that H is a legal entity (or otherwise has legal obligations). Thus this cannot be determined.\n- Answer: Unknown.\n\nQuestion 2:\n- The statement requires both \u201chas legal obligations\u201d and \u201cis a private company.\u201d We have deduced H is not a private company. Hence the conjunction is false.\n- Answer: False.\n\nQuestion 3:\n- If H is a private company, then by the chain above H is a legal entity, which implies both legal obligations and created under law. Therefore, if H is a private company, then it has legal obligations or is created under law.\n- Answer: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 933,
        "conclusion": "The Harvard Weekly Book club has legal obligations.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 934,
        "conclusion": "The Harvard Weekly Book club has legal obligations and is a private company.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 935,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 472,
    "premises": "Wall Street is a street which runs through the Financial District of New York City, which due to many financial centers being located on the street is further a metonym for the Economy of the United States. The Howden Insurance Mile is a New Zealand Thoroughbred horse race run at Hastings Racecourse in Hawke's Bay. Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Wall Street is a street which runs through the Financial District of New York City, which due to many financial centers being located on the street is further a metonym for the Economy of the United States. The Howden Insurance Mile is a New Zealand Thoroughbred horse race run at Hastings Racecourse in Hawke's Bay. Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Harry is a queen bee.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Harry is an invertebrate or a queen bee.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: All queen bees are bees; Harry is a bee.\n- This only gives that queen bee implies bee, not that bee implies queen bee.\n- Therefore we cannot conclude whether Harry is a queen bee.\n- Conclusion: Unknown.\n\nQuestion 2:\n- From: All animals with backbones -> reproduce by male-and-female mating.\n- From: Bees -> not reproduce by male-and-female mating.\n- By contraposition, not reproduce by male-and-female mating -> not (animal with a backbone). So Harry is not an animal with a backbone.\n- From: All vertebrates have a backbone; by contraposition, not backbone -> not vertebrate. So Harry is not a vertebrate.\n- None of this implies Harry is an invertebrate (we lack that Harry is an animal), and we still don\u2019t know if he is a queen bee.\n- The disjunction \u201cinvertebrate or queen bee\u201d is not entailed nor contradicted.\n- Conclusion: Unknown.\n\nQuestion 3:\n- As above, Harry is not an animal with a backbone and not a vertebrate, so the antecedent \u201ceither both vertebrate and with a backbone, or neither\u201d holds (the \u201cneither\u201d case).\n- The consequent \u201cneither an invertebrate nor a queen bee\u201d is not supported: we cannot infer not-invertebrate (we don\u2019t even know Harry is an animal) nor not-queen.\n- Hence the implication is not entailed; it can be false in a model where Harry is a queen bee.\n- Conclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1366,
        "conclusion": "Harry is a queen bee.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1367,
        "conclusion": "Harry is an invertebrate or a queen bee.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1368,
        "conclusion": "If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 379,
    "premises": "Shanker Adhikari is the chairman of the union. It was also reported from Nepal, Bhutan, Bangladesh and Myanmar. People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Shanker Adhikari is the chairman of the union. It was also reported from Nepal, Bhutan, Bangladesh and Myanmar. People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Luke spends a lot of time hanging out and playing with his siblings.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Luke complains often about annoying siblings.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Luke is neither born in a multiple birth nor complains often about annoying siblings.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Rules:\n  - Born in a multiple birth with siblings \u21d2 spend a lot of time with siblings.\n  - Spend a lot of time with siblings \u21d2 often live at home.\n  - Live at home \u21d2 not live with strangers.\n  - Complain often about annoying siblings \u21d2 have siblings born together \u21d2 born in a multiple birth.\n- Luke: Either (baby \u2227 born in a multiple birth \u2227 live with strangers) OR (not a baby born in a multiple birth \u2227 not live with strangers). The second disjunct does not rule out being born in a multiple birth (he could be non-baby but born in a multiple birth).\n\nQuestion 1:\n- In the first case, born in a multiple birth implies he spends a lot of time with siblings.\n- In the second case, we have no information implying he spends a lot of time with siblings.\n- Therefore, not determined. Answer: Unknown.\n\nQuestion 2:\n- No rule or given fact implies that Luke complains often about annoying siblings.\n- Therefore, not determined. Answer: Unknown.\n\nQuestion 3:\n- The claim is: not born in a multiple birth AND not complaining.\n- From the disjunction, Luke could be born in a multiple birth (first case), and even in the second case he might still be born in a multiple birth (just not a baby). We also have no information about complaining.\n- Thus the conjunction is not entailed and not contradicted. Answer: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1011,
        "conclusion": "Luke spends a lot of time hanging out and playing with his siblings.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1012,
        "conclusion": "Luke complains often about annoying siblings.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1013,
        "conclusion": "Luke is neither born in a multiple birth nor complains often about annoying siblings.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 197,
    "premises": "The southern terminus of the route is at the Virginia state line (and southern city limits of Bluefield), where WV 598 continues southward as Virginia State Route 598. It is just east of Lovina and is also the centre of Buleleng District, which covers an area of 46. It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The southern terminus of the route is at the Virginia state line (and southern city limits of Bluefield), where WV 598 continues southward as Virginia State Route 598. It is just east of Lovina and is also the centre of Buleleng District, which covers an area of 46. It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? ETS provides financial aid to Tom.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? It costs below US $300 to take the GRE test.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? No one taking the GRE test has financial aid provided to them by something.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- ETS provides financial aid to GRE applicants who prove economic hardship.\n- People in single-parent families or with few resources can prove economic hardship.\n- Tom is an applicant and meets those conditions, so he can prove hardship.\n- However, \u201ccan prove\u201d does not imply he actually proved it. Therefore, it\u2019s not certain he receives aid.\nAnswer: Unknown.\n\nQuestion 2:\n- The text states the GRE costs $205, which is cheaper than $300.\n- Therefore, it costs below $300.\nAnswer: True.\n\nQuestion 3:\n- The claim says no one taking the GRE has any financial aid.\n- ETS provides aid to applicants who prove hardship, so aid is possible.\n- But we are not told that any specific test taker actually received aid; Tom only \u201ccan\u201d prove hardship.\n- Thus we cannot determine the universal claim\u2019s truth.\nAnswer: Unknown.\n\nANSWERS:\n1: Unknown\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 560,
        "conclusion": "ETS provides financial aid to Tom.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 561,
        "conclusion": "It costs below US $300 to take the GRE test.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 562,
        "conclusion": "No one taking the GRE test has financial aid provided to them by something.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 361,
    "premises": "A. In enzymology, a 4-(hydroxymethyl)benzenesulfonate dehydrogenase (EC 1. If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: A. In enzymology, a 4-(hydroxymethyl)benzenesulfonate dehydrogenase (EC 1. If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Peter is notably tidy.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- From the rules: S \u2192 \u00acT, Cly \u2192 T, V \u2192 Cly, F \u2192 V, CF \u2192 S.\n- Given: (S \u2227 Cly) \u2228 (\u00acS \u2227 \u00acCly) for Peter. The first disjunct (S \u2227 Cly) yields T and \u00acT, a contradiction. Hence the second disjunct must hold: \u00acS and \u00acCly.\n\nQuestion 1:\n- From \u00acS and \u00acCly, we cannot infer T or \u00acT (only the forward implications are given). So whether Peter is notably tidy remains undetermined.\n- Conclusion: Unknown.\n\nQuestion 2:\n- From \u00acS and CF \u2192 S, by contrapositive, \u00acS \u2192 \u00acCF, so \u00acCF.\n- From \u00acCly and V \u2192 Cly, by contrapositive, \u00acCly \u2192 \u00acV; and from F \u2192 V, contrapositive gives \u00acV \u2192 \u00acF, so \u00acF.\n- Thus both CF and F are false, so \u201cCF or F\u201d is false.\n- Conclusion: False.\n\nQuestion 3:\n- We have \u00acCF and \u00acF, so (\u00acCF \u2227 \u00acF) is true, making \u201c(CF \u2227 F) or (\u00acCF \u2227 \u00acF)\u201d true.\n- Conclusion: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 958,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 959,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 960,
        "conclusion": "Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 262,
    "premises": "It was created by the Civil Rights Act of 1964, and its mission was broadened by the Matthew Shepard and James Byrd Jr. The company was founded in 1928 as the National Aluminate Corporation, formed from the merger of Chicago Chemical Company and the Aluminum Sales Corporation. All fir trees are evergreens.\nSome objects of worship are fir trees.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: It was created by the Civil Rights Act of 1964, and its mission was broadened by the Matthew Shepard and James Byrd Jr. The company was founded in 1928 as the National Aluminate Corporation, formed from the merger of Chicago Chemical Company and the Aluminum Sales Corporation. All fir trees are evergreens.\nSome objects of worship are fir trees.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some evergreens are not objects of worship.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- All fir trees are evergreens; some objects of worship are fir trees. Thus, some objects of worship are evergreens.\n- This does not entail that any evergreen is not an object of worship. It\u2019s consistent both that all evergreens are objects of worship and that some are not.\n- Therefore, the statement \u201cSome evergreens are not objects of worship\u201d cannot be determined from the given information.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 706,
        "conclusion": "Some evergreens are not objects of worship.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 124,
    "premises": "A similar pastiche of hit songs, set to polka music, has since appeared on nearly all of Yankovic's albums. Rubric may also refer to:\n\nRubric (academic), a set of criteria for grading assignments\nRubric (translation organisation), a global language service provider. The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: A similar pastiche of hit songs, set to polka music, has since appeared on nearly all of Yankovic's albums. Rubric may also refer to:\n\nRubric (academic), a set of criteria for grading assignments\nRubric (translation organisation), a global language service provider. The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Juan de Onate visited a mountain range in New Mexico.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Juan de Onate visited a mountain range in Texas.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The Harding Pegmatite Mine is not located in a mountain range in New Mexico.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- The Picuris Mountains are said to be in New Mexico or Texas. The Harding Pegmatite Mine is located in the Picuris Mountains and was donated. The text also states there are no mountain ranges in Texas that have mines that have been donated. Therefore, the Picuris Mountains cannot be in Texas. Given the \u201cor\u201d between New Mexico or Texas, this implies the Picuris Mountains are in New Mexico.\n- Juan de Onate visited the Picuris Mountains, so he visited a mountain range in New Mexico.\n- There is no information that Juan de Onate visited any mountain range in Texas beyond the Picuris reference, and since Picuris is not in Texas, we cannot conclude he visited a Texas mountain range.\n- The Harding Pegmatite Mine is located in the Picuris Mountains, which we established are in New Mexico, so it is located in a mountain range in New Mexico.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 370,
        "conclusion": "Juan de Onate visited a mountain range in New Mexico.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 371,
        "conclusion": "Juan de Onate visited a mountain range in Texas.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 372,
        "conclusion": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 183,
    "premises": "Wayning Moments is the third album by saxophonist Wayne Shorter (and his final album for Vee-Jay Records), showcasing Wayne playing hard bop with trumpeter Freddie Hubbard, pianist Eddie Higgins, bassist Jymie Merritt and drummer Marshall Thompson. Nephrotoma appendiculata, the spotted crane fly, is a species of crane fly. If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Wayning Moments is the third album by saxophonist Wayne Shorter (and his final album for Vee-Jay Records), showcasing Wayne playing hard bop with trumpeter Freddie Hubbard, pianist Eddie Higgins, bassist Jymie Merritt and drummer Marshall Thompson. Nephrotoma appendiculata, the spotted crane fly, is a species of crane fly. If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Peter is shorter than a man in Michael's class.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Windy is a great shooter.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Peter can block Windy's shooting.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Michael is taller than everyone else in his class.\n- Peter is taller than Michael.\n- By transitivity, Peter is taller than everyone in Michael\u2019s class.\n- Therefore, no man in Michael\u2019s class is taller than Peter. The statement is false.\n\nQuestion 2:\n- If a person does not jump when shooting, Michael can block their shooting.\n- Contrapositive: If Michael cannot block a person\u2019s shooting, that person jumps when shooting.\n- Given Michael cannot block Windy\u2019s shooting, Windy jumps when shooting.\n- A shooter who can jump when shooting is a great shooter. Hence, Windy is a great shooter. The statement is true.\n\nQuestion 3:\n- The general blocking rule for men requires knowing that Peter is taller than Windy and that Windy is a man.\n- We do not know Windy\u2019s gender or relative height to Peter.\n- Michael\u2019s special blocking rule does not apply to Peter.\n- Therefore, it is unknown whether Peter can block Windy\u2019s shooting.\n\nANSWERS:\n1: False\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 527,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 528,
        "conclusion": "Windy is a great shooter.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 529,
        "conclusion": "Peter can block Windy's shooting.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 151,
    "premises": "Roraima is the least populous state in Brazil, with an estimated population of 631,181 inhabitants as of 2020. It is endemic to Colombia. Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Roraima is the least populous state in Brazil, with an estimated population of 631,181 inhabitants as of 2020. It is endemic to Colombia. Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Barutin Cove is named after all islands in Antarctica.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? There is at least one cove in Antarctica named after a place in Bulgaria.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Barutin Cove is not located in Antarctica.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- Given facts:\n  - Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\n  - Barutin Cove is on the southwest coast of Snow Island.\n  - Snow Island is located in the South Shetland Islands.\n  - Antarctica is located on the South Shetland Islands.\n  - Transitivity: If A is in B and B is in C, then A is in C.\n- From this, we can deduce: Barutin Cove is located in the South Shetland Islands. We cannot deduce its location relative to Antarctica, since the given relation places Antarctica in the South Shetland Islands, not the other way around.\n\nQuestion 1:\n- The statement claims Barutin Cove is named after all islands in Antarctica.\n- We are told it is named after the Bulgarian settlement of Barutin. This contradicts the claim that it is named after all Antarctic islands.\n- Conclusion: False.\n\nQuestion 2:\n- The statement claims there exists at least one cove in Antarctica named after a place in Bulgaria.\n- We know of a cove (Barutin Cove) named after a Bulgarian place, but we cannot conclude it is in Antarctica from the provided relations.\n- Conclusion: Unknown.\n\nQuestion 3:\n- The statement claims Barutin Cove is not located in Antarctica.\n- From the given information, we cannot determine whether Barutin Cove is or is not in Antarctica; we only know it is in the South Shetland Islands and that Antarctica is located in the South Shetland Islands.\n- Conclusion: Unknown.\n\nANSWERS:\n1: False\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 439,
        "conclusion": "Barutin Cove is named after all islands in Antarctica.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 440,
        "conclusion": "There is at least one cove in Antarctica named after a place in Bulgaria.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 441,
        "conclusion": "Barutin Cove is not located in Antarctica.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 295,
    "premises": "It is located exactly mid-line, between the anterior 2/3 and posterior 1/3 of the tongue. The area would have been used by the Peramangk people before European settlement began in the late 1830s. Some affection is love.\nSome love is positive.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: It is located exactly mid-line, between the anterior 2/3 and posterior 1/3 of the tongue. The area would have been used by the Peramangk people before European settlement began in the late 1830s. Some affection is love.\nSome love is positive.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some affection is positive.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- \"Some affection is love\" means there exists at least one thing that is both affection and love.\n- \"Some love is positive\" means there exists at least one thing that is both love and positive.\n- These two existential statements might refer to different instances of love. Without a universal rule linking all love to positive, we cannot conclude that there exists an instance that is both affection and positive.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 739,
        "conclusion": "Some affection is positive.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 315,
    "premises": "2926 for restoration. p\u0254. If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: 2926 for restoration. p\u0254. If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? John's car is a Tesla Model 3.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? John's car is a Solo EV.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? John's car is not a Solo EV.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From the premises: TM3 -> can transport multiple passengers -> not one-seater. Solo EV -> single-seat electric car -> one-seater. Thus, no car can be both TM3 and Solo EV, but we have no facts about which John has.\n- The conditional about John\u2019s car (if not TM3 then not TM3 or single-seat electric car) is a tautology and provides no substantive information about John\u2019s car.\n\nQuestion 1:\n- No premise specifies John\u2019s car is a Tesla Model 3, and the given conditional adds nothing. Both TM3 and not TM3 are consistent.\n- Conclusion: Unknown.\n\nQuestion 2:\n- No premise specifies John\u2019s car is a Solo EV. Both Solo EV and not Solo EV are consistent.\n- Conclusion: Unknown.\n\nQuestion 3:\n- We cannot infer that John\u2019s car is not a Solo EV; it remains possible. Also, nothing forces it to be a Solo EV.\n- Conclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 786,
        "conclusion": "John's car is a Tesla Model 3.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 787,
        "conclusion": "John's car is a Solo EV.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 788,
        "conclusion": "John's car is not a Solo EV.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 467,
    "premises": "George Howard Monks (1853\u20131933) was an American surgeon who also invented board games. Montepuez is the second largest city in the province of Cabo Delgado in Mozambique, after the provincial capital of Pemba. All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: George Howard Monks (1853\u20131933) was an American surgeon who also invented board games. Montepuez is the second largest city in the province of Cabo Delgado in Mozambique, after the provincial capital of Pemba. All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Rock is a monkey.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Rock has wings.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Rock does not have wings.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- From \"Peter's pets are all either monkeys or birds\" and \"Rock is Peter's pet,\" we get Monkey(Rock) or Bird(Rock).\n- Nothing forces Rock to be a monkey (he could be a bird), nor rules out that he could be a monkey.\n- Therefore, whether Rock is a monkey cannot be determined.\n\nQuestion 2:\n- Consider two exhaustive cases from above:\n  - If Rock is a bird, then as one of Peter's birds, Rock can fly; as a Peter\u2019s pet that can fly, Rock has wings.\n  - If Rock is not a bird, then he must be a monkey. Monkeys are mammals; as Peter\u2019s pet and a mammal, Rock is an animal; all Peter\u2019s animal-pets can breathe, so Rock can breathe. The given disjunction (CanFly \u2228 Bird \u2228 \u00acCanBreathe) then reduces to CanFly \u2228 false, so CanFly is true. As a Peter\u2019s pet that can fly, Rock has wings.\n- In all cases, Rock has wings. So the statement is true.\n\nQuestion 3:\n- From Question 2, Rock necessarily has wings. Therefore, \"Rock does not have wings\" is false.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1348,
        "conclusion": "Rock is a monkey.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1349,
        "conclusion": "Rock has wings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1350,
        "conclusion": "Rock does not have wings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 379,
    "premises": "Shanker Adhikari is the chairman of the union. It was also reported from Nepal, Bhutan, Bangladesh and Myanmar. People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Shanker Adhikari is the chairman of the union. It was also reported from Nepal, Bhutan, Bangladesh and Myanmar. People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Luke spends a lot of time hanging out and playing with his siblings.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Luke complains often about annoying siblings.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Luke is neither born in a multiple birth nor complains often about annoying siblings.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n\n- Rules:\n  - If someone is born in a multiple birth (M), then they spend a lot of time with siblings (S).\n  - If someone complains about annoying siblings (C), then they have siblings born together \u21d2 they were born in a multiple birth (C -> M).\n  - If someone spends a lot of time with siblings (S), then they live at home (H), and if they live at home (H), then they do not live with strangers (\u00acStr).\n  - Thus: M -> S -> H -> \u00acStr, and C -> M -> S -> H -> \u00acStr.\n\n- Luke\u2019s disjunction: either (Baby\u2227M \u2227 Str) or (\u00ac(Baby\u2227M) \u2227 \u00acStr).\n  - The first branch (Baby\u2227M \u2227 Str) implies M, hence S, hence \u00acStr, which contradicts Str. So the first branch is impossible.\n  - Therefore the second branch must hold: \u00ac(Baby\u2227M) and \u00acStr. This only tells us \u00acStr and not(Baby\u2227M); it does not determine M or S or C.\n\nQuestion 1: Does Luke spend a lot of time with his siblings (S)?\n- We know \u00acStr, but there is no rule \u00acStr -> S. Also \u00ac(Baby\u2227M) does not imply \u00acM. So S cannot be determined.\n- Answer: Unknown.\n\nQuestion 2: Does Luke complain often about annoying siblings (C)?\n- C would imply \u00acStr, which is consistent with what we know, but we cannot infer C from \u00acStr. Both C and \u00acC remain possible.\n- Answer: Unknown.\n\nQuestion 3: Is Luke neither born in a multiple birth nor complains often (\u00acM \u2227 \u00acC)?\n- We cannot deduce \u00acM (since \u00ac(Baby\u2227M) allows M if not a baby), nor can we deduce \u00acC. So the conjunction cannot be established.\n- Answer: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1011,
        "conclusion": "Luke spends a lot of time hanging out and playing with his siblings.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1012,
        "conclusion": "Luke complains often about annoying siblings.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1013,
        "conclusion": "Luke is neither born in a multiple birth nor complains often about annoying siblings.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 197,
    "premises": "The southern terminus of the route is at the Virginia state line (and southern city limits of Bluefield), where WV 598 continues southward as Virginia State Route 598. It is just east of Lovina and is also the centre of Buleleng District, which covers an area of 46. It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The southern terminus of the route is at the Virginia state line (and southern city limits of Bluefield), where WV 598 continues southward as Virginia State Route 598. It is just east of Lovina and is also the centre of Buleleng District, which covers an area of 46. It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? ETS provides financial aid to Tom.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? It costs below US $300 to take the GRE test.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? No one taking the GRE test has financial aid provided to them by something.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- Relevant facts:\n  - ETS provides financial aid to GRE applicants who prove economic hardship.\n  - Those living in single-parent families or having few resources can prove economic hardship.\n  - Tom lives in a single-parent family, has few resources, and is applying to take the GRE.\n\nQuestion 1:\n- Tom is a GRE applicant and can prove economic hardship. However, the condition for aid is that he proves it, not merely that he can prove it. The text does not state that he actually proved hardship. Therefore, we cannot conclude he receives aid.\n- Conclusion: Unknown.\n\nQuestion 2:\n- The text states it costs $205 to take the GRE, which is cheaper than $300. Therefore, it costs below $300.\n- Conclusion: True.\n\nQuestion 3:\n- The statement claims no one taking the GRE has financial aid provided by anything. We know ETS provides aid to applicants who prove hardship, but we are not told that any specific test-taker actually receives aid. Without a concrete instance, we cannot declare the universal statement false, nor can we confirm it true.\n- Conclusion: Unknown.\n\nANSWERS:\n1: Unknown\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 560,
        "conclusion": "ETS provides financial aid to Tom.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 561,
        "conclusion": "It costs below US $300 to take the GRE test.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 562,
        "conclusion": "No one taking the GRE test has financial aid provided to them by something.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 361,
    "premises": "A. In enzymology, a 4-(hydroxymethyl)benzenesulfonate dehydrogenase (EC 1. If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: A. In enzymology, a 4-(hydroxymethyl)benzenesulfonate dehydrogenase (EC 1. If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Peter is notably tidy.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From S(x) -> \u00acN(x) and C(x) -> N(x), S \u2227 C implies a contradiction (N \u2227 \u00acN). So \u00ac(S \u2227 C).\n- Given (S \u2227 C) \u2228 (\u00acS \u2227 \u00acC) for Peter, we conclude \u00acS \u2227 \u00acC.\n- From G -> S and \u00acS, we get \u00acG (Peter is not a clumsy foodie).\n- From F -> V -> C, we have F -> C; with \u00acC, we get \u00acF (Peter\u2019s family does not prioritize order and spotlessness).\n\nQuestion 1:\n- We have \u00acS and \u00acC. C -> N can\u2019t be used (since C is false), and S -> \u00acN can\u2019t be used (since S is false). N remains undetermined.\n- Conclusion: Unknown.\n\nQuestion 2:\n- We have \u00acG and \u00acF, so G \u2228 F is false.\n- Conclusion: False.\n\nQuestion 3:\n- With \u00acG and \u00acF, (G \u2227 F) \u2228 (\u00acG \u2227 \u00acF) reduces to (false) \u2228 (true) = true.\n- Conclusion: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 958,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 959,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 960,
        "conclusion": "Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 262,
    "premises": "It was created by the Civil Rights Act of 1964, and its mission was broadened by the Matthew Shepard and James Byrd Jr. The company was founded in 1928 as the National Aluminate Corporation, formed from the merger of Chicago Chemical Company and the Aluminum Sales Corporation. All fir trees are evergreens.\nSome objects of worship are fir trees.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: It was created by the Civil Rights Act of 1964, and its mission was broadened by the Matthew Shepard and James Byrd Jr. The company was founded in 1928 as the National Aluminate Corporation, formed from the merger of Chicago Chemical Company and the Aluminum Sales Corporation. All fir trees are evergreens.\nSome objects of worship are fir trees.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some evergreens are not objects of worship.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \"All fir trees are evergreens\" and \"Some objects of worship are fir trees,\" we infer that some evergreens are objects of worship (since some fir trees\u2014being evergreens\u2014are objects of worship).\n- The claim to assess is \"Some evergreens are not objects of worship.\" The premises provide no information about any evergreen that is not an object of worship.\n- It remains possible that all evergreens are objects of worship or that some are not; the data do not decide this.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 706,
        "conclusion": "Some evergreens are not objects of worship.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 124,
    "premises": "A similar pastiche of hit songs, set to polka music, has since appeared on nearly all of Yankovic's albums. Rubric may also refer to:\n\nRubric (academic), a set of criteria for grading assignments\nRubric (translation organisation), a global language service provider. The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: A similar pastiche of hit songs, set to polka music, has since appeared on nearly all of Yankovic's albums. Rubric may also refer to:\n\nRubric (academic), a set of criteria for grading assignments\nRubric (translation organisation), a global language service provider. The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Juan de Onate visited a mountain range in New Mexico.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Juan de Onate visited a mountain range in Texas.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The Harding Pegmatite Mine is not located in a mountain range in New Mexico.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- The Picuris Mountains are stated to be in New Mexico or Texas.\n- The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\n- There are no mountain ranges in Texas that have mines that have been donated. Therefore, the Picuris Mountains cannot be in Texas; they must be in New Mexico.\n- Juan de Onate visited the Picuris Mountains, so he visited a mountain range in New Mexico.\nConclusion: True.\n\nQuestion 2:\n- We only know Juan de Onate visited the Picuris Mountains, which are in New Mexico (as deduced).\n- There is no statement that he visited any mountain range in Texas, nor that he did not.\nConclusion: Unknown.\n\nQuestion 3:\n- The Harding Pegmatite Mine is located in the Picuris Mountains.\n- The Picuris Mountains are in New Mexico (as deduced).\n- Therefore, the mine is located in a mountain range in New Mexico. The statement denies this.\nConclusion: False.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 370,
        "conclusion": "Juan de Onate visited a mountain range in New Mexico.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 371,
        "conclusion": "Juan de Onate visited a mountain range in Texas.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 372,
        "conclusion": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 183,
    "premises": "Wayning Moments is the third album by saxophonist Wayne Shorter (and his final album for Vee-Jay Records), showcasing Wayne playing hard bop with trumpeter Freddie Hubbard, pianist Eddie Higgins, bassist Jymie Merritt and drummer Marshall Thompson. Nephrotoma appendiculata, the spotted crane fly, is a species of crane fly. If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Wayning Moments is the third album by saxophonist Wayne Shorter (and his final album for Vee-Jay Records), showcasing Wayne playing hard bop with trumpeter Freddie Hubbard, pianist Eddie Higgins, bassist Jymie Merritt and drummer Marshall Thompson. Nephrotoma appendiculata, the spotted crane fly, is a species of crane fly. If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Peter is shorter than a man in Michael's class.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Windy is a great shooter.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Peter can block Windy's shooting.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Michael is taller than everyone in his class.\n- Peter is taller than Michael.\n- By transitivity, Peter is taller than everyone in Michael\u2019s class.\n- Therefore, Peter is not shorter than any man in Michael\u2019s class. If there are no men in the class, the existential statement is still false.\nAnswer: False.\n\nQuestion 2:\n- Michael can block any shooting from a person if the person does not jump when shooting.\n- Michael cannot block Windy\u2019s shooting.\n- Therefore, Windy must jump when shooting.\n- Every shooter who can jump when shooting is a great shooter.\n- Hence, Windy is a great shooter.\nAnswer: True.\n\nQuestion 3:\n- The only general blocking rule (besides Michael\u2019s special rule) is: if a man is taller than another man, the taller can block the other\u2019s shooting.\n- We do not know Windy\u2019s gender or height relative to Peter; we only know Windy jumps when shooting.\n- Thus, we cannot determine whether Peter can block Windy\u2019s shooting.\nAnswer: Unknown.\n\nANSWERS:\n1: False\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 527,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 528,
        "conclusion": "Windy is a great shooter.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 529,
        "conclusion": "Peter can block Windy's shooting.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 151,
    "premises": "Roraima is the least populous state in Brazil, with an estimated population of 631,181 inhabitants as of 2020. It is endemic to Colombia. Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Roraima is the least populous state in Brazil, with an estimated population of 631,181 inhabitants as of 2020. It is endemic to Colombia. Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Barutin Cove is named after all islands in Antarctica.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? There is at least one cove in Antarctica named after a place in Bulgaria.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Barutin Cove is not located in Antarctica.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- We are told explicitly that Barutin Cove is named after the Bulgarian settlement of Barutin. There is no information suggesting it is named after any islands, let alone all islands in Antarctica. Therefore the statement in Q1 is false.\n- Barutin Cove is on Snow Island; Snow Island is in the South Shetland Islands. We are also told (even if counter to real-world facts) that Antarctica is located on the South Shetland Islands. This does not let us conclude Barutin Cove is in Antarctica (we lack a chain showing South Shetland Islands is in Antarctica or that Barutin Cove is in Antarctica). Thus we cannot confirm there exists a cove in Antarctica named after a Bulgarian place; it remains unknown.\n- Similarly, we cannot conclude Barutin Cove is not in Antarctica; the provided relations are insufficient to establish either inclusion or exclusion. Hence the negation is also unknown.\n\nANSWERS:\n1: False\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 439,
        "conclusion": "Barutin Cove is named after all islands in Antarctica.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 440,
        "conclusion": "There is at least one cove in Antarctica named after a place in Bulgaria.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 441,
        "conclusion": "Barutin Cove is not located in Antarctica.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 295,
    "premises": "It is located exactly mid-line, between the anterior 2/3 and posterior 1/3 of the tongue. The area would have been used by the Peramangk people before European settlement began in the late 1830s. Some affection is love.\nSome love is positive.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: It is located exactly mid-line, between the anterior 2/3 and posterior 1/3 of the tongue. The area would have been used by the Peramangk people before European settlement began in the late 1830s. Some affection is love.\nSome love is positive.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some affection is positive.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n- From \"Some affection is love,\" there exists at least one entity that is both affection and love.\n- From \"Some love is positive,\" there exists at least one entity that is both love and positive.\n- These two existential statements could refer to different instances of love. Therefore, we cannot conclude that there exists an entity that is both affection and positive.\n- Hence, the statement \"Some affection is positive\" is not entailed; it is possible but not guaranteed.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 739,
        "conclusion": "Some affection is positive.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 315,
    "premises": "2926 for restoration. p\u0254. If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: 2926 for restoration. p\u0254. If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? John's car is a Tesla Model 3.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? John's car is a Solo EV.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? John's car is not a Solo EV.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From the premises: \n  - If something can transport multiple passengers, then it is not a one-seater.\n  - All Tesla Model 3 can transport multiple passengers, hence any Tesla Model 3 is not a one-seater.\n  - All Solo EV are single-seat electric cars, and all single-seat electric cars are one-seaters. Hence any Solo EV is a one-seater.\n  - Therefore, Tesla Model 3 and Solo EV are mutually exclusive categories (one implies not one-seater; the other implies one-seater).\n- The conditional about John\u2019s car (\u201cIf John\u2019s car is not a Tesla Model 3, then John\u2019s car is not a Tesla Model 3 or a single-seat electric car\u201d) is a tautology (A -> A \u2228 B) and adds no information about whether John\u2019s car is a Tesla Model 3 or a Solo EV.\n- There is no explicit information about what John\u2019s car is, so none of the specific claims about John\u2019s car can be determined.\n\nQuestion 1: We have no evidence that John\u2019s car is a Tesla Model 3. Unknown.\n\nQuestion 2: We have no evidence that John\u2019s car is a Solo EV. Unknown.\n\nQuestion 3: Since we don\u2019t know whether John\u2019s car is a Solo EV, we cannot assert it is not one. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 786,
        "conclusion": "John's car is a Tesla Model 3.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 787,
        "conclusion": "John's car is a Solo EV.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 788,
        "conclusion": "John's car is not a Solo EV.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 467,
    "premises": "George Howard Monks (1853\u20131933) was an American surgeon who also invented board games. Montepuez is the second largest city in the province of Cabo Delgado in Mozambique, after the provincial capital of Pemba. All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: George Howard Monks (1853\u20131933) was an American surgeon who also invented board games. Montepuez is the second largest city in the province of Cabo Delgado in Mozambique, after the provincial capital of Pemba. All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Rock is a monkey.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Rock has wings.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Rock does not have wings.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- Rock is Peter's pet. Every Peter\u2019s pet is either a monkey or a bird. All monkeys are mammals; any Peter\u2019s pet that is a mammal is an animal; any Peter\u2019s pet that is an animal can breathe. Thus any Peter\u2019s pet that is a monkey must breathe.\n- Peter\u2019s birds can fly, and any Peter\u2019s pet that can fly has wings.\n- We also know: Rock can fly, or Rock is a bird, or Rock cannot breathe.\n\nKey deduction about wings:\n- Suppose Rock neither flies nor is a bird. Then the disjunction forces \u201cRock cannot breathe.\u201d But if Rock is not a bird and is a Peter\u2019s pet, then he must be a monkey (by the either/or), hence a mammal, hence an animal, hence can breathe\u2014contradiction. Therefore, Rock must either fly or be a bird. In either case (bird implies fly), Rock can fly, and thus Rock has wings.\n\nQuestion 1: Rock is a monkey.\n- From \u201cpet -> (monkey or bird),\u201d Rock could be a bird (and need not be a monkey). Nothing forces him to be a monkey. So this is not entailed.\nAnswer: Unknown.\n\nQuestion 2: Rock has wings.\n- As shown above, Rock must fly; any flying Peter\u2019s pet has wings.\nAnswer: True.\n\nQuestion 3: Rock does not have wings.\n- This contradicts the conclusion that Rock has wings.\nAnswer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1348,
        "conclusion": "Rock is a monkey.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1349,
        "conclusion": "Rock has wings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1350,
        "conclusion": "Rock does not have wings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 330,
    "premises": "The terms allopatry and vicariance are often used in biogeography to describe the relationship between organisms whose ranges do not significantly overlap but are immediately adjacent to each other\u2014they do not occur together or only occur within a narrow zone of contact. A Liberal, he was elected again in 1917 and 1921. All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 4)",
    "user_prompt": "Textual context: The terms allopatry and vicariance are often used in biogeography to describe the relationship between organisms whose ranges do not significantly overlap but are immediately adjacent to each other\u2014they do not occur together or only occur within a narrow zone of contact. A Liberal, he was elected again in 1917 and 1921. All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? John has a larger family.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? John does not have a larger family.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? John is engaged.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? John neither has a larger family nor does he invite others to his wedding.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Let W(x): makes wedding plans; E(x): engaged; I(x): invites others; A(x): has a well-attended wedding; L(x): has a larger family; F(x): invites friends.\n- Given: \n  - W -> E\n  - I -> W\n  - A -> I\n  - \u2203x (A(x) \u2227 L(x)) [not necessarily John]\n  - For John: E(J) -> \u00ac(F(J) \u2227 W(J))\n  - For John: L(J) -> (A(J) \u2228 F(J))\n- From these, A -> I -> W -> E, and W -> \u00acF for John (since E -> \u00ac(F \u2227 W)).\n- No premises assert L(J), \u00acL(J), E(J), or I(J) for John. The existence claim does not specify John.\n\nQuestion 1: We have no information that entails L(J). Unknown.\nQuestion 2: No information entails \u00acL(J). Unknown.\nQuestion 3: E(J) would follow if W(J), I(J), or A(J) were known, but none are. Unknown.\nQuestion 4: This asserts \u00acL(J) \u2227 \u00acI(J). Both components are individually undetermined, so the conjunction is undetermined. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown\n4: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 846,
        "conclusion": "John has a larger family.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 847,
        "conclusion": "John does not have a larger family.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 848,
        "conclusion": "John is engaged.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 849,
        "conclusion": "John neither has a larger family nor does he invite others to his wedding.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.25
  },
  {
    "story_id": 26,
    "premises": "Later, Conrad commanded Gemini 11 in 1966, and Apollo 12 in 1969. Orient is a city in Orient Township, Adair County, Iowa, United States. Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Later, Conrad commanded Gemini 11 in 1966, and Apollo 12 in 1969. Orient is a city in Orient Township, Adair County, Iowa, United States. Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Platypuses are mammals with no teeth.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Platypuses are reptiles.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Humans are mammals.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\nQ1: Given \"Platypuses are mammals\" and \"Platypuses have no teeth,\" the combined statement \"Platypuses are mammals with no teeth\" follows directly. True.\n\nQ2: We are only told \"Platypuses are mammals.\" Nothing in the provided information states that mammals and reptiles are mutually exclusive. We cannot conclude they are reptiles or not. Unknown.\n\nQ3: We are told \"Humans have teeth\" and \"Some mammals have teeth.\" From this alone, we cannot conclude that humans are mammals. Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 74,
        "conclusion": "Platypuses are mammals with no teeth.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 75,
        "conclusion": "Platypuses are reptiles.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 76,
        "conclusion": "Humans are mammals.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 203,
    "premises": "Smith was a right-handed batsman and played three innings in two first-class matches, making a total of 9 runs. One of the dead hijackers was later identified by the Central Intelligence Agency as a Lebanese national named Ribal Khalil Jallul, whose passport photo was matched to a Hezbollah martyr poster found near a mosque in Beirut. Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Smith was a right-handed batsman and played three innings in two first-class matches, making a total of 9 runs. One of the dead hijackers was later identified by the Central Intelligence Agency as a Lebanese national named Ribal Khalil Jallul, whose passport photo was matched to a Hezbollah martyr poster found near a mosque in Beirut. Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Space sucks.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Space is a vampire.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If something is a household appliance, it sucks.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: Vacuums suck. Space is a vacuum.\n- Therefore: Space sucks (modus ponens).\n- Conclusion: True.\n\nQuestion 2:\n- Given: Vampires suck.\n- This only implies if something is a vampire, then it sucks; not vice versa.\n- We know space sucks (from Q1), but that doesn\u2019t imply it\u2019s a vampire. No information states or implies space is a vampire.\n- Conclusion: Unknown.\n\nQuestion 3:\n- Statement claims: All household appliances suck.\n- Given: A duster is a household appliance that doesn\u2019t suck (a counterexample).\n- Therefore the universal claim is false.\n- Conclusion: False.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 578,
        "conclusion": "Space sucks.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 579,
        "conclusion": "Space is a vampire.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 580,
        "conclusion": "If something is a household appliance, it sucks.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 131,
    "premises": "(\u5927\u962a\u5916\u74b0\u72b6\u9244\u9053\u682a\u5f0f\u4f1a\u793e, \u014csaka Sotokanj\u014d Tetsud\u014d Kabushiki Kaisha) as a Category-3 railway business under the Railway Business Act of Japan. Centuries ago words were added to many of the melodies and these words provided the names of the tunes as we know them today. Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: (\u5927\u962a\u5916\u74b0\u72b6\u9244\u9053\u682a\u5f0f\u4f1a\u793e, \u014csaka Sotokanj\u014d Tetsud\u014d Kabushiki Kaisha) as a Category-3 railway business under the Railway Business Act of Japan. Centuries ago words were added to many of the melodies and these words provided the names of the tunes as we know them today. Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Supervised learning is used to train the state-of-the-art text summarization model.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Unsupervised learning is used to train the state-of-the-art text summarization model.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning for Question 1:\n- ML algorithms are categorized as supervised, unsupervised, and reinforcement learning.\n- The state-of-the-art text summarization model is trained with ML algorithms.\n- Reinforcement learning is not used.\n- The algorithm used for training text summarization models requires labeled data.\n- Unsupervised learning does not require labeled data, so it cannot be unsupervised.\n- By elimination, it must be supervised.\n\nConclusion: True.\n\nReasoning for Question 2:\n- The training requires labeled data.\n- Unsupervised learning does not require labeled data.\n- Therefore, unsupervised learning is not used.\n\nConclusion: False.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 388,
        "conclusion": "Supervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 389,
        "conclusion": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 460,
    "premises": "Junior Francisco F\u00e9lix S\u00e1nchez (born October 3, 1967) is a Dominican former professional baseball player who played in Major League Baseball as an outfielder from 1989\u20131994. 135,000 sq. If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Junior Francisco F\u00e9lix S\u00e1nchez (born October 3, 1967) is a Dominican former professional baseball player who played in Major League Baseball as an outfielder from 1989\u20131994. 135,000 sq. If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? \"Hachi: A dog's Tale\" is rated General Audience.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? \"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? \"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- From: All family-friendly animated films (FFAF) -> General Audience (GA) -> Appropriate for all ages (A).\n- Given: Hachi is (FFAF or A).\n- Since FFAF -> A, (FFAF or A) implies A. So Hachi is appropriate for all ages.\n- But A does not imply GA (only GA -> A is given). Therefore, we cannot conclude GA.\n- Answer: Unknown.\n\nQuestion 2:\n- From Question 1, Hachi is appropriate for all ages.\n- Appropriate -> children can watch without guidance.\n- From contrapositive of: If contains excessive erotic/violent (EEV) -> children cannot watch, we get: If children can watch -> not EEV.\n- Therefore, Hachi does not contain EEV.\n- The statement reduces to: Hachi is in the Frozen series.\n- We have no information that Hachi is in the Frozen series.\n- Answer: Unknown.\n\nQuestion 3:\n- We have not EEV.\n- The statement is (EEV and Frozen) or (not EEV and not Frozen). With not EEV true, this reduces to not Frozen.\n- We have no information about whether Hachi is in the Frozen series.\n- Answer: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1327,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1328,
        "conclusion": "\"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1329,
        "conclusion": "\"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 46,
    "premises": "Hans Wagner  may refer to:\n\nJohannes \"Honus\" Wagner (1874\u20131955), baseball player and Hall of Fame shortstop\nHans Wagner (entomologist) (1884-1949), German entomologist; see Trichapion\nHans Wagner (general) (1896\u20131967), German World War II general\nHans Wagner (medicine) (1905\u20131989), Swiss ophthalmologist\nHans Wagner (sculptor) (1905\u20131982), German sculptor and painter\nHans Wagner (ice hockey) (1923-2010), Austrian ice hockey player\nHans Wagner (bobsleigh) (fl. The manuscript declares the date \u2014 the first year of the emperor Decius, whose full name was Gaius Messius Quintus Traianus Decius. Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: Hans Wagner  may refer to:\n\nJohannes \"Honus\" Wagner (1874\u20131955), baseball player and Hall of Fame shortstop\nHans Wagner (entomologist) (1884-1949), German entomologist; see Trichapion\nHans Wagner (general) (1896\u20131967), German World War II general\nHans Wagner (medicine) (1905\u20131989), Swiss ophthalmologist\nHans Wagner (sculptor) (1905\u20131982), German sculptor and painter\nHans Wagner (ice hockey) (1923-2010), Austrian ice hockey player\nHans Wagner (bobsleigh) (fl. The manuscript declares the date \u2014 the first year of the emperor Decius, whose full name was Gaius Messius Quintus Traianus Decius. Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some Heck cattle are artificially selected.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Aurochs are extinct.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Breeding back is stated to be a form of artificial selection.\n- Heck cattle were bred back in the 1920s.\n- Therefore, the process that produced Heck cattle involved artificial selection, so at least some Heck cattle are artificially selected.\nConclusion: True.\n\nQuestion 2:\n- We know aurochs are animals and that Heck cattle were bred back to resemble aurochs.\n- We also know some bred-back animals resemble extinct animals, but this is not a universal claim.\n- There is no explicit statement that aurochs are extinct in the given text.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 133,
        "conclusion": "Some Heck cattle are artificially selected.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 134,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 483,
    "premises": "The S postcode area is one of six with a population above 1 million. This, along with House Of Traps and Five Element Ninjas is one of the more violent and darker-themed Shaw Brothers films. Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: The S postcode area is one of six with a population above 1 million. This, along with House Of Traps and Five Element Ninjas is one of the more violent and darker-themed Shaw Brothers films. Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Vladimir is a Russian federation official\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Vladimir is not a Russian federation official\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From the premises: US citizenship \u21d2 can register to vote \u21d2 can participate in the 2024 US presidential election.\n- Everyone is either a US citizen or a Taiwanese citizen.\n- Russian federation official \u21d2 not Taiwanese citizen.\n- Vladimir: not Taiwanese citizen, and not a Gazprom manager. From either-US-or-Taiwanese plus not Taiwanese, Vladimir is a US citizen \u21d2 can register \u21d2 can participate. No information determines whether he is an RF official.\n- Ekaterina: (can register) or (is RF official). If she can register, then she can participate. If she is an RF official, then not Taiwanese \u21d2 US citizen \u21d2 can register \u21d2 can participate. Hence Ekaterina can register and can participate.\n\nQuestion 1: Whether Vladimir is an RF official is not determined by the premises. Unknown.\n\nQuestion 2: Whether Vladimir is not an RF official is also not determined. Unknown.\n\nQuestion 3: Ekaterina can participate (as shown), so \u201cparticipate or Gazprom manager\u201d is true. True.\n\nQuestion 4: Ekaterina can participate (true), and Vladimir is not a Gazprom manager (given), but the disjunction is true because the first part is true. True.\n\nQuestion 5: We have Ekaterina can register (true) and Vladimir can participate (true), so the conjunction is true; therefore its negation is false. False.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1410,
        "conclusion": "Vladimir is a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1411,
        "conclusion": "Vladimir is not a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1412,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1413,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1414,
        "conclusion": "It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 80,
    "premises": "Croatia maintains a close security and foreign intelligence relationship with NATO and the United States. In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Croatia maintains a close security and foreign intelligence relationship with NATO and the United States. In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Neapolitan Chronicles is an English book.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Harry Potter was published by New Vessel Press.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Palace of Flies was translated from Italian.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. All of New Vessel Press's published books are in English, and Neapolitan Chronicles is published by New Vessel Press. Therefore, Neapolitan Chronicles is an English book.\n2. There is no information linking Harry Potter to New Vessel Press. We cannot determine this from the given context.\n3. Palace of Flies is published by New Vessel Press, so it is in English, but there is no information about its source language. We cannot conclude it was translated from Italian.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 243,
        "conclusion": "Neapolitan Chronicles is an English book.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 244,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 245,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 363,
    "premises": "It is also known by its product code FR9. p. All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: It is also known by its product code FR9. p. All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The mixture contains carbon.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The mixture is an alkane and contains carbon.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nFrom \u201cThe mixture either both is a chemical compound and contains only one element, or neither\u201d and \u201cNo chemical compounds contain only one element,\u201d the first option (chemical compound and only one element) is impossible. Therefore, the mixture is neither a chemical compound nor contains only one element.\n\nAll alkanes are hydrocarbons, all hydrocarbons are organic compounds, and all organic compounds are chemical compounds. Thus, all alkanes are chemical compounds. Since the mixture is not a chemical compound, it cannot be an alkane.\n\nAll organic compounds contain carbon, but the mixture is not an organic compound (since it is not a chemical compound), so we cannot infer whether it contains carbon.\n\nQuestion 1: We have no information establishing whether the mixture contains carbon; it could, but need not. So Unknown.\n\nQuestion 2: The mixture is not an alkane. Therefore, \u201cthe mixture is an alkane and contains carbon\u201d is false (a conjunction with a false conjunct).\n\nQuestion 3: The consequent (\u201cthe mixture is neither a chemical compound nor an alkane\u201d) is true as shown. An implication with a true consequent is true regardless of the antecedent. So True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 964,
        "conclusion": "The mixture contains carbon.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 965,
        "conclusion": "The mixture is an alkane and contains carbon.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 966,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 258,
    "premises": "In 1984, he was elected general secretary of the Local Government and Public Services Union. They consist of mainly solid tissue, while ovarian cysts contain fluid. All humans are mortal.\nAll Greeks are humans.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: In 1984, he was elected general secretary of the Local Government and Public Services Union. They consist of mainly solid tissue, while ovarian cysts contain fluid. All humans are mortal.\nAll Greeks are humans.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some Greeks are mortal.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n- From \"All Greeks are humans\" and \"All humans are mortal,\" we can infer \"All Greeks are mortal.\"\n- However, \"Some Greeks are mortal\" requires that at least one Greek exists.\n- The given information contains only universal statements and no existential claim about the existence of Greeks.\n- Therefore, we cannot conclude \"Some Greeks are mortal\" from the provided premises alone.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 702,
        "conclusion": "Some Greeks are mortal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 330,
    "premises": "The terms allopatry and vicariance are often used in biogeography to describe the relationship between organisms whose ranges do not significantly overlap but are immediately adjacent to each other\u2014they do not occur together or only occur within a narrow zone of contact. A Liberal, he was elected again in 1917 and 1921. All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 4)",
    "user_prompt": "Textual context: The terms allopatry and vicariance are often used in biogeography to describe the relationship between organisms whose ranges do not significantly overlap but are immediately adjacent to each other\u2014they do not occur together or only occur within a narrow zone of contact. A Liberal, he was elected again in 1917 and 1921. All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? John has a larger family.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? John does not have a larger family.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? John is engaged.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? John neither has a larger family nor does he invite others to his wedding.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Let E(x): engaged, W(x): makes wedding plans, I_o(x): invites others, I_f(x): invites friends, A(x): well-attended wedding, L(x): has a larger family.\n- Given:\n  - W(x) -> E(x).\n  - I_o(x) -> W(x).\n  - A(x) -> I_o(x).\n  - \u2203x (A(x) and L(x)) [not necessarily John].\n  - For John: E(J) -> (not I_f(J) and W(J)).\n  - For John: L(J) -> (A(J) or I_f(J)).\n\n- From these, for John: E(J) -> W(J) and W(J) -> E(J), so E(J) iff W(J). No premise asserts E(J), W(J), L(J), A(J), I_o(J), or I_f(J) for John.\n\nQuestion 1: Nothing entails L(J), and models exist where L(J) is true or false. So Unknown.\n\nQuestion 2: Same reasoning: not(L(J)) is not entailed. Unknown.\n\nQuestion 3: E(J) is not entailed; it would follow if, e.g., A(J) or I_o(J) or W(J) held, but none are given. Unknown.\n\nQuestion 4: The conjunction not L(J) and not I_o(J) is not entailed; there are models where it is true and models where it is false (e.g., if A(J) then I_o(J) holds). Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown\n4: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 846,
        "conclusion": "John has a larger family.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 847,
        "conclusion": "John does not have a larger family.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 848,
        "conclusion": "John is engaged.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 849,
        "conclusion": "John neither has a larger family nor does he invite others to his wedding.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.25
  },
  {
    "story_id": 26,
    "premises": "Later, Conrad commanded Gemini 11 in 1966, and Apollo 12 in 1969. Orient is a city in Orient Township, Adair County, Iowa, United States. Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Later, Conrad commanded Gemini 11 in 1966, and Apollo 12 in 1969. Orient is a city in Orient Township, Adair County, Iowa, United States. Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Platypuses are mammals with no teeth.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Platypuses are reptiles.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Humans are mammals.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: Platypuses are mammals. Platypuses have no teeth.\n- The statement combines both facts: mammals (true) with no teeth (true).\n- Conclusion: True.\n\nQuestion 2:\n- Given: Platypuses are mammals.\n- No information provided about reptiles or exclusivity between mammals and reptiles.\n- Cannot conclude they are reptiles or not based on provided info.\n- Conclusion: Unknown.\n\nQuestion 3:\n- Given: Humans have teeth. Some mammals have teeth.\n- \"Some mammals have teeth\" does not imply that all beings with teeth are mammals.\n- No direct statement that humans are mammals.\n- Conclusion: Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 74,
        "conclusion": "Platypuses are mammals with no teeth.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 75,
        "conclusion": "Platypuses are reptiles.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 76,
        "conclusion": "Humans are mammals.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 203,
    "premises": "Smith was a right-handed batsman and played three innings in two first-class matches, making a total of 9 runs. One of the dead hijackers was later identified by the Central Intelligence Agency as a Lebanese national named Ribal Khalil Jallul, whose passport photo was matched to a Hezbollah martyr poster found near a mosque in Beirut. Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Smith was a right-handed batsman and played three innings in two first-class matches, making a total of 9 runs. One of the dead hijackers was later identified by the Central Intelligence Agency as a Lebanese national named Ribal Khalil Jallul, whose passport photo was matched to a Hezbollah martyr poster found near a mosque in Beirut. Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Space sucks.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Space is a vampire.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If something is a household appliance, it sucks.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. Premises: \"Vacuums suck.\" and \"Space is a vacuum.\" From these, by modus ponens, space sucks. So the statement is true.\n2. \"Vampires suck.\" does not imply that anything that sucks is a vampire. We have no statement linking vacuums (or space) to vampires. So we cannot determine; it's unknown.\n3. The statement claims all household appliances suck. But \"A duster is a household appliance that doesn't suck.\" provides a counterexample. Therefore the universal claim is false.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 578,
        "conclusion": "Space sucks.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 579,
        "conclusion": "Space is a vampire.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 580,
        "conclusion": "If something is a household appliance, it sucks.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 131,
    "premises": "(\u5927\u962a\u5916\u74b0\u72b6\u9244\u9053\u682a\u5f0f\u4f1a\u793e, \u014csaka Sotokanj\u014d Tetsud\u014d Kabushiki Kaisha) as a Category-3 railway business under the Railway Business Act of Japan. Centuries ago words were added to many of the melodies and these words provided the names of the tunes as we know them today. Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: (\u5927\u962a\u5916\u74b0\u72b6\u9244\u9053\u682a\u5f0f\u4f1a\u793e, \u014csaka Sotokanj\u014d Tetsud\u014d Kabushiki Kaisha) as a Category-3 railway business under the Railway Business Act of Japan. Centuries ago words were added to many of the melodies and these words provided the names of the tunes as we know them today. Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Supervised learning is used to train the state-of-the-art text summarization model.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Unsupervised learning is used to train the state-of-the-art text summarization model.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- ML categories: supervised, unsupervised, reinforcement.\n- The SOTA text summarization model is trained with ML algorithms.\n- Reinforcement learning is not used.\n- The ML algorithm for training text summarization models requires labeled data.\n- Unsupervised learning does not require labeled data, so it cannot be the algorithm used.\n- Therefore, the remaining category that requires labeled data is supervised learning.\n- Conclusion: Supervised learning is used.\n\nQuestion 2:\n- Unsupervised learning does not require labeled data.\n- The training algorithm for text summarization requires labeled data.\n- Therefore, unsupervised learning is not used.\n- Conclusion: The statement is false.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 388,
        "conclusion": "Supervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 389,
        "conclusion": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 460,
    "premises": "Junior Francisco F\u00e9lix S\u00e1nchez (born October 3, 1967) is a Dominican former professional baseball player who played in Major League Baseball as an outfielder from 1989\u20131994. 135,000 sq. If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Junior Francisco F\u00e9lix S\u00e1nchez (born October 3, 1967) is a Dominican former professional baseball player who played in Major League Baseball as an outfielder from 1989\u20131994. 135,000 sq. If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? \"Hachi: A dog's Tale\" is rated General Audience.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? \"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? \"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- Let:\n  - AA(x): appropriate for all ages\n  - K(x): children can watch without guidance\n  - GA(x): rated General Audience\n  - E(x): contains excessive erotic and violent content\n  - FFA(x): family-friendly animated\n  - Fr(x): in the Frozen series\n\n- Rules:\n  1) AA \u2192 K\n  2) E \u2192 \u00acK (contrapositive: K \u2192 \u00acE)\n  3) GA \u2192 AA\n  4) FFA \u2192 GA\n  5) Fr \u2192 FFA\n\n- Facts:\n  - Hachi is a film.\n  - Hachi is FFA or AA.\n\nFrom \u201cFFA or AA\u201d:\n- If FFA, then GA (by 4), then AA (by 3), then K (by 1).\n- If AA, then K (by 1).\nThus, in any case, K(Hachi) holds. By contrapositive of 2, K \u2192 \u00acE, so \u00acE(Hachi). We have no information about Fr(Hachi).\n\nQuestion 1:\n- GA(Hachi)? If FFA, yes; if only AA, not necessarily. Therefore Unknown.\n\nQuestion 2:\n- E(Hachi) or Fr(Hachi)? We have \u00acE(Hachi); Fr(Hachi) is unknown. Therefore Unknown.\n\nQuestion 3:\n- (E \u2227 Fr) \u2228 (\u00acE \u2227 \u00acFr). Since \u00acE is true and Fr is unknown, this disjunction is Unknown (true if \u00acFr, false if Fr).\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1327,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1328,
        "conclusion": "\"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1329,
        "conclusion": "\"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 46,
    "premises": "Hans Wagner  may refer to:\n\nJohannes \"Honus\" Wagner (1874\u20131955), baseball player and Hall of Fame shortstop\nHans Wagner (entomologist) (1884-1949), German entomologist; see Trichapion\nHans Wagner (general) (1896\u20131967), German World War II general\nHans Wagner (medicine) (1905\u20131989), Swiss ophthalmologist\nHans Wagner (sculptor) (1905\u20131982), German sculptor and painter\nHans Wagner (ice hockey) (1923-2010), Austrian ice hockey player\nHans Wagner (bobsleigh) (fl. The manuscript declares the date \u2014 the first year of the emperor Decius, whose full name was Gaius Messius Quintus Traianus Decius. Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: Hans Wagner  may refer to:\n\nJohannes \"Honus\" Wagner (1874\u20131955), baseball player and Hall of Fame shortstop\nHans Wagner (entomologist) (1884-1949), German entomologist; see Trichapion\nHans Wagner (general) (1896\u20131967), German World War II general\nHans Wagner (medicine) (1905\u20131989), Swiss ophthalmologist\nHans Wagner (sculptor) (1905\u20131982), German sculptor and painter\nHans Wagner (ice hockey) (1923-2010), Austrian ice hockey player\nHans Wagner (bobsleigh) (fl. The manuscript declares the date \u2014 the first year of the emperor Decius, whose full name was Gaius Messius Quintus Traianus Decius. Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some Heck cattle are artificially selected.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Aurochs are extinct.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Breeding back is defined as a form of artificial selection.\n- Heck cattle were bred back in the 1920s.\n- Therefore, Heck cattle underwent artificial selection, so at least some Heck cattle are artificially selected.\nConclusion: True.\n\nQuestion 2:\n- We are told aurochs are animals and that Heck cattle were bred back to resemble aurochs.\n- We are also told that some animals bred back resemble extinct animals, but this does not imply all such targets are extinct.\n- There is no explicit statement that aurochs are extinct.\nConclusion: Unknown.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 133,
        "conclusion": "Some Heck cattle are artificially selected.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 134,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 483,
    "premises": "The S postcode area is one of six with a population above 1 million. This, along with House Of Traps and Five Element Ninjas is one of the more violent and darker-themed Shaw Brothers films. Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: The S postcode area is one of six with a population above 1 million. This, along with House Of Traps and Five Element Ninjas is one of the more violent and darker-themed Shaw Brothers films. Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Vladimir is a Russian federation official\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Vladimir is not a Russian federation official\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nGiven rules and facts:\n- If someone can register to vote in the US, then they can participate in the 2024 US presidential election. (Register -> Participate)\n- If someone has US citizenship, then they can register to vote in the US. (USC -> Register)\n- Every person has either US or Taiwanese citizenship. (USC or TC)\n- No Russian Federation officials have Taiwanese citizenship. (Official -> \u00acTC)\n- Vladimir: \u00acTC(Vladimir) and \u00acManagerGazprom(Vladimir).\n- Ekaterina: Register(Ekaterina) or Official(Ekaterina).\n\nDerived:\n- From \u00acTC(Vladimir) and (USC or TC), we get USC(Vladimir) -> Register(Vladimir) -> Participate(Vladimir).\n- For Ekaterina:\n  - If Register(Ekaterina), then Participate(Ekaterina).\n  - If Official(Ekaterina), then \u00acTC(Ekaterina); with (USC or TC), get USC(Ekaterina) -> Register(Ekaterina) -> Participate(Ekaterina).\n  Thus both disjuncts imply Participate(Ekaterina) and in fact Register(Ekaterina). So Register(Ekaterina) and Participate(Ekaterina) are true.\n\nQuestions:\n1) Vladimir is a Russian federation official. No information implies this; \u00acTC does not imply not-official or official. Unknown.\n2) Vladimir is not a Russian federation official. Also not derivable. Unknown.\n3) Ekaterina can participate in the 2024 US presidential election or is a manager at Gazprom. Participate(Ekaterina) is true, so the disjunction is true. True.\n4) Ekaterina can participate in the 2024 US presidential election or Vladimir is a manager at Gazprom. Participate(Ekaterina) is true, so the disjunction is true. True.\n5) Not (Ekaterina can register in the US and Vladimir can participate in the 2024 US presidential election). Both Register(Ekaterina) and Participate(Vladimir) are true, so the conjunction is true; its negation is false. False.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1410,
        "conclusion": "Vladimir is a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1411,
        "conclusion": "Vladimir is not a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1412,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1413,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1414,
        "conclusion": "It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 80,
    "premises": "Croatia maintains a close security and foreign intelligence relationship with NATO and the United States. In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Croatia maintains a close security and foreign intelligence relationship with NATO and the United States. In the Roman Empire it was known as the Year of the Consulship of Poplicola and Tricipitinus (or, less frequently, year 250  Ab urbe condita). New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Neapolitan Chronicles is an English book.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Harry Potter was published by New Vessel Press.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Palace of Flies was translated from Italian.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Premise: All of New Vessel Press's published books are in English.\n- Premise: Neapolitan Chronicles is a book published by New Vessel Press.\n- Therefore, Neapolitan Chronicles is in English. True.\n\nQuestion 2:\n- There is no information connecting Harry Potter to New Vessel Press.\n- Therefore, we cannot determine whether it was published by New Vessel Press. Unknown.\n\nQuestion 3:\n- Premise: Palace of Flies is a book published by New Vessel Press.\n- We know NVP specializes in translating foreign literature into English, but this does not imply all books are translated, nor that translations are specifically from Italian.\n- No direct statement about Palace of Flies\u2019 source language. Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 243,
        "conclusion": "Neapolitan Chronicles is an English book.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 244,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 245,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 363,
    "premises": "It is also known by its product code FR9. p. All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: It is also known by its product code FR9. p. All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The mixture contains carbon.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The mixture is an alkane and contains carbon.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cNo chemical compounds contain only one element\u201d and \u201cThe mixture either both is a chemical compound and contains only one element, or neither,\u201d the first option (both) is impossible. Therefore, the mixture is neither a chemical compound nor contains only one element.\n- Contrapositives:\n  - From \u201cAll organic compounds are chemical compounds,\u201d not chemical compound \u21d2 not organic.\n  - From \u201cAll hydrocarbons are organic compounds,\u201d not organic \u21d2 not hydrocarbon.\n  - From \u201cAll alkanes are hydrocarbons,\u201d not hydrocarbon \u21d2 not alkane.\n- \u201cAll organic compounds contain carbon\u201d does not imply that non-organic things lack carbon; thus, whether the mixture contains carbon is undetermined.\n\nQuestion 1: We have no rule determining carbon content for non-organic/non-compound items. So Unknown.\n\nQuestion 2: The mixture is not an alkane; hence \u201calkane and contains carbon\u201d is false regardless of carbon. So False.\n\nQuestion 3: The consequent (\u201cneither a chemical compound nor an alkane\u201d) is true as deduced, making the implication true regardless of the antecedent. So True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 964,
        "conclusion": "The mixture contains carbon.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 965,
        "conclusion": "The mixture is an alkane and contains carbon.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 966,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 258,
    "premises": "In 1984, he was elected general secretary of the Local Government and Public Services Union. They consist of mainly solid tissue, while ovarian cysts contain fluid. All humans are mortal.\nAll Greeks are humans.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: In 1984, he was elected general secretary of the Local Government and Public Services Union. They consist of mainly solid tissue, while ovarian cysts contain fluid. All humans are mortal.\nAll Greeks are humans.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some Greeks are mortal.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Given: All humans are mortal. All Greeks are humans.\n- From these, it follows that all Greeks are mortal.\n- The statement \u201cSome Greeks are mortal\u201d requires that at least one Greek exists.\n- The provided context does not assert the existence of any Greeks.\n- Therefore, we cannot conclude \u201cSome Greeks are mortal\u201d from the given information alone.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 702,
        "conclusion": "Some Greeks are mortal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 435,
    "premises": "The Blues EP is the second recording by Some Girls. It breeds in Sakhalin, the Kuril Islands and Japan; it winters in south toward the Ryukyu Islands, Taiwan, Hainan and the northern Philippines. None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 4)",
    "user_prompt": "Textual context: The Blues EP is the second recording by Some Girls. It breeds in Sakhalin, the Kuril Islands and Japan; it winters in south toward the Ryukyu Islands, Taiwan, Hainan and the northern Philippines. None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? James has a part-time job offered by the university.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? James does not have a part-time job offered by the university.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? James either takes the database course or has a part-time job offered by the university.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? James takes the database course.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- From \u201cAll students working in the lab are taking a class with Professor David\u201d and \u201cAll of the students taking a class with Professor David are taking the database course,\u201d if James works in the lab, then James takes the database course.\n- The text explicitly states both \u201cJames is a student working in the lab\u201d and \u201cJames doesn't work in the lab or have a part-time job offered by the university.\u201d The latter reads as \u201cJames neither works in the lab nor has a part-time job.\u201d This creates a contradiction about lab work, but it directly gives that James does not have a part-time job.\n- Regardless of the lab-work contradiction, from the given \u201cJames is a student working in the lab,\u201d we can derive that James takes the database course; there is no information that implies he does not take the database course.\n- Therefore:\n  - Q1: James having a part-time job is contradicted by the statement that he does not have one \u2192 False.\n  - Q2: James not having a part-time job is directly stated \u2192 True.\n  - Q3: \u201cDatabase course or part-time job\u201d holds because James takes the database course \u2192 True.\n  - Q4: James takes the database course via the lab \u2192 Professor David \u2192 database chain \u2192 True.\n\nANSWERS:\n1: False\n2: True\n3: True\n4: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1244,
        "conclusion": "James has a part-time job offered by the university.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1245,
        "conclusion": "James does not have a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1246,
        "conclusion": "James either takes the database course or has a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1247,
        "conclusion": "James takes the database course.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.75
  },
  {
    "story_id": 217,
    "premises": "8-mile-long rail trail in Oakland County, Michigan. The Henry August (or Augustus) Rowland House is a historic row house at 915 Cathedral Street in Baltimore, Maryland. If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: 8-mile-long rail trail in Oakland County, Michigan. The Henry August (or Augustus) Rowland House is a historic row house at 915 Cathedral Street in Baltimore, Maryland. If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? If George likes music and has access to a program, he will compose.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? If George will not compose, George can not compose.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: If likes music (LM) then wants to compose (W). If has access to a program (A) then can compose (C). If can compose and wants to compose (C \u2227 W) then will compose (Do).\n- From LM \u2227 A, we get W and C, hence C \u2227 W, hence Do.\n- Therefore, the statement is true.\n\nQuestion 2:\n- From the third rule, contrapositive: If not Do, then (not C) or (not W): \u00acDo \u2192 (\u00acC \u2228 \u00acW).\n- The statement claims \u00acDo \u2192 \u00acC, which is stronger than what is given.\n- It could be that \u00acDo and C hold because W is false (e.g., he doesn\u2019t want to compose), which is consistent with the premises.\n- Therefore, the statement is not entailed; its truth is unknown based on the given information.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 618,
        "conclusion": "If George likes music and has access to a program, he will compose.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 619,
        "conclusion": "If George will not compose, George can not compose.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 292,
    "premises": "I Was Lord Kitchener's Valet is a clothing boutique which achieved fame in 1960s \"Swinging London\" by promoting antique military uniforms as fashion items. Present-day Illinois was inhabited by Indigenous cultures for thousands of years. A hawk never swims. \nSome birds are hawks.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: I Was Lord Kitchener's Valet is a clothing boutique which achieved fame in 1960s \"Swinging London\" by promoting antique military uniforms as fashion items. Present-day Illinois was inhabited by Indigenous cultures for thousands of years. A hawk never swims. \nSome birds are hawks.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? All birds swim.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n- Given: A hawk never swims.\n- Given: Some birds are hawks. Therefore, there exists at least one bird that is a hawk.\n- Since hawks never swim, that bird does not swim.\n- Therefore, it is not the case that all birds swim.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 736,
        "conclusion": "All birds swim.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 318,
    "premises": "Joppa is now largely residential, but salt was once produced from seawater by evaporation at Joppa Pans. A member of the Sisodia dynasty, he controlled parts of present-day Rajasthan, Gujarat, Madhya Pradesh, Haryana, Sindh, and Uttar Pradesh with his capital at Chittorgarh. Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Joppa is now largely residential, but salt was once produced from seawater by evaporation at Joppa Pans. A member of the Sisodia dynasty, he controlled parts of present-day Rajasthan, Gujarat, Madhya Pradesh, Haryana, Sindh, and Uttar Pradesh with his capital at Chittorgarh. Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Breaking Bad is on Monday at 8 pm.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If roses are given out during Breaking Bad, then it is on Monday at 8 pm.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From: If a show gives out roses on TV, then it is an episode of The Bachelor; The Bachelor portrays the lives of real people; all shows portraying real people are reality TV shows. Therefore, any show that gives out roses is a reality TV show.\n- Breaking Bad is not a reality TV show. Hence, Breaking Bad does not give out roses on TV (otherwise it would be reality TV).\n- The only scheduling information provided is that some show that gives out roses airs Monday at 8 pm. No schedule is given for Breaking Bad.\n\nQuestion 1:\n- No information about Breaking Bad\u2019s airing time. Conclusion: Unknown.\n\nQuestion 2:\n- Claims roses are given out during Breaking Bad; but we deduced Breaking Bad does not give out roses. Conclusion: False.\n\nQuestion 3:\n- If roses are given out during Breaking Bad, then Monday at 8 pm. Since roses are not given out during Breaking Bad, the antecedent is false, making the conditional vacuously true. Conclusion: True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 802,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 803,
        "conclusion": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 804,
        "conclusion": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 107,
    "premises": "The French Antarctic Expedition  is any of several French expeditions in Antarctica. When necessary, the ten-digit number may be prefixed with the trunk code 1, which is referred to as 1+10-digit dialing or national format. Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The French Antarctic Expedition  is any of several French expeditions in Antarctica. When necessary, the ten-digit number may be prefixed with the trunk code 1, which is referred to as 1+10-digit dialing or national format. Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Heinrich Schmidt was German or Russian or both.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? No politicians are part of the Nazi Reichstag.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. The statement uses an inclusive \"or.\" The text states Heinrich Schmidt was a German politician. Therefore, \"German or Russian or both\" is satisfied because he is German.\n2. The text states Heinrich Schmidt was a German politician and also a member of both the Prussian State Parliament and the Nazi Reichstag. Hence, there exists such a German politician.\n3. The text provides a counterexample: Heinrich Schmidt was a politician and a member of the Nazi Reichstag. Therefore, it's not true that no politicians are part of the Nazi Reichstag.\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 323,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 324,
        "conclusion": "Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 325,
        "conclusion": "No politicians are part of the Nazi Reichstag.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 386,
    "premises": "From 1980 to 1988, Stewart wrote two books about Merlin, translating and exploring medieval texts on the topic (now published in one volume as Merlin: the Prophetic Vision and Mystic Life, by Penguin Arkana). Inspired by Fascist Italy and Vichy France, the group attracted support from many young nationalists during the Algerian war (1954\u201362), especially in the French colonial army. If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: From 1980 to 1988, Stewart wrote two books about Merlin, translating and exploring medieval texts on the topic (now published in one volume as Merlin: the Prophetic Vision and Mystic Life, by Penguin Arkana). Inspired by Fascist Italy and Vichy France, the group attracted support from many young nationalists during the Algerian war (1954\u201362), especially in the French colonial army. If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Colorectal cancer is a kind of severe cancer\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From the premises: bile duct cancer -> severe cancer -> deadly disease -> low survival. Hence, bile duct cancer -> low survival.\n- Given: not(colorectal is bile duct cancer AND low survival). Combining with bile duct cancer -> low survival, we conclude colorectal is not a bile duct cancer. Since Cholangiocarcinoma -> bile duct cancer, colorectal is also not Cholangiocarcinoma.\n- No premise links colorectal cancer to being severe or to mild flu.\n\nQuestion 1:\n- We have no information that colorectal cancer is severe, nor can we infer the negation. So its severity status is undetermined.\n- Answer: Unknown.\n\nQuestion 2:\n- The antecedent (colorectal is bile duct cancer or Cholangiocarcinoma) is impossible given the premises (both are false for colorectal cancer). Therefore, the implication is vacuously true.\n- Answer: True.\n\nQuestion 3:\n- The statement is a disjunction including cases that require colorectal cancer to be Cholangiocarcinoma and/or a bile duct cancer. Since both are ruled out, all disjuncts are false regardless of the mild flu part.\n- Answer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1032,
        "conclusion": "Colorectal cancer is a kind of severe cancer",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1033,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1034,
        "conclusion": "Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 355,
    "premises": "The party put forward 142 candidates for the 52 seats in the National Assembly. In 2023, it was the 212th most commonly prescribed medication in the United States, with more than 2 million prescriptions. All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The party put forward 142 candidates for the 52 seats in the National Assembly. In 2023, it was the 212th most commonly prescribed medication in the United States, with more than 2 million prescriptions. All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Taylor eats salads regularly.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Taylor visits the gym at least once a day.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Let S = eats salads regularly; C = very conscious about health/eating; H = grew up in a health-conscious childhood home; N = fulfills daily nutritional intakes; D = disregards physical well-being; G = visits the gym at least once a day.\n- Given: S -> C; H -> S; N -> H; D -> \u00acC; G -> N.\n- Taylor: (H \u2227 D) \u2228 (\u00acH \u2227 \u00acD). If H \u2227 D held, then H -> S -> C and D -> \u00acC, a contradiction. So the first disjunct is impossible, hence \u00acH \u2227 \u00acD.\n- From G -> N -> H, contrapositive gives \u00acH -> \u00acG. Since \u00acH, we have \u00acG.\n\nQuestion 1:\n- From \u00acH we cannot infer whether S holds (H -> S does not imply \u00acH -> \u00acS). So Unknown.\n\nQuestion 2:\n- We derived \u00acG, so the statement \u201cvisits the gym at least once a day\u201d is False.\n\nQuestion 3:\n- We have \u00acH and \u00acG; thus \u201cneither H nor visits the gym at least once a day\u201d is True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 941,
        "conclusion": "Taylor eats salads regularly.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 942,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 943,
        "conclusion": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 51,
    "premises": "Shapiro resigned abruptly from Warner Bros. the Glenmorgan Generous Stakes, in 2003, when it was raced at Otaki. The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Shapiro resigned abruptly from Warner Bros. the Glenmorgan Generous Stakes, in 2003, when it was raced at Otaki. The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The world championships is a sporting event.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The last summer Olympic games were not in Tokyo.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The United States won the most medals in the last summer Olympic games.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: \"The summer Olympic games is a sporting event.\"\n- No information is provided about \"the world championships.\"\n- Conclusion: Cannot determine from the text.\n- Answer: Unknown\n\nQuestion 2:\n- Given: \"The last summer Olympic games was in Tokyo.\"\n- Statement claims they were not in Tokyo.\n- This directly contradicts the given information.\n- Answer: False\n\nQuestion 3:\n- Given: \"The last summer Olympic games was in Tokyo.\" and \"The United States won the most medals in Tokyo.\"\n- Therefore, the United States won the most medals in the last summer Olympic games.\n- Answer: True\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 147,
        "conclusion": "The world championships is a sporting event.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 148,
        "conclusion": "The last summer Olympic games were not in Tokyo.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 149,
        "conclusion": "The United States won the most medals in the last summer Olympic games.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 259,
    "premises": "Evelyn Baring, 1st Baron Howick of Glendale, was the third son of the first Earl. In 1979, Wishman filmed her first and only feature horror film, A Night to Dismember, which she spent several years editing after multiple reels were destroyed during post-production. All horses have hooves.\nNo humans have hooves.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: Evelyn Baring, 1st Baron Howick of Glendale, was the third son of the first Earl. In 1979, Wishman filmed her first and only feature horror film, A Night to Dismember, which she spent several years editing after multiple reels were destroyed during post-production. All horses have hooves.\nNo humans have hooves.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some humans are horses.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From the context: All horses have hooves.\n- Also: No humans have hooves.\n- If any human were a horse, that human would have hooves (by the first statement), which contradicts the second statement.\n- Therefore, no human is a horse, making the statement \"Some humans are horses\" false.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 703,
        "conclusion": "Some humans are horses.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 152,
    "premises": "Lilly suspended sales of Oraflex in 1982 after reports from the British government and the United States Food and Drug Administration (US FDA) of adverse effects and deaths linked to the drug. The oldest HS station on FM is WNAS in New Albany, Indiana, which started broadcasting in May 1949. Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: Lilly suspended sales of Oraflex in 1982 after reports from the British government and the United States Food and Drug Administration (US FDA) of adverse effects and deaths linked to the drug. The oldest HS station on FM is WNAS in New Albany, Indiana, which started broadcasting in May 1949. Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Susan flies from LGA airport.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? John flies to LGA airport.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Q1: It states Susan flies to LGA. Since departure and arrival cannot be the same airport, her departure cannot be LGA. Therefore, the statement that she flies from LGA is false.\n- Q2: It states John flies from LGA. Since departure and arrival cannot be the same airport, his arrival cannot be LGA. Therefore, the statement that he flies to LGA is false.\n\nANSWERS:\n1: False\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 442,
        "conclusion": "Susan flies from LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 443,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 435,
    "premises": "The Blues EP is the second recording by Some Girls. It breeds in Sakhalin, the Kuril Islands and Japan; it winters in south toward the Ryukyu Islands, Taiwan, Hainan and the northern Philippines. None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 4)",
    "user_prompt": "Textual context: The Blues EP is the second recording by Some Girls. It breeds in Sakhalin, the Kuril Islands and Japan; it winters in south toward the Ryukyu Islands, Taiwan, Hainan and the northern Philippines. None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? James has a part-time job offered by the university.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? James does not have a part-time job offered by the university.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? James either takes the database course or has a part-time job offered by the university.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? James takes the database course.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cJames is a student working in the lab\u201d and the rules: Lab \u2192 Class with David \u2192 Database \u2192 Computer Science. So James takes the database course.\n- From \u201cJames doesn't work in the lab or have a part-time job offered by the university,\u201d read as \u201cneither works in the lab nor has a university-offered part-time job,\u201d we get that James does not have such a part-time job. This conflicts with \u201cJames is working in the lab,\u201d but the part-time job negation still stands and there is no statement asserting he does have one.\n- Therefore:\n  - Q1 (James has a part-time job): contradicted by the explicit negation \u2192 False.\n  - Q2 (James does not have a part-time job): explicitly stated \u2192 True.\n  - Q3 (James either takes the database course or has a part-time job): database course is true, so the disjunction is true \u2192 True.\n  - Q4 (James takes the database course): follows from Lab \u2192 David \u2192 Database \u2192 True.\n\nANSWERS:\n1: False\n2: True\n3: True\n4: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1244,
        "conclusion": "James has a part-time job offered by the university.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1245,
        "conclusion": "James does not have a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1246,
        "conclusion": "James either takes the database course or has a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1247,
        "conclusion": "James takes the database course.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.75
  },
  {
    "story_id": 217,
    "premises": "8-mile-long rail trail in Oakland County, Michigan. The Henry August (or Augustus) Rowland House is a historic row house at 915 Cathedral Street in Baltimore, Maryland. If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: 8-mile-long rail trail in Oakland County, Michigan. The Henry August (or Augustus) Rowland House is a historic row house at 915 Cathedral Street in Baltimore, Maryland. If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? If George likes music and has access to a program, he will compose.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? If George will not compose, George can not compose.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- If George likes music, then he wants to compose.\n- If he has access to a program, then he can compose.\n- If he can compose and wants to compose, then he will compose.\n- Therefore, if he likes music and has access to a program, he both wants and can compose, which implies he will compose. So the statement is true.\n\nQuestion 2:\n- We have: (can compose \u2227 wants to compose) -> will compose.\n- From not will compose, we can only infer not(can \u2227 wants), which means either not can or not wants.\n- It does not follow that not will implies not can specifically; he might be able to compose but not want to. Hence the statement cannot be concluded as true or false from the given info. It is unknown.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 618,
        "conclusion": "If George likes music and has access to a program, he will compose.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 619,
        "conclusion": "If George will not compose, George can not compose.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 292,
    "premises": "I Was Lord Kitchener's Valet is a clothing boutique which achieved fame in 1960s \"Swinging London\" by promoting antique military uniforms as fashion items. Present-day Illinois was inhabited by Indigenous cultures for thousands of years. A hawk never swims. \nSome birds are hawks.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: I Was Lord Kitchener's Valet is a clothing boutique which achieved fame in 1960s \"Swinging London\" by promoting antique military uniforms as fashion items. Present-day Illinois was inhabited by Indigenous cultures for thousands of years. A hawk never swims. \nSome birds are hawks.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? All birds swim.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- \"A hawk never swims\" means no hawks swim.\n- \"Some birds are hawks\" means at least one bird is a hawk.\n- Therefore, at least one bird does not swim.\n- Hence, the statement \"All birds swim\" is false.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 736,
        "conclusion": "All birds swim.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 318,
    "premises": "Joppa is now largely residential, but salt was once produced from seawater by evaporation at Joppa Pans. A member of the Sisodia dynasty, he controlled parts of present-day Rajasthan, Gujarat, Madhya Pradesh, Haryana, Sindh, and Uttar Pradesh with his capital at Chittorgarh. Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Joppa is now largely residential, but salt was once produced from seawater by evaporation at Joppa Pans. A member of the Sisodia dynasty, he controlled parts of present-day Rajasthan, Gujarat, Madhya Pradesh, Haryana, Sindh, and Uttar Pradesh with his capital at Chittorgarh. Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Breaking Bad is on Monday at 8 pm.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If roses are given out during Breaking Bad, then it is on Monday at 8 pm.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cSome show airing at 8 pm on Monday gives out roses on TV\u201d and \u201cIf a show gives out roses on TV, then the show is an episode of The Bachelor,\u201d we know there exists a Monday 8 pm show that is (an episode of) The Bachelor.\n- The Bachelor portrays the lives of real people, and all shows portraying the lives of real people are reality TV shows. Hence, shows that give out roses are reality TV.\n- Breaking Bad is a show and is not a reality TV show. Therefore, Breaking Bad does not give out roses and is not the Monday 8 pm rose-giving show.\n- We have no information about Breaking Bad\u2019s airing time.\n- The statement \u201cIf roses are given out during Breaking Bad, then it is on Monday at 8 pm\u201d has a false antecedent (since Breaking Bad does not give out roses), making the implication vacuously true.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 802,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 803,
        "conclusion": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 804,
        "conclusion": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 107,
    "premises": "The French Antarctic Expedition  is any of several French expeditions in Antarctica. When necessary, the ten-digit number may be prefixed with the trunk code 1, which is referred to as 1+10-digit dialing or national format. Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The French Antarctic Expedition  is any of several French expeditions in Antarctica. When necessary, the ten-digit number may be prefixed with the trunk code 1, which is referred to as 1+10-digit dialing or national format. Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Heinrich Schmidt was German or Russian or both.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? No politicians are part of the Nazi Reichstag.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- We are told Heinrich Schmidt was a German politician and a member of both the Prussian State Parliament and the Nazi Reichstag.\n- Q1 asks about a disjunction (German or Russian or both). Since he is German, the disjunction is satisfied regardless of whether he is Russian.\n- Q2 asks for existence: there exists a German politician who was part of both bodies. Heinrich Schmidt satisfies this.\n- Q3 asserts no politicians are part of the Nazi Reichstag. This is contradicted by Heinrich Schmidt being a politician and a member of the Nazi Reichstag.\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 323,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 324,
        "conclusion": "Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 325,
        "conclusion": "No politicians are part of the Nazi Reichstag.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 386,
    "premises": "From 1980 to 1988, Stewart wrote two books about Merlin, translating and exploring medieval texts on the topic (now published in one volume as Merlin: the Prophetic Vision and Mystic Life, by Penguin Arkana). Inspired by Fascist Italy and Vichy France, the group attracted support from many young nationalists during the Algerian war (1954\u201362), especially in the French colonial army. If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: From 1980 to 1988, Stewart wrote two books about Merlin, translating and exploring medieval texts on the topic (now published in one volume as Merlin: the Prophetic Vision and Mystic Life, by Penguin Arkana). Inspired by Fascist Italy and Vichy France, the group attracted support from many young nationalists during the Algerian war (1954\u201362), especially in the French colonial army. If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Colorectal cancer is a kind of severe cancer\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nGiven facts:\n- Deadly disease -> Low survival.\n- Severe cancer -> Deadly disease -> Low survival.\n- Bile duct cancer -> Severe cancer -> Low survival.\n- Cholangiocarcinoma -> Bile duct cancer -> Low survival.\n- Mild flu -> Low survival.\n- Not (Colorectal is bile duct cancer AND colorectal has low survival).\n\nFrom Bile duct -> Low survival and Not (Bile duct \u2227 Low survival), we deduce colorectal is not bile duct cancer. From Cholangiocarcinoma -> Bile duct, we also deduce colorectal is not Cholangiocarcinoma.\n\nQuestion 1:\nWe have no information linking colorectal cancer to severe cancer except via bile duct cancer, which we know it is not. So we cannot conclude it is severe. Answer: Unknown.\n\nQuestion 2:\nAntecedent: colorectal is bile duct cancer or Cholangiocarcinoma. Both disjuncts are false, so the antecedent is false; hence the conditional is vacuously true. Answer: True.\n\nQuestion 3:\nThe statement is (Cholangiocarcinoma and mild flu) or bile duct cancer (or all of the above). Since Cholangiocarcinoma implies bile duct cancer, this reduces to \u201cbile duct cancer.\u201d We established colorectal is not bile duct cancer, so the statement is false. Answer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1032,
        "conclusion": "Colorectal cancer is a kind of severe cancer",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1033,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1034,
        "conclusion": "Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 355,
    "premises": "The party put forward 142 candidates for the 52 seats in the National Assembly. In 2023, it was the 212th most commonly prescribed medication in the United States, with more than 2 million prescriptions. All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: The party put forward 142 candidates for the 52 seats in the National Assembly. In 2023, it was the 212th most commonly prescribed medication in the United States, with more than 2 million prescriptions. All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Taylor eats salads regularly.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Taylor visits the gym at least once a day.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Let S = eats salads regularly, C = very conscious about health/eating habits, H = grew up in a health-conscious childhood home, N = fulfills daily nutritional intakes, D = disregards physical well-being, G = visits the gym at least once a day.\n- Given: S -> C; H -> S; N -> H; D -> \u00acC; G -> N.\n- For Taylor: (H \u2227 D) \u2228 (\u00acH \u2227 \u00acD).\n- If H \u2227 D held, then H -> S -> C and D -> \u00acC, yielding C \u2227 \u00acC, a contradiction. So the first disjunct is impossible, hence Taylor satisfies \u00acH \u2227 \u00acD.\n\nQuestion 1:\n- From \u00acH we cannot infer \u00acS (we only have H -> S, not its converse). No other rule determines S. Therefore unknown.\n\nQuestion 2:\n- From \u00acH and N -> H, by contrapositive \u00acH -> \u00acN. From \u00acN and G -> N, by contrapositive \u00acN -> \u00acG. Hence Taylor does not visit the gym at least once a day. Therefore false.\n\nQuestion 3:\n- We have \u00acH and, as shown above, \u00acG. So the statement that Taylor neither grew up in a health-conscious childhood home nor visits the gym at least once a day is true.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 941,
        "conclusion": "Taylor eats salads regularly.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 942,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 943,
        "conclusion": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 51,
    "premises": "Shapiro resigned abruptly from Warner Bros. the Glenmorgan Generous Stakes, in 2003, when it was raced at Otaki. The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Shapiro resigned abruptly from Warner Bros. the Glenmorgan Generous Stakes, in 2003, when it was raced at Otaki. The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? The world championships is a sporting event.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? The last summer Olympic games were not in Tokyo.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? The United States won the most medals in the last summer Olympic games.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1. The context only states that the summer Olympic games is a sporting event; it says nothing about the world championships. Therefore, we cannot determine if the world championships is a sporting event from the given information.\n2. The context explicitly states that the last summer Olympic games was in Tokyo. Therefore, the statement that they were not in Tokyo is false.\n3. Since the last summer Olympic games was in Tokyo, and the United States won the most medals in Tokyo, it follows that the United States won the most medals in the last summer Olympic games.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 147,
        "conclusion": "The world championships is a sporting event.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 148,
        "conclusion": "The last summer Olympic games were not in Tokyo.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 149,
        "conclusion": "The United States won the most medals in the last summer Olympic games.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 259,
    "premises": "Evelyn Baring, 1st Baron Howick of Glendale, was the third son of the first Earl. In 1979, Wishman filmed her first and only feature horror film, A Night to Dismember, which she spent several years editing after multiple reels were destroyed during post-production. All horses have hooves.\nNo humans have hooves.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: Evelyn Baring, 1st Baron Howick of Glendale, was the third son of the first Earl. In 1979, Wishman filmed her first and only feature horror film, A Night to Dismember, which she spent several years editing after multiple reels were destroyed during post-production. All horses have hooves.\nNo humans have hooves.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Some humans are horses.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- All horses have hooves.\n- No humans have hooves.\n- If any humans were horses, they would have hooves, contradicting \"No humans have hooves.\"\n- Therefore, no humans are horses, making the statement \"Some humans are horses\" false.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 703,
        "conclusion": "Some humans are horses.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 152,
    "premises": "Lilly suspended sales of Oraflex in 1982 after reports from the British government and the United States Food and Drug Administration (US FDA) of adverse effects and deaths linked to the drug. The oldest HS station on FM is WNAS in New Albany, Indiana, which started broadcasting in May 1949. Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: Lilly suspended sales of Oraflex in 1982 after reports from the British government and the United States Food and Drug Administration (US FDA) of adverse effects and deaths linked to the drug. The oldest HS station on FM is WNAS in New Albany, Indiana, which started broadcasting in May 1949. Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Susan flies from LGA airport.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? John flies to LGA airport.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Q1: Susan\u2019s arrival airport is LGA. Since departure and arrival cannot be the same, Susan\u2019s departure cannot be LGA. Therefore, \u201cSusan flies from LGA\u201d is false.\n- Q2: John\u2019s departure airport is LGA. Since departure and arrival cannot be the same, John\u2019s arrival cannot be LGA. Therefore, \u201cJohn flies to LGA\u201d is false.\n\nANSWERS:\n1: False\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 442,
        "conclusion": "Susan flies from LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 443,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 441,
    "premises": "This article incorporates text from a publication now in the public domain: Gilman, D. Vancouver Mall is a shopping mall owned by Cenntenial Real Estate, and located in the city of Vancouver, Washington, U. No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: This article incorporates text from a publication now in the public domain: Gilman, D. Vancouver Mall is a shopping mall owned by Cenntenial Real Estate, and located in the city of Vancouver, Washington, U. No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Tom is a grumpy person.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Tom is not both a grumpy person and mean to animals.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cAll pet owners love animals\u201d and \u201cAll animal lovers are nice to animals,\u201d Tom (a pet owner) is an animal lover and thus nice to animals.\n- From \u201cNo one nice to animals is also mean to animals,\u201d anyone nice is not mean; therefore, Tom is not mean to animals.\n\nQuestion 1:\n- Nothing links Tom to being grumpy. Some grumpy people are mean, but not all; and Tom being nice (hence not mean) doesn\u2019t determine whether he is grumpy. So this is unknown.\n\nQuestion 2:\n- Since Tom is not mean, he cannot be both grumpy and mean. So the statement \u201cTom is not both grumpy and mean\u201d is true.\n\nQuestion 3:\n- Antecedent \u201cTom is not both grumpy and mean\u201d is true (from above).\n- Consequent \u201cTom is neither grumpy nor an animal lover\u201d is false because Tom is an animal lover.\n- A true antecedent and false consequent makes the implication false.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1268,
        "conclusion": "Tom is a grumpy person.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1269,
        "conclusion": "Tom is not both a grumpy person and mean to animals.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1270,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 64,
    "premises": "Liam Cormier (born February 9, 1980) is a Canadian musician from Toronto, Ontario. In 1980, however, the current name\u2014Australian Army Reserve\u2014was officially adopted, and it now consists of a number of components based around the level of commitment and training obligation that its members are required to meet. A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Liam Cormier (born February 9, 1980) is a Canadian musician from Toronto, Ontario. In 1980, however, the current name\u2014Australian Army Reserve\u2014was officially adopted, and it now consists of a number of components based around the level of commitment and training obligation that its members are required to meet. A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Dani Shapiro is a novel writer.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Family Secrets is a novel.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Dani Shapiro was born in Boston.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: Family History is a novel, and it is written by Dani Shapiro.\n- Rule: If a book is a novel and it is written by a person, then the person is a novel writer.\n- Therefore, Dani Shapiro is a novel writer. Answer: True.\n\nQuestion 2:\n- Given: Dani Shapiro created a podcast called Family Secrets.\n- Rule: A podcast is not a novel.\n- Therefore, Family Secrets is not a novel. Answer: False.\n\nQuestion 3:\n- Given: If a person is born in an American city, the person is American. Boston is an American city. Dani Shapiro is American.\n- However, we are not told where Dani Shapiro was born; being American does not imply being born in Boston.\n- Therefore, we cannot conclude she was born in Boston. Answer: Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 189,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 190,
        "conclusion": "Family Secrets is a novel.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 191,
        "conclusion": "Dani Shapiro was born in Boston.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 456,
    "premises": "The trust was delisted from the Toronto Stock Exchange and the New York Stock Exchange in December 2009. Jean Lemire crossed the Atlantic Ocean between 1650 and 1653. Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: The trust was delisted from the Toronto Stock Exchange and the New York Stock Exchange in December 2009. Jean Lemire crossed the Atlantic Ocean between 1650 and 1653. Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Yuri is an American national.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Yuri is not an American professional basketball player.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Yuri is an American professional basketball player.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \"If someone leaps straight into the air, they activate their leg muscles\" and \"Yuri does not activate his leg muscles,\" we infer Yuri does not leap straight into the air (contrapositive).\n- From \"If someone can jump shots, they leap straight into the air,\" we infer that if someone does not leap straight into the air, they cannot do jump shots. Hence, Yuri cannot do jump shots.\n- From \"All professional basketball players can do jump shots,\" we infer that if someone cannot do jump shots, they are not a professional basketball player. Hence, Yuri is not a professional basketball player.\n- The statement about some professional basketball players not being American provides no information about Yuri\u2019s nationality.\n\nQuestion 1: Nothing determines Yuri\u2019s nationality. Unknown.\nQuestion 2: Since Yuri is not a professional basketball player, he is not an American professional basketball player. True.\nQuestion 3: Yuri is not a professional basketball player, so he cannot be an American professional basketball player. False.\nQuestion 4: The antecedent (Yuri does not leap) is true, but the consequent (Yuri is an American professional basketball player) is false; thus the implication is false. False.\nQuestion 5: The antecedent (Yuri is not an American professional basketball player) is true, but the consequent (Yuri is a professional basketball player) is false; thus the implication is false. False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False\n4: False\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1313,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1314,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1315,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1316,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1317,
        "conclusion": "If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 280,
    "premises": "Parallax measurements yield a distance estimate of 80. In 2018, Marino won election to a redrawn 12th district; while he remained the congressman for the 10th district into January 2019, he moved within the new district's boundaries beforehand. Events are either happy or sad.\nAt least one event is happy. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: Parallax measurements yield a distance estimate of 80. In 2018, Marino won election to a redrawn 12th district; while he remained the congressman for the 10th district into January 2019, he moved within the new district's boundaries beforehand. Events are either happy or sad.\nAt least one event is happy. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? All events are sad.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Step-by-step reasoning:\n- The statement \"Events are either happy or sad\" indicates a partition: each event is one of the two (and typically not both).\n- \"At least one event is happy\" means there exists an event that is happy.\n- Therefore, there exists at least one event that is not sad.\n- Hence, it cannot be the case that all events are sad.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 724,
        "conclusion": "All events are sad.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 140,
    "premises": "In the series, Torres was admitted to Starfleet academy but dropped out before graduating. state of Michigan. The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: In the series, Torres was admitted to Starfleet academy but dropped out before graduating. state of Michigan. The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Steinhauer was not the winner of the 1992 du Maurier Classic.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: \"The winner of the 1992 du Maurier Classic was Steinhauer.\"\n- The statement says Steinhauer was not the winner, which directly contradicts the given fact.\n- Conclusion: False.\n\nQuestion 2:\n- Given: There was a six-way tie on the leaderboard, and one person in the tie was from Belgium.\n- Also given: Descampe is from Belgium and on the leaderboard.\n- However, nothing states that Descampe is the Belgian in the six-way tie; there could be another Belgian, or \"one person\" could simply indicate existence without identifying who.\n- Conclusion: Unknown.\n\nANSWERS:\n1: False\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 411,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 412,
        "conclusion": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 459,
    "premises": "Bush to be the U. It is critically acclaimed and regarded by many as their best work. Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Bush to be the U. It is critically acclaimed and regarded by many as their best work. Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? KiKi is terricolous.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? KiKi is a barking dog.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? KiKi does not bark and he is not a dog.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From \u201cIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs,\u201d we can use logical equivalence: (\u00acJ \u2227 \u00acL) \u2192 (T \u2228 L) is equivalent to J \u2228 L \u2228 T.\n- Given L \u2192 J and T \u2192 L \u2192 J, the disjunction J \u2228 L \u2228 T forces J to be true. Therefore, KiKi jumps.\n- KiKi is an animal and all jumping animals are liked by Jane, so Jane likes KiKi.\n- Jane does not like any animals that bark. Since Jane likes KiKi, KiKi cannot bark. Hence, KiKi does not bark.\n- All dogs bark. By contrapositive, if KiKi does not bark, then KiKi is not a dog.\n\nQuestion 1: We have no rule that implies KiKi is terricolous; jumping does not imply terricolous. So this is unknown.\nQuestion 2: \u201cKiKi is a barking dog\u201d is false because we derived that KiKi does not bark (and also is not a dog).\nQuestion 3: \u201cKiKi does not bark and he is not a dog\u201d is true, as shown above.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1324,
        "conclusion": "KiKi is terricolous.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1325,
        "conclusion": "KiKi is a barking dog.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1326,
        "conclusion": "KiKi does not bark and he is not a dog.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 101,
    "premises": "The Village is an SiriusXM channel that specializes in folk music, described by SiriusXM as \"from the ballads of early American songwriters to the contemporary masters of folk. APPC is mainly used by IBM installations running operating systems such z/OS (formerly MVS then OS/390), z/VM (formerly VM/CMS), z/TPF, IBM i (formerly OS/400), OS/2, AIX and z/VSE (formerly DOS/VSE). Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: The Village is an SiriusXM channel that specializes in folk music, described by SiriusXM as \"from the ballads of early American songwriters to the contemporary masters of folk. APPC is mainly used by IBM installations running operating systems such z/OS (formerly MVS then OS/390), z/VM (formerly VM/CMS), z/TPF, IBM i (formerly OS/400), OS/2, AIX and z/VSE (formerly DOS/VSE). Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? No one playing for Nautico is Brazilian.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Ailton Silva does not play for a football club.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Ailton was not loaned out to a football club.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? Ailton Silva played for Fluminense.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? Ailton Silva was loaned out to a football club.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n1: We know Ailton Silva is Brazilian and plays for N\u00e1utico. Therefore, it's not true that no one playing for N\u00e1utico is Brazilian. False.\n\n2: Ailton Silva plays for N\u00e1utico, and N\u00e1utico is a football club. Therefore, the statement that he does not play for a football club is false. False.\n\n3: Ailton (the same person, as Ailton Silva is commonly known as Ailton) was loaned out to Braga, which is a football club. Therefore, saying he was not loaned out to a football club is false. False.\n\n4: The text does not state that Ailton Silva played for Fluminense; it only says Fluminense is a football club. Insufficient information. Unknown.\n\n5: As established, Ailton was loaned out to Braga, a football club. Therefore, he was loaned out to a football club. True.\n\nANSWERS:\n1: False\n2: False\n3: False\n4: Unknown\n5: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 304,
        "conclusion": "No one playing for Nautico is Brazilian.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 305,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 306,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 307,
        "conclusion": "Ailton Silva played for Fluminense.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 308,
        "conclusion": "Ailton Silva was loaned out to a football club.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.8
  },
  {
    "story_id": 441,
    "premises": "This article incorporates text from a publication now in the public domain: Gilman, D. Vancouver Mall is a shopping mall owned by Cenntenial Real Estate, and located in the city of Vancouver, Washington, U. No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: This article incorporates text from a publication now in the public domain: Gilman, D. Vancouver Mall is a shopping mall owned by Cenntenial Real Estate, and located in the city of Vancouver, Washington, U. No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Tom is a grumpy person.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Tom is not both a grumpy person and mean to animals.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- From: All pet owners love animals; All animal lovers are nice to animals; No one nice to animals is also mean to animals; and Tom is a pet owner.\n- Therefore: Tom loves animals (is an animal lover) \u2192 Tom is nice to animals \u2192 Tom is not mean to animals.\n\nQuestion 1:\n- Nothing relates grumpiness directly to being a pet owner, animal lover, or nice (except that some grumpy people are mean, not all).\n- We cannot deduce whether Tom is grumpy.\n- Answer: Unknown.\n\nQuestion 2:\n- Since Tom is not mean to animals, he cannot be both grumpy and mean.\n- Answer: True.\n\nQuestion 3:\n- Antecedent: \u201cTom is not both grumpy and mean\u201d is true (Tom is not mean).\n- Consequent: \u201cTom is neither grumpy nor an animal lover\u201d is false because Tom is an animal lover.\n- A true antecedent and false consequent makes the conditional false.\n- Answer: False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1268,
        "conclusion": "Tom is a grumpy person.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1269,
        "conclusion": "Tom is not both a grumpy person and mean to animals.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1270,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 64,
    "premises": "Liam Cormier (born February 9, 1980) is a Canadian musician from Toronto, Ontario. In 1980, however, the current name\u2014Australian Army Reserve\u2014was officially adopted, and it now consists of a number of components based around the level of commitment and training obligation that its members are required to meet. A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Liam Cormier (born February 9, 1980) is a Canadian musician from Toronto, Ontario. In 1980, however, the current name\u2014Australian Army Reserve\u2014was officially adopted, and it now consists of a number of components based around the level of commitment and training obligation that its members are required to meet. A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Dani Shapiro is a novel writer.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Family Secrets is a novel.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Dani Shapiro was born in Boston.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Question 1 reasoning:\n- Premise: Family History is written by Dani Shapiro.\n- Premise: Family History is a novel.\n- Rule: If a book is a novel and it is written by a person, then the person is a novel writer.\n- Therefore, Dani Shapiro is a novel writer. Conclusion: True.\n\nQuestion 2 reasoning:\n- Premise: Dani Shapiro created a podcast called Family Secrets.\n- Rule: A podcast is not a novel.\n- Therefore, Family Secrets is not a novel. Conclusion: False.\n\nQuestion 3 reasoning:\n- Premise: Boston is an American city.\n- Rule: If a person is born in an American city, the person is American.\n- Premise: Dani Shapiro is an American writer. However, this does not imply she was born in an American city or in Boston specifically.\n- No information states Dani Shapiro was born in Boston. Conclusion: Unknown.\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 189,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 190,
        "conclusion": "Family Secrets is a novel.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 191,
        "conclusion": "Dani Shapiro was born in Boston.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 456,
    "premises": "The trust was delisted from the Toronto Stock Exchange and the New York Stock Exchange in December 2009. Jean Lemire crossed the Atlantic Ocean between 1650 and 1653. Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: The trust was delisted from the Toronto Stock Exchange and the New York Stock Exchange in December 2009. Jean Lemire crossed the Atlantic Ocean between 1650 and 1653. Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Yuri is an American national.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Yuri is not an American professional basketball player.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Yuri is an American professional basketball player.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- Let P(x) = x is a professional basketball player; A(x) = x is an American national; J(x) = x can do jump shots; L(x) = x leaps straight into the air; M(x) = x activates leg muscles.\n- Given: P -> J; J -> L; L -> M. Yuri: \u00acM.\n- By contrapositive chaining: \u00acM -> \u00acL -> \u00acJ -> \u00acP. So Yuri is not a professional basketball player.\n\nQuestion 1: No information about Yuri\u2019s nationality. Unknown.\n\nQuestion 2: \u201cYuri is not an American professional basketball player\u201d means \u00ac(A \u2227 P). Since \u00acP, this is true. True.\n\nQuestion 3: Claims A \u2227 P. Since \u00acP, this is false. False.\n\nQuestion 4: If \u00acL then A \u2227 P. We have \u00acL (from \u00acM). But \u00acP, so the consequent A \u2227 P is false. True antecedent, false consequent \u2192 False.\n\nQuestion 5: If \u00ac(A \u2227 P) then P. Antecedent true (since \u00acP implies \u00ac(A \u2227 P)), consequent false (\u00acP). True antecedent, false consequent \u2192 False.\n\nANSWERS:\n1: Unknown\n2: True\n3: False\n4: False\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1313,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1314,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1315,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1316,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1317,
        "conclusion": "If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 280,
    "premises": "Parallax measurements yield a distance estimate of 80. In 2018, Marino won election to a redrawn 12th district; while he remained the congressman for the 10th district into January 2019, he moved within the new district's boundaries beforehand. Events are either happy or sad.\nAt least one event is happy. ",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 1)",
    "user_prompt": "Textual context: Parallax measurements yield a distance estimate of 80. In 2018, Marino won election to a redrawn 12th district; while he remained the congressman for the 10th district into January 2019, he moved within the new district's boundaries beforehand. Events are either happy or sad.\nAt least one event is happy. \n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? All events are sad.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n- \"Events are either happy or sad\" means each event is in exactly one of the two categories.\n- \"At least one event is happy\" ensures the existence of a happy event.\n- Therefore, it cannot be the case that all events are sad.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 724,
        "conclusion": "All events are sad.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 140,
    "premises": "In the series, Torres was admitted to Starfleet academy but dropped out before graduating. state of Michigan. The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 2)",
    "user_prompt": "Textual context: In the series, Torres was admitted to Starfleet academy but dropped out before graduating. state of Michigan. The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? Steinhauer was not the winner of the 1992 du Maurier Classic.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\nQuestion 1:\n- Given: \"The winner of the 1992 du Maurier Classic was Steinhauer.\"\n- The statement claims Steinhauer was not the winner, which directly contradicts the given fact.\n- Therefore, the statement is false.\n\nQuestion 2:\n- Given: There was a six-way tie on the leaderboard, and at least one person in that tie was from Belgium.\n- Also given: Descampe is from Belgium and on the leaderboard.\n- However, it does not state that Descampe is the Belgian in the six-way tie; there could be other Belgians on the leaderboard. So we cannot conclude Descampe is in the six-way tie.\n- Therefore, the truth of the statement is uncertain.\n\nANSWERS:\n1: False\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 411,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 412,
        "conclusion": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 459,
    "premises": "Bush to be the U. It is critically acclaimed and regarded by many as their best work. Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 3)",
    "user_prompt": "Textual context: Bush to be the U. It is critically acclaimed and regarded by many as their best work. Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? KiKi is terricolous.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? KiKi is a barking dog.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? KiKi does not bark and he is not a dog.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n\n- From If an animal has legs, then it jumps and If an animal is terricolous, then it has legs, and the special rule If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs:\n  Assume KiKi does not jump. Then by contrapositive of (legs -> jumps), KiKi does not have legs. Then the special rule\u2019s antecedent holds, yielding terricolous or has legs. With not having legs, this reduces to terricolous. But terricolous implies has legs, contradicting not having legs. Hence the assumption is false; KiKi does jump. This does not tell us whether KiKi is terricolous.\n\n- Since KiKi is an animal that jumps, Jane likes KiKi (Jane likes all animals that jump). Jane does not like any animals that bark means (Animal \u2227 Barks) -> \u00acLikes; by contrapositive, Likes -> \u00ac(Animal \u2227 Barks). Given KiKi is an animal and Jane likes KiKi, KiKi does not bark.\n\n- All dogs are animals that bark implies dogs bark. Since KiKi does not bark, KiKi is not a dog.\n\nAnswers to questions:\n\n1) KiKi is terricolous: We cannot determine this from the given information. Unknown.\n\n2) KiKi is a barking dog: Since KiKi does not bark, this is false.\n\n3) KiKi does not bark and he is not a dog: Both parts are established above. True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1324,
        "conclusion": "KiKi is terricolous.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1325,
        "conclusion": "KiKi is a barking dog.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1326,
        "conclusion": "KiKi does not bark and he is not a dog.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 101,
    "premises": "The Village is an SiriusXM channel that specializes in folk music, described by SiriusXM as \"from the ballads of early American songwriters to the contemporary masters of folk. APPC is mainly used by IBM installations running operating systems such z/OS (formerly MVS then OS/390), z/VM (formerly VM/CMS), z/TPF, IBM i (formerly OS/400), OS/2, AIX and z/VSE (formerly DOS/VSE). Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.",
    "system_prompt": "You are a logical reasoning assistant. Your task is to carefully analyze the given context and answer questions by reasoning step-by-step.\n\nFor each question, think through the logic carefully before providing your answer. Each answer should be exactly one of: True, False, or Unknown.\n\nIMPORTANT: After your reasoning for all questions, provide your final answers in exactly this format:\n\nANSWERS:\n1: True/False/Unknown\n2: True/False/Unknown\n3: True/False/Unknown\n(Use the exact number of questions provided: 5)",
    "user_prompt": "Textual context: The Village is an SiriusXM channel that specializes in folk music, described by SiriusXM as \"from the ballads of early American songwriters to the contemporary masters of folk. APPC is mainly used by IBM installations running operating systems such z/OS (formerly MVS then OS/390), z/VM (formerly VM/CMS), z/TPF, IBM i (formerly OS/400), OS/2, AIX and z/VSE (formerly DOS/VSE). Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.\n\nQuestion 1: Based on the above information, is the following statement true, false, or uncertain? No one playing for Nautico is Brazilian.\n\nQuestion 2: Based on the above information, is the following statement true, false, or uncertain? Ailton Silva does not play for a football club.\n\nQuestion 3: Based on the above information, is the following statement true, false, or uncertain? Ailton was not loaned out to a football club.\n\nQuestion 4: Based on the above information, is the following statement true, false, or uncertain? Ailton Silva played for Fluminense.\n\nQuestion 5: Based on the above information, is the following statement true, false, or uncertain? Ailton Silva was loaned out to a football club.\n\nPlease reason through each question step-by-step, then provide your final answers in the required format.",
    "model": "gpt-5",
    "model_config": {},
    "model_response": "Reasoning:\n1) Ailton Silva is Brazilian and plays for N\u00e1utico. Therefore, at least one player for N\u00e1utico is Brazilian. The statement is false.\n2) He plays for N\u00e1utico, which is a football club. So the statement that he does not play for a football club is false.\n3) He was loaned out to Braga, and Braga is a football club. So the statement that he was not loaned out to a football club is false.\n4) The text provides no information that he played for Fluminense; it only states Fluminense is a football club. Therefore, unknown.\n5) As noted, he was loaned out to Braga, a football club. Therefore, true.\n\nANSWERS:\n1: False\n2: False\n3: False\n4: Unknown\n5: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 304,
        "conclusion": "No one playing for Nautico is Brazilian.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 305,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 306,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 307,
        "conclusion": "Ailton Silva played for Fluminense.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 308,
        "conclusion": "Ailton Silva was loaned out to a football club.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.8
  }
]