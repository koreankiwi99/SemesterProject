[
  {
    "story_id": 380,
    "premises": "People in this club who perform in school talent shows often attend and are very engaged with school events.\nPeople in this club either perform in school talent shows often or are inactive and disinterested community members.\nPeople in this club who chaperone high school dances are not students who attend the school.\nAll people in this club who are inactive and disinterested members of their community chaperone high school dances.\nAll young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \nBonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school.",
    "gpt_response": "Lean formalization and attempt at proofs\n\nWe model the domain with a type of people and predicates capturing the properties mentioned. Bonnie is a constant individual. The premises are axioms; we then derive useful lemmas and try to prove the three questions.\n\nopen Classical\n\nuniverse u\n\nconstant Person : Type u\n\n-- Predicates\nconstant Club      : Person \u2192 Prop\nconstant Performs  : Person \u2192 Prop      -- performs in school talent shows often\nconstant Engaged   : Person \u2192 Prop      -- attends and is very engaged with school events\nconstant Inactive  : Person \u2192 Prop      -- inactive and disinterested community member\nconstant Chaperone : Person \u2192 Prop      -- chaperones high school dances\nconstant Student   : Person \u2192 Prop      -- student who attends the school\nconstant YoungTeen : Person \u2192 Prop      -- (young child or teenager)\nconstant Wishes    : Person \u2192 Prop      -- wishes to further academic careers and educational opportunities\n\n-- Individual\nconstant Bonnie : Person\n\n-- Axioms (premises)\naxiom h1 : \u2200 x, Club x \u2227 Performs x \u2192 Engaged x\naxiom h2 : \u2200 x, Club x \u2192 (Performs x \u2228 Inactive x)\naxiom h3 : \u2200 x, Club x \u2227 Chaperone x \u2192 \u00ac Student x\naxiom h4 : \u2200 x, Club x \u2227 Inactive x \u2192 Chaperone x\naxiom h5 : \u2200 x, Club x \u2227 YoungTeen x \u2227 Wishes x \u2192 Student x\naxiom h6a : Club Bonnie\n-- Bonnie satisfies (Engaged \u2194 Student) expressed as (E \u2227 S) \u2228 (\u00acE \u2227 \u00acS)\naxiom h6b : (Engaged Bonnie \u2227 Student Bonnie) \u2228 (\u00acEngaged Bonnie \u2227 \u00acStudent Bonnie)\n\n-- Useful derived lemmas about Bonnie\n\nlemma bonnie_E_implies_S : Engaged Bonnie \u2192 Student Bonnie := by\n  intro e\n  cases h6b with\n  | inl h => exact h.right\n  | inr h => exact (h.left e).elim\n\nlemma bonnie_S_implies_E : Student Bonnie \u2192 Engaged Bonnie := by\n  intro s\n  cases h6b with\n  | inl h => exact h.left\n  | inr h => exact (h.right s).elim\n\nlemma bonnie_P_implies_E : Performs Bonnie \u2192 Engaged Bonnie := by\n  intro p\n  exact h1 Bonnie \u27e8h6a, p\u27e9\n\nlemma bonnie_P_implies_S : Performs Bonnie \u2192 Student Bonnie := by\n  intro p\n  exact bonnie_E_implies_S (bonnie_P_implies_E p)\n\nlemma bonnie_I_implies_notS : Inactive Bonnie \u2192 \u00ac Student Bonnie := by\n  intro i\n  have c : Chaperone Bonnie := h4 Bonnie \u27e8h6a, i\u27e9\n  exact h3 Bonnie \u27e8h6a, c\u27e9\n\nlemma bonnie_S_implies_notI : Student Bonnie \u2192 \u00ac Inactive Bonnie := by\n  intro s i\n  exact (bonnie_I_implies_notS i) s\n\nlemma bonnie_P_implies_notI : Performs Bonnie \u2192 \u00ac Inactive Bonnie := by\n  intro p i\n  exact (bonnie_I_implies_notS i) (bonnie_P_implies_S p)\n\nlemma bonnie_I_implies_notP : Inactive Bonnie \u2192 \u00ac Performs Bonnie := by\n  intro i p\n  have e : Engaged Bonnie := bonnie_P_implies_E p\n  have ne : \u00ac Engaged Bonnie := by\n    -- from I \u2192 C \u2192 \u00acS and (E \u2194 S), derive \u00acE\n    have ns : \u00ac Student Bonnie := bonnie_I_implies_notS i\n    have se : Student Bonnie := bonnie_E_implies_S e\n    exact ns se\n  exact ne e\n\nlemma bonnie_S_or_I : Student Bonnie \u2228 Inactive Bonnie := by\n  have h : Performs Bonnie \u2228 Inactive Bonnie := h2 Bonnie h6a\n  cases h with\n  | inl p => exact Or.inl (bonnie_P_implies_S p)\n  | inr i => exact Or.inr i\n\nlemma bonnie_C_or_P : Chaperone Bonnie \u2228 Performs Bonnie := by\n  have h : Performs Bonnie \u2228 Inactive Bonnie := h2 Bonnie h6a\n  cases h with\n  | inl p => exact Or.inr p\n  | inr i =>\n      have c : Chaperone Bonnie := h4 Bonnie \u27e8h6a, i\u27e9\n      exact Or.inl c\n\n-- Question 2 (proved): the consequent holds for Bonnie regardless of the antecedent\ntheorem Q2\n  : ((YoungTeen Bonnie \u2227 Wishes Bonnie \u2227 Chaperone Bonnie) \u2228 \u00ac (YoungTeen Bonnie \u2227 Wishes Bonnie))\n    \u2192 (Student Bonnie \u2228 Inactive Bonnie) := by\n  intro _\n  exact bonnie_S_or_I\n\n\nInformal conclusions\n\n- Q1: From the premises we know Bonnie is either Performs or Inactive. If she is Inactive, then she Chaperones and is not a Student; using (Engaged \u2194 Student) and \u201cPerforms \u2192 Engaged,\u201d this implies she does not Perform. If she is not Inactive, then by the disjunction she Performs. Both cases are consistent with the premises; we cannot determine which holds. Unknown\n\n- Q2: For Bonnie, from \u201cClub \u2192 (Performs \u2228 Inactive)\u201d, \u201cPerforms \u2192 Engaged\u201d, and (Engaged \u2194 Student), we get Student \u2228 Inactive unconditionally. Hence the implication holds regardless of the antecedent. True\n\n- Q3: From \u201cClub \u2192 (Performs \u2228 Inactive)\u201d and \u201cInactive \u2192 Chaperone\u201d we know the antecedent (Chaperone \u2228 Performs) is always true for Bonnie. The conclusion requires YoungTeen \u2227 Wishes \u2227 Inactive, which is neither forced by the premises nor refutable; indeed, if Bonnie Performs then she is not Inactive. Therefore the implication is not determined. Unknown\n\nFinal answers:\n- Question 1: Unknown\n- Question 2: True\n- Question 3: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1014,
        "conclusion": "Bonnie performs in school talent shows often.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1015,
        "conclusion": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1016,
        "conclusion": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 426,
    "premises": "All employees who schedule a meeting with their customers will go to the company building today. \nEveryone who has lunch in the company building schedules meetings with their customers. \nEmployees have lunch either in the company building or at home.\nIf an employee has lunch at home, they are working remotely from home.\nAll employees who are in other countries work remotely from home. \nNo managers work remotely from home. \nJames will appear in the company today if and only if he is a manager.",
    "gpt_response": "Below is a faithful Lean formalization of the given premises and the three queried statements about James, together with model constructions that show what can and cannot be derived. In particular, for each question, I produce two concrete models (worlds) satisfying the premises in which the queried statement is true in one model and false in the other; this establishes that none of the three statements, nor their negations, are derivable from the premises, i.e., they are all Unknown.\n\nLean code:\n\nnamespace CompanyReasoning\n\nuniverse u\n\n-- We package the domain, predicates, and premises into one structure.\nstructure World where\n  Person : Type u\n  James : Person\n  Employee : Person \u2192 Prop\n  Manager : Person \u2192 Prop\n  Schedules : Person \u2192 Prop\n  GoBuilding : Person \u2192 Prop\n  LunchCompany : Person \u2192 Prop\n  LunchHome : Person \u2192 Prop\n  Remote : Person \u2192 Prop\n  InOtherCountries : Person \u2192 Prop\n  -- Premises:\n  -- 1) All employees who schedule a meeting with their customers will go to the company building today.\n  A1 : \u2200 x, Employee x \u2227 Schedules x \u2192 GoBuilding x\n  -- 2) Everyone who has lunch in the company building schedules meetings with their customers.\n  A2 : \u2200 x, LunchCompany x \u2192 Schedules x\n  -- 3) Employees have lunch either in the company building or at home (and not both).\n  A3 : \u2200 x, Employee x \u2192 (LunchCompany x \u2228 LunchHome x) \u2227 \u00ac(LunchCompany x \u2227 LunchHome x)\n  -- 4) If an employee has lunch at home, they are working remotely from home.\n  A4 : \u2200 x, LunchHome x \u2192 Remote x\n  -- 5) All employees who are in other countries work remotely from home.\n  A5 : \u2200 x, InOtherCountries x \u2192 Remote x\n  -- 6) No managers work remotely from home.\n  A6 : \u2200 x, Manager x \u2192 \u00ac Remote x\n  -- 7) James will appear in the company today iff he is a manager.\n  --    We identify \"appear in the company today\" with \"go to the company building today\".\n  A7 : GoBuilding James \u2194 Manager James\n\n-- The three queried statements:\ndef Q1 (W : World) : Prop := W.LunchCompany W.James\ndef Q2 (W : World) : Prop := \u00ac W.LunchCompany W.James\ndef Q3 (W : World) : Prop :=\n  ((W.Manager W.James \u2228 W.InOtherCountries W.James) \u2192 \u00ac (W.LunchHome W.James \u2228 W.Remote W.James)) \u2227\n  ((W.LunchHome W.James \u2228 W.Remote W.James) \u2192 (\u00ac W.Manager W.James \u2227 \u00ac W.InOtherCountries W.James))\n\n-- Model 1: Everything true that needs to be, with James a manager who lunches in the company, not remote, etc.\ndef Wt : World :=\n{ Person := PUnit,\n  James := (),\n  Employee := fun _ => True,\n  Manager := fun _ => True,\n  Schedules := fun _ => True,\n  GoBuilding := fun _ => True,\n  LunchCompany := fun _ => True,\n  LunchHome := fun _ => False,\n  Remote := fun _ => False,\n  InOtherCountries := fun _ => False,\n  A1 := by\n    intro x hx; exact True.intro,\n  A2 := by\n    intro x hx; exact True.intro,\n  A3 := by\n    intro x hx\n    refine And.intro ?disj ?nconj\n    \u00b7 exact Or.inl True.intro\n    \u00b7 intro hboth\n      cases hboth with\n      | intro _ hhome => cases hhome,\n  A4 := by\n    intro x h; cases h,\n  A5 := by\n    intro x h; cases h,\n  A6 := by\n    intro x hm hrem; cases hrem,\n  A7 := Iff.intro (fun _ => True.intro) (fun _ => True.intro) }\n\n-- Model 2: James is not a manager, is in other countries, lunches at home, is remote, does not go to the building.\ndef Wf : World :=\n{ Person := PUnit,\n  James := (),\n  Employee := fun _ => True,\n  Manager := fun _ => False,\n  Schedules := fun _ => False,\n  GoBuilding := fun _ => False,\n  LunchCompany := fun _ => False,\n  LunchHome := fun _ => True,\n  Remote := fun _ => True,\n  InOtherCountries := fun _ => True,\n  A1 := by\n    intro x hx; cases hx with\n    | intro _ hs => cases hs,\n  A2 := by\n    intro x hx; cases hx,\n  A3 := by\n    intro x hx\n    refine And.intro ?disj ?nconj\n    \u00b7 exact Or.inr True.intro\n    \u00b7 intro hboth\n      cases hboth with\n      | intro hlc _ => cases hlc,\n  A4 := by\n    intro x h; exact h,\n  A5 := by\n    intro x h; exact True.intro,\n  A6 := by\n    intro x hm hrem; cases hm,\n  A7 := by\n    apply Iff.intro\n    \u00b7 intro hg; cases hg\n    \u00b7 intro hm; cases hm }\n\n-- Sanity checks showing the queried statements take different truth values across the two models.\n\n-- Q1: true in Wt, false in Wf\nlemma Q1_holds_in_Wt : Q1 Wt := True.intro\nlemma Q1_fails_in_Wf : \u00ac Q1 Wf := by intro h; cases h\n\n-- Q2: false in Wt, true in Wf\nlemma Q2_fails_in_Wt : \u00ac Q2 Wt := by intro h; apply h; exact True.intro\nlemma Q2_holds_in_Wf : Q2 Wf := by intro h; cases h\n\n-- Q3: true in Wt, false in Wf\nlemma Q3_holds_in_Wt : Q3 Wt := by\n  unfold Q3\n  apply And.intro\n  \u00b7 intro _ hdisj\n    cases hdisj with\n    | inl lh => cases lh\n    | inr r  => cases r\n  \u00b7 intro hdisj\n    cases hdisj with\n    | inl lh => cases lh\n    | inr r  => cases r\nlemma Q3_fails_in_Wf : \u00ac Q3 Wf := by\n  intro h\n  have himpl := And.left h\n  have hAnte : (Wf.Manager Wf.James \u2228 Wf.InOtherCountries Wf.James) := Or.inr True.intro\n  have hcontra : \u00ac (Wf.LunchHome Wf.James \u2228 Wf.Remote Wf.James) := himpl hAnte\n  have hdisj : (Wf.LunchHome Wf.James \u2228 Wf.Remote Wf.James) := Or.inl True.intro\n  exact hcontra hdisj\n\nend CompanyReasoning\n\nConclusions:\n\n- Question 1: The premises do not pin down whether James has lunch in the company; there is a model where he does and a model where he does not. Unknown\n\n- Question 2: Likewise, the premises do not pin down whether he does not have lunch in the company. Unknown\n\n- Question 3: The compounded contrapositive statement is not entailed by the premises (it is true in one model and false in another). Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1208,
        "conclusion": "James has lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1209,
        "conclusion": "James does not have lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1210,
        "conclusion": "If James is either a manager or in other countries,  then James does not either has lunch at home or work remotely from home. If James either has lunch at home or works remotely from home, then he is neither a manager nor does he work in other countries. [contrapositive is more natural]",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 198,
    "premises": "When the Monkeypox virus occurs in a being, it may get Monkeypox. \nMonkeypox virus can occur in certain animals.\nHumans are mammals.\nMammals are animals.\nSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness. \nPeople feel tired when they get the flu.",
    "gpt_response": "Lean formalization and attempt at proofs (Lean 4):\n\nuniverse u\n\nconstant Being : Type u\n\n-- Predicates on beings\nconstant Animal : Being \u2192 Prop\nconstant Mammal : Being \u2192 Prop\nconstant Human : Being \u2192 Prop\nconstant Person : Being \u2192 Prop\n\nconstant MPV_occurs : Being \u2192 Prop          -- Monkeypox virus occurs (actually occurs)\nconstant MPV_can_occur : Being \u2192 Prop       -- Monkeypox virus can occur (possibility)\nconstant MayGetMonkeypox : Being \u2192 Prop\nconstant GetsFlu : Being \u2192 Prop\nconstant FeelsTired : Being \u2192 Prop\n\n-- Symptoms universe\ninductive SymptomName where\n| fever | headache | muscle_pains | tiredness | coughing\nderiving DecidableEq\n\nconstant SymptomOfMonkeypox : SymptomName \u2192 Prop\n\n-- Axioms extracted from the text\naxiom humans_are_mammals : \u2200 x, Human x \u2192 Mammal x\naxiom mammals_are_animals : \u2200 x, Mammal x \u2192 Animal x\n\n-- \u201cWhen the Monkeypox virus occurs in a being, it may get Monkeypox.\u201d\naxiom virus_occurs_implies_may_get : \u2200 x, MPV_occurs x \u2192 MayGetMonkeypox x\n\n-- \u201cMonkeypox virus can occur in certain animals.\u201d\naxiom mpv_can_occur_in_certain_animals : \u2203 x, Animal x \u2227 MPV_can_occur x\n\n-- \u201cSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness.\u201d\naxiom symptom_fever        : SymptomOfMonkeypox SymptomName.fever\naxiom symptom_headache     : SymptomOfMonkeypox SymptomName.headache\naxiom symptom_muscle_pains : SymptomOfMonkeypox SymptomName.muscle_pains\naxiom symptom_tiredness    : SymptomOfMonkeypox SymptomName.tiredness\n\n-- \u201cPeople feel tired when they get the flu.\u201d\naxiom flu_implies_tired_for_people : \u2200 x, Person x \u2192 GetsFlu x \u2192 FeelsTired x\n\n-- Optional bridge: people are humans (not strictly needed for these questions)\naxiom people_are_humans : \u2200 x, Person x \u2192 Human x\n\n-- Question 1 target: \u201cThere is an animal.\u201d\n-- We formalize it as \u2203 x, Animal x.\ntheorem Q1 : \u2203 x, Animal x := by\n  rcases mpv_can_occur_in_certain_animals with \u27e8a, ha\u27e9\n  exact \u27e8a, ha.left\u27e9\n\n-- Question 2 target: \u201cNo one gets the flu.\u201d\n-- We formalize it as \u00ac \u2203 x : Being, GetsFlu x.\ndef Q2 : Prop := \u00ac \u2203 x : Being, GetsFlu x\n\n-- With the given axioms, neither Q2 nor its negation is provable.\n\n-- Question 3 target: \u201cSymptoms of Monkeypox include coughing.\u201d\n-- We formalize it as SymptomOfMonkeypox SymptomName.coughing.\ndef Q3 : Prop := SymptomOfMonkeypox SymptomName.coughing\n\n-- With the given axioms, neither Q3 nor its negation is provable.\n\n\n\nAnswers:\n1) Yes. From \u201cMonkeypox virus can occur in certain animals\u201d we get existence of at least one animal. True\n2) Cannot be determined from the premises; no information rules out flu cases. Unknown\n3) Cannot be determined; the listed symptoms are not stated to be exhaustive. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 563,
        "conclusion": "There is an animal.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 564,
        "conclusion": "No one gets the flu.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 565,
        "conclusion": "Symptoms of Monkeypox include coughing.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 20,
    "premises": "A Japanese game company created the game the Legend of Zelda.\nAll games on the Top 10 list are made by Japanese game companies.\nIf a game sells more than one million copies, then it will be included in the Top 10 list.\nThe Legend of Zelda sold more than one million copies.",
    "gpt_response": "Lean translation and proofs:\n\n-- We model games, predicates, and the given facts\nuniverse u\n\nconstant Game : Type u\nconstant Zelda : Game\nconstant FIFA22 : Game\n\nconstant MadeByJapaneseCompany : Game \u2192 Prop\nconstant OnTop10 : Game \u2192 Prop\nconstant SoldOver1M : Game \u2192 Prop\n\naxioms\n  -- A Japanese game company created The Legend of Zelda.\n  (h1 : MadeByJapaneseCompany Zelda)\n  -- All games on the Top 10 list are made by Japanese game companies.\n  (h2 : \u2200 g : Game, OnTop10 g \u2192 MadeByJapaneseCompany g)\n  -- If a game sells more than one million copies, then it will be included in the Top 10 list.\n  (h3 : \u2200 g : Game, SoldOver1M g \u2192 OnTop10 g)\n  -- The Legend of Zelda sold more than one million copies.\n  (h4 : SoldOver1M Zelda)\n\n-- From h3 and h4, The Legend of Zelda is on the Top 10 list.\ntheorem Zelda_on_top10 : OnTop10 Zelda := h3 Zelda h4\n\n-- Sanity check: either premise gives LoZ made by a Japanese company.\ntheorem Zelda_made_by_JP_from_top10 : MadeByJapaneseCompany Zelda := h2 Zelda Zelda_on_top10\ntheorem Zelda_made_by_JP_from_fact  : MadeByJapaneseCompany Zelda := h1\n\n-- If FIFA22 is on the Top 10 list, then it is made by a Japanese company.\ntheorem FIFA22_made_by_JP_if_top10 : OnTop10 FIFA22 \u2192 MadeByJapaneseCompany FIFA22 := h2 FIFA22\n\n-- Q1 target: OnTop10 Zelda\ntheorem Q1 : OnTop10 Zelda := Zelda_on_top10\n\n-- Q3 target is the statement \"\u00ac OnTop10 Zelda\"; we can prove its negation.\ntheorem Q3_neg_of_statement : \u00ac (\u00ac OnTop10 Zelda) := by\n  intro hnot\n  exact hnot Q1\n\n\nAnswers:\n- Question 1: Yes. From SoldOver1M(LoZ) and the rule that any game selling over one million is on the Top 10 list, LoZ is on the Top 10 list. True\n- Question 2: We have no information about FIFA 22 being on the Top 10 list or selling over one million in the given context, so we cannot conclude it was made by a Japanese company. Unknown\n- Question 3: No. Since LoZ is on the Top 10 list (from Q1), the statement that it is not on the Top 10 list is false. False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 57,
        "conclusion": "The Legend of Zelda is on the Top 10 list.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 58,
        "conclusion": "FIFA 22 is made by a Japanese video game company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 59,
        "conclusion": "The Legend of Zelda is not on the Top 10 list.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 282,
    "premises": "All squares are four-sided.\nAll four-sided things are shapes. ",
    "gpt_response": "Lean translation and proof:\n\nuniverse u\n\nconstant U : Type u\nconstant Square : U \u2192 Prop\nconstant FourSided : U \u2192 Prop\nconstant Shape : U \u2192 Prop\n\n-- Premises\naxiom all_squares_four_sided : \u2200 x : U, Square x \u2192 FourSided x\naxiom all_four_sided_shapes : \u2200 x : U, FourSided x \u2192 Shape x\n\n-- Conclusion to prove: All squares are shapes.\ntheorem all_squares_shapes : \u2200 x : U, Square x \u2192 Shape x := by\n  intro x hx\n  exact all_four_sided_shapes x (all_squares_four_sided x hx)\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 726,
        "conclusion": "All squares are shapes.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 471,
    "premises": "All rabbits that can be spotted near the campus are cute. \nSome turtles can be spotted near the campus. \nThe only animals that can be spotted near the campus are rabbits and squirrels.\nIf something is skittish, then it is not calm.\nAll the squirrels that can be spotted near the campus are skittish.\nRockie can be spotted near the campus, and it is calm.",
    "gpt_response": "Lean formalization and proofs:\n\nnamespace Campus\n\nuniverse u\n\nconstant Animal : Type u\n\nconstants Rabbit Turtle Squirrel Spotted Cute Skittish Calm : Animal \u2192 Prop\nconstant Rockie : Animal\n\naxioms\n  (A1 : \u2200 x, Rabbit x \u2227 Spotted x \u2192 Cute x)\n  (A2 : \u2203 x, Turtle x \u2227 Spotted x)\n  (A3 : \u2200 x, Spotted x \u2192 (Rabbit x \u2228 Squirrel x))\n  (A4 : \u2200 x, Skittish x \u2192 \u00ac Calm x)\n  (A5 : \u2200 x, Squirrel x \u2227 Spotted x \u2192 Skittish x)\n  (A6 : Spotted Rockie \u2227 Calm Rockie)\n\nlemma spotted_R : Spotted Rockie := And.left A6\nlemma calm_R    : Calm Rockie    := And.right A6\n\nlemma not_skittish_R : \u00ac Skittish Rockie := by\n  intro sk\n  have : \u00ac Calm Rockie := A4 Rockie sk\n  exact this calm_R\n\nlemma not_squirrel_R : \u00ac Squirrel Rockie := by\n  intro sq\n  have sk : Skittish Rockie := A5 Rockie \u27e8sq, spotted_R\u27e9\n  exact not_skittish_R sk\n\nlemma rabbit_R : Rabbit Rockie := by\n  have h : Rabbit Rockie \u2228 Squirrel Rockie := A3 Rockie spotted_R\n  cases h with\n  | inl r => exact r\n  | inr s => exact (False.elim (not_squirrel_R s))\n\nlemma cute_R : Cute Rockie := A1 Rockie \u27e8rabbit_R, spotted_R\u27e9\n\ntheorem Q3_true : Turtle Rockie \u2228 Cute Rockie :=\n  Or.inr cute_R\n\ntheorem Q4_true : \u00ac (Turtle Rockie \u2227 Squirrel Rockie) \u2192 (Cute Rockie \u2228 Skittish Rockie) :=\n  fun _ => Or.inl cute_R\n\ntheorem Q5_neg : \u00ac ((Cute Rockie \u2227 Calm Rockie) \u2192 (Skittish Rockie \u2227 Turtle Rockie)) := by\n  intro h\n  have ant : Cute Rockie \u2227 Calm Rockie := \u27e8cute_R, calm_R\u27e9\n  have concl : Skittish Rockie \u2227 Turtle Rockie := h ant\n  exact not_skittish_R concl.left\n\nend Campus\n\nAnswers:\n1) Rockie is a turtle. Unknown\n2) Rockie is not a turtle. Unknown\n3) Rockie is a turtle or cute. True\n4) If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish. True\n5) If Rockie is cute and calm, then Rockie is a skittish turtle. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1361,
        "conclusion": "Rockie is a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1362,
        "conclusion": "Rockie is not a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1363,
        "conclusion": "Rockie is a turtle or cute.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1364,
        "conclusion": "If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 5,
        "example_id": 1365,
        "conclusion": "If Rockie is cute and calm, then Rockie is a skittish turtle.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.2
  },
  {
    "story_id": 184,
    "premises": "\"Stranger Things\" is a popular Netflix show.\nIf a Netflix show is popular, Karen will binge-watch it.\nIf and only if Karen binge-watches a Netflix show, she will download it.\nKaren does not download \"Black Mirror.\"\n\"Black Mirror\" is a Netflix show.\nIf Karen binge-watches a Netflix show, she will share it with Lisa.",
    "gpt_response": "Lean translation and proofs:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Show : Type u\nconstant ST : Show\nconstant BM : Show\n\nconstant N : Show \u2192 Prop      -- is a Netflix show\nconstant P : Show \u2192 Prop      -- is popular\nconstant B : Show \u2192 Prop      -- Karen binge-watches it\nconstant D : Show \u2192 Prop      -- Karen downloads it\nconstant S : Show \u2192 Prop      -- Karen shares it with Lisa\n\n-- Given facts and rules:\naxiom ax1 : N ST\naxiom ax2 : P ST\naxiom ax3 : \u2200 x : Show, N x \u2227 P x \u2192 B x\naxiom ax4 : \u2200 x : Show, N x \u2192 (D x \u2194 B x)\naxiom ax5 : \u00ac D BM\naxiom ax6 : N BM\naxiom ax7 : \u2200 x : Show, N x \u2192 (B x \u2192 S x)\n\n-- Q1: Karen will share \"Stranger Things\" with Lisa.\ntheorem Q1 : S ST := by\n  have hB : B ST := ax3 ST \u27e8ax1, ax2\u27e9\n  exact ax7 ST ax1 hB\n\n-- Q2: \"Black Mirror\" is popular. We can prove its negation.\ntheorem not_pop_BM : \u00ac P BM := by\n  intro hP\n  have hB : B BM := ax3 BM \u27e8ax6, hP\u27e9\n  have hD : D BM := (Iff.mpr (ax4 BM ax6)) hB\n  exact ax5 hD\n\n-- Derived helper: Karen does not binge-watch \"Black Mirror\".\ntheorem not_binge_BM : \u00ac B BM := by\n  intro hB\n  have hD : D BM := (Iff.mpr (ax4 BM ax6)) hB\n  exact ax5 hD\n\n-- From the given axioms we cannot derive S BM nor its negation.\n\nend Reasoning\n\nAnswers:\n1) Yes. From popularity and being a Netflix show, Karen binge-watches \"Stranger Things\"; then she shares any Netflix show she binge-watches with Lisa. True\n2) No. If \"Black Mirror\" were popular then, since it\u2019s a Netflix show, Karen would binge-watch and thus download it, contradicting that she does not download it. False\n3) Uncertain. We only know Karen does not binge-watch \"Black Mirror\"; sharing is only implied by binge-watching, so we cannot conclude whether she shares it. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 530,
        "conclusion": "Karen will share \"Stranger Things\" with Lisa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 531,
        "conclusion": "\"Black Mirror\" is popular.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 532,
        "conclusion": "Karen will share \"Black Mirror\" with Lisa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 232,
    "premises": "Beijing is the capital of the People's Republic of China. \nBeijing is the capital city of the world's most populous nation.\nBeijing is located in Northern China.\nBeijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nBeijing has hosted the Summer and Winter Olympics and the Summer and Winter Paralympics.\nMany of Beijing's 91 universities consistently rank among the best universities in the world.",
    "gpt_response": "Lean formalization and attempt at proofs:\n\n-- Entities\nconstant City : Type\nconstant Beijing : City\n\n-- Predicates\nconstant HostedSummer2008 : City \u2192 Prop\nconstant HostedWinterOlympics : City \u2192 Prop\nconstant HostedSummerParalympics2008 : City \u2192 Prop\nconstant HostedSummerOlympics : City \u2192 Prop\nconstant HostedSummerParalympics : City \u2192 Prop\nconstant HostedWinterParalympics : City \u2192 Prop\nconstant LocatedNorthernChina : City \u2192 Prop\nconstant LocatedSouthernChina : City \u2192 Prop\n\n-- Facts from the text\naxiom beijing_summer2008 : HostedSummer2008 Beijing\naxiom beijing_summer_paralympics2008 : HostedSummerParalympics2008 Beijing\naxiom beijing_summer_and_winter_all :\n  HostedSummerOlympics Beijing \u2227 HostedWinterOlympics Beijing \u2227\n  HostedSummerParalympics Beijing \u2227 HostedWinterParalympics Beijing\naxiom beijing_located_north : LocatedNorthernChina Beijing\n\n-- Q1: \u201cBeijing hosted both the 2008 Summer Olympics and the Winter Olympics.\u201d\n-- This follows from beijing_summer2008 and the Winter component of beijing_summer_and_winter_all.\ntheorem Q1 : HostedSummer2008 Beijing \u2227 HostedWinterOlympics Beijing := by\n  refine And.intro ?h1 ?h2\n  \u00b7 exact beijing_summer2008\n  \u00b7 exact beijing_summer_and_winter_all.right.left\n\n-- Q2: \u201cBeijing is located in southern China.\u201d\n-- From the given facts, we only know LocatedNorthernChina Beijing. No axiom relates\n-- Northern and Southern (e.g., disjointness), so neither the statement nor its negation\n-- is derivable here.\n\n-- Q3: \u201cBeijing is the second largest Chinese city.\u201d\n-- No predicates/facts provided about size rankings, so neither the statement nor its negation\n-- is derivable here.\n\nAnswers:\n\nQuestion 1: The text states Beijing hosted the 2008 Summer Olympics and that it has hosted the Winter Olympics; thus both hold. True\nQuestion 2: We only know Beijing is in Northern China; nothing given rules out Southern China, so it\u2019s not derivable either way. Unknown\nQuestion 3: No information about city-size rankings is provided. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 657,
        "conclusion": "Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 658,
        "conclusion": "Beijing is located in southern China.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 659,
        "conclusion": "Beijing is the second largest Chinese city.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 452,
    "premises": "All aliens are extraterrestrials.\nIf someone is from Mars, then they are an alien.\nNo extraterrestrials are human.\nAll highly intelligent beings from Earth are humans.\nMarvin is a highly intelligent being.\nMarvin is either from Earth and from Mars, or he is from neither.\nIf Marvin is not from Earth, then Marvin is an extraterrestrial.",
    "gpt_response": "Lean formalization and proofs:\n\nset_option autoImplicit false\n\nuniverse u\n\nsection\n\nvariable (Person : Type u)\nvariable (Alien Extraterrestrial Human FromMars FromEarth High : Person \u2192 Prop)\nvariable (Marvin : Person)\n\n-- Axioms from the textual context\nvariable\n  (all_aliens_are_extraterrestrials : \u2200 x : Person, Alien x \u2192 Extraterrestrial x)\n  (mars_implies_alien : \u2200 x : Person, FromMars x \u2192 Alien x)\n  (no_extraterrestrials_are_human : \u2200 x : Person, Extraterrestrial x \u2192 \u00ac Human x)\n  (intelligent_earthlings_are_human : \u2200 x : Person, High x \u2227 FromEarth x \u2192 Human x)\n  (Marvin_high : High Marvin)\n  (Marvin_earth_mars_xnor : (FromEarth Marvin \u2227 FromMars Marvin) \u2228 (\u00ac FromEarth Marvin \u2227 \u00ac FromMars Marvin))\n  (not_earth_implies_extraterrestrial_Marvin : \u00ac FromEarth Marvin \u2192 Extraterrestrial Marvin)\n\nopen Classical\n\n-- Marvin cannot be both from Earth and from Mars\nlemma not_earth_and_mars :\n  \u00ac (FromEarth Marvin \u2227 FromMars Marvin) :=\nby\n  intro h\n  rcases h with \u27e8hE, hM\u27e9\n  have hA  : Alien Marvin := mars_implies_alien Marvin hM\n  have hET : Extraterrestrial Marvin := all_aliens_are_extraterrestrials Marvin hA\n  have hNotH : \u00ac Human Marvin := no_extraterrestrials_are_human Marvin hET\n  have hH    : Human Marvin := intelligent_earthlings_are_human Marvin \u27e8Marvin_high, hE\u27e9\n  exact hNotH hH\n\n-- Therefore Marvin is from neither Earth nor Mars\nlemma not_earth_and_not_mars :\n  \u00ac FromEarth Marvin \u2227 \u00ac FromMars Marvin :=\nby\n  have := Marvin_earth_mars_xnor\n  exact Or.resolve_left this\n    (not_earth_and_mars Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n      all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n      intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n      not_earth_implies_extraterrestrial_Marvin)\n\nlemma not_from_earth : \u00ac FromEarth Marvin :=\n  (not_earth_and_not_mars Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n    all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n    intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n    not_earth_implies_extraterrestrial_Marvin).left\n\nlemma not_from_mars : \u00ac FromMars Marvin :=\n  (not_earth_and_not_mars Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n    all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n    intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n    not_earth_implies_extraterrestrial_Marvin).right\n\nlemma extraterrestrial_Marvin : Extraterrestrial Marvin :=\n  not_earth_implies_extraterrestrial_Marvin\n    (not_from_earth Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n      all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n      intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n      not_earth_implies_extraterrestrial_Marvin)\n\nlemma not_human_Marvin : \u00ac Human Marvin :=\nby\n  have hET := extraterrestrial_Marvin Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n    all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n    intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n    not_earth_implies_extraterrestrial_Marvin\n  exact no_extraterrestrials_are_human Marvin hET\n\n-- Q2: Marvin is neither a human nor from Mars (provable)\ntheorem Q2 :\n  \u00ac Human Marvin \u2227 \u00ac FromMars Marvin :=\nAnd.intro\n  (not_human_Marvin Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n    all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n    intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n    not_earth_implies_extraterrestrial_Marvin)\n  (not_from_mars Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n    all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n    intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n    not_earth_implies_extraterrestrial_Marvin)\n\n-- Q3: If Marvin is not from Mars, then Marvin is a human (we prove the negation)\ntheorem Q3_false :\n  \u00ac (\u00ac FromMars Marvin \u2192 Human Marvin) :=\nby\n  intro hImp\n  have hNotM : \u00ac FromMars Marvin :=\n    not_from_mars Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n      all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n      intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n      not_earth_implies_extraterrestrial_Marvin\n  have hH : Human Marvin := hImp hNotM\n  have hNotH : \u00ac Human Marvin :=\n    not_human_Marvin Person Alien Extraterrestrial Human FromMars FromEarth High Marvin\n      all_aliens_are_extraterrestrials mars_implies_alien no_extraterrestrials_are_human\n      intelligent_earthlings_are_human Marvin_high Marvin_earth_mars_xnor\n      not_earth_implies_extraterrestrial_Marvin\n  exact hNotH hH\n\nend\n\nAnswers:\n- Q1: Marvin is an alien. From the premises we can derive that Marvin is not from Mars and not from Earth, is extraterrestrial, and not human. There is no premise allowing us to conclude Alien Marvin from these; nor can we refute Alien Marvin. Unknown\n- Q2: Marvin is neither a human nor from Mars. As proved (Q2), we derived \u00acHuman Marvin \u2227 \u00acFromMars Marvin. True\n- Q3: If Marvin is not from Mars, then Marvin is a human. As proved (Q3_false), this implication is refuted since \u00acFromMars Marvin holds while \u00acHuman Marvin also holds. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1301,
        "conclusion": "Marvin is an alien.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1302,
        "conclusion": "Marvin is neither a human nor from Mars.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1303,
        "conclusion": "If Marvin is not from Mars, then Marvin is a human.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 340,
    "premises": "Everyone at the mixer is a Grand Slam champion or an Oscar-nominated actor.\nEvery Grand Slam champion at the mixer is a professional tennis player.\nAll Oscar-nominated actors at the mixer are celebrities.\nAll professional tennis players at the mixer are athletes.\nIf a person at the mixer is a celebrity, then they are well paid.\nIf a person at the mixer is an athlete, then they are famous.\nAll well-paid people at the mixer live in tax havens.\nDjokovic is at the mixer: if Djokovic is a famous athlete, then Djokovic is well-paid.",
    "gpt_response": "Lean formalization:\n\nuniverse u\n\nconstant Person : Type\n\nconstants\n  At GSC ONA PTP Cel Ath WP Fam LTH : Person \u2192 Prop\n\nconstant djokovic : Person\n\naxioms\n  H1  : \u2200 x, At x \u2192 (GSC x \u2228 ONA x)                      -- Everyone at the mixer is GSC or ONA\n  H2  : \u2200 x, At x \u2192 GSC x \u2192 PTP x                         -- Every GSC at the mixer is a PTP\n  H3  : \u2200 x, At x \u2192 ONA x \u2192 Cel x                         -- All ONA at the mixer are celebrities\n  H4  : \u2200 x, At x \u2192 PTP x \u2192 Ath x                         -- All PTP at the mixer are athletes\n  H5  : \u2200 x, At x \u2192 Cel x \u2192 WP x                          -- If at the mixer and celebrity, then well paid\n  H6  : \u2200 x, At x \u2192 Ath x \u2192 Fam x                         -- If at the mixer and athlete, then famous\n  H7  : \u2200 x, At x \u2192 WP x \u2192 LTH x                          -- All well-paid at the mixer live in tax havens\n  H8a : At djokovic                                       -- Djokovic is at the mixer\n  H8b : (Fam djokovic \u2227 Ath djokovic) \u2192 WP djokovic       -- If Djokovic is a famous athlete, then he is well-paid\n\ntheorem djokovic_lives_in_tax_haven : LTH djokovic :=\nby\n  have h : GSC djokovic \u2228 ONA djokovic := H1 djokovic H8a\n  cases h with\n  | inl hgsc =>\n      have hptp : PTP djokovic := (H2 djokovic H8a) hgsc\n      have hath : Ath djokovic := (H4 djokovic H8a) hptp\n      have hfam : Fam djokovic := (H6 djokovic H8a) hath\n      have hwp  : WP djokovic  := H8b \u27e8hfam, hath\u27e9\n      exact (H7 djokovic H8a) hwp\n  | inr hona =>\n      have hcel : Cel djokovic := (H3 djokovic H8a) hona\n      have hwp  : WP djokovic  := (H5 djokovic H8a) hcel\n      exact (H7 djokovic H8a) hwp\n\n-- From this, we also get \u00ac(\u00ac LTH djokovic)\ntheorem not_not_not_lth_false : \u00ac (\u00ac LTH djokovic) :=\nby\n  intro h\n  exact h djokovic_lives_in_tax_haven\n\n\nAnswers:\n1) Djokovic is a Grand Slam champion. Unknown\n2) Djokovic lives in a tax haven. True\n3) Djokovic does not live in a tax haven. False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 893,
        "conclusion": "Djokovic is a Grand Slam champion.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 894,
        "conclusion": "Djokovic lives in a tax haven.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 895,
        "conclusion": "Djokovic does not live in a tax haven.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 96,
    "premises": "Diamond Mine is a professional wrestling stable formed in WWE.\nRoderick Strong leads Diamond Mine.\nDiamond Mine includes the Creed Brothers and Ivy Nile.\nImperium has a feud with Diamond Mine.",
    "gpt_response": "Lean formalization and proofs:\n\n-- Basic setup\nconstant Entity : Type\n\nconstants\n  DiamondMine RoderickStrong CreedBrothers IvyNile Imperium : Entity\n\nconstants\n  Stable   : Entity \u2192 Prop\n  Leads    : Entity \u2192 Entity \u2192 Prop\n  Includes : Entity \u2192 Entity \u2192 Prop\n  Feud     : Entity \u2192 Entity \u2192 Prop\n\n-- Facts from the textual context\naxiom hStableDM    : Stable DiamondMine\naxiom hLeadsRS_DM  : Leads RoderickStrong DiamondMine\naxiom hInclDM_CB   : Includes DiamondMine CreedBrothers\naxiom hInclDM_IN   : Includes DiamondMine IvyNile\naxiom hFeudImp_DM  : Feud Imperium DiamondMine\n\n-- Q1: \u2203 s, Stable s \u2227 Leads RoderickStrong s\ntheorem Q1_true : \u2203 s, Stable s \u2227 Leads RoderickStrong s := by\n  exact \u27e8DiamondMine, \u27e8hStableDM, hLeadsRS_DM\u27e9\u27e9\n\n-- Q3: original statement is \u00ac \u2203 s, Stable s \u2227 Includes s IvyNile \u2227 Feud Imperium s\n-- We prove its negation by exhibiting DiamondMine.\ntheorem Q3_neg : \u2203 s, Stable s \u2227 Includes s IvyNile \u2227 Feud Imperium s := by\n  exact \u27e8DiamondMine, \u27e8hStableDM, \u27e8hInclDM_IN, hFeudImp_DM\u27e9\u27e9\u27e9\n\n\nAnswers:\n- Question 1: Roderick Strong leads Diamond Mine, and Diamond Mine is a professional wrestling stable. Therefore, he leads a professional wrestling stable. True\n- Question 2: The facts do not state that he leads the Creed Brothers individually; only that he leads Diamond Mine, which includes them. Unknown\n- Question 3: Imperium does have a feud with Diamond Mine, a professional wrestling stable that includes Ivy Nile, so the statement denying this is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 289,
        "conclusion": "Roderick Strong leads a professional wrestling stable.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 290,
        "conclusion": "Roderick Strong leads the Creed Brothers.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 291,
        "conclusion": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 219,
    "premises": "Symphony No. 9 is a music piece.\nComposers write music pieces.\nBeethoven wrote Symphony No. 9.\nVienna Music Society premiered Symphony No. 9.\nVienna Music Society is an orchestra.\nBeethoven leads the Vienna Music Society.\nOrchestras are led by conductors.",
    "gpt_response": "Lean formalization and attempted proofs:\n\n-- We model entities and predicates\nuniverse u\nconstant Entity : Type u\n\n-- Constants for specific entities\nconstant Beethoven : Entity\nconstant Symphony9 : Entity\nconstant ViennaMusicSociety : Entity\n\n-- Predicates/relations\nconstant MusicPiece  : Entity \u2192 Prop\nconstant Composer    : Entity \u2192 Prop\nconstant Wrote       : Entity \u2192 Entity \u2192 Prop\nconstant Premiered   : Entity \u2192 Entity \u2192 Prop\nconstant Orchestra   : Entity \u2192 Prop\nconstant Leads       : Entity \u2192 Entity \u2192 Prop\nconstant Conductor   : Entity \u2192 Prop\n\n-- Facts from the context\naxiom Symphony9_is_music      : MusicPiece Symphony9\naxiom composers_write_some    : \u2200 x, Composer x \u2192 \u2203 y, MusicPiece y \u2227 Wrote x y\naxiom Beethoven_wrote_S9      : Wrote Beethoven Symphony9\naxiom VMS_premiered_S9        : Premiered ViennaMusicSociety Symphony9\naxiom VMS_is_orchestra        : Orchestra ViennaMusicSociety\naxiom Beethoven_leads_VMS     : Leads Beethoven ViennaMusicSociety\naxiom leaders_of_orchestras_are_conductors :\n  \u2200 p o, Orchestra o \u2192 Leads p o \u2192 Conductor p\n\n-- The three statements (as Props)\ndef Q1_stmt : Prop := Composer Beethoven\ndef Q2_stmt : Prop := \u2203 o p, Orchestra o \u2227 MusicPiece p \u2227 Premiered o p\ndef Q3_stmt : Prop := \u00ac Conductor Beethoven\n\n-- Q2 can be proved directly using the given witnesses\ntheorem Q2_proved : Q2_stmt := by\n  refine Exists.intro ViennaMusicSociety ?_\n  refine Exists.intro Symphony9 ?_\n  exact And.intro VMS_is_orchestra (And.intro Symphony9_is_music VMS_premiered_S9)\n\n-- From \u201cOrchestras are led by conductors\u201d and \u201cBeethoven leads VMS (an orchestra)\u201d,\n-- we can derive that Beethoven is a conductor.\ntheorem Beethoven_is_conductor : Conductor Beethoven := by\n  exact leaders_of_orchestras_are_conductors Beethoven ViennaMusicSociety\n    VMS_is_orchestra Beethoven_leads_VMS\n\n-- Therefore, the negation of Q3 (which asserts Beethoven is not a conductor) is provable.\ntheorem not_Q3 : \u00ac Q3_stmt := by\n  intro h\n  exact h Beethoven_is_conductor\n\n-- We cannot derive Q1_stmt or its negation from the given axioms.\n\nAnswers:\n- Q1: From \u201cComposers write music pieces\u201d and \u201cBeethoven wrote Symphony No. 9,\u201d we cannot infer that only composers write music. So we cannot conclude Beethoven is a composer. Unknown\n- Q2: Vienna Music Society is an orchestra and it premiered Symphony No. 9, a music piece; hence some orchestras premiered music pieces. True\n- Q3: Since Beethoven leads an orchestra and orchestras are led by conductors, Beethoven is a conductor. Therefore, \u201cBeethoven is not a conductor\u201d is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 621,
        "conclusion": "Beethoven is a composer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 622,
        "conclusion": "Some orchestras premiered music pieces.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 623,
        "conclusion": "Beethoven is not a conductor.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 350,
    "premises": "All of Zaha Hadid's design styles that Max adores have interesting geometries.\nNo brutalist buildings that Max adores have interesting geometries.\nEvery style that Max adores is either Zaha Hadid's design style or Kelly Wearstler's design style. \nAll of Kelly Wearstler's design styles that Max adores are evocative.\nAll of Kelly Wearstler's design styles that Max adores are dreamy.\nIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative.",
    "gpt_response": "Lean formalization and attempt at proof:\n\nnamespace MaxDesigns\n\nuniverse u\n\nconstant Obj : Type u\nconstant Adores : Obj \u2192 Prop\nconstant ZahaStyle : Obj \u2192 Prop\nconstant KellyStyle : Obj \u2192 Prop\nconstant Brutalist : Obj \u2192 Prop\nconstant Interesting : Obj \u2192 Prop\nconstant Evocative : Obj \u2192 Prop\nconstant Dreamy : Obj \u2192 Prop\nconstant DesignByMax : Obj \u2192 Prop\n\n-- All Zaha styles Max adores have interesting geometries.\naxiom h1 : \u2200 x, ZahaStyle x \u2192 Adores x \u2192 Interesting x\n-- No brutalist buildings that Max adores have interesting geometries.\naxiom h2 : \u2200 x, Brutalist x \u2192 Adores x \u2192 \u00ac Interesting x\n-- Every style that Max adores is either Zaha's or Kelly's.\naxiom h3 : \u2200 x, Adores x \u2192 (ZahaStyle x \u2228 KellyStyle x)\n-- All Kelly styles Max adores are evocative.\naxiom h4 : \u2200 x, KellyStyle x \u2192 Adores x \u2192 Evocative x\n-- All Kelly styles Max adores are dreamy.\naxiom h5 : \u2200 x, KellyStyle x \u2192 Adores x \u2192 Dreamy x\n-- If a design by Max that he adores has interesting geometries, then it is brutalist and evocative.\naxiom h6 : \u2200 x, DesignByMax x \u2192 Adores x \u2192 Interesting x \u2192 Brutalist x \u2227 Evocative x\n\n-- Consequences we can prove:\n-- No design by Max that he adores can have interesting geometries (would be a contradiction).\nlemma no_adored_interesting_design_by_max :\n  \u2200 x, DesignByMax x \u2192 Adores x \u2192 Interesting x \u2192 False := by\n  intro x dx ax ix\n  have hb : Brutalist x \u2227 Evocative x := h6 x dx ax ix\n  have hni : \u00ac Interesting x := h2 x hb.left ax\n  exact hni ix\n\n-- Anything Zaha and adored by Max cannot be brutalist.\nlemma adored_zaha_not_brutalist :\n  \u2200 x, Adores x \u2192 ZahaStyle x \u2192 \u00ac Brutalist x := by\n  intro x ax zx\n  intro bx\n  have hni : \u00ac Interesting x := h2 x bx ax\n  have hi : Interesting x := h1 x zx ax\n  exact hni hi\n\n-- Anything Kelly and adored by Max is both evocative and dreamy.\nlemma adored_kelly_evocative_and_dreamy :\n  \u2200 x, Adores x \u2192 KellyStyle x \u2192 Evocative x \u2227 Dreamy x := by\n  intro x ax kx\n  have e : Evocative x := h4 x kx ax\n  have d : Dreamy x := h5 x kx ax\n  exact And.intro e d\n\n-- Target statements (existential readings of the questions):\ndef Q1 : Prop := \u2203 x, DesignByMax x \u2227 Brutalist x\ndef Q2 : Prop := \u2203 x, DesignByMax x \u2227 Evocative x \u2227 Dreamy x\ndef Q3 : Prop := \u2203 x, DesignByMax x \u2227 (Evocative x \u2228 Dreamy x)\n\n-- From the given axioms, neither Q1, nor Q2, nor Q3 is derivable or refutable.\n\nend MaxDesigns\n\nAnswers:\n- Question 1: Unknown\n- Question 2: Unknown\n- Question 3: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 927,
        "conclusion": "A design by Max is a brutalist building.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 928,
        "conclusion": "A design by Max is evocative and dreamy.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 929,
        "conclusion": "A design by Max is either evocative or dreamy.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 385,
    "premises": "If someone is ranked highly by the Women's Tennis Association, then they are one of the most active players in major tennis. \nEveryone who lost to Iga \u015awi\u0105tek at Roland Garros 2022 is ranked highly by the Women's Tennis Association.\nAll female tennis players at Roland Garros 2022 lost to Iga \u015awi\u0105tek.\nAll tennis players at Roland Garros 2022 are either female or male.\nAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal.\nIf Coco Gauff is ranked highly by the Women's Tennis Association or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nCoco Gauff is at Roland Garros 2022.",
    "gpt_response": "Lean formalization and proofs:\n\n-- Universe of discourse\nconstant Person : Type\nconstant Coco : Person\n\n-- Predicates\nconstant RG : Person \u2192 Prop                    -- tennis player at Roland Garros 2022\nconstant Female : Person \u2192 Prop\nconstant Male : Person \u2192 Prop\nconstant LostIga : Person \u2192 Prop               -- lost to Iga \u015awi\u0105tek\nconstant LostNadal : Person \u2192 Prop             -- lost to Rafael Nadal\nconstant High : Person \u2192 Prop                  -- ranked highly by WTA\nconstant Most : Person \u2192 Prop                  -- among the most active major-tennis players\n\n-- Axioms from the text\naxiom A1 : \u2200 x, High x \u2192 Most x\naxiom A2 : \u2200 x, LostIga x \u2192 High x\naxiom A3 : \u2200 x, RG x \u2227 Female x \u2192 LostIga x\naxiom A4 : \u2200 x, RG x \u2192 Female x \u2228 Male x\naxiom A5 : \u2200 x, RG x \u2227 Male x \u2192 LostNadal x\naxiom A6 : (High Coco \u2228 LostNadal Coco) \u2192 \u00ac (RG Coco \u2227 Male Coco)\naxiom A7 : RG Coco\n\n-- Derived lemmas\ntheorem Coco_most : Most Coco := by\n  have h : Female Coco \u2228 Male Coco := A4 Coco A7\n  cases h with\n  | inl hf =>\n    have hLI : LostIga Coco := A3 Coco \u27e8A7, hf\u27e9\n    have hH : High Coco := A2 Coco hLI\n    exact A1 Coco hH\n  | inr hm =>\n    have hLN : LostNadal Coco := A5 Coco \u27e8A7, hm\u27e9\n    have contra : False := by\n      have notMaleRG := A6 (Or.inr hLN)\n      exact notMaleRG \u27e8A7, hm\u27e9\n    exact False.elim contra\n\ntheorem Coco_lostIga : LostIga Coco := by\n  have h : Female Coco \u2228 Male Coco := A4 Coco A7\n  cases h with\n  | inl hf =>\n    exact A3 Coco \u27e8A7, hf\u27e9\n  | inr hm =>\n    have hLN : LostNadal Coco := A5 Coco \u27e8A7, hm\u27e9\n    have contra : False := by\n      have notMaleRG := A6 (Or.inr hLN)\n      exact notMaleRG \u27e8A7, hm\u27e9\n    exact False.elim contra\n\ntheorem Coco_lostIga_and_most : LostIga Coco \u2227 Most Coco :=\n  And.intro Coco_lostIga Coco_most\n\n-- The Q3 statement (\u201cCoco is not both \u2026\u201d) is false\ndef Q3_stmt : Prop := \u00ac (LostIga Coco \u2227 Most Coco)\ntheorem Q3_false : \u00ac Q3_stmt := by\n  intro h\n  exact h Coco_lostIga_and_most\n\n\nAnswers:\n\n1) From RG Coco and the gender disjunction, the male case leads to a contradiction via the Nadal rule and the special Coco constraint, so Coco must be in the safe branch that yields Lost-to-Iga \u2192 High \u2192 Most; hence she is among the most active Grand-Slam players. True\n\n2) We only know all male RG players lost to Nadal, and Coco is not male-at-RG (from the special constraint together with our derivations), but nothing states that non-male players did not or did lose to Nadal; thus this cannot be concluded. Unknown\n\n3) We proved Coco_lostIga_and_most, so the statement \u201cCoco is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis\u201d is false. False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 1029,
        "conclusion": "Coco Gauff is among the most active Grand-Slam players.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1030,
        "conclusion": "Coco Gauff has lost to Rafael Nadal.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1031,
        "conclusion": "Coco Gauff is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 256,
    "premises": "All cats are mammals.\nSome pets are not mammals.",
    "gpt_response": "Lean formalization and proof attempt\n\nInformal translation:\n- Domain: objects\n- Predicates: Cat(x), Mammal(x), Pet(x)\n- Premises:\n  1) \u2200x, Cat(x) \u2192 Mammal(x)  (all cats are mammals)\n  2) \u2203x, Pet(x) \u2227 \u00acMammal(x) (some pets are not mammals)\n- Claim S: \u2200x, Pet(x) \u2192 \u00acCat(x) (no pets are cats)\n\nNegation of S: \u2203x, Pet(x) \u2227 Cat(x) (some pet is a cat)\n\nLean code:\nuniverse u\n\n/-\nWe show the claim S is not provable from the premises by giving a concrete\ncountermodel where the premises hold but S fails.\n-/\ninductive A | a | b\nopen A\n\ndef CatA : A \u2192 Prop\n| a => True\n| b => False\n\ndef MammalA : A \u2192 Prop\n| a => True\n| b => False\n\ndef PetA : A \u2192 Prop\n| a => True\n| b => True\n\nlemma A_all_cats_mammals : \u2200 x, CatA x \u2192 MammalA x := by\n  intro x hx\n  cases x <;> simp [CatA, MammalA] at *\n\nlemma A_some_pet_not_mammal : \u2203 x, PetA x \u2227 \u00ac MammalA x := by\n  refine \u27e8b, ?_, ?_\u27e9 <;> simp [PetA, MammalA]\n\nlemma A_not_no_pets_are_cats : \u00ac (\u2200 x, PetA x \u2192 \u00ac CatA x) := by\n  intro h\n  have h' := h a\n  have pa : PetA a := by simp [PetA]\n  have ca : CatA a := by simp [CatA]\n  exact (h' pa) ca\n\ntheorem not_entails_no_pets_are_cats :\n  \u00ac ((\u2200 x, CatA x \u2192 MammalA x) \u2192\n     (\u2203 x, PetA x \u2227 \u00ac MammalA x) \u2192\n     (\u2200 x, PetA x \u2192 \u00ac CatA x)) := by\n  intro h\n  have h1 := A_all_cats_mammals\n  have h2 := A_some_pet_not_mammal\n  have concl := h h1 h2\n  exact A_not_no_pets_are_cats concl\n\n/-\nWe also show the negation of S is not provable from the premises by giving a\ndifferent model where the premises hold and S is true (so its negation fails).\n-/\ninductive B | a | b\nopen B\n\ndef CatB : B \u2192 Prop\n| a => True     -- a is a cat\n| b => False\n\ndef MammalB : B \u2192 Prop\n| a => True     -- all cats are mammals\n| b => False    -- b is not a mammal\n\ndef PetB : B \u2192 Prop\n| a => False    -- no pet cats\n| b => True     -- b is a pet\n\nlemma B_all_cats_mammals : \u2200 x, CatB x \u2192 MammalB x := by\n  intro x hx\n  cases x <;> simp [CatB, MammalB] at *\n\nlemma B_some_pet_not_mammal : \u2203 x, PetB x \u2227 \u00ac MammalB x := by\n  refine \u27e8b, ?_, ?_\u27e9 <;> simp [PetB, MammalB]\n\nlemma B_no_pet_is_cat : \u2200 x, PetB x \u2192 \u00ac CatB x := by\n  intro x hx\n  cases x <;> simp [PetB, CatB] at *\n\nlemma B_not_exists_pet_cat : \u00ac \u2203 x, PetB x \u2227 CatB x := by\n  intro h\n  rcases h with \u27e8x, hxP, hxC\u27e9\n  cases x <;> simp [PetB, CatB] at *\n\ntheorem not_entails_exists_pet_cat :\n  \u00ac ((\u2200 x, CatB x \u2192 MammalB x) \u2192\n     (\u2203 x, PetB x \u2227 \u00ac MammalB x) \u2192\n     (\u2203 x, PetB x \u2227 CatB x)) := by\n  intro h\n  have h1 := B_all_cats_mammals\n  have h2 := B_some_pet_not_mammal\n  have concl := h h1 h2\n  exact B_not_exists_pet_cat concl\n\nConclusion: From the premises, the statement \u201cNo pets are cats\u201d is not determined. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 700,
        "conclusion": "No pets are cats.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 159,
    "premises": "There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.",
    "gpt_response": "Lean translation and attempt at proofs:\n\nuniverse u\n\nconstant Person : Type u\n\ninductive Season where\n| Spring | Summer | Fall | Winter\nderiving DecidableEq\n\nopen Season\n\nconstants (Emma Mia James : Person)\n\nconstant fav : Person \u2192 Season\nconstant Student : Person \u2192 Prop\nconstant WantsLongVacation : Person \u2192 Prop\n\n-- All students who want a long vacation have summer as their favorite season.\naxiom rule : \u2200 p, Student p \u2192 WantsLongVacation p \u2192 fav p = Summer\n\n-- Emma's favorite season is summer.\naxiom emma_fav : fav Emma = Summer\n\n-- Mia's favorite season is not the same as Emma's.\naxiom mia_diff_emma : fav Mia \u2260 fav Emma\n\n-- James wants to have a long vacation.\naxiom james_wants : WantsLongVacation James\n\n-- Useful consequence: Mia does not have Summer as her favorite season.\nlemma mia_not_summer : fav Mia \u2260 Summer := by\n  intro h\n  have : fav Mia = fav Emma := Eq.trans h emma_fav.symm\n  exact mia_diff_emma this\n\n-- What we can prove about James: if he is a student, then his favorite is Summer.\nlemma james_summer_if_student : Student James \u2192 fav James = Summer := by\n  intro hstu\n  exact rule James hstu james_wants\n\n-- We cannot prove fav James = Summer outright (Student James is not given).\n-- We also cannot prove its negation from the given axioms.\n\n-- We also cannot prove fav Mia = Spring; we only know fav Mia \u2260 Summer.\n\n\nAnswers:\n\nQuestion 1: From the rule we need James to be a student to conclude his favorite season is summer, but we are not given that. Therefore the statement cannot be determined from the information. Unknown\n\nQuestion 2: We only know Mia\u2019s favorite season is not Summer; it could be Spring, Fall, or Winter. Therefore the statement cannot be determined from the information. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 456,
        "conclusion": "James's favorite season is summer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 457,
        "conclusion": "Mia's favorite season is spring.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 343,
    "premises": "No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.",
    "gpt_response": "Lean formalization and proofs:\n\n-- Universe and objects\nuniverse u\nconstant Obj : Type u\n\n-- Predicates\nconstant Digital Analog Printed Streaming Hardcover : Obj \u2192 Prop\n\n-- Constant for the object \"1984\"\nconstant b1984 : Obj\n\n-- Axioms from the textual context\naxiom no_digital_are_analog : \u2200 x, Digital x \u2192 \u00ac Analog x\naxiom printed_are_analog    : \u2200 x, Printed x \u2192 Analog x\naxiom streaming_are_digital : \u2200 x, Streaming x \u2192 Digital x\naxiom hardcover_implies_printed : \u2200 x, Hardcover x \u2192 Printed x\naxiom streaming1984_implies_hardcover : Streaming b1984 \u2192 Hardcover b1984\n\n-- Derived lemmas\ntheorem streaming_1984_implies_analog : Streaming b1984 \u2192 Analog b1984 := by\n  intro hs\n  have hh : Hardcover b1984 := streaming1984_implies_hardcover hs\n  have hp : Printed b1984 := hardcover_implies_printed b1984 hh\n  exact printed_are_analog b1984 hp\n\ntheorem streaming_1984_implies_digital : Streaming b1984 \u2192 Digital b1984 :=\n  fun hs => streaming_are_digital b1984 hs\n\n-- Main consequence: 1984 is not a streaming service\ntheorem not_streaming_1984 : \u00ac Streaming b1984 := by\n  intro hs\n  have ha : Analog b1984 := streaming_1984_implies_analog hs\n  have hd : Digital b1984 := streaming_1984_implies_digital hs\n  have hna : \u00ac Analog b1984 := no_digital_are_analog b1984 hd\n  exact hna ha\n\nAnswers:\n- Question 1: We cannot derive that 1984 is printed text, nor can we derive that it is not. Unknown\n- Question 2: From the proof above, 1984 is not a streaming service, so the statement \u201c1984 is a streaming service\u201d is false. False\n- Question 3: As shown, \u00ac Streaming 1984 holds. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 904,
        "conclusion": "1984 is printed text.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 905,
        "conclusion": "1984 is a streaming service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 906,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Connection error."
  },
  {
    "error": "Request timed out."
  },
  {
    "story_id": 306,
    "premises": "If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.",
    "gpt_response": "Lean formalization and proofs:\n\nconstant Restaurant : Type\nconstant Listed : Restaurant \u2192 Prop\nconstant Negative : Restaurant \u2192 Prop\nconstant RatingGt4 : Restaurant \u2192 Prop\nconstant Takeout : Restaurant \u2192 Prop\nconstant Popular : Restaurant \u2192 Prop\nconstant H : Restaurant\n\n-- Premises\naxiom listed_not_negative : \u2200 x, Listed x \u2192 \u00ac Negative x\naxiom rating_listed : \u2200 x, RatingGt4 x \u2192 Listed x\naxiom some_no_takeout_negative : \u2203 x, \u00ac Takeout x \u2227 Negative x\naxiom popular_rating : \u2200 x, Popular x \u2192 RatingGt4 x\naxiom H_rating_or_pop : RatingGt4 H \u2228 Popular H\n\n-- Derived facts about H\nlemma H_rating : RatingGt4 H :=\n  Or.elim H_rating_or_pop (fun r => r) (fun p => popular_rating H p)\n\nlemma H_not_negative : \u00ac Negative H :=\nby\n  have l : Listed H := rating_listed H H_rating\n  exact listed_not_negative H l\n\n-- Q1: (Takeout H \u2227 Negative H) \u2192 (RatingGt4 H \u2227 \u00ac Takeout H)\ntheorem Q1_statement : (Takeout H \u2227 Negative H) \u2192 (RatingGt4 H \u2227 \u00ac Takeout H) :=\nby\n  intro h\n  have : False := H_not_negative h.right\n  exact False.elim this\n\n-- Q2: Takeout H \u2228 \u00ac Negative H\ntheorem Q2_statement : Takeout H \u2228 \u00ac Negative H :=\n  Or.inr H_not_negative\n\n-- Q3 (\u00ac Takeout H) is not derivable from the given premises.\n\nAnswers:\n- Question 1: True\n- Question 2: True\n- Question 3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 754,
        "conclusion": "If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 755,
        "conclusion": "The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 756,
        "conclusion": "The Hamden Plaza store does not provide take-out service.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 245,
    "premises": "In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.",
    "gpt_response": "-- Lean 4 formalization and proof\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Person : Type u\nconstant Movie : Type u\n\nconstant Good : Person -> Prop\nconstant Bad : Person -> Prop\nconstant Fights : Person -> Person -> Prop\nconstant Wins : Person -> Prop\nconstant SuperheroMovie : Movie -> Prop\nconstant NamedAfter : Movie -> Person -> Prop\nconstant InMovie : Person -> Movie -> Prop\n\nconstant SirDigby : Person\nconstant NemesisOfSirDigby : Person\nconstant TSDCC : Movie  -- The Surprising Adventures of Sir Digby Chicken Caesar\n\n-- Axioms translated from the textual context:\n\n-- 1. In superhero movies, the good guys always win.\naxiom good_guys_win_in_superhero_movies :\n  \u2200 m : Movie, SuperheroMovie m -> \u2200 p : Person, Good p -> Wins p\n\n-- 2. The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\naxiom the_movie_is_superhero : SuperheroMovie TSDCC\n\n-- 3. Good guys fight bad guys and vice versa.\naxiom good_fight_bad_and_vice_versa :\n  \u2200 x y : Person, (Good x \u2227 Bad y) -> (Fights x y \u2227 Fights y x)\n\n-- 4. Sir Digby fights his nemesis.\naxiom sir_digby_fights_his_nemesis :\n  Fights SirDigby NemesisOfSirDigby\n\n-- 5. If a superhero movie is named after a character, that character is a good guy.\naxiom named_after_implies_good_guy :\n  \u2200 m : Movie, \u2200 p : Person, (SuperheroMovie m \u2227 NamedAfter m p) -> Good p\n\n-- 6. The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\naxiom the_movie_is_named_after_sir_digby :\n  NamedAfter TSDCC SirDigby\n\n-- 7. If somebody wins a fight, the person they are fighting does not win.\naxiom fight_winner_excludes_opponent_win :\n  \u2200 x y : Person, (Wins x \u2227 Fights x y) -> \u00ac Wins y\n\n-- 8. If a superhero movie is named after a character, that character is in the movie.\naxiom named_after_implies_in_movie :\n  \u2200 m : Movie, \u2200 p : Person, (SuperheroMovie m \u2227 NamedAfter m p) -> InMovie p m\n\n-- Target: Sir Digby\u2019s nemesis does not win.\ntheorem nemesis_does_not_win : \u00ac Wins NemesisOfSirDigby := by\n  -- Sir Digby is a good guy (5,2,6)\n  have hGoodDigby : Good SirDigby := by\n    exact named_after_implies_good_guy TSDCC SirDigby\n      (And.intro the_movie_is_superhero the_movie_is_named_after_sir_digby)\n  -- In this superhero movie, good guys win, so Sir Digby wins (1,2)\n  have hGoodImpliesWins : \u2200 p : Person, Good p -> Wins p :=\n    good_guys_win_in_superhero_movies TSDCC the_movie_is_superhero\n  have hWinsDigby : Wins SirDigby := hGoodImpliesWins SirDigby hGoodDigby\n  -- Sir Digby fights his nemesis (4), so his opponent does not win (7)\n  exact fight_winner_excludes_opponent_win SirDigby NemesisOfSirDigby\n    (And.intro hWinsDigby sir_digby_fights_his_nemesis)\n\nend Reasoning\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 688,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 58,
    "premises": "Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.",
    "gpt_response": "Lean formalization and attempted proofs:\n\nuniverse u\n\nconstant Person : Type u\nconstant Book   : Type u\n\nconstant ContainsKnowledge   : Book \u2192 Prop\nconstant Reads               : Person \u2192 Book \u2192 Prop\nconstant GainsKnowledge      : Person \u2192 Prop\nconstant SmarterThanBefore   : Person \u2192 Prop\n\naxiom BooksContainKnowledge    : \u2200 b : Book, ContainsKnowledge b\naxiom ReadingGivesKnowledge    : \u2200 p : Person, \u2200 b : Book, Reads p b \u2192 GainsKnowledge p\naxiom KnowledgeMakesSmarter    : \u2200 p : Person, GainsKnowledge p \u2192 SmarterThanBefore p\n\nconstant Harry  : Person\nconstant Walden : Book\naxiom HarryReadWalden : Reads Harry Walden\n\n-- Q1\ntheorem Q1_WaldenContainsKnowledge : ContainsKnowledge Walden :=\n  BooksContainKnowledge Walden\n\n-- Q2\ntheorem Q2_HarrySmarterThanBefore : SmarterThanBefore Harry :=\nby\n  apply KnowledgeMakesSmarter\n  exact ReadingGivesKnowledge Harry Walden HarryReadWalden\n\n-- Q3 (attempt): From the given axioms we only have GainsKnowledge \u2192 SmarterThanBefore,\n-- not the converse. We cannot derive \u2200 p, SmarterThanBefore p \u2192 GainsKnowledge p,\n-- nor can we derive its negation from the given information.\n\nAnswers:\n1) Walden contains knowledge. True\n2) Harry is smarter than before. True\n3) A smarter person has gained knowledge. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 171,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 172,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 173,
        "conclusion": "A smarter person has gained knowledge.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 191,
    "premises": "A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.",
    "gpt_response": "Lean formalization and proof attempt\n\nI model tasks, predicates, and the given premises explicitly, prove Q1, and show Q2 is not entailed by giving two concrete models (one where it\u2019s true and one where it\u2019s false).\n\nLean code:\n\nnamespace NLPTasks\n\nuniverse u\n\n-- A world of discourse with the relevant predicates and axioms\nstructure World where\n  Task : Type u\n  NLP LGen LUnd OutputText : Task \u2192 Prop\n  MachineTranslation : Task\n  -- Premises from the problem:\n  ax1 : \u2200 t, NLP t \u2192 (LGen t \u2228 LUnd t)\n  ax2 : \u2200 t, OutputText t \u2192 LGen t\n  ax3 : NLP MachineTranslation\n  ax4 : OutputText MachineTranslation\n\n-- Q1: From ax2 and ax4, MachineTranslation is a language generation task.\ntheorem Q1 (w : World) : w.LGen w.MachineTranslation :=\n  w.ax2 _ w.ax4\n\n-- Independence of Q2 (not determined by the premises):\n\n-- Model where MachineTranslation is NOT a language understanding task\ndef worldGenOnly : World where\n  Task := Unit\n  NLP := fun _ => True\n  LGen := fun _ => True\n  LUnd := fun _ => False\n  OutputText := fun _ => True\n  MachineTranslation := ()\n  ax1 := by intro _ _; exact Or.inl trivial\n  ax2 := by intro _ _; exact trivial\n  ax3 := trivial\n  ax4 := trivial\n\nlemma worldGenOnly_not_understanding :\n  \u00ac worldGenOnly.LUnd worldGenOnly.MachineTranslation := by\n  intro h; exact h\n\n-- Model where MachineTranslation IS a language understanding task\ndef worldBoth : World where\n  Task := Unit\n  NLP := fun _ => True\n  LGen := fun _ => True\n  LUnd := fun _ => True\n  OutputText := fun _ => True\n  MachineTranslation := ()\n  ax1 := by intro _ _; exact Or.inl trivial\n  ax2 := by intro _ _; exact trivial\n  ax3 := trivial\n  ax4 := trivial\n\nlemma worldBoth_understanding :\n  worldBoth.LUnd worldBoth.MachineTranslation := trivial\n\nend NLPTasks\n\nReasoning summary\n\n- From \u201cIf the output is a text sequence, then it is a language generation task\u201d and \u201cThe output of machine translation is a text sequence,\u201d we can directly conclude that machine translation is a language generation task. This is proved as Q1 in Lean.\n- The premise \u201can NLP task can be categorized as either a language generation task or a language understanding task\u201d is taken as an inclusive or (no exclusivity is stated). Hence, even knowing that machine translation is a generation task does not rule out it also being an understanding task. The two constructed models show that the premises are consistent both with \u201cmachine translation is a language understanding task\u201d and with its negation, so Q2 is not determined by the given information.\n\nAnswers\n\n- Question 1: Machine translation is a language generation task. True\n- Question 2: Machine translation is a language understanding task. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 546,
        "conclusion": "Machine translation is a language generation task.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 547,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 166,
    "premises": "Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. ",
    "gpt_response": "Lean formalization and attempted proofs:\n\nopen Classical\n\nconstant Building : Type\nconstant Person : Type\nconstant Animal : Type\n\n-- Predicates and functions\nconstant Managed : Building \u2192 Prop\nconstant AllowsPets : Building \u2192 Prop\nconstant MonthlyRent : Building \u2192 Nat\nconstant SecurityDeposit : Building \u2192 Nat\nconstant Pet : Animal \u2192 Prop\nconstant Cat : Animal \u2192 Prop\nconstant AllowedMoveInWith : Person \u2192 Animal \u2192 Building \u2192 Prop\nconstant WillRentIn : Person \u2192 Building \u2192 Prop\n\n-- Entities\nconstant Tom : Person\nconstant Fluffy : Animal\nconstant OliveGarden : Building\n\n-- Facts from the text\naxiom some_allows_pets : \u2203 b, Managed b \u2227 AllowsPets b\naxiom deposit_ge_rent : \u2200 b, Managed b \u2192 SecurityDeposit b \u2265 MonthlyRent b\naxiom cats_are_pets : \u2200 a, Cat a \u2192 Pet a\naxiom Fluffy_is_cat : Cat Fluffy\naxiom Olive_is_managed : Managed OliveGarden\naxiom rent_olive : MonthlyRent OliveGarden = 2000\naxiom gt_2000_1500 : 2000 > 1500\naxiom if_allows_then_people_with_pets_allowed :\n  \u2200 b, Managed b \u2192 AllowsPets b \u2192 \u2200 p a, Pet a \u2192 AllowedMoveInWith p a b\naxiom tom_rents_if_allowed_and_deposit_small :\n  \u2200 b, Managed b \u2192 AllowedMoveInWith Tom Fluffy b \u2192 SecurityDeposit b \u2264 1500 \u2192 WillRentIn Tom b\n\n-- Useful derived facts\nlemma Fluffy_is_pet : Pet Fluffy :=\n  cats_are_pets Fluffy Fluffy_is_cat\n\nlemma deposit_ge_2000_at_olive : SecurityDeposit OliveGarden \u2265 2000 := by\n  have h := deposit_ge_rent OliveGarden Olive_is_managed\n  simpa [rent_olive] using h\n\nlemma deposit_not_le_1500_at_olive : \u00ac SecurityDeposit OliveGarden \u2264 1500 := by\n  have h2000_le_dep : 2000 \u2264 SecurityDeposit OliveGarden := deposit_ge_2000_at_olive\n  have h1500_lt2000 : 1500 < 2000 := gt_2000_1500\n  have h1500_lt_dep : 1500 < SecurityDeposit OliveGarden := lt_of_lt_of_le h1500_lt2000 h2000_le_dep\n  exact not_le_of_gt h1500_lt_dep\n\n-- Conditional permission at Olive Garden if it allows pets\nlemma allowed_with_fluffy_if_OG_allows : AllowsPets OliveGarden \u2192 AllowedMoveInWith Tom Fluffy OliveGarden := by\n  intro hallow\n  have h := if_allows_then_people_with_pets_allowed OliveGarden Olive_is_managed hallow\n  simpa using h Tom Fluffy Fluffy_is_pet\n\n-- Q3 can be proved:\ntheorem Q3_formal : SecurityDeposit OliveGarden \u2265 2000 :=\n  deposit_ge_2000_at_olive\n\n-- Q1 and Q2 cannot be derived nor refuted from the given axioms:\n-- We cannot prove WillRentIn Tom OliveGarden (lack of sufficient conditions),\n-- nor its negation. Likewise, we cannot prove AllowedMoveInWith Tom Fluffy OliveGarden\n-- (we lack AllowsPets OliveGarden) nor its negation.\n\nAnswers:\n1) Tom will rent an apartment in The Olive Garden. Unknown\n2) Tom is allowed to move into an apartment in The Olive Garden with Fluffy. Unknown\n3) The security deposit at the Olive Garden is either $2000 or more. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 476,
        "conclusion": "Tom will rent an apartment in The Olive Garden.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 477,
        "conclusion": "Tom is allowed to move into an apartment in The Olive Garden with Fluffy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 478,
        "conclusion": "The security deposit at the Olive Garden is either $2000 or more.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 352,
    "premises": "All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. ",
    "gpt_response": "Lean formalization and proofs for the shared context:\n\n-- Universe and basic setup\nuniverse u\n\nconstant Entity : Type u\n\nconstant BusinessOrganization : Entity \u2192 Prop\nconstant Company : Entity \u2192 Prop\nconstant PrivateCompany : Entity \u2192 Prop\nconstant LegalEntity : Entity \u2192 Prop\nconstant CreatedUnderLaw : Entity \u2192 Prop\nconstant HasLegalObligations : Entity \u2192 Prop\n\nconstant hwb : Entity  -- Harvard Weekly Book Club\n\n-- Axioms from the textual context\naxiom A1 : \u2200 x, BusinessOrganization x \u2192 LegalEntity x\naxiom A2 : \u2200 x, Company x \u2192 BusinessOrganization x\naxiom A3 : \u2200 x, PrivateCompany x \u2192 Company x\naxiom A4 : \u2200 x, LegalEntity x \u2192 CreatedUnderLaw x\naxiom A5 : \u2200 x, LegalEntity x \u2192 HasLegalObligations x\naxiom A6 : CreatedUnderLaw hwb \u2192 \u00ac PrivateCompany hwb\n\n-- Useful derived lemmas\nlemma private_to_legal : \u2200 x, PrivateCompany x \u2192 LegalEntity x := by\n  intro x hpc\n  exact A1 x (A2 x (A3 x hpc))\n\nlemma not_private_hwb : \u00ac PrivateCompany hwb := by\n  intro hpc\n  have hlegal : LegalEntity hwb := private_to_legal hwb hpc\n  have hcul   : CreatedUnderLaw hwb := A4 hwb hlegal\n  have hnp    : \u00ac PrivateCompany hwb := A6 hcul\n  exact hnp hpc\n\n\nQuestion 1:\nTarget statement in Lean: HasLegalObligations hwb\n\nAttempt: From the axioms, we can derive HasLegalObligations x only for those x that are LegalEntity x (by A5). We have no premise that hwb is a company, business organization, or legal entity. Hence neither the statement nor its negation is derivable from the given axioms.\n\nConclusion: Unknown\n\nQuestion 2:\nTarget statement in Lean: HasLegalObligations hwb \u2227 PrivateCompany hwb\n\nLean proof of its negation:\n\ntheorem Q2_neg : \u00ac (HasLegalObligations hwb \u2227 PrivateCompany hwb) := by\n  intro h\n  exact not_private_hwb h.right\n\nTherefore the conjunction cannot hold.\n\nConclusion: False\n\nQuestion 3:\nTarget statement in Lean: PrivateCompany hwb \u2192 (HasLegalObligations hwb \u2228 CreatedUnderLaw hwb)\n\nLean proof:\n\ntheorem Q3 : PrivateCompany hwb \u2192 (HasLegalObligations hwb \u2228 CreatedUnderLaw hwb) := by\n  intro hpc\n  have hlegal : LegalEntity hwb := private_to_legal hwb hpc\n  have hcul   : CreatedUnderLaw hwb := A4 hwb hlegal\n  -- We could also derive HasLegalObligations hwb via A5; either disjunct suffices.\n  exact Or.inr hcul\n\nConclusion: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 933,
        "conclusion": "The Harvard Weekly Book club has legal obligations.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 934,
        "conclusion": "The Harvard Weekly Book club has legal obligations and is a private company.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 935,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 472,
    "premises": "Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.",
    "gpt_response": "Here is a faithful Lean formalization of the statements and an attempt at the three questions.\n\nLean formalization:\n\n- Universe of discourse: U\n- Predicates on U:\n  - Animal, Vertebrate, Invertebrate, Backbone, MF (reproduces by male-and-female mating), Bee, QueenBee\n- Constant: harry : U\n\nAxioms, as given by the text:\n- A1: All animals are either invertebrates or vertebrates:\n  \u2200 x, Animal x \u2192 (Invertebrate x \u2228 Vertebrate x)\n- A2: All animals with backbones reproduce by male-and-female mating:\n  \u2200 x, Animal x \u2192 Backbone x \u2192 MF x\n- A3: All vertebrate animals have a backbone:\n  \u2200 x, Animal x \u2192 Vertebrate x \u2192 Backbone x\n- A4: All bees do not reproduce by male-and-female mating:\n  \u2200 x, Bee x \u2192 \u00ac MF x\n- A5: All queen bees are bees:\n  \u2200 x, QueenBee x \u2192 Bee x\n- A6: Harry is a bee:\n  Bee harry\n\nLean code:\n\nnamespace Puzzle\n\nuniverse u\nconstant U : Type u\n\nconstant Animal : U \u2192 Prop\nconstant Vertebrate : U \u2192 Prop\nconstant Invertebrate : U \u2192 Prop\nconstant Backbone : U \u2192 Prop\nconstant MF : U \u2192 Prop\nconstant Bee : U \u2192 Prop\nconstant QueenBee : U \u2192 Prop\n\nconstant harry : U\n\naxiom A1 : \u2200 x, Animal x \u2192 (Invertebrate x \u2228 Vertebrate x)\naxiom A2 : \u2200 x, Animal x \u2192 Backbone x \u2192 MF x\naxiom A3 : \u2200 x, Animal x \u2192 Vertebrate x \u2192 Backbone x\naxiom A4 : \u2200 x, Bee x \u2192 \u00ac MF x\naxiom A5 : \u2200 x, QueenBee x \u2192 Bee x\naxiom A6 : Bee harry\n\nopen Classical\n\n-- Some useful derived facts\nlemma vertebrate_animal_has_backbone {x : U} (ha : Animal x) (hv : Vertebrate x) : Backbone x :=\n  A3 x ha hv\n\nlemma vertebrate_animal_MF {x : U} (ha : Animal x) (hv : Vertebrate x) : MF x :=\n  A2 x ha (vertebrate_animal_has_backbone ha hv)\n\n-- In particular, the \u201cleft branch\u201d of Q3\u2019s antecedent contradicts Bee harry\nlemma left_branch_of_Q3_impossible :\n  (Vertebrate harry \u2227 Animal harry \u2227 Backbone harry) \u2192 False :=\nby\n  intro h\n  rcases h with \u27e8hv, ha, hb\u27e9\n  have hmf : MF harry := A2 harry ha hb\n  have hnot : \u00ac MF harry := A4 harry A6\n  exact hnot hmf\n\n-- Targets (not provable from the axioms as stated):\ndef Q1 : Prop := QueenBee harry\ndef Q2 : Prop := Invertebrate harry \u2228 QueenBee harry\ndef Q3 : Prop :=\n  ((Vertebrate harry \u2227 Animal harry \u2227 Backbone harry) \u2228 (\u00ac Vertebrate harry \u2227 \u00ac (Animal harry \u2227 Backbone harry)))\n  \u2192 (\u00ac Invertebrate harry \u2227 \u00ac QueenBee harry)\n\nend Puzzle\n\nAttempted proofs and conclusions:\n\n- For Q1 (Harry is a queen bee): From A5 and A6 we only get that if Harry is a queen bee then he is a bee, but not conversely. There is no information to prove QueenBee harry or its negation. Unknown\n\n- For Q2 (Harry is an invertebrate or a queen bee): We cannot use A1 to classify Harry as invertebrate or vertebrate because we do not have Bee \u2192 Animal in the premises. Nor do we have any premise implying Harry is a queen bee. We cannot prove the disjunction or its negation. Unknown\n\n- For Q3 (If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee): We can show the left disjunct of the antecedent leads to a contradiction (it would force MF harry, contradicting A4 and A6). Thus the antecedent, if true, reduces to the right disjunct. From the right disjunct alone, there is no way to derive \u00acInvertebrate harry \u2227 \u00acQueenBee harry from the given axioms, nor can we force the negation of the implication. Unknown\n\nAnswers:\n1) Unknown\n2) Unknown\n3) Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1366,
        "conclusion": "Harry is a queen bee.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1367,
        "conclusion": "Harry is an invertebrate or a queen bee.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1368,
        "conclusion": "If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 379,
    "premises": "People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers",
    "gpt_response": "Lean translation and attempted proofs:\n\n-- Domain and predicates\nconstant Person : Type\nconstant Luke : Person\n\nconstant MultipleBirth : Person \u2192 Prop\nconstant SpendTimeWithSibs : Person \u2192 Prop\nconstant HaveSibsBornTogether : Person \u2192 Prop\nconstant ComplainOften : Person \u2192 Prop\nconstant LiveAtHome : Person \u2192 Prop\nconstant LiveWithStrangers : Person \u2192 Prop\nconstant Baby : Person \u2192 Prop\n\n-- Axioms from the text\naxiom ax1 : \u2200 x : Person, MultipleBirth x \u2192 SpendTimeWithSibs x\naxiom ax2 : \u2200 x : Person, HaveSibsBornTogether x \u2192 MultipleBirth x\naxiom ax3 : \u2200 x : Person, ComplainOften x \u2192 HaveSibsBornTogether x\naxiom ax4 : \u2200 x : Person, LiveAtHome x \u2192 \u00ac LiveWithStrangers x\naxiom ax5 : \u2200 x : Person, SpendTimeWithSibs x \u2192 LiveAtHome x\naxiom ax6 :\n  (Baby Luke \u2227 MultipleBirth Luke \u2227 LiveWithStrangers Luke) \u2228\n  (\u00ac (Baby Luke \u2227 MultipleBirth Luke) \u2227 \u00ac LiveWithStrangers Luke)\n\n-- Useful derived facts\nlemma M_implies_not_LWS (x : Person) : MultipleBirth x \u2192 \u00ac LiveWithStrangers x :=\nby\n  intro hM\n  have hS : SpendTimeWithSibs x := ax1 x hM\n  have hH : LiveAtHome x := ax5 x hS\n  exact ax4 x hH\n\nlemma no_left_disjunct :\n  \u00ac (Baby Luke \u2227 MultipleBirth Luke \u2227 LiveWithStrangers Luke) :=\nby\n  intro h\n  rcases h with \u27e8_, hM, hLWS\u27e9\n  exact (M_implies_not_LWS Luke hM) hLWS\n\nlemma right_disjunct :\n  (\u00ac (Baby Luke \u2227 MultipleBirth Luke) \u2227 \u00ac LiveWithStrangers Luke) :=\nby\n  cases ax6 with\n  | inl h => exact False.elim (no_left_disjunct h)\n  | inr h => exact h\n\nlemma luke_not_LWS : \u00ac LiveWithStrangers Luke := right_disjunct.2\n\nlemma complain_implies_not_LWS (x : Person) :\n  ComplainOften x \u2192 \u00ac LiveWithStrangers x :=\nby\n  intro hc\n  have hM : MultipleBirth x := ax2 x (ax3 x hc)\n  exact M_implies_not_LWS x hM\n\n-- Observations:\n-- \u2022 From ax6 and the other axioms we can prove \u00ac LiveWithStrangers Luke.\n-- \u2022 We cannot derive MultipleBirth Luke, SpendTimeWithSibs Luke, or ComplainOften Luke,\n--   nor their negations, from the given premises.\n\nAnswers:\n\n1) Luke spends a lot of time hanging out and playing with his siblings. Unknown\n\n2) Luke complains often about annoying siblings. Unknown\n\n3) Luke is neither born in a multiple birth nor complains often about annoying siblings. Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1011,
        "conclusion": "Luke spends a lot of time hanging out and playing with his siblings.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1012,
        "conclusion": "Luke complains often about annoying siblings.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1013,
        "conclusion": "Luke is neither born in a multiple birth nor complains often about annoying siblings.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 197,
    "premises": "It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.",
    "gpt_response": "Lean formalization and proofs attempt:\n\n-- Entities and predicates\nuniverse u\n\nconstant Agent : Type u\nconstant ETS Tom : Agent\n\nconstant Applicant : Agent \u2192 Prop\nconstant TakingGRE : Agent \u2192 Prop\nconstant ProveHardship : Agent \u2192 Prop\nconstant SingleParentFamily : Agent \u2192 Prop\nconstant FewResources : Agent \u2192 Prop\nconstant ProvidesAid : Agent \u2192 Agent \u2192 Prop\n\nconstant costGRE : Nat\n\n-- Assumptions from the text\n-- \"It costs $205 ... which is cheaper than $300.\"\naxiom h_cost_eq : costGRE = 205\naxiom h_cost_lt300 : costGRE < 300\n\n-- \"ETS provides financial aid to those GRE applicants who prove economic hardship.\"\naxiom rule_aid : \u2200 x, Applicant x \u2227 ProveHardship x \u2192 ProvidesAid ETS x\n\n-- \"Those living in single-parent families or having few resources ... can prove economic hardship.\"\naxiom rule_hardship : \u2200 x, (SingleParentFamily x \u2228 FewResources x) \u2192 ProveHardship x\n\n-- Facts about Tom\naxiom fact_tom_spf : SingleParentFamily Tom\naxiom fact_tom_few : FewResources Tom\naxiom fact_tom_app : Applicant Tom\n\n-- Q1: ETS provides financial aid to Tom.\ntheorem Q1 : ProvidesAid ETS Tom := by\n  have h_hard : ProveHardship Tom := rule_hardship Tom (Or.inl fact_tom_spf)\n  exact rule_aid Tom \u27e8fact_tom_app, h_hard\u27e9\n\n-- Q2: It costs below US $300 to take the GRE test.\ntheorem Q2 : costGRE < 300 := h_cost_lt300\n\n-- Q3 statement: \"No one taking the GRE test has financial aid provided to them by something.\"\ndef Q3_stmt : Prop := \u2200 x, TakingGRE x \u2192 \u00ac \u2203 y, ProvidesAid y x\n-- From the given assumptions, we cannot derive Q3_stmt, nor can we derive its negation,\n-- because we have no link between TakingGRE and Applicant.\n\n\nAnswers:\n- Question 1: Yes. Tom is a GRE applicant and proves economic hardship (single-parent family), so by the policy ETS provides him financial aid. True\n- Question 2: Yes. The cost is $205, which is below $300. True\n- Question 3: Uncertain. We know applicants with hardship can receive aid (e.g., Tom), but we are not told that anyone who is taking the GRE is receiving aid, nor that Tom is actually taking (as opposed to applying). Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 560,
        "conclusion": "ETS provides financial aid to Tom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 561,
        "conclusion": "It costs below US $300 to take the GRE test.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 562,
        "conclusion": "No one taking the GRE test has financial aid provided to them by something.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 361,
    "premises": "If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly",
    "gpt_response": "Lean formalization and attempted proofs:\n\nWe model a domain of people with predicates:\n- Spills : Person \u2192 Prop         -- spills a lot of food on their clothing\n- Tidy   : Person \u2192 Prop         -- notably tidy\n- Clean  : Person \u2192 Prop         -- cleanly\n- Values : Person \u2192 Prop         -- values order and spotlessness\n- Family : Person \u2192 Prop         -- family prioritizes order and spotlessness\n- Goer   : Person \u2192 Prop         -- clumsy foodie who goes out frequently to find new food restaurants to try\n\nConstants:\n- Person : Type\n- Peter  : Person\n\nAxioms from the text:\n- a1: \u2200 x, Spills x \u2192 \u00ac Tidy x\n- a2: \u2200 x, Goer x \u2192 Spills x\n- a3: \u2200 x, Clean x \u2192 Tidy x\n- a4: \u2200 x, Values x \u2192 Clean x\n- a5: \u2200 x, Family x \u2192 Values x\n- a6: (Spills Peter \u2227 Clean Peter) \u2228 (\u00ac Spills Peter \u2227 \u00ac Clean Peter)\n\nLean code:\n\nsection\n\nuniverse u\n\nconstant Person : Type u\nconstant Peter  : Person\n\nconstant Spills : Person \u2192 Prop\nconstant Tidy   : Person \u2192 Prop\nconstant Clean  : Person \u2192 Prop\nconstant Values : Person \u2192 Prop\nconstant Family : Person \u2192 Prop\nconstant Goer   : Person \u2192 Prop\n\naxiom a1 : \u2200 x, Spills x \u2192 \u00ac Tidy x\naxiom a2 : \u2200 x, Goer x \u2192 Spills x\naxiom a3 : \u2200 x, Clean x \u2192 Tidy x\naxiom a4 : \u2200 x, Values x \u2192 Clean x\naxiom a5 : \u2200 x, Family x \u2192 Values x\naxiom a6 : (Spills Peter \u2227 Clean Peter) \u2228 (\u00ac Spills Peter \u2227 \u00ac Clean Peter)\n\n-- 1) From a1 and a3, (Spills \u2227 Clean) is impossible for Peter\nlemma not_spills_and_clean : \u00ac (Spills Peter \u2227 Clean Peter) := by\n  intro h\n  have s : Spills Peter := h.left\n  have c : Clean Peter  := h.right\n  have t  : Tidy Peter  := a3 Peter c\n  have nt : \u00ac Tidy Peter := a1 Peter s\n  exact nt t\n\n-- 2) Therefore, from a6 we must have \u00acSpills Peter \u2227 \u00acClean Peter\nlemma not_spills_and_not_clean : \u00ac Spills Peter \u2227 \u00ac Clean Peter := by\n  cases a6 with\n  | inl sc => exact False.elim (not_spills_and_clean sc)\n  | inr nsnc => exact nsnc\n\nlemma not_spills : \u00ac Spills Peter := (not_spills_and_not_clean).left\nlemma not_clean  : \u00ac Clean Peter  := (not_spills_and_not_clean).right\n\n-- 3) Propagate negations back through the given implications\nlemma not_goer  : \u00ac Goer Peter := by\n  -- a2 Peter : Goer Peter \u2192 Spills Peter\n  -- not_spills : \u00ac Spills Peter\n  exact mt (a2 Peter) not_spills\n\nlemma not_values : \u00ac Values Peter := by\n  -- a4 Peter : Values Peter \u2192 Clean Peter\n  -- not_clean : \u00ac Clean Peter\n  exact mt (a4 Peter) not_clean\n\nlemma not_family : \u00ac Family Peter := by\n  -- a5 Peter : Family Peter \u2192 Values Peter\n  -- not_values : \u00ac Values Peter\n  exact mt (a5 Peter) not_values\n\n-- Q2: Peter is either a Goer or Family\n-- We can prove the negation (False), since we have \u00acGoer and \u00acFamily\ntheorem Q2_false : \u00ac (Goer Peter \u2228 Family Peter) := by\n  intro h\n  cases h with\n  | inl hg => exact not_goer hg\n  | inr hf => exact not_family hf\n\n-- Q3: (Goer \u2227 Family) \u2228 (\u00acGoer \u2227 \u00acFamily) holds; we prove the right disjunct\ntheorem Q3_true : (Goer Peter \u2227 Family Peter) \u2228 (\u00ac Goer Peter \u2227 \u00ac Family Peter) := by\n  exact Or.inr \u27e8not_goer, not_family\u27e9\n\n-- Q1 (Tidy Peter) is not derivable from the axioms above; we do not have a proof of Tidy Peter or its negation.\n\nend\n\nConclusions:\n- From the axioms we derive \u00acSpills Peter and \u00acClean Peter, and consequently \u00acGoer Peter and \u00acFamily Peter.\n- Q1 (Peter is notably tidy): We cannot derive Tidy Peter nor its negation from the given information. Unknown\n- Q2 (Peter is either a clumsy foodie goer or someone whose family prioritizes order and spotlessness): We proved its negation. False\n- Q3 (Peter is either both a clumsy foodie goer and someone whose family prioritizes order and spotlessness, or neither): We proved the second disjunct. True\n\nAnswers:\n- Question 1: Unknown\n- Question 2: False\n- Question 3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 958,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 959,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 960,
        "conclusion": "Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 262,
    "premises": "All fir trees are evergreens.\nSome objects of worship are fir trees.",
    "gpt_response": "Natural-language reasoning:\n- Premises:\n  1) All fir trees are evergreens. (\u2200x, Fir(x) \u2192 Evergreen(x))\n  2) Some objects of worship are fir trees. (\u2203x, Worship(x) \u2227 Fir(x))\n- Claim: Some evergreens are not objects of worship. (\u2203x, Evergreen(x) \u2227 \u00acWorship(x))\n\nFrom the premises we only know there exists a fir that is worshiped, hence there exists an evergreen that is worshiped. We have no information guaranteeing the existence of any evergreen that is not worshiped. It is consistent that all evergreens are worshiped, and also consistent that some are not. Therefore the truth of the claim is not determined by the premises.\n\nLean formalization and attempt:\n\nuniverse u\n\nsection\n\nvariable (U : Type u) (Fir Evergreen Worship : U \u2192 Prop)\nvariable (h1 : \u2200 x, Fir x \u2192 Evergreen x)\nvariable (h2 : \u2203 x, Worship x \u2227 Fir x)\n\n-- Target statement: \u201cSome evergreens are not objects of worship.\u201d\ndef Statement : Prop := \u2203 x, Evergreen x \u2227 \u00ac Worship x\n\n-- There is no derivation of Statement from just h1 and h2.\n-- Below we show the statement is not logically valid given only the premises\n-- by providing a countermodel (a one-element universe where all three predicates are True).\nend\n\ntheorem not_valid :\n  \u00ac (\u2200 (U : Type) (Fir Evergreen Worship : U \u2192 Prop),\n       (\u2200 x, Fir x \u2192 Evergreen x) \u2192\n       (\u2203 x, Worship x \u2227 Fir x) \u2192\n       (\u2203 x, Evergreen x \u2227 \u00ac Worship x)) :=\nby\n  intro h\n  -- Model: one-element type where all predicates are True\n  let U := Unit\n  let Fir : U \u2192 Prop := fun _ => True\n  let Evergreen : U \u2192 Prop := fun _ => True\n  let Worship : U \u2192 Prop := fun _ => True\n  have h1 : \u2200 x : U, Fir x \u2192 Evergreen x := by intro _ _; exact True.intro\n  have h2 : \u2203 x : U, Worship x \u2227 Fir x :=\n    \u27e8(), And.intro True.intro True.intro\u27e9\n  have concl := h U Fir Evergreen Worship h1 h2\n  rcases concl with \u27e8x, hx\u27e9\n  have : False := by\n    have : \u00ac True := hx.right\n    exact this True.intro\n  exact this\n\nConclusion: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 706,
        "conclusion": "Some evergreens are not objects of worship.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 124,
    "premises": "The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.",
    "gpt_response": "Lean translation and proofs:\n\nnamespace Reasoning\n\ninductive State where\n| NewMexico | Texas\nderiving DecidableEq\n\nconstant MountainRange : Type\nconstant Mine : Type\nconstant Person : Type\n\nconstant InState  : MountainRange \u2192 State \u2192 Prop\nconstant LocatedIn : Mine \u2192 MountainRange \u2192 Prop\nconstant Donated : Mine \u2192 Prop\nconstant Visited : Person \u2192 MountainRange \u2192 Prop\n\nconstant Picuris : MountainRange\nconstant Harding : Mine\nconstant Juan : Person\n\naxiom h_picuris_loc : InState Picuris State.NewMexico \u2228 InState Picuris State.Texas\naxiom h_juan_visit : Visited Juan Picuris\naxiom h_harding_loc : LocatedIn Harding Picuris\naxiom h_harding_donated : Donated Harding\naxiom h_no_tx_donated_ranges :\n  \u2200 r : MountainRange, InState r State.Texas \u2192 \u00ac \u2203 m : Mine, LocatedIn m r \u2227 Donated m\n\nlemma picuris_not_texas : \u00ac InState Picuris State.Texas := by\n  intro htx\n  have hx : \u2203 m : Mine, LocatedIn m Picuris \u2227 Donated m :=\n    \u27e8Harding, And.intro h_harding_loc h_harding_donated\u27e9\n  have hcontra := h_no_tx_donated_ranges Picuris htx\n  exact hcontra hx\n\nlemma picuris_newmexico : InState Picuris State.NewMexico := by\n  cases h_picuris_loc with\n  | inl hnm => exact hnm\n  | inr htx => exact False.elim (picuris_not_texas htx)\n\n-- Q1: Juan visited a mountain range in New Mexico.\ntheorem Q1_true : \u2203 r : MountainRange, Visited Juan r \u2227 InState r State.NewMexico :=\n  \u27e8Picuris, And.intro h_juan_visit picuris_newmexico\u27e9\n\n-- Q2 is independent of the given axioms (cannot be proved or refuted here).\n\n-- Q3: \"The Harding Pegmatite Mine is not located in a mountain range in New Mexico.\" is false.\nlemma harding_in_nm_range : \u2203 r : MountainRange, InState r State.NewMexico \u2227 LocatedIn Harding r :=\n  \u27e8Picuris, And.intro picuris_newmexico h_harding_loc\u27e9\n\ntheorem Q3_is_false :\n  \u00ac (\u00ac \u2203 r : MountainRange, InState r State.NewMexico \u2227 LocatedIn Harding r) := by\n  intro hnot\n  exact hnot harding_in_nm_range\n\nend Reasoning\n\nAnswers:\n1) Juan de Onate visited a mountain range in New Mexico. True\n2) Juan de Onate visited a mountain range in Texas. Unknown\n3) The Harding Pegmatite Mine is not located in a mountain range in New Mexico. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 370,
        "conclusion": "Juan de Onate visited a mountain range in New Mexico.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 371,
        "conclusion": "Juan de Onate visited a mountain range in Texas.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 372,
        "conclusion": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 183,
    "premises": "If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.",
    "gpt_response": "Lean formalization\n\n-- Basic setup\nuniverse u\nconstant Person : Type\nconstant Michael Peter Windy : Person\n\n-- Predicates and relations\nconstant Man : Person \u2192 Prop\nconstant Taller : Person \u2192 Person \u2192 Prop\nconstant CanBlock : Person \u2192 Person \u2192 Prop\nconstant Jumps : Person \u2192 Prop\nconstant Great : Person \u2192 Prop\nconstant InMClass : Person \u2192 Prop   -- \u201cin Michael\u2019s class\u201d\n\n-- Axioms from the text\naxiom A1_block_if_taller_men :\n  \u2200 {x y : Person}, Man x \u2192 Man y \u2192 Taller x y \u2192 CanBlock x y\n\naxiom A2_taller_trans :\n  \u2200 {x y z : Person}, Taller x y \u2192 Taller y z \u2192 Taller x z\n\naxiom A3_peter_facts : Man Peter \u2227 Taller Peter Michael\n\naxiom A4_michael_facts :\n  Man Michael \u2227 (\u2200 {y : Person}, InMClass y \u2192 y \u2260 Michael \u2192 Taller Michael y)\n\naxiom A5_michael_blocks_nonjumpers :\n  \u2200 {p : Person}, \u00ac Jumps p \u2192 CanBlock Michael p\n\naxiom A6_michael_cannot_block_windy :\n  \u00ac CanBlock Michael Windy\n\naxiom A7_jumpers_are_great :\n  \u2200 {s : Person}, Jumps s \u2192 Great s\n\nopen Classical\n\n-- From A5 and A6 we derive that Windy jumps, hence is great.\ntheorem windy_is_great : Great Windy := by\n  -- First show Windy jumps by contrapositive of A5 and A6\n  have windy_jumps : Jumps Windy := by\n    have h : (\u00ac Jumps Windy) \u2192 CanBlock Michael Windy := A5\n    exact by_contra (fun hNJ => A6 (h hNJ))\n  -- Then apply that all who jump are great\n  exact A7 windy_jumps\n\n\nAnswers\n\nQuestion 1:\nWe know Peter is taller than Michael, and Michael is taller than everyone else in his class (other than himself). By transitivity, Peter is taller than every other member of Michael\u2019s class (besides Michael). However, we are not given that \u201ctaller than\u201d is asymmetric, so we cannot rule out Michael being taller than Peter based solely on the given axioms; nor are we given that Michael is (or is not) in his own class for use as a witness. Thus, from the given information alone, we cannot prove the statement nor its negation. Unknown\n\nQuestion 2:\nFrom \u201cMichael can block any shooting from a person as long as the person does not jump when shooting\u201d (A5), and \u201cMichael cannot block Windy\u2019s shooting\u201d (A6), it follows (by contrapositive) that Windy does jump when shooting. By \u201cEvery shooter who can jump when shooting is a great shooter\u201d (A7), Windy is a great shooter. True\n\nQuestion 3:\nWe have no rule that allows Peter to block Windy merely from what we know; the \u201ctaller implies can block\u201d rule requires both to be men, and we are not told Windy is a man nor that Peter can block jumpers in general. We also cannot derive that Peter cannot block Windy. Therefore, the truth value is not determined. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 527,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 528,
        "conclusion": "Windy is a great shooter.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 529,
        "conclusion": "Peter can block Windy's shooting.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 151,
    "premises": "Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.",
    "gpt_response": "Lean formalization and attempted proofs:\n\nnamespace BarutinCove\n\nuniverse u\n\nconstant Place : Type u\n\nconstants\n  BarutinCove BarutinSettlement SnowIsland GreenwichIsland DeceptionIsland SouthShetlandIslands Antarctica : Place\n\n-- Predicates\nconstant Cove : Place \u2192 Prop\nconstant Island : Place \u2192 Prop\nconstant LocatedIn : Place \u2192 Place \u2192 Prop\nconstant NamedAfter : Place \u2192 Place \u2192 Prop\nconstant InBulgaria : Place \u2192 Prop\n\n-- Facts from the text\naxiom BarutinCove_is_cove : Cove BarutinCove\naxiom BarutinCove_named_after_Barutin : NamedAfter BarutinCove BarutinSettlement\naxiom BarutinSettlement_in_Bulgaria : InBulgaria BarutinSettlement\n\naxiom BarutinCove_in_SnowIsland : LocatedIn BarutinCove SnowIsland\n\naxiom SnowIsland_is_island : Island SnowIsland\naxiom GreenwichIsland_is_island : Island GreenwichIsland\naxiom DeceptionIsland_is_island : Island DeceptionIsland\n\naxiom SnowIsland_in_SouthShetlands : LocatedIn SnowIsland SouthShetlandIslands\naxiom GreenwichIsland_in_SouthShetlands : LocatedIn GreenwichIsland SouthShetlandIslands\naxiom DeceptionIsland_in_SouthShetlands : LocatedIn DeceptionIsland SouthShetlandIslands\n\n-- As stated in the text (taken literally):\naxiom Antarctica_in_SouthShetlands : LocatedIn Antarctica SouthShetlandIslands\n\n-- Transitivity of \"located in\"\naxiom locatedIn_trans {A B C : Place} : LocatedIn A B \u2192 LocatedIn B C \u2192 LocatedIn A C\n\n-- A derivable consequence\nlemma BarutinCove_in_SouthShetlands : LocatedIn BarutinCove SouthShetlandIslands :=\n  locatedIn_trans BarutinCove_in_SnowIsland SnowIsland_in_SouthShetlands\n\n-- The three questions as propositions\ndef Q1 : Prop := \u2200 x : Place, Island x \u2227 LocatedIn x Antarctica \u2192 NamedAfter BarutinCove x\n\ndef Q2 : Prop := \u2203 x : Place, Cove x \u2227 LocatedIn x Antarctica \u2227 (\u2203 y : Place, InBulgaria y \u2227 NamedAfter x y)\n\ndef Q3 : Prop := \u00ac LocatedIn BarutinCove Antarctica\n\n-- Attempt status:\n-- From these axioms, we cannot derive Q1, nor its negation; we also cannot derive Q2 or its negation,\n-- and we cannot derive Q3 or its negation. The data allow us to place Barutin Cove in the South Shetland\n-- Islands but give no link from South Shetland Islands to Antarctica (only the reverse), so nothing about\n-- \u201cin Antarctica\u201d can be concluded.\n-- Therefore all three questions are Unknown from the given information.\n\nend BarutinCove\n\nAnswers:\n\n1) \u201cBarutin Cove is named after all islands in Antarctica.\u201d There is no information connecting Barutin Cove\u2019s name to any islands, let alone all islands in Antarctica. Unknown\n\n2) \u201cThere is at least one cove in Antarctica named after a place in Bulgaria.\u201d We know Barutin Cove is a cove named after a Bulgarian settlement, and it is in the South Shetland Islands; however, from the given (Antarctica is located on the South Shetland Islands), we cannot conclude Barutin Cove is in Antarctica. Unknown\n\n3) \u201cBarutin Cove is not located in Antarctica.\u201d We can\u2019t conclude that it is in Antarctica, nor that it is not, from the given facts. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 439,
        "conclusion": "Barutin Cove is named after all islands in Antarctica.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 440,
        "conclusion": "There is at least one cove in Antarctica named after a place in Bulgaria.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 441,
        "conclusion": "Barutin Cove is not located in Antarctica.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 295,
    "premises": "Some affection is love.\nSome love is positive.",
    "gpt_response": "Lean translation and attempt:\n\nuniverse u\n\nsection\n\nvariable {U : Type u} (Affection Love Positive : U \u2192 Prop)\n\ndef Premises : Prop :=\n  (\u2203 x, Affection x \u2227 Love x) \u2227\n  (\u2203 x, Love x \u2227 Positive x)\n\ndef Conclusion : Prop :=\n  \u2203 x, Affection x \u2227 Positive x\n\n-- The following shows the entailment Premises \u2192 Conclusion is not valid in general.\ntheorem not_valid :\n  \u00ac (\u2200 (U : Type) (Affection Love Positive : U \u2192 Prop),\n        (\u2203 x, Affection x \u2227 Love x) \u2192\n        (\u2203 x, Love x \u2227 Positive x) \u2192\n        (\u2203 x, Affection x \u2227 Positive x)) := by\n  intro h\n  -- Countermodel with two disjoint witnesses\n  let U := Sum Unit Unit\n  let Affection : U \u2192 Prop := fun u => \u2203 a : Unit, u = Sum.inl a\n  let Love : U \u2192 Prop := fun _ => True\n  let Positive : U \u2192 Prop := fun u => \u2203 b : Unit, u = Sum.inr b\n  have h1 : \u2203 x : U, Affection x \u2227 Love x := by\n    refine \u27e8Sum.inl (), ?_\u27e9\n    exact \u27e8\u27e8(), rfl\u27e9, trivial\u27e9\n  have h2 : \u2203 x : U, Love x \u2227 Positive x := by\n    refine \u27e8Sum.inr (), ?_\u27e9\n    exact \u27e8trivial, \u27e8(), rfl\u27e9\u27e9\n  have : \u2203 x : U, Affection x \u2227 Positive x := h U Affection Love Positive h1 h2\n  rcases this with \u27e8x, \u27e8a, hxA\u27e9, \u27e8b, hxP\u27e9\u27e9\n  have eqInlInr : Sum.inl a = Sum.inr b := by exact hxA.trans hxP\n  cases eqInlInr\n\nend\n\nExplanation: From \u201cSome affection is love\u201d and \u201cSome love is positive,\u201d the witnesses could be different elements, so \u201cSome affection is positive\u201d does not follow logically, nor does its negation follow from the premises.\n\nAnswer: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 739,
        "conclusion": "Some affection is positive.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 315,
    "premises": "If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. ",
    "gpt_response": "Lean formalization and attempted proofs:\n\nuniverse u\n\nconstant Car : Type u\nconstants\n  MultiPassenger : Car \u2192 Prop\n  OneSeater : Car \u2192 Prop\n  TM3 : Car \u2192 Prop\n  SingleSeatElectricCar : Car \u2192 Prop\n  SoloEV : Car \u2192 Prop\nconstant j : Car\n\naxioms\n  (A1 : \u2200 x, MultiPassenger x \u2192 \u00ac OneSeater x)\n  (A2 : \u2200 x, TM3 x \u2192 MultiPassenger x)\n  (A3 : \u2200 x, SingleSeatElectricCar x \u2192 OneSeater x)\n  (A4 : \u2200 x, SoloEV x \u2192 SingleSeatElectricCar x)\n  (A5 : \u00ac TM3 j \u2192 (\u00ac TM3 j \u2228 SingleSeatElectricCar j))\n\n-- Useful derived lemmas\nlemma TM3_not_OneSeater : \u2200 x, TM3 x \u2192 \u00ac OneSeater x := by\n  intro x hx\n  have hmp : MultiPassenger x := A2 x hx\n  exact A1 x hmp\n\nlemma SoloEV_OneSeater : \u2200 x, SoloEV x \u2192 OneSeater x := by\n  intro x hx\n  have hss : SingleSeatElectricCar x := A4 x hx\n  exact A3 x hss\n\n-- They cannot be both TM3 and SoloEV\nlemma not_both_TM3_and_SoloEV : \u00ac (TM3 j \u2227 SoloEV j) := by\n  intro h\n  rcases h with \u27e8htm3, hsol\u27e9\n  have hno : \u00ac OneSeater j := TM3_not_OneSeater j htm3\n  have ho : OneSeater j := SoloEV_OneSeater j hsol\n  exact hno ho\n\n-- Targets of the questions:\ndef Q1 := TM3 j\ndef Q2 := SoloEV j\ndef Q3 := \u00ac SoloEV j\n\n-- None of Q1, Q2, or Q3 (nor their negations) are derivable from the given axioms alone.\n-- We proved only the incompatibility: \u00ac(TM3 j \u2227 SoloEV j).\n\n\nAnswers:\n\n- Question 1: The premises do not entail that John\u2019s car is a Tesla Model 3, nor its negation. Unknown\n\n- Question 2: The premises do not entail that John\u2019s car is a Solo EV, nor its negation. Unknown\n\n- Question 3: From the premises we cannot conclude that John\u2019s car is not a Solo EV. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 786,
        "conclusion": "John's car is a Tesla Model 3.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 787,
        "conclusion": "John's car is a Solo EV.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 788,
        "conclusion": "John's car is not a Solo EV.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 467,
    "premises": "All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. ",
    "gpt_response": "Lean translation and attempt at proofs:\n\nnamespace PeterPets\n\nuniverse u\n\nconstant Entity : Type u\n\nconstant Pet : Entity \u2192 Prop\nconstant Mammal : Entity \u2192 Prop\nconstant Animal : Entity \u2192 Prop\nconstant Monkey : Entity \u2192 Prop\nconstant Bird : Entity \u2192 Prop\nconstant CanFly : Entity \u2192 Prop\nconstant CanBreathe : Entity \u2192 Prop\nconstant HasWings : Entity \u2192 Prop\n\nconstant Rock : Entity\n\n-- Axioms from the text\naxiom A1 : \u2200 x, Pet x \u2192 Mammal x \u2192 Animal x                            -- Peter's pets that are mammals are animals\naxiom A2 : \u2200 x, Monkey x \u2192 Mammal x                                    -- All monkeys are mammals\naxiom A3 : \u2200 x, Pet x \u2192 (Monkey x \u2228 Bird x)                            -- Peter's pets are either monkeys or birds\naxiom A4 : \u2200 x, Pet x \u2192 Bird x \u2192 CanFly x                              -- Peter's birds can fly\naxiom A5 : \u2200 x, Pet x \u2192 Animal x \u2192 CanBreathe x                        -- Peter's pet animals can breathe\naxiom A6 : \u2200 x, Pet x \u2192 CanFly x \u2192 HasWings x                          -- If Peter's pet can fly, it has wings\naxiom A7 : Pet Rock                                                    -- Rock is Peter's pet\naxiom A8 : CanFly Rock \u2228 Bird Rock \u2228 \u00ac CanBreathe Rock                 -- Given disjunction\n\n-- Some derived lemmas\nlemma rock_pet : Pet Rock := A7\n\nlemma rock_monkey_or_bird : Monkey Rock \u2228 Bird Rock :=\n  A3 Rock A7\n\nlemma bird_implies_canFly : Bird Rock \u2192 CanFly Rock :=\n  A4 Rock A7\n\nlemma canFly_implies_hasWings : CanFly Rock \u2192 HasWings Rock :=\n  A6 Rock A7\n\nlemma bird_implies_hasWings : Bird Rock \u2192 HasWings Rock :=\n  fun hb => canFly_implies_hasWings (bird_implies_canFly hb)\n\nlemma canFly_or_bird_implies_hasWings : (CanFly Rock \u2228 Bird Rock) \u2192 HasWings Rock :=\nby\n  intro h\n  cases h with\n  | inl hf => exact canFly_implies_hasWings hf\n  | inr hb => exact bird_implies_hasWings hb\n\n-- Attempt to prove the questions:\n-- Q1: Monkey Rock          (not derivable from A1\u2013A8)\n-- Q2: HasWings Rock        (not derivable from A1\u2013A8, since A8 might hold via \u00acCanBreathe Rock)\n-- Q3: \u00ac HasWings Rock      (also not derivable)\n\nend PeterPets\n\nAnswers:\n\n1) Rock is a monkey. Unknown\n2) Rock has wings. Unknown\n3) Rock does not have wings. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1348,
        "conclusion": "Rock is a monkey.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1349,
        "conclusion": "Rock has wings.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1350,
        "conclusion": "Rock does not have wings.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 330,
    "premises": "All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. ",
    "gpt_response": "Lean formalization (distinct predicates for \u201cinvites others\u201d vs \u201cinvites friends\u201d):\n\nopen Classical\n\nuniverse u\n\nconstant Person : Type u\n\nconstant MakesPlans    : Person \u2192 Prop\nconstant Engaged       : Person \u2192 Prop\nconstant InvitesOthers : Person \u2192 Prop\nconstant WellAttended  : Person \u2192 Prop\nconstant LargerFamily  : Person \u2192 Prop\nconstant InvitesFriends: Person \u2192 Prop\nconstant John          : Person\n\n-- Axioms from the text\naxiom A1 : \u2200 x : Person, MakesPlans x \u2192 Engaged x\naxiom A2 : \u2200 x : Person, InvitesOthers x \u2192 MakesPlans x\naxiom A3 : \u2200 x : Person, WellAttended x \u2192 InvitesOthers x\naxiom A4 : \u2203 x : Person, WellAttended x \u2227 LargerFamily x\naxiom A5 : Engaged John \u2192 \u00ac (InvitesFriends John \u2227 MakesPlans John)\naxiom A6 : LargerFamily John \u2192 (WellAttended John \u2228 InvitesFriends John)\n\n-- Some derived lemmas (provable)\nlemma well_attended_engaged (x : Person) : WellAttended x \u2192 Engaged x := by\n  intro h\n  exact A1 x (A2 x (A3 x h))\n\nlemma john_large_implies_engaged_or_invitesfriends :\n  LargerFamily John \u2192 Engaged John \u2228 InvitesFriends John := by\n  intro h\n  cases A6 h with\n  | inl hw =>\n      left; exact well_attended_engaged John hw\n  | inr hf =>\n      right; exact hf\n\nlemma john_large_and_wellattended_implies_not_invitesfriends :\n  LargerFamily John \u2192 WellAttended John \u2192 \u00ac InvitesFriends John := by\n  intro hL hW\n  have hE : Engaged John := well_attended_engaged John hW\n  have hM : MakesPlans John := A2 John (A3 John hW)\n  intro hF\n  exact (A5 hE) \u27e8hF, hM\u27e9\n\nAttempted proofs of the four queried statements (or their negations) do not go through from these axioms; there is no way to derive any of them or their negations about John. Hence each is Undetermined.\n\nAnswers:\n1) John has a larger family. Unknown\n2) John does not have a larger family. Unknown\n3) John is engaged. Unknown\n4) John neither has a larger family nor does he invite others to his wedding. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 846,
        "conclusion": "John has a larger family.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 847,
        "conclusion": "John does not have a larger family.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 848,
        "conclusion": "John is engaged.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 849,
        "conclusion": "John neither has a larger family nor does he invite others to his wedding.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.25
  },
  {
    "story_id": 26,
    "premises": "Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.",
    "gpt_response": "Lean formalization and attempted proofs:\n\n-- We model the domain of animals and relevant predicates\nuniverse u\nconstant Animal : Type u\nconstant Mammal Reptile HasTeeth Platypus Human : Animal \u2192 Prop\n\n-- Axioms from the textual context\naxiom some_mammals_have_teeth : \u2203 x : Animal, Mammal x \u2227 HasTeeth x\naxiom platypuses_no_teeth : \u2200 x : Animal, Platypus x \u2192 \u00ac HasTeeth x\naxiom platypuses_are_mammals : \u2200 x : Animal, Platypus x \u2192 Mammal x\naxiom humans_have_teeth : \u2200 x : Animal, Human x \u2192 HasTeeth x\n\n-- Q1: Platypuses are mammals with no teeth\n-- Formal: \u2200 x, Platypus x \u2192 (Mammal x \u2227 \u00ac HasTeeth x)\ntheorem Q1 : \u2200 x : Animal, Platypus x \u2192 (Mammal x \u2227 \u00ac HasTeeth x) := by\n  intro x hx\n  exact And.intro (platypuses_are_mammals x hx) (platypuses_no_teeth x hx)\n\n-- Q2: Platypuses are reptiles\n-- Formal: \u2200 x, Platypus x \u2192 Reptile x\n-- Not derivable from the given axioms, and its negation is also not derivable.\n\n-- Q3: Humans are mammals\n-- Formal: \u2200 x, Human x \u2192 Mammal x\n-- Not derivable from the given axioms, and its negation is also not derivable.\n\n\nAnswers:\n- Question 1: Platypuses are mammals with no teeth. True\n- Question 2: Platypuses are reptiles. Unknown\n- Question 3: Humans are mammals. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 74,
        "conclusion": "Platypuses are mammals with no teeth.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 75,
        "conclusion": "Platypuses are reptiles.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 76,
        "conclusion": "Humans are mammals.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 203,
    "premises": "Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.",
    "gpt_response": "Lean formalization of the context:\n\nconstant Thing : Type\nconstant Plunger Vacuum Vampire HouseholdAppliance Sucks : Thing \u2192 Prop\nconstant space duster : Thing\n\n-- Axioms from the text\naxiom plungers_suck : \u2200 x, Plunger x \u2192 Sucks x\naxiom vacuums_suck  : \u2200 x, Vacuum x \u2192 Sucks x\naxiom vampires_suck : \u2200 x, Vampire x \u2192 Sucks x\naxiom space_is_vacuum : Vacuum space\naxiom duster_is_household : HouseholdAppliance duster\naxiom duster_doesnt_suck : \u00ac Sucks duster\n\n-- Q1: Space sucks.\ntheorem Q1 : Sucks space := vacuums_suck space space_is_vacuum\n\n-- Q2: Space is a vampire. (Not provable or refutable from the axioms.)\n\n-- Q3: If something is a household appliance, it sucks. (Refuted by the duster.)\ntheorem not_Q3 : \u00ac (\u2200 x, HouseholdAppliance x \u2192 Sucks x) := by\n  intro h\n  have hs : Sucks duster := h duster duster_is_household\n  exact duster_doesnt_suck hs\n\n\nAnswers:\n1) From space_is_vacuum and vacuums_suck, we derive Sucks space. True\n2) There is no information linking being a vacuum to being a vampire (nor its negation), so the status of Vampire space is undetermined. Unknown\n3) The duster is a household appliance that does not suck, so the universal claim is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 578,
        "conclusion": "Space sucks.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 579,
        "conclusion": "Space is a vampire.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 580,
        "conclusion": "If something is a household appliance, it sucks.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 131,
    "premises": "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.",
    "gpt_response": "Lean formalization and proofs:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Alg : Type u\n\nconstants\n  Used : Alg \u2192 Prop\n  ML : Alg \u2192 Prop\n  Supervised : Alg \u2192 Prop\n  Unsupervised : Alg \u2192 Prop\n  Reinforcement : Alg \u2192 Prop\n  RequiresLabels : Alg \u2192 Prop\n\nconstant A : Alg\n\naxioms\n  usedA : Used A\n  mlA : ML A\n  unsup_no_labels : \u2200 a, Unsupervised a \u2192 \u00ac RequiresLabels a\n  not_reinforcementA : \u00ac Reinforcement A\n  requires_labelsA : RequiresLabels A\n  ml_categorized : \u2200 a, ML a \u2192 (Supervised a \u2228 Unsupervised a \u2228 Reinforcement a)\n\ntheorem not_unsupervisedA : \u00ac Unsupervised A :=\nby\n  intro hU\n  have hnl : \u00ac RequiresLabels A := unsup_no_labels A hU\n  exact hnl requires_labelsA\n\ntheorem supervisedA : Supervised A :=\nby\n  have h := ml_categorized A mlA\n  have hU := not_unsupervisedA\n  have hR := not_reinforcementA\n  rcases h with hs | hur\n  \u00b7 exact hs\n  \u00b7 rcases hur with hu | hr\n    \u00b7 exact False.elim (hU hu)\n    \u00b7 exact False.elim (hR hr)\n\ntheorem Q1 : Used A \u2227 Supervised A :=\nAnd.intro usedA supervisedA\n\ntheorem Q2_neg : \u00ac (Used A \u2227 Unsupervised A) :=\nby\n  intro h\n  have hU : Unsupervised A := And.right h\n  exact not_unsupervisedA hU\n\nend Reasoning\n\nAnswers:\nQuestion 1: True\nQuestion 2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 388,
        "conclusion": "Supervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 389,
        "conclusion": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 460,
    "premises": "If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. ",
    "gpt_response": "Lean formalization and derivations:\n\nuniverse u\n\nconstant Obj : Type u\n\n-- Predicates\nconstant Film : Obj \u2192 Prop\nconstant AppropriateAllAges : Obj \u2192 Prop\nconstant ChildrenCanWatchWithoutGuidance : Obj \u2192 Prop\nconstant ExcessiveEroticViolent : Obj \u2192 Prop\nconstant RatedGA : Obj \u2192 Prop\nconstant FamilyFriendlyAnimated : Obj \u2192 Prop\nconstant InFrozenSeries : Obj \u2192 Prop\n\n-- Constant for the specific film\nconstant Hachi : Obj\n\n-- Axioms (from the textual context)\naxiom ax1 : \u2200 f : Obj, AppropriateAllAges f \u2192 ChildrenCanWatchWithoutGuidance f\naxiom ax2 : \u2200 f : Obj, ExcessiveEroticViolent f \u2192 \u00ac ChildrenCanWatchWithoutGuidance f\naxiom ax3 : \u2200 f : Obj, RatedGA f \u2192 AppropriateAllAges f\naxiom ax4 : \u2200 f : Obj, FamilyFriendlyAnimated f \u2192 RatedGA f\naxiom ax5 : \u2200 f : Obj, InFrozenSeries f \u2192 FamilyFriendlyAnimated f\naxiom ax6 : Film Hachi\naxiom ax7 : FamilyFriendlyAnimated Hachi \u2228 AppropriateAllAges Hachi\n\n-- Useful derived facts\nlemma appropriate_Hachi : AppropriateAllAges Hachi :=\n  Or.elim ax7\n    (fun hffa => ax3 _ (ax4 _ hffa))\n    (fun happ => happ)\n\nlemma canWatch_Hachi : ChildrenCanWatchWithoutGuidance Hachi :=\n  ax1 _ appropriate_Hachi\n\nlemma not_excessive_Hachi : \u00ac ExcessiveEroticViolent Hachi :=\n  fun hEx => (ax2 _ hEx) canWatch_Hachi\n\n-- From not_excessive_Hachi we also get that the conjunction with Frozen is impossible\nlemma not_excessive_and_frozen_Hachi : \u00ac (ExcessiveEroticViolent Hachi \u2227 InFrozenSeries Hachi) :=\n  fun h => not_excessive_Hachi h.left\n\n-- What we cannot prove (and also cannot refute) from the given axioms:\n-- 1) RatedGA Hachi      (neither provable nor refutable)\n-- 2) ExcessiveEroticViolent Hachi \u2228 InFrozenSeries Hachi\n-- 3) (ExcessiveEroticViolent Hachi \u2227 InFrozenSeries Hachi) \u2228 (\u00ac ExcessiveEroticViolent Hachi \u2227 \u00ac InFrozenSeries Hachi)\n--    We can prove \u00ac ExcessiveEroticViolent Hachi, but we have no information about InFrozenSeries Hachi or its negation.\n\n\nAnswers:\n\n- Question 1: \"Hachi: A dog's Tale\" is rated General Audience.\n  From the axioms we can derive AppropriateAllAges Hachi, but we cannot derive RatedGA Hachi (the converse of axiom 3 is not given), nor can we refute it. Unknown\n\n- Question 2: \"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.\n  We have proved \u00acExcessiveEroticViolent Hachi, so the statement reduces to InFrozenSeries Hachi, which we neither can prove nor refute. Unknown\n\n- Question 3: \"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.\n  The first disjunct is false because \u00acExcessiveEroticViolent Hachi; the second requires \u00acInFrozenSeries Hachi, which is not derivable. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1327,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1328,
        "conclusion": "\"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1329,
        "conclusion": "\"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 46,
    "premises": "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.",
    "gpt_response": "Lean formalization and proofs attempted:\n\nuniverse u\nnamespace BackBreeding\n\nconstant U : Sort u\n\n-- Predicates/entities\nconstant Animal : U \u2192 Prop\nconstant HeckCattle : U \u2192 Prop\nconstant Aurochs : U \u2192 Prop\nconstant ArtificiallySelected : U \u2192 Prop\nconstant BredBack : U \u2192 Prop\nconstant ToBeBredBack : U \u2192 Prop\nconstant Resembles : U \u2192 U \u2192 Prop\nconstant Extinct : U \u2192 Prop\nconstant Domestic : U \u2192 Prop\n\n-- Axioms from the text\n-- Breeding back is a form of artificial selection\naxiom A1 : \u2200 x:U, BredBack x \u2192 ArtificiallySelected x\n-- Heck cattle are animals\naxiom A2 : \u2200 x:U, HeckCattle x \u2192 Animal x\n-- Aurochs are animals\naxiom A3 : \u2200 x:U, Aurochs x \u2192 Animal x\n-- Heck cattle were bred back (to resemble the aurochs)\naxiom A4 : \u2203 x y:U, HeckCattle x \u2227 Aurochs y \u2227 BredBack x \u2227 Resembles x y\n-- Some animals to be bred back resemble extinct animals\naxiom A5 : \u2203 x y:U, Animal x \u2227 ToBeBredBack x \u2227 Animal y \u2227 Extinct y \u2227 Resembles x y\n\n-- Q1: Some Heck cattle are artificially selected.\ntheorem Q1 : \u2203 x:U, HeckCattle x \u2227 ArtificiallySelected x := by\n  rcases A4 with \u27e8x, y, hx, hy, hbb, hres\u27e9\n  have hAS : ArtificiallySelected x := A1 x hbb\n  exact \u27e8x, \u27e8hx, hAS\u27e9\u27e9\n\n-- Q2 formalization (cannot be proved from the axioms):\ndef AurochsAreExtinct : Prop := \u2200 y:U, Aurochs y \u2192 Extinct y\n\nend BackBreeding\n\nAnswers:\n\n- Question 1: From \u201cHeck cattle were bred back \u2026\u201d and \u201cBreeding back is a form of artificial selection,\u201d there exists a Heck cattle that is artificially selected. True\n\n- Question 2: The premises do not state or entail that aurochs are extinct; we only know some bred-back animals resemble extinct animals. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 133,
        "conclusion": "Some Heck cattle are artificially selected.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 134,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 483,
    "premises": "Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.",
    "gpt_response": "Lean formalization and attempted proofs:\n\n```\nuniverse u\n\nconstant Person : Type u\nconstants (Vladimir Ekaterina : Person)\n\n-- Predicates\nconstants\n  (CanRegisterUS : Person \u2192 Prop)\n  (CanParticipate2024 : Person \u2192 Prop)\n  (USCitizen : Person \u2192 Prop)\n  (TaiwanCitizen : Person \u2192 Prop)\n  (RFO : Person \u2192 Prop)                -- Russian Federation official\n  (ManagerGazprom : Person \u2192 Prop)\n\n-- Axioms from the textual context\naxioms\n  (H1 : \u2200 x, CanRegisterUS x \u2192 CanParticipate2024 x)\n  (H2 : \u2200 x, USCitizen x \u2192 CanRegisterUS x)\n  (H3 : \u2200 x, USCitizen x \u2228 TaiwanCitizen x)\n  (H4 : \u2200 x, RFO x \u2192 \u00ac TaiwanCitizen x)\n  (H5 : \u00ac TaiwanCitizen Vladimir \u2227 \u00ac ManagerGazprom Vladimir)\n  (H6 : CanRegisterUS Ekaterina \u2228 RFO Ekaterina)\n\n-- Derived facts about Vladimir\nlemma vladimir_not_TW : \u00ac TaiwanCitizen Vladimir := H5.left\nlemma vladimir_not_MG : \u00ac ManagerGazprom Vladimir := H5.right\n\nlemma vladimir_USC : USCitizen Vladimir := by\n  have h := H3 Vladimir\n  cases h with\n  | inl hUS => exact hUS\n  | inr hTW => exact False.elim (vladimir_not_TW hTW)\n\nlemma vladimir_can_register : CanRegisterUS Vladimir :=\n  H2 Vladimir vladimir_USC\n\nlemma vladimir_can_participate : CanParticipate2024 Vladimir :=\n  H1 Vladimir vladimir_can_register\n\n-- Derived facts about Ekaterina\nlemma ekaterina_can_register : CanRegisterUS Ekaterina := by\n  cases H6 with\n  | inl hReg => exact hReg\n  | inr hRFO =>\n      have hNotTW : \u00ac TaiwanCitizen Ekaterina := H4 Ekaterina hRFO\n      have hUSorTW := H3 Ekaterina\n      -- From US \u2228 TW and \u00acTW, conclude US, hence she can register.\n      cases hUSorTW with\n      | inl hUS => exact H2 Ekaterina hUS\n      | inr hTW => exact False.elim (hNotTW hTW)\n\nlemma ekaterina_can_participate : CanParticipate2024 Ekaterina :=\n  H1 Ekaterina ekaterina_can_register\n\n-- Questions encoded as propositions\ndef Q1 : Prop := RFO Vladimir\ndef Q2 : Prop := \u00ac RFO Vladimir\ndef Q3 : Prop := CanParticipate2024 Ekaterina \u2228 ManagerGazprom Ekaterina\ndef Q4 : Prop := CanParticipate2024 Ekaterina \u2228 ManagerGazprom Vladimir\ndef Q5 : Prop := \u00ac (CanRegisterUS Ekaterina \u2227 CanParticipate2024 Vladimir)\n\n-- What we can prove:\n-- Q3 is true because ekaterina_can_participate holds\ntheorem Q3_true : Q3 := Or.inl ekaterina_can_participate\n\n-- Q4 is true because ekaterina_can_participate holds\ntheorem Q4_true : Q4 := Or.inl ekaterina_can_participate\n\n-- Q5 is false because both conjuncts hold (we can register Ekaterina and Vladimir can participate)\ntheorem not_Q5 : \u00ac Q5 := by\n  intro h\n  exact h \u27e8ekaterina_can_register, vladimir_can_participate\u27e9\n```\n\nAnswers:\n1) Unknown. Unknown\n2) Unknown. Unknown\n3) True. True\n4) True. True\n5) False. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1410,
        "conclusion": "Vladimir is a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1411,
        "conclusion": "Vladimir is not a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1412,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1413,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1414,
        "conclusion": "It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.4
  },
  {
    "story_id": 80,
    "premises": "New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.",
    "gpt_response": "Lean formalization and attempted proofs:\n\nnamespace NVP\n\nconstant Book : Type\nconstant NC HP PF : Book\nconstant InEnglish : Book \u2192 Prop\nconstant TranslatedFromItalian : Book \u2192 Prop\nconstant PublishedByNVP : Book \u2192 Prop\n\n-- Premises\naxiom all_nvp_books_english : \u2200 b, PublishedByNVP b \u2192 InEnglish b\naxiom nc_published : PublishedByNVP NC\naxiom nc_from_italian : TranslatedFromItalian NC\naxiom pf_published : PublishedByNVP PF\n\n-- Q1: Neapolitan Chronicles is an English book.\ntheorem Q1 : InEnglish NC :=\n  all_nvp_books_english NC nc_published\n\n-- Q2: Harry Potter was published by New Vessel Press. (Not derivable from the axioms.)\n-- theorem Q2 : PublishedByNVP HP := by\n--   sorry\n\n-- Q3: Palace of Flies was translated from Italian. (Not derivable from the axioms.)\n-- theorem Q3 : TranslatedFromItalian PF := by\n--   sorry\n\n-- Derivable auxiliary fact:\ntheorem PF_English : InEnglish PF :=\n  all_nvp_books_english PF pf_published\n\nend NVP\n\nAnswers:\n- Question 1: Yes. From \u201cAll of New Vessel Press\u2019s published books are in English\u201d and \u201cNeapolitan Chronicles is published by New Vessel Press,\u201d it follows that Neapolitan Chronicles is in English. True\n- Question 2: We have no information about Harry Potter being published by New Vessel Press. Unknown\n- Question 3: We are not told that Palace of Flies was translated from Italian; only that it was published by New Vessel Press and that their books are in English. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 243,
        "conclusion": "Neapolitan Chronicles is an English book.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 244,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 245,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 363,
    "premises": "All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. ",
    "gpt_response": "Lean formalization:\n\nuniverse u\n\nopen Classical\n\nconstant U : Type u\n\n-- Predicates\nconstant Hydrocarbon : U \u2192 Prop\nconstant Organic : U \u2192 Prop\nconstant Chemical : U \u2192 Prop\nconstant Alkane : U \u2192 Prop\nconstant ContainsCarbon : U \u2192 Prop\nconstant OnlyOne : U \u2192 Prop\n\n-- Axioms from the text\naxiom H_h_o : \u2200 x : U, Hydrocarbon x \u2192 Organic x                -- all hydrocarbons are organic\naxiom H_a_h : \u2200 x : U, Alkane x \u2192 Hydrocarbon x                 -- all alkanes are hydrocarbons\naxiom H_o_c : \u2200 x : U, Organic x \u2192 Chemical x                   -- all organic compounds are chemical compounds\naxiom H_o_cc : \u2200 x : U, Organic x \u2192 ContainsCarbon x            -- all organic compounds contain carbon\naxiom H_c_not_one : \u2200 x : U, Chemical x \u2192 \u00ac OnlyOne x           -- no chemical compounds contain only one element\n\n-- The mixture and its special condition\nconstant mixture : U\naxiom mix_either :\n  (Chemical mixture \u2227 OnlyOne mixture) \u2228 (\u00ac Chemical mixture \u2227 \u00ac OnlyOne mixture)\n-- (equivalently: Chemical mixture \u2194 OnlyOne mixture)\n\n-- Useful derived facts\nlemma mixture_not_chemical : \u00ac Chemical mixture := by\n  intro hC\n  cases mix_either with\n  | inl h =>\n      have hno : \u00ac OnlyOne mixture := H_c_not_one mixture h.left\n      exact hno h.right\n  | inr h =>\n      exact h.left hC\n\nlemma mixture_not_one : \u00ac OnlyOne mixture := by\n  intro h1\n  cases mix_either with\n  | inl h =>\n      have hno : \u00ac OnlyOne mixture := H_c_not_one mixture h.left\n      exact hno h1\n  | inr h =>\n      exact h.right h1\n\nlemma mixture_not_organic : \u00ac Organic mixture := by\n  intro hO\n  have hC : Chemical mixture := H_o_c mixture hO\n  exact mixture_not_chemical hC\n\nlemma mixture_not_alkane : \u00ac Alkane mixture := by\n  intro hA\n  have hH  : Hydrocarbon mixture := H_a_h mixture hA\n  have hO  : Organic mixture     := H_h_o mixture hH\n  have hC  : Chemical mixture    := H_o_c mixture hO\n  exact mixture_not_chemical hC\n\n-- Q2: The mixture is an alkane and contains carbon. This is false.\ntheorem Q2_false : \u00ac (Alkane mixture \u2227 ContainsCarbon mixture) := by\n  intro h\n  exact mixture_not_alkane h.left\n\n-- Q3: If the mixture contains only one element or contains carbon,\n--     then the mixture is neither a chemical compound nor an alkane. This is true.\ntheorem Q3_true :\n  (OnlyOne mixture \u2228 ContainsCarbon mixture) \u2192 (\u00ac Chemical mixture \u2227 \u00ac Alkane mixture) := by\n  intro _\n  exact And.intro mixture_not_chemical mixture_not_alkane\n\n\nExplanations and answers:\n\n- From the axioms and the special condition on the mixture, we can derive that the mixture is not a chemical compound and does not contain only one element. Consequently, it is neither organic, nor a hydrocarbon, nor an alkane. However, nothing given forces or forbids the mixture from containing carbon unless it is organic, and we have shown it is not organic. So we cannot determine whether it contains carbon.\n\nQuestion 1: The mixture contains carbon.\nAnswer: We cannot prove this or its negation from the given information. Unknown\n\nQuestion 2: The mixture is an alkane and contains carbon.\nAnswer: Since the mixture is not a chemical compound, it cannot be an alkane, so the conjunction is false. False\n\nQuestion 3: If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.\nAnswer: We have proved that the mixture is neither a chemical compound nor an alkane unconditionally, so the implication holds. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 964,
        "conclusion": "The mixture contains carbon.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 965,
        "conclusion": "The mixture is an alkane and contains carbon.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 966,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 258,
    "premises": "All humans are mortal.\nAll Greeks are humans.",
    "gpt_response": "Lean translation and attempt:\n\nWe model a universe U with predicates Human, Greek, Mortal : U \u2192 Prop. The premises are:\n- h\u2081: \u2200 x, Human x \u2192 Mortal x\n- h\u2082: \u2200 x, Greek x \u2192 Human x\n\nGoal: \u2203 x, Greek x \u2227 Mortal x.\n\nLean code:\n\nsection\n\nvariable (U : Type) (Human Greek Mortal : U \u2192 Prop)\nvariable (h\u2081 : \u2200 x, Human x \u2192 Mortal x)\nvariable (h\u2082 : \u2200 x, Greek x \u2192 Human x)\n\n-- From the premises we can derive that all Greeks are mortal\ntheorem all_greeks_mortal : \u2200 x, Greek x \u2192 Mortal x := by\n  intro x gx\n  exact h\u2081 x (h\u2082 x gx)\n\n-- If we also assume that some Greek exists, then some Greek is mortal\ntheorem some_greek_mortal_of_exists (hx : \u2203 x, Greek x) : \u2203 x, Greek x \u2227 Mortal x := by\n  cases hx with\n  | intro x gx =>\n    refine \u27e8x, ?_\u27e9\n    exact And.intro gx (all_greeks_mortal U Human Greek Mortal h\u2081 h\u2082 x gx)\n\n-- Countermodel showing the existential does not follow from the premises alone\nexample :\n  \u2203 (U : Type) (Human Greek Mortal : U \u2192 Prop),\n    (\u2200 x, Human x \u2192 Mortal x) \u2227\n    (\u2200 x, Greek x \u2192 Human x) \u2227\n    \u00ac \u2203 x, Greek x \u2227 Mortal x := by\n  refine \u27e8Unit, (\u03bb _ => True), (\u03bb _ => False), (\u03bb _ => True), ?_, ?_, ?_\u27e9\n  \u00b7 intro x hx; trivial\n  \u00b7 intro x gx; trivial\n  \u00b7 intro h\n    cases h with\n    | intro x hx =>\n      cases hx.left\n\nend\n\nConclusion:\nFrom the given premises we can prove \u201cAll Greeks are mortal,\u201d and we can prove \u201cSome Greeks are mortal\u201d only if we additionally assume that some Greek exists. Since existence of a Greek is not given, neither the statement nor its negation is derivable from the premises alone.\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 702,
        "conclusion": "Some Greeks are mortal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 435,
    "premises": "None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.",
    "gpt_response": "Here is a faithful Lean formalization of the predicates and facts, followed by proofs for the four queried statements (or their negations).\n\nLean code:\n```\nuniverse u\n\nsection\n\nvariable {U : Type u}\nvariable (Library CS PT DB David Lab : U \u2192 Prop)\nvariable (James : U)\n\n-- Facts from the problem\nvariable (h1 : \u2200 x, Library x \u2192 \u00ac CS x)      -- None working in library are CS\nvariable (h2 : \u2200 x, PT x \u2192 Library x)         -- All with PT jobs work in library\nvariable (h3 : \u2200 x, DB x \u2192 CS x)              -- All taking DB are CS\nvariable (h4 : \u2200 x, David x \u2192 DB x)           -- All with David take DB\nvariable (h5 : \u2200 x, Lab x \u2192 David x)          -- All in lab take David's class\nvariable (h6 : Lab James)                     -- James works in the lab\nvariable (h7 : \u00ac Lab James \u2227 \u00ac PT James)      -- James does not work in lab and does not have a PT job\n\n-- The four statements to evaluate\ndef S1 : Prop := PT James\ndef S2 : Prop := \u00ac PT James\ndef S3 : Prop := DB James \u2228 PT James\ndef S4 : Prop := DB James\n\n-- Q4: James takes the database course.\ntheorem Q4_proved : S4 Lab David DB James h5 h4 h6 := by\n  -- From Lab James, get David James, then DB James\n  have hDavid : David James := h5 James h6\n  exact h4 James hDavid\n\n-- Q3: James either takes DB or has a PT job.\ntheorem Q3_proved : S3 Library CS PT DB David Lab James h1 h2 h3 h4 h5 h6 h7 := by\n  -- Left disjunct holds because Q4 holds\n  exact Or.inl (Q4_proved Lab David DB James h5 h4 h6)\n\n-- Q2: James does not have a PT job.\ntheorem Q2_proved : S2 Library CS PT DB David Lab James h1 h2 h3 h4 h5 h6 h7 := by\n  -- From the given conjunction, take the right conjunct \u00ac PT James\n  exact (And.right h7)\n\n-- Q1: James has a PT job is false (we prove its negation).\ntheorem Q1_neg : \u00ac S1 Library CS PT DB David Lab James h1 h2 h3 h4 h5 h6 h7 := by\n  -- Same as Q2_proved\n  exact (And.right h7)\n\nend\n```\n\nExplanation of the reasoning:\n- From \u201cLab \u2192 David\u201d and \u201cDavid \u2192 DB\u201d and the fact that James is in the lab, we get that James takes the database course (DB James).\n- From \u201cJames doesn\u2019t \u2026 have a part-time job,\u201d we directly get \u00ac PT James.\n- Therefore:\n  - \u201cJames has a PT job\u201d is false (since \u00ac PT James).\n  - \u201cJames does not have a PT job\u201d is true.\n  - \u201cJames takes DB or has a PT job\u201d is true (the left side holds).\n  - \u201cJames takes the database course\u201d is true.\n\nAnswers:\n- Question 1: False\n- Question 2: True\n- Question 3: True\n- Question 4: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1244,
        "conclusion": "James has a part-time job offered by the university.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1245,
        "conclusion": "James does not have a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1246,
        "conclusion": "James either takes the database course or has a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1247,
        "conclusion": "James takes the database course.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 217,
    "premises": "If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.",
    "gpt_response": "Predicates\n- L: George likes music\n- W: George wants to compose\n- A: George has access to a program\n- C: George can compose\n- P: George will compose\n\nPremises\n- h1: L \u2192 W\n- h2: A \u2192 C\n- h3: C \u2227 W \u2192 P\n\nLean formalization and proofs\n\nnamespace George\n\n-- Q1: From the premises, (L \u2227 A) \u2192 P is derivable.\ntheorem Q1_valid :\n  \u2200 {L A W C P : Prop}, (L \u2192 W) \u2192 (A \u2192 C) \u2192 (C \u2227 W \u2192 P) \u2192 (L \u2227 A \u2192 P) := by\n  intro L A W C P hLW hAC hCWP hLA\n  rcases hLA with \u27e8hL, hA\u27e9\n  have hW : W := hLW hL\n  have hC : C := hAC hA\n  exact hCWP \u27e8hC, hW\u27e9\n\n-- Q2: The entailment (\u00acP \u2192 \u00acC) does not follow from the premises (countermodel).\ntheorem Q2_not_valid :\n  \u00ac (\u2200 (L A W C P : Prop), (L \u2192 W) \u2192 (A \u2192 C) \u2192 (C \u2227 W \u2192 P) \u2192 (\u00acP \u2192 \u00acC)) := by\n  intro h\n  -- instantiate with L=False, A=True, W=False, C=True, P=False\n  have hinst := h False True False True False\n  have h1 : False \u2192 False := by intro f; exact f\n  have h2 : True \u2192 True := by intro _; exact True.intro\n  have h3 : (True \u2227 False) \u2192 False := by\n    intro hcf\n    exact hcf.2\n  have concl := hinst h1 h2 h3\n  have hnP : \u00acFalse := by intro p; exact p\n  have hnC : \u00acTrue := concl hnP\n  exact hnC True.intro\n\nend George\n\nAnswers\n- Question 1: From L \u2227 A, we get W by h1 and C by h2, hence C \u2227 W, so P by h3. True\n- Question 2: From \u00acP we only get \u00ac(C \u2227 W), which does not imply \u00acC. The Lean countermodel above shows the entailment is invalid. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 618,
        "conclusion": "If George likes music and has access to a program, he will compose.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 619,
        "conclusion": "If George will not compose, George can not compose.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 292,
    "premises": "A hawk never swims. \nSome birds are hawks.",
    "gpt_response": "Lean formalization and proof attempt\n\nInformal predicates:\n- Bird x: x is a bird\n- Hawk x: x is a hawk\n- Swims x: x swims\n\nPremises:\n1. \u2200 x, Hawk x \u2192 \u00ac Swims x        -- A hawk never swims\n2. \u2203 x, Bird x \u2227 Hawk x            -- Some birds are hawks\n\nClaim to assess: \u2200 x, Bird x \u2192 Swims x  -- \u201cAll birds swim\u201d\n\nLean code:\nuniverse u\n\nsection\nvariable {Animal : Type u}\nvariable (Bird Hawk Swims : Animal \u2192 Prop)\n\ntheorem not_all_birds_swim\n  (hawk_never_swims : \u2200 x, Hawk x \u2192 \u00ac Swims x)\n  (some_birds_are_hawks : \u2203 x, Bird x \u2227 Hawk x) :\n  \u00ac \u2200 x, Bird x \u2192 Swims x := by\n  intro hAll\n  rcases some_birds_are_hawks with \u27e8a, ha\u27e9\n  rcases ha with \u27e8haBird, haHawk\u27e9\n  have hNot : \u00ac Swims a := hawk_never_swims a haHawk\n  have hYes : Swims a := hAll a haBird\n  exact hNot hYes\nend\n\nExplanation: From the existence of a bird that is a hawk and the fact that hawks never swim, there exists a bird that does not swim. Hence \u201cAll birds swim\u201d is false.\n\nFalse",
    "results": [
      {
        "question_num": 1,
        "example_id": 736,
        "conclusion": "All birds swim.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 318,
    "premises": "Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.",
    "gpt_response": "Lean translation and proofs:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Show : Type u\n\nconstant Monday8 : Show \u2192 Prop\nconstant GivesRoses : Show \u2192 Prop\nconstant EpisodeBachelor : Show \u2192 Prop\nconstant PortraysReal : Show \u2192 Prop\nconstant RealityTV : Show \u2192 Prop\n\nconstant BreakingBad : Show\n\naxiom exists_monday8_rose_show : \u2203 s : Show, Monday8 s \u2227 GivesRoses s\naxiom roses_implies_bachelor : \u2200 s : Show, GivesRoses s \u2192 EpisodeBachelor s\naxiom bachelor_portrays_real : \u2200 s : Show, EpisodeBachelor s \u2192 PortraysReal s\naxiom portrays_implies_reality : \u2200 s : Show, PortraysReal s \u2192 RealityTV s\naxiom not_reality_BB : \u00ac RealityTV BreakingBad\n\nlemma roses_implies_reality (s : Show) (h : GivesRoses s) : RealityTV s :=\n  portrays_implies_reality s (bachelor_portrays_real s (roses_implies_bachelor s h))\n\nlemma not_roses_BB : \u00ac GivesRoses BreakingBad := by\n  intro h\n  have : RealityTV BreakingBad := roses_implies_reality BreakingBad h\n  exact not_reality_BB this\n\ndef Q1 : Prop := Monday8 BreakingBad\ndef Q2 : Prop := GivesRoses BreakingBad \u2227 Monday8 BreakingBad\ndef Q3 : Prop := GivesRoses BreakingBad \u2192 Monday8 BreakingBad\n\nlemma Q2_false : \u00ac Q2 := by\n  intro h\n  exact not_roses_BB h.left\n\nlemma Q3_true : Q3 := by\n  intro h\n  exact False.elim (not_roses_BB h)\n\n-- Note: From the given axioms, neither Q1 nor its negation is derivable.\n\nend Reasoning\n\nAnswers:\n1) We have no information linking Breaking Bad to Monday at 8 pm. Unknown\n2) If Breaking Bad gave out roses, it would be reality TV, contradicting that it is not; hence the conjunction is false. False\n3) Since roses cannot be given out during Breaking Bad, the implication holds vacuously. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 802,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 803,
        "conclusion": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 804,
        "conclusion": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 107,
    "premises": "Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.",
    "gpt_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Person : Type u\nconstant HeinrichSchmidt : Person\n\n-- Predicates\nconstant German : Person \u2192 Prop\nconstant Russian : Person \u2192 Prop\nconstant Politician : Person \u2192 Prop\nconstant MemberPrussianStateParliament : Person \u2192 Prop\nconstant MemberNaziReichstag : Person \u2192 Prop\n\n-- Facts from the text\naxiom hs_is_German : German HeinrichSchmidt\naxiom hs_is_politician : Politician HeinrichSchmidt\naxiom hs_in_PSP : MemberPrussianStateParliament HeinrichSchmidt\naxiom hs_in_NR : MemberNaziReichstag HeinrichSchmidt\n\n-- Q1: Heinrich Schmidt was German or Russian or both.\ntheorem Q1_true :\n  German HeinrichSchmidt \u2228 Russian HeinrichSchmidt \u2228 (German HeinrichSchmidt \u2227 Russian HeinrichSchmidt) :=\nby\n  exact Or.inl hs_is_German\n\n-- Q2: Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.\ntheorem Q2_true :\n  \u2203 x, German x \u2227 Politician x \u2227 MemberPrussianStateParliament x \u2227 MemberNaziReichstag x :=\nby\n  refine \u27e8HeinrichSchmidt, ?_\u27e9\n  exact And.intro hs_is_German (And.intro hs_is_politician (And.intro hs_in_PSP hs_in_NR))\n\n-- Q3: No politicians are part of the Nazi Reichstag. (This is false; we prove its negation.)\ndef Q3_stmt : Prop := \u2200 x, Politician x \u2192 \u00ac MemberNaziReichstag x\n\ntheorem Q3_false : \u00ac Q3_stmt :=\nby\n  intro h\n  have h1 : \u00ac MemberNaziReichstag HeinrichSchmidt := h HeinrichSchmidt hs_is_politician\n  exact h1 hs_in_NR\n\ntheorem exists_counterexample_Q3 : \u2203 x, Politician x \u2227 MemberNaziReichstag x :=\nby\n  exact \u27e8HeinrichSchmidt, And.intro hs_is_politician hs_in_NR\u27e9\n\nAnswers:\n- Q1: He is stated to be German, so \u201cGerman or Russian or both\u201d holds. True\n- Q2: Heinrich Schmidt is a German politician and a member of both bodies, so such a person exists. True\n- Q3: Heinrich Schmidt is a politician and a member of the Nazi Reichstag, so \u201cno politicians are part of the Nazi Reichstag\u201d is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 323,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 324,
        "conclusion": "Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 325,
        "conclusion": "No politicians are part of the Nazi Reichstag.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 386,
    "premises": "If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.",
    "gpt_response": "Lean formalization and attempted proofs:\n\nuniverse u\n\nconstant Disease : Type u\nconstant Deadly LowSurvival SevereCancer BileDuctCancer Cholangiocarcinoma MildFlu : Disease \u2192 Prop\nconstant ColorectalCancer : Disease\n\n-- Axioms from the text\naxiom deadly_low : \u2200 x, Deadly x \u2192 LowSurvival x\naxiom severe_deadly : \u2200 x, SevereCancer x \u2192 Deadly x\naxiom bile_severe : \u2200 x, BileDuctCancer x \u2192 SevereCancer x\naxiom chol_bile : \u2200 x, Cholangiocarcinoma x \u2192 BileDuctCancer x\naxiom mild_low : \u2200 x, MildFlu x \u2192 LowSurvival x\naxiom colorectal_not_bile_and_low : \u00ac (BileDuctCancer ColorectalCancer \u2227 LowSurvival ColorectalCancer)\n\n-- Derived: bile duct cancer implies low survival\nlemma bile_low : \u2200 x, BileDuctCancer x \u2192 LowSurvival x := by\n  intro x hb\n  exact deadly_low x (severe_deadly x (bile_severe x hb))\n\n-- Therefore, colorectal cancer is not a bile duct cancer\nlemma not_bile_colorectal : \u00ac BileDuctCancer ColorectalCancer := by\n  intro hb\n  have hl : LowSurvival ColorectalCancer := bile_low ColorectalCancer hb\n  exact colorectal_not_bile_and_low \u27e8hb, hl\u27e9\n\n-- And thus not a cholangiocarcinoma either\nlemma not_chol_colorectal : \u00ac Cholangiocarcinoma ColorectalCancer := by\n  intro hc\n  have hb : BileDuctCancer ColorectalCancer := chol_bile ColorectalCancer hc\n  exact not_bile_colorectal hb\n\n-- Question 1 statement (we cannot prove or refute it from the axioms):\ndef Q1 : Prop := SevereCancer ColorectalCancer\n\n-- Question 2 statement and proof: it is true (vacuously, since the antecedent is impossible)\ndef Q2 : Prop :=\n  (BileDuctCancer ColorectalCancer \u2228 Cholangiocarcinoma ColorectalCancer) \u2192\n  (BileDuctCancer ColorectalCancer \u2227 MildFlu ColorectalCancer)\n\ntheorem Q2_true : Q2 := by\n  intro h\n  have : False := by\n    cases h with\n    | inl hb => exact not_bile_colorectal hb\n    | inr hc =>\n      have hb : BileDuctCancer ColorectalCancer := chol_bile ColorectalCancer hc\n      exact not_bile_colorectal hb\n  exact False.elim this\n\n-- Question 3 statement (interpreting \u201cor all of the above\u201d as adding the full conjunction)\n-- This reduces to a disjunction of two cases, both requiring Cholangiocarcinoma ColorectalCancer.\ndef Q3 : Prop :=\n  (Cholangiocarcinoma ColorectalCancer \u2227 (MildFlu ColorectalCancer \u2228 BileDuctCancer ColorectalCancer)) \u2228\n  (Cholangiocarcinoma ColorectalCancer \u2227 MildFlu ColorectalCancer \u2227 BileDuctCancer ColorectalCancer)\n\n-- We can prove the negation of Q3 from the axioms (hence Q3 is false).\ntheorem Q3_false : \u00ac Q3 := by\n  intro h\n  cases h with\n  | inl h1 => exact not_chol_colorectal h1.1\n  | inr h2 => exact not_chol_colorectal h2.1\n\n\nAnswers:\n\n- Question 1: We cannot derive that colorectal cancer is a severe cancer, nor can we derive its negation, from the given information. Unknown\n\n- Question 2: From the axioms we get \u00ac(BileDuctCancer ColorectalCancer) and hence also \u00ac(Cholangiocarcinoma ColorectalCancer). Therefore the antecedent is impossible, making the implication true. True\n\n- Question 3: Both disjuncts require Cholangiocarcinoma ColorectalCancer, which we proved false; thus the whole statement is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1032,
        "conclusion": "Colorectal cancer is a kind of severe cancer",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1033,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1034,
        "conclusion": "Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 355,
    "premises": "All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.",
    "gpt_response": "Lean formalization and proofs attempt:\n\n-- Begin Lean\nnamespace Reasoning\n\nconstant Person : Type\n\n-- Predicates\nconstant EatSalads : Person \u2192 Prop\nconstant VeryConscious : Person \u2192 Prop\nconstant HCHome : Person \u2192 Prop\nconstant Fulfills : Person \u2192 Prop\nconstant Disregards : Person \u2192 Prop\nconstant VisitsGymDaily : Person \u2192 Prop\n\n-- Axioms from the text\naxiom A1 : \u2200 x : Person, EatSalads x \u2192 VeryConscious x\naxiom A2 : \u2200 x : Person, HCHome x \u2192 EatSalads x\naxiom A3 : \u2200 x : Person, Fulfills x \u2192 HCHome x\naxiom A4 : \u2200 x : Person, Disregards x \u2192 \u00ac VeryConscious x\naxiom A5 : \u2200 x : Person, VisitsGymDaily x \u2192 Fulfills x\n\n-- Individual\nconstant Taylor : Person\n\n-- Given disjunction about Taylor\naxiom T1 : (HCHome Taylor \u2227 Disregards Taylor) \u2228 (\u00ac HCHome Taylor \u2227 \u00ac Disregards Taylor)\n\n-- Eliminate the impossible disjunct\nlemma not_hc_and_disregards : \u00ac (HCHome Taylor \u2227 Disregards Taylor) := by\n  intro h\n  rcases h with \u27e8hh, hd\u27e9\n  have vc : VeryConscious Taylor := A1 Taylor (A2 Taylor hh)\n  have nvc : \u00ac VeryConscious Taylor := A4 Taylor hd\n  exact nvc vc\n\nlemma taylor_not_hc_and_not_disregards : \u00ac HCHome Taylor \u2227 \u00ac Disregards Taylor := by\n  exact Or.resolve_left T1 not_hc_and_disregards\n\n-- Q2: Taylor does not visit the gym daily\ntheorem taylor_not_visits : \u00ac VisitsGymDaily Taylor := by\n  intro hv\n  have nhc : \u00ac HCHome Taylor := (taylor_not_hc_and_not_disregards).left\n  have hc  : HCHome Taylor := A3 Taylor (A5 Taylor hv)\n  exact nhc hc\n\n-- Q3: Taylor neither HCHome nor visits daily\ntheorem taylor_neither_hchome_nor_visits : \u00ac HCHome Taylor \u2227 \u00ac VisitsGymDaily Taylor := by\n  constructor\n  \u00b7 exact (taylor_not_hc_and_not_disregards).left\n  \u00b7 exact taylor_not_visits\n\nend Reasoning\n-- End Lean\n\nConclusions:\n- From the axioms, the disjunct (HCHome Taylor \u2227 Disregards Taylor) is impossible, hence we get \u00acHCHome Taylor \u2227 \u00acDisregards Taylor. Then VisitsGymDaily Taylor \u2192 Fulfills Taylor \u2192 HCHome Taylor, contradicting \u00acHCHome Taylor, so \u00acVisitsGymDaily Taylor. There is no way to conclude EatSalads Taylor or its negation from the given information.\n\nAnswers:\nQuestion 1: Taylor eats salads regularly. Unknown\nQuestion 2: Taylor visits the gym at least once a day. False\nQuestion 3: Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 941,
        "conclusion": "Taylor eats salads regularly.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 942,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 943,
        "conclusion": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 51,
    "premises": "The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. ",
    "gpt_response": "Lean formalization and proofs attempt:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant U : Type u\n\n-- Entities\nconstant SummerOlympicGames : U\nconstant LastSummerOlympics : U\nconstant Tokyo : U\nconstant UnitedStates : U\nconstant WorldChampionships : U\n\n-- Predicates/relations\nconstant SportingEvent : U \u2192 Prop\nconstant WonMostMedalsIn : U \u2192 U \u2192 Prop\n\n-- Facts from the text\naxiom summer_olympics_is_sporting : SportingEvent SummerOlympicGames\naxiom last_summer_olympics_is_Tokyo : LastSummerOlympics = Tokyo\naxiom us_won_most_medals_in_Tokyo : WonMostMedalsIn UnitedStates Tokyo\n\n-- Queries as propositions\ndef Q1 : Prop := SportingEvent WorldChampionships\ndef Q2 : Prop := LastSummerOlympics \u2260 Tokyo\ndef Q3 : Prop := WonMostMedalsIn UnitedStates LastSummerOlympics\n\n-- Q2 is false given last_summer_olympics_is_Tokyo\ntheorem Q2_neg : \u00ac Q2 := by\n  intro h\n  exact h last_summer_olympics_is_Tokyo\n\n-- Q3 is true by rewriting with last_summer_olympics_is_Tokyo\ntheorem Q3_true : Q3 := by\n  simpa [Q3, last_summer_olympics_is_Tokyo] using us_won_most_medals_in_Tokyo\n\n-- Q1 cannot be derived (nor its negation) from the given axioms.\n\nend Reasoning\n\nAnswers:\n1) Unknown\n2) False\n3) True",
    "results": [
      {
        "question_num": 1,
        "example_id": 147,
        "conclusion": "The world championships is a sporting event.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 148,
        "conclusion": "The last summer Olympic games were not in Tokyo.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 149,
        "conclusion": "The United States won the most medals in the last summer Olympic games.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 259,
    "premises": "All horses have hooves.\nNo humans have hooves.",
    "gpt_response": "Lean formalization and proof:\n\nuniverse u\n\nvariable {U : Type u}\nvariables (Human Horse Hooves : U \u2192 Prop)\n\n-- Premises:\n-- 1) \u2200 x, Horse x \u2192 Hooves x        (All horses have hooves)\n-- 2) \u2200 x, Human x \u2192 \u00ac Hooves x      (No humans have hooves)\n\n-- Statement in question: \u2203 x, Human x \u2227 Horse x  (Some humans are horses)\n\ntheorem no_human_is_a_horse\n  (allHorseHooves : \u2200 x, Horse x \u2192 Hooves x)\n  (noHumanHooves : \u2200 x, Human x \u2192 \u00ac Hooves x) :\n  \u00ac (\u2203 x, Human x \u2227 Horse x) := by\n  intro h\n  rcases h with \u27e8x, hx\u27e9\n  rcases hx with \u27e8hxHuman, hxHorse\u27e9\n  have hxHooves : Hooves x := allHorseHooves x hxHorse\n  have hxNoHooves : \u00ac Hooves x := noHumanHooves x hxHuman\n  exact hxNoHooves hxHooves\n\nAnswer to Question 1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 703,
        "conclusion": "Some humans are horses.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 152,
    "premises": "Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.",
    "gpt_response": "Lean formalization and proofs:\n\nconstant Person : Type\nconstant Airport : Type\n\nconstant Susan John : Person\nconstant LGA : Airport\n\nconstant dep : Person \u2192 Airport\nconstant arr : Person \u2192 Airport\n\n-- Axiom: departure and arrival cannot be the same airport\naxiom dep_ne_arr : \u2200 p : Person, dep p \u2260 arr p\n\n-- Facts from the context\naxiom susan_to_LGA : arr Susan = LGA\naxiom john_from_LGA : dep John = LGA\n\n-- Question 1 target: dep Susan = LGA (we prove its negation)\ntheorem Q1_false : dep Susan \u2260 LGA := by\n  intro hdep\n  have hda : dep Susan = arr Susan := by\n    calc\n      dep Susan = LGA := hdep\n      _ = arr Susan := susan_to_LGA.symm\n  exact (dep_ne_arr Susan) hda\n\n-- Question 2 target: arr John = LGA (we prove its negation)\ntheorem Q2_false : arr John \u2260 LGA := by\n  intro harr\n  have hda : dep John = arr John := by\n    calc\n      dep John = LGA := john_from_LGA\n      _ = arr John := harr\n  exact (dep_ne_arr John) hda\n\nAnswers:\n- Question 1: Susan flies from LGA airport. False\n- Question 2: John flies to LGA airport. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 442,
        "conclusion": "Susan flies from LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 443,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 441,
    "premises": "No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.",
    "gpt_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Person : Type u\nconstant Nice Mean Grumpy Lover PetOwner : Person \u2192 Prop\nconstant Tom : Person\n\n-- Axioms from the textual context\naxiom H1 : \u2200 x : Person, Nice x \u2192 \u00ac Mean x                      -- No one nice to animals is also mean to animals\naxiom H2 : \u2203 x : Person, Grumpy x \u2227 Mean x                      -- Some grumpy people are mean to animals\naxiom H3 : \u2200 x : Person, Lover x \u2192 Nice x                       -- All animal lovers are nice to animals\naxiom H4 : \u2200 x : Person, PetOwner x \u2192 Lover x                   -- All pet owners love animals\naxiom H5 : PetOwner Tom                                         -- Tom is a pet owner\n\n-- Derived facts about Tom\nlemma lover_Tom : Lover Tom := H4 Tom H5\nlemma nice_Tom : Nice Tom := H3 Tom lover_Tom\nlemma not_mean_Tom : \u00ac Mean Tom := H1 Tom nice_Tom\n\n-- Q2: Tom is not both grumpy and mean to animals (provable)\nlemma Q2 : \u00ac (Grumpy Tom \u2227 Mean Tom) := by\n  intro h\n  exact not_mean_Tom h.right\n\n-- Q3: The given implication is false; we prove its negation\nlemma not_consequent : \u00ac (\u00ac Grumpy Tom \u2227 \u00ac Lover Tom) := by\n  intro h\n  have hNotL : \u00ac Lover Tom := h.right\n  exact hNotL lover_Tom\n\nlemma Q3_neg :\n  \u00ac ( (\u00ac (Grumpy Tom \u2227 Mean Tom)) \u2192 (\u00ac Grumpy Tom \u2227 \u00ac Lover Tom) ) := by\n  intro h\n  have ante : \u00ac (Grumpy Tom \u2227 Mean Tom) := Q2\n  have cons : (\u00ac Grumpy Tom \u2227 \u00ac Lover Tom) := h ante\n  exact not_consequent cons\n\n\nAnswers with justification:\n\n- Question 1: From the premises we can derive Lover Tom, Nice Tom, and \u00acMean Tom, but nothing about whether Tom is Grumpy. So we cannot determine if Tom is grumpy. Unknown\n\n- Question 2: Since Tom is an animal lover, he is nice to animals, hence not mean to animals; therefore he cannot be both grumpy and mean. True\n\n- Question 3: The antecedent (Tom is not both grumpy and mean) is true, but the consequent (Tom is neither grumpy nor an animal lover) is false because Tom is an animal lover. Hence the implication is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1268,
        "conclusion": "Tom is a grumpy person.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1269,
        "conclusion": "Tom is not both a grumpy person and mean to animals.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1270,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 64,
    "premises": "A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.",
    "gpt_response": "Lean translation and proofs:\nuniverse u\n\nconstant Entity : Type u\n\n-- Predicates\nconstant Podcast : Entity \u2192 Prop\nconstant Novel : Entity \u2192 Prop\nconstant WrittenBy : Entity \u2192 Entity \u2192 Prop\nconstant NovelWriter : Entity \u2192 Prop\nconstant American : Entity \u2192 Prop\nconstant BornIn : Entity \u2192 Entity \u2192 Prop\nconstant AmericanCity : Entity \u2192 Prop\nconstant Writer : Entity \u2192 Prop\nconstant CreatedBy : Entity \u2192 Entity \u2192 Prop\nconstant WrittenInYear : Entity \u2192 Nat \u2192 Prop\n\n-- Named entities\nconstant DaniShapiro FamilyHistory FamilySecrets Boston : Entity\n\n-- Axioms from the textual context\naxiom podcast_not_novel : \u2200 x, Podcast x \u2192 \u00ac Novel x\naxiom born_in_american_city_american : \u2200 p c, BornIn p c \u2227 AmericanCity c \u2192 American p\naxiom novel_written_implies_novel_writer : \u2200 b p, Novel b \u2227 WrittenBy b p \u2192 NovelWriter p\n\naxiom dani_american_writer : American DaniShapiro \u2227 Writer DaniShapiro\naxiom family_history_written_by_dani : WrittenBy FamilyHistory DaniShapiro\naxiom family_history_novel : Novel FamilyHistory\naxiom dani_created_family_secrets : CreatedBy DaniShapiro FamilySecrets \u2227 Podcast FamilySecrets\naxiom boston_is_american_city : AmericanCity Boston\naxiom family_history_written_2003 : WrittenInYear FamilyHistory 2003\n\n-- Q1: Dani Shapiro is a novel writer.\ntheorem Q1 : NovelWriter DaniShapiro := by\n  have h : Novel FamilyHistory \u2227 WrittenBy FamilyHistory DaniShapiro :=\n    And.intro family_history_novel family_history_written_by_dani\n  exact novel_written_implies_novel_writer FamilyHistory DaniShapiro h\n\n-- Q2 (we can prove the negation): Family Secrets is not a novel.\ntheorem Q2_neg : \u00ac Novel FamilySecrets := by\n  have hpod : Podcast FamilySecrets := And.right dani_created_family_secrets\n  exact podcast_not_novel FamilySecrets hpod\n\n-- Q3: No derivation either way from the given axioms.\ndef Q3_claim : Prop := BornIn DaniShapiro Boston\n\n\nAnswers:\n1) From Family History being a novel and written by Dani Shapiro, the rule implies Dani Shapiro is a novel writer. True\n2) Family Secrets is a podcast, and podcasts are not novels, so Family Secrets is not a novel. False\n3) There is no information about where Dani Shapiro was born; Boston being an American city and Dani being American do not imply she was born in Boston. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 189,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 190,
        "conclusion": "Family Secrets is a novel.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 191,
        "conclusion": "Dani Shapiro was born in Boston.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 456,
    "premises": "Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.",
    "gpt_response": "Lean translation and proofs:\n\n-- Universe and domain\nuniverse u\nconstant Person : Type u\n\n-- Predicates\nconstant American : Person \u2192 Prop\nconstant ProBB : Person \u2192 Prop              -- professional basketball player\nconstant CanJumpShot : Person \u2192 Prop\nconstant LeapsStraightUp : Person \u2192 Prop\nconstant ActivatesLegs : Person \u2192 Prop\n\n-- Individual\nconstant Yuri : Person\n\n-- Axioms from the text\nconstant ax_some_nonAmerican : \u2203 x, ProBB x \u2227 \u00ac American x\nconstant ax_pro_jump : \u2200 x, ProBB x \u2192 CanJumpShot x\nconstant ax_jump_leap : \u2200 x, CanJumpShot x \u2192 LeapsStraightUp x\nconstant ax_leap_legs : \u2200 x, LeapsStraightUp x \u2192 ActivatesLegs x\nconstant ax_yuri_not_legs : \u00ac ActivatesLegs Yuri\n\n-- Derived lemmas\nlemma pro_imp_legs (x : Person) (hp : ProBB x) : ActivatesLegs x :=\n  ax_leap_legs x (ax_jump_leap x (ax_pro_jump x hp))\n\nlemma not_legs_not_pro (x : Person) (hnl : \u00ac ActivatesLegs x) : \u00ac ProBB x :=\nby\n  intro hp\n  exact hnl (pro_imp_legs x hp)\n\nlemma yuri_not_pro : \u00ac ProBB Yuri :=\n  not_legs_not_pro Yuri ax_yuri_not_legs\n\nlemma yuri_not_leap : \u00ac LeapsStraightUp Yuri :=\nby\n  intro h\n  exact ax_yuri_not_legs (ax_leap_legs Yuri h)\n\n-- Q2: Yuri is not an American professional basketball player.\n-- i.e., \u00ac (American Yuri \u2227 ProBB Yuri)\ntheorem Q2 : \u00ac (American Yuri \u2227 ProBB Yuri) :=\nby\n  intro h\n  exact yuri_not_pro h.right\n\n-- Q3 (negation is provable): Yuri is an American professional basketball player is false.\ntheorem Q3_neg : \u00ac (American Yuri \u2227 ProBB Yuri) := Q2\n\n-- Q4 (negation is provable): \u00ac( (\u00ac LeapsStraightUp Yuri) \u2192 (American Yuri \u2227 ProBB Yuri) )\ntheorem Q4_neg : \u00ac ( (\u00ac LeapsStraightUp Yuri) \u2192 (American Yuri \u2227 ProBB Yuri) ) :=\nby\n  intro h\n  have hAP : American Yuri \u2227 ProBB Yuri := h yuri_not_leap\n  exact yuri_not_pro hAP.right\n\n-- Q5 (negation is provable): \u00ac( (\u00ac(American Yuri \u2227 ProBB Yuri)) \u2192 ProBB Yuri )\ntheorem Q5_neg : \u00ac ( (\u00ac(American Yuri \u2227 ProBB Yuri)) \u2192 ProBB Yuri ) :=\nby\n  intro h\n  have hnot : \u00ac(American Yuri \u2227 ProBB Yuri) := Q2\n  have hp : ProBB Yuri := h hnot\n  exact yuri_not_pro hp\n\n\nAnswers:\n- Q1: Unknown. The premises do not constrain Yuri\u2019s nationality. Unknown\n- Q2: True. From \u00acActivatesLegs(Yuri) and the chain Pro \u2192 Jump \u2192 Leap \u2192 ActivatesLegs, we get \u00acPro(Yuri), hence \u00ac(American(Yuri) \u2227 Pro(Yuri)). True\n- Q3: False. Being an American professional basketball player implies Pro(Yuri), but we proved \u00acPro(Yuri). False\n- Q4: False. We have \u00acLeapsStraightUp(Yuri) from \u00acActivatesLegs(Yuri) and Leap \u2192 ActivatesLegs; the implication would then assert American(Yuri) \u2227 Pro(Yuri), contradicting \u00acPro(Yuri). False\n- Q5: False. Since \u00acPro(Yuri), the antecedent \u00ac(American(Yuri) \u2227 Pro(Yuri)) holds, but the consequent Pro(Yuri) is false. False\n\nTrue/False/Unknown status justified by the Lean proofs above:\n- Q1: Unknown\n- Q2: True\n- Q3: False\n- Q4: False\n- Q5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1313,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1314,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1315,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 4,
        "example_id": 1316,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1317,
        "conclusion": "If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.4
  },
  {
    "story_id": 280,
    "premises": "Events are either happy or sad.\nAt least one event is happy. ",
    "gpt_response": "Lean translation and proof attempt:\n\n- Domain: events\n- Predicates: Happy, Sad\n- Assumptions:\n  1) Every event is either happy or sad, but not both (exclusive or).\n  2) There exists at least one happy event.\n- Goal: Determine whether \u2200 e, Sad e holds.\n\nLean code:\n\nuniverse u\n\nconstant Event : Type u\nconstant Happy : Event \u2192 Prop\nconstant Sad   : Event \u2192 Prop\n\n-- \"Either ... or\" taken as exclusive or\naxiom either_exclusive : \u2200 e : Event, (Happy e \u2228 Sad e) \u2227 \u00ac (Happy e \u2227 Sad e)\naxiom exists_happy     : \u2203 e : Event, Happy e\n\ndef AllEventsSad : Prop := \u2200 e : Event, Sad e\n\n-- We prove the negation of the target statement.\ntheorem not_AllEventsSad : \u00ac AllEventsSad := by\n  intro h_all_sad\n  rcases exists_happy with \u27e8e0, he0_happy\u27e9\n  have he0_sad : Sad e0 := h_all_sad e0\n  have h_not_both : \u00ac (Happy e0 \u2227 Sad e0) := (either_exclusive e0).2\n  exact h_not_both \u27e8he0_happy, he0_sad\u27e9\n\nConclusion: Since we can prove the negation of \u201cAll events are sad,\u201d the statement is false.\n\nFalse",
    "results": [
      {
        "question_num": 1,
        "example_id": 724,
        "conclusion": "All events are sad.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 140,
    "premises": "The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.",
    "gpt_response": "Lean formalization and proofs attempt:\n\nuniverse u\n\nconstant Person : Type\n\nconstants steinhauer descampe : Person\n\n-- Predicates (all for the 1992 du Maurier Classic)\nconstant Winner : Person \u2192 Prop\nconstant Participated : Person \u2192 Prop\nconstant OnLeaderboard : Person \u2192 Prop\nconstant InSixWayTie : Person \u2192 Prop\nconstant FromBelgium : Person \u2192 Prop\n\n-- Facts from the text\naxiom hWinner : Winner steinhauer\naxiom hSteinPart : Participated steinhauer\naxiom hDescampeBelg : FromBelgium descampe\naxiom hDescampeOnLb : OnLeaderboard descampe\naxiom hTieBelgianExists : \u2203 p, InSixWayTie p \u2227 FromBelgium p\naxiom hTieOnLeaderboard : \u2200 p, InSixWayTie p \u2192 OnLeaderboard p\naxiom hLeaderboardParticipated : \u2200 p, OnLeaderboard p \u2192 Participated p\n\n-- Q1: \u201cSteinhauer was not the winner\u201d\ndef Q1_stmt : Prop := \u00ac Winner steinhauer\n\n-- We can prove the negation of Q1_stmt from hWinner\ntheorem Q1_neg : \u00ac Q1_stmt := by\n  intro h\n  exact h hWinner\n\n-- Q2: \u201cDescampe is in the six-way tie\u201d\ndef Q2_stmt : Prop := InSixWayTie descampe\n-- From the given axioms, we cannot derive Q2_stmt nor its negation.\n\n\nAnswers:\n\n- Question 1: The text states explicitly that the winner was Steinhauer, so \u201cSteinhauer was not the winner\u201d is false. False\n\n- Question 2: We only know there exists at least one Belgian in the six-way tie and that Descampe is Belgian and on the leaderboard; nothing entails that Descampe is the Belgian in the tie, nor that he isn\u2019t. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 411,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 412,
        "conclusion": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 459,
    "premises": "Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.",
    "gpt_response": "Lean formalization of the context:\n\nuniverse u\n\nconstant Entity : Type u\n\nconstants Animal Dog Barks Jumps HasLegs Terricolous : Entity \u2192 Prop\nconstant Likes : Entity \u2192 Entity \u2192 Prop\n\nconstants Jane KiKi : Entity\n\naxiom A1 : \u2200 x, (Animal x \u2227 Barks x) \u2192 \u00ac Likes Jane x\naxiom A2 : \u2200 x, Dog x \u2192 (Animal x \u2227 Barks x)\naxiom A3 : \u2200 x, (Animal x \u2227 Jumps x) \u2192 Likes Jane x\naxiom A4 : \u2200 x, (Animal x \u2227 HasLegs x) \u2192 Jumps x\naxiom A5 : \u2200 x, (Animal x \u2227 Terricolous x) \u2192 HasLegs x\naxiom A6 : Animal KiKi\naxiom A7 : (\u00ac Jumps KiKi \u2227 \u00ac HasLegs KiKi) \u2192 (Terricolous KiKi \u2228 HasLegs KiKi)\n\nAttempted theorems (not provable from the axioms; neither their negations are provable either):\n\n-- Q1: Terricolous KiKi\n-- Not derivable: from A6\u2013A7 we cannot conclude Terricolous KiKi without further premises.\n-- theorem Q1 : Terricolous KiKi := by sorry\n\n-- Q2: Dog KiKi \u2227 Barks KiKi\n-- Not derivable: we have no information that KiKi is a dog.\n-- theorem Q2 : Dog KiKi \u2227 Barks KiKi := by sorry\n\n-- Q3: \u00ac Barks KiKi \u2227 \u00ac Dog KiKi\n-- Not derivable: nothing rules out KiKi being a barking dog.\n-- theorem Q3 : \u00ac Barks KiKi \u2227 \u00ac Dog KiKi := by sorry\n\nAnswers:\n\n1) KiKi is terricolous.\nReason: Not entailed by the premises; the special conditional about KiKi does not force terricolous, and there is no other rule implying it. Unknown\n\n2) KiKi is a barking dog.\nReason: We have no information that KiKi is a dog (and hence barks). Unknown\n\n3) KiKi does not bark and he is not a dog.\nReason: Also not entailed; nothing rules out KiKi being a dog that barks. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1324,
        "conclusion": "KiKi is terricolous.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1325,
        "conclusion": "KiKi is a barking dog.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1326,
        "conclusion": "KiKi does not bark and he is not a dog.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 101,
    "premises": "Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.",
    "gpt_response": "Lean formalization and proofs:\n\n-- We model persons, clubs, and the stated facts.\nuniverse u\n\nconstant Person : Type\nconstant Club   : Type\n\nconstant Ailton       : Person\nconstant AiltonSilva  : Person\nconstant Nautico      : Club\nconstant Braga        : Club\nconstant Fluminense   : Club\n\nconstant PlaysFor   : Person \u2192 Club \u2192 Prop\nconstant LoanedTo   : Person \u2192 Club \u2192 Prop\nconstant Brazilian  : Person \u2192 Prop\nconstant Footballer : Person \u2192 Prop\n\n-- Facts from the text\naxiom alias               : Ailton = AiltonSilva\naxiom brazil_AS           : Brazilian AiltonSilva\naxiom footballer_AS       : Footballer AiltonSilva\naxiom plays_AS_Nautico    : PlaysFor AiltonSilva Nautico\naxiom loan_Ailton_Braga   : LoanedTo Ailton Braga\n\n-- Questions as propositions\ndef Q1 : Prop := \u2200 x : Person, PlaysFor x Nautico \u2192 \u00ac Brazilian x\ndef Q2 : Prop := \u00ac \u2203 c : Club, PlaysFor AiltonSilva c\ndef Q3 : Prop := \u00ac \u2203 c : Club, LoanedTo Ailton c\ndef Q4 : Prop := PlaysFor AiltonSilva Fluminense\ndef Q5 : Prop := \u2203 c : Club, LoanedTo AiltonSilva c\n\n-- Proofs (or their negations)\ntheorem Q1_false : \u00ac Q1 := by\n  intro h\n  have h1 : \u00ac Brazilian AiltonSilva := h AiltonSilva plays_AS_Nautico\n  exact h1 brazil_AS\n\ntheorem Q2_false : \u00ac Q2 := by\n  intro h\n  apply h\n  exact \u27e8Nautico, plays_AS_Nautico\u27e9\n\ntheorem Q3_false : \u00ac Q3 := by\n  intro h\n  apply h\n  exact \u27e8Braga, loan_Ailton_Braga\u27e9\n\n-- We cannot derive either Q4 or its negation from the given facts.\n\ntheorem Q5_true : Q5 := by\n  have : LoanedTo AiltonSilva Braga := by simpa [alias] using loan_Ailton_Braga\n  exact \u27e8Braga, this\u27e9\n\nAnswers:\n1) False\n2) False\n3) False\n4) Unknown\n5) True",
    "results": [
      {
        "question_num": 1,
        "example_id": 304,
        "conclusion": "No one playing for Nautico is Brazilian.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 305,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 306,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 307,
        "conclusion": "Ailton Silva played for Fluminense.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 5,
        "example_id": 308,
        "conclusion": "Ailton Silva was loaned out to a football club.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.6
  }
]