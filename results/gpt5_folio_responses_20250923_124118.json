[
  {
    "story_id": 380,
    "premises": "People in this club who perform in school talent shows often attend and are very engaged with school events.\nPeople in this club either perform in school talent shows often or are inactive and disinterested community members.\nPeople in this club who chaperone high school dances are not students who attend the school.\nAll people in this club who are inactive and disinterested members of their community chaperone high school dances.\nAll young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \nBonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school.",
    "gpt_response": "Lean formalization and attempt:\n\n-- Universe and basic setup\nuniverse u\nconstant Person : Type\n\n-- Predicates\nconstants InClub Perform AttendEngaged Inactive Chaperone Student YT Wish : Person \u2192 Prop\n\n-- Individual\nconstant Bonnie : Person\n\n-- Axioms from the textual context\naxiom A1 : \u2200 x, InClub x \u2227 Perform x \u2192 AttendEngaged x\naxiom A2 : \u2200 x, InClub x \u2192 (Perform x \u2228 Inactive x)\naxiom A3 : \u2200 x, InClub x \u2227 Chaperone x \u2192 \u00ac Student x\naxiom A4 : \u2200 x, InClub x \u2227 Inactive x \u2192 Chaperone x\naxiom A5 : \u2200 x, InClub x \u2227 YT x \u2227 Wish x \u2192 Student x\naxiom Bonnie_in : InClub Bonnie\n-- Bonnie's given equivalence as a disjunction:\n-- (AttendEngaged \u2227 Student) \u2228 (\u00acAttendEngaged \u2227 \u00acStudent)\naxiom Bonnie_link : (AttendEngaged Bonnie \u2227 Student Bonnie) \u2228 (\u00ac AttendEngaged Bonnie \u2227 \u00ac Student Bonnie)\n\nopen Classical\n\n-- From Bonnie_link, derive the two implications AttendEngaged \u2192 Student and Student \u2192 AttendEngaged\nlemma Bonnie_A_imp_S : AttendEngaged Bonnie \u2192 Student Bonnie := by\n  intro hA\n  cases Bonnie_link with\n  | inl h => exact h.2\n  | inr h =>\n      have : False := h.1 hA\n      exact False.elim this\n\nlemma Bonnie_S_imp_A : Student Bonnie \u2192 AttendEngaged Bonnie := by\n  intro hS\n  cases Bonnie_link with\n  | inl h => exact h.1\n  | inr h =>\n      have : False := h.2 hS\n      exact False.elim this\n\n-- A useful unconditional disjunction: Bonnie is a Student or Inactive\nlemma Bonnie_student_or_inactive : Student Bonnie \u2228 Inactive Bonnie := by\n  have h := A2 Bonnie Bonnie_in\n  cases h with\n  | inl hPerf =>\n      have hA := A1 Bonnie \u27e8Bonnie_in, hPerf\u27e9\n      exact Or.inl (Bonnie_A_imp_S hA)\n  | inr hInact =>\n      exact Or.inr hInact\n\n-- Q2: The implication holds unconditionally (hence is provable)\n-- If ((YT \u2227 Wish) \u2227 Chaperone) \u2228 \u00ac(YT \u2227 Wish) then Student \u2228 Inactive.\ntheorem Q2 :\n  (((YT Bonnie \u2227 Wish Bonnie) \u2227 Chaperone Bonnie) \u2228 \u00ac (YT Bonnie \u2227 Wish Bonnie))\n  \u2192 (Student Bonnie \u2228 Inactive Bonnie) := by\n  intro _\n  exact Bonnie_student_or_inactive\n\n\nDiscussion of the three questions:\n\n- Q1: \u201cBonnie performs in school talent shows often.\u201d From A2 we only get Perform Bonnie \u2228 Inactive Bonnie. If Inactive, then by A4 and A3 we get \u00acStudent, which is consistent with Bonnie_link\u2019s second disjunct. If Perform, then via A1 and Bonnie_link we get Student. Both branches are consistent, so Perform Bonnie is not derivable nor refutable. Unknown\n\n- Q2: \u201cIf Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.\u201d As shown in theorem Q2, Student Bonnie \u2228 Inactive Bonnie holds unconditionally (via A2, A1, Bonnie_link), so the implication is provable. True\n\n- Q3: \u201cIf Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.\u201d The antecedent simplifies to Chaperone Bonnie \u2228 Perform Bonnie, which is always satisfied under the given axioms (A2 plus A4 yield Perform \u2228 Chaperone). The consequent asserts (YT Bonnie \u2227 Wish Bonnie) \u2227 Inactive Bonnie, which we cannot derive from the premises, nor can we derive its negation. Hence the implication is not provable nor refutable from the given information. Unknown\n\nAnswers:\n- Question 1: Unknown\n- Question 2: True\n- Question 3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1014,
        "conclusion": "Bonnie performs in school talent shows often.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1015,
        "conclusion": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1016,
        "conclusion": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 426,
    "premises": "All employees who schedule a meeting with their customers will go to the company building today. \nEveryone who has lunch in the company building schedules meetings with their customers. \nEmployees have lunch either in the company building or at home.\nIf an employee has lunch at home, they are working remotely from home.\nAll employees who are in other countries work remotely from home. \nNo managers work remotely from home. \nJames will appear in the company today if and only if he is a manager.",
    "gpt_response": "Lean translation and attempted proofs:\n\n-- Domain and predicates\nuniverse u\n\nconstant Person : Type u\n\nconstants\n  Employee          : Person \u2192 Prop\n  Manager           : Person \u2192 Prop\n  InOtherCountries  : Person \u2192 Prop\n  LunchInBuilding   : Person \u2192 Prop\n  LunchAtHome       : Person \u2192 Prop\n  RemoteFromHome    : Person \u2192 Prop\n  SchedulesMeeting  : Person \u2192 Prop\n  GoesBuildingToday : Person \u2192 Prop\n  AppearsToday      : Person \u2192 Prop\n\nconstant James : Person\n\n-- Axioms extracted from the textual context\naxiom A1 : \u2200 x : Person, Employee x \u2227 SchedulesMeeting x \u2192 GoesBuildingToday x\naxiom A2 : \u2200 x : Person, LunchInBuilding x \u2192 SchedulesMeeting x\naxiom A3 : \u2200 x : Person, Employee x \u2192 (LunchInBuilding x \u2228 LunchAtHome x)\naxiom A4 : \u2200 x : Person, Employee x \u2227 LunchAtHome x \u2192 RemoteFromHome x\naxiom A5 : \u2200 x : Person, Employee x \u2227 InOtherCountries x \u2192 RemoteFromHome x\naxiom A6 : \u2200 x : Person, Manager x \u2192 \u00ac RemoteFromHome x\naxiom A7 : AppearsToday James \u2194 Manager James\n\n-- Targets (questions)\n\n-- Q1: James has lunch in the company (building).\n-- Attempt to prove: LunchInBuilding James\n-- There is no way to derive LunchInBuilding James from the axioms (no information that James is an employee, etc.).\n-- Likewise, its negation is not derivable from the axioms.\n-- Hence unprovable in this theory.\n\n-- theorem Q1 : LunchInBuilding James := by\n--   -- No derivation available from the given axioms.\n--   sorry\n\n-- theorem Q1_neg : \u00ac LunchInBuilding James := by\n--   -- Also not derivable.\n--   sorry\n\n\n-- Q2: James does not have lunch in the company.\n-- Attempt to prove: \u00ac LunchInBuilding James\n-- Same situation as Q1; neither statement nor its negation is derivable.\n\n-- theorem Q2 : \u00ac LunchInBuilding James := by\n--   -- Not derivable.\n--   sorry\n\n-- theorem Q2_neg : \u00ac (\u00ac LunchInBuilding James) := by\n--   -- Not derivable.\n--   sorry\n\n\n-- Q3: (Manager James \u2228 InOtherCountries James) \u2192 \u00ac (LunchAtHome James \u2228 RemoteFromHome James)\n--     \u2227 (LunchAtHome James \u2228 RemoteFromHome James) \u2192 (\u00ac Manager James \u2227 \u00ac InOtherCountries James)\n--\n-- From A6 we have Manager \u2192 \u00ac RemoteFromHome, but we cannot derive \u00ac LunchAtHome\n-- unless we also know Employee James (to use A4: LunchAtHome \u2192 RemoteFromHome).\n-- We have no information that James is an Employee.\n-- For InOtherCountries, we only get RemoteFromHome if Employee James (A5), which again is unknown.\n-- Thus neither the claimed implication nor its negation is derivable from the axioms.\n\ndef Claim3 : Prop :=\n  (Manager James \u2228 InOtherCountries James) \u2192 \u00ac (LunchAtHome James \u2228 RemoteFromHome James)\n  \u2227 (LunchAtHome James \u2228 RemoteFromHome James) \u2192 (\u00ac Manager James \u2227 \u00ac InOtherCountries James)\n\n-- theorem Q3 : Claim3 := by\n--   -- Not derivable from the given axioms.\n--   sorry\n\n-- theorem Q3_neg : \u00ac Claim3 := by\n--   -- Also not derivable.\n--   sorry\n\n\nAnswers:\n\n1) Unknown\n2) Unknown\n3) Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1208,
        "conclusion": "James has lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1209,
        "conclusion": "James does not have lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1210,
        "conclusion": "If James is either a manager or in other countries,  then James does not either has lunch at home or work remotely from home. If James either has lunch at home or works remotely from home, then he is neither a manager nor does he work in other countries. [contrapositive is more natural]",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 198,
    "premises": "When the Monkeypox virus occurs in a being, it may get Monkeypox. \nMonkeypox virus can occur in certain animals.\nHumans are mammals.\nMammals are animals.\nSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness. \nPeople feel tired when they get the flu.",
    "gpt_response": "Lean 4 formalization and attempt at proofs:\n\nset_option autoImplicit false\nset_option pp.unicode true\nset_option pp.colors false\nset_option sorryAllowed true\n\nuniverse u\n\nconstant Being : Type u\n\n-- Predicates\nconstant Animal Human Mammal : Being \u2192 Prop\nconstant OccursVirus : Being \u2192 Prop        -- Monkeypox virus occurs in\nconstant MayGetMonkeypox : Being \u2192 Prop    -- may get Monkeypox (possibility)\nconstant HasMonkeypox : Being \u2192 Prop\nconstant Fever Headache MusclePain Tired Coughing Flu : Being \u2192 Prop\n\n-- Axioms from the textual context\n\n-- 1) When the Monkeypox virus occurs in a being, it may get Monkeypox.\naxiom ax_occurs_implies_mayget : \u2200 x : Being, OccursVirus x \u2192 MayGetMonkeypox x\n\n-- 2) Monkeypox virus can occur in certain animals. (Existence of some animals with the virus)\naxiom ax_exists_animal_with_virus : \u2203 x : Being, Animal x \u2227 OccursVirus x\n\n-- 3) Humans are mammals.\naxiom ax_human_mammal : \u2200 x : Being, Human x \u2192 Mammal x\n\n-- 4) Mammals are animals.\naxiom ax_mammal_animal : \u2200 x : Being, Mammal x \u2192 Animal x\n\n-- 5) Symptoms of Monkeypox include fever, headache, muscle pains, and tiredness.\naxiom ax_monkeypox_symptoms :\n  \u2200 x : Being, HasMonkeypox x \u2192 Fever x \u2227 Headache x \u2227 MusclePain x \u2227 Tired x\n\n-- 6) People feel tired when they get the flu.\naxiom ax_flu_tired : \u2200 x : Being, Flu x \u2192 Tired x\n\n-- Question 1: There is an animal.\ntheorem Q1 : \u2203 x : Being, Animal x := by\n  rcases ax_exists_animal_with_virus with \u27e8x, hxA, _hxV\u27e9\n  exact \u27e8x, hxA\u27e9\n\n-- Question 2: No one gets the flu. (i.e., \u2200 x, \u00ac Flu x)\ntheorem Q2 : \u2200 x : Being, \u00ac Flu x := by\n  -- Not derivable from the given axioms.\n  sorry\n\n-- Question 3: Symptoms of Monkeypox include coughing. (i.e., \u2200 x, HasMonkeypox x \u2192 Coughing x)\ntheorem Q3 : \u2200 x : Being, HasMonkeypox x \u2192 Coughing x := by\n  -- Not derivable from the given axioms.\n  sorry\n\n-- We proved Q1. We could not prove Q2 or Q3, nor their negations, from the given axioms.\n\n\nAnswers:\n1) There is an animal. True\n2) No one gets the flu. Unknown\n3) Symptoms of Monkeypox include coughing. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 563,
        "conclusion": "There is an animal.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 564,
        "conclusion": "No one gets the flu.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 565,
        "conclusion": "Symptoms of Monkeypox include coughing.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 20,
    "premises": "A Japanese game company created the game the Legend of Zelda.\nAll games on the Top 10 list are made by Japanese game companies.\nIf a game sells more than one million copies, then it will be included in the Top 10 list.\nThe Legend of Zelda sold more than one million copies.",
    "gpt_response": "Lean formalization and proofs:\n\nnamespace QA\n\nconstant Game : Type\nconstant OnTop10 : Game \u2192 Prop\nconstant MadeByJapaneseCompany : Game \u2192 Prop\nconstant SoldMoreThan1M : Game \u2192 Prop\nconstant zelda : Game\nconstant fifa22 : Game\n\naxiom A1 : MadeByJapaneseCompany zelda\naxiom A2 : \u2200 g : Game, OnTop10 g \u2192 MadeByJapaneseCompany g\naxiom A3 : \u2200 g : Game, SoldMoreThan1M g \u2192 OnTop10 g\naxiom A4 : SoldMoreThan1M zelda\n\n-- Q1: The Legend of Zelda is on the Top 10 list.\ntheorem q1 : OnTop10 zelda := by\n  exact (A3 zelda) A4\n\n-- Q2 (cannot be proven outright): we can only derive it from being Top 10.\ntheorem q2_conditional : OnTop10 fifa22 \u2192 MadeByJapaneseCompany fifa22 := by\n  intro h\n  exact A2 fifa22 h\n\n-- Q3: \"The Legend of Zelda is not on the Top 10 list\" is false.\ntheorem q3_false : \u00ac (\u00ac OnTop10 zelda) := by\n  intro hn\n  exact hn q1\n\nend QA\n\nAnswers:\n1) Yes. From \u201csold more than one million copies\u201d and \u201cif a game sells more than one million copies, then it\u2019s on the Top 10 list,\u201d it follows that The Legend of Zelda is on the Top 10 list. True\n2) Uncertain. We have no information about FIFA 22\u2019s sales or Top 10 status; thus we cannot conclude it is made by a Japanese company. Unknown\n3) No. Since The Legend of Zelda is on the Top 10 list, the statement that it is not on the Top 10 list is false. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 57,
        "conclusion": "The Legend of Zelda is on the Top 10 list.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 58,
        "conclusion": "FIFA 22 is made by a Japanese video game company.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 59,
        "conclusion": "The Legend of Zelda is not on the Top 10 list.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 282,
    "premises": "All squares are four-sided.\nAll four-sided things are shapes. ",
    "gpt_response": "Lean formalization and proof:\n\nuniverse u\nvariable (U : Type u) (Square FourSided Shape : U \u2192 Prop)\n\ntheorem squares_are_shapes\n  (h1 : \u2200 x, Square x \u2192 FourSided x)\n  (h2 : \u2200 x, FourSided x \u2192 Shape x) :\n  \u2200 x, Square x \u2192 Shape x :=\nby\n  intro x hx\n  exact h2 x (h1 x hx)\n\nAnswer: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 726,
        "conclusion": "All squares are shapes.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 471,
    "premises": "All rabbits that can be spotted near the campus are cute. \nSome turtles can be spotted near the campus. \nThe only animals that can be spotted near the campus are rabbits and squirrels.\nIf something is skittish, then it is not calm.\nAll the squirrels that can be spotted near the campus are skittish.\nRockie can be spotted near the campus, and it is calm.",
    "gpt_response": "Natural language conclusions:\n- From \u201cRockie can be spotted near the campus\u201d and \u201conly rabbits and squirrels can be spotted near the campus,\u201d Rockie is either a rabbit or a squirrel.\n- From \u201cAll squirrels near the campus are skittish\u201d and \u201cskittish implies not calm,\u201d but Rockie is calm, Rockie cannot be a squirrel. Hence Rockie is a rabbit.\n- From \u201cAll rabbits near the campus are cute,\u201d Rockie is cute.\n- Nothing given decides whether Rockie is a turtle.\n\nAnswers:\n1) Rockie is a turtle. Unknown\n2) Rockie is not a turtle. Unknown\n3) Rockie is a turtle or cute. True\n4) If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish. True\n5) If Rockie is cute and calm, then Rockie is a skittish turtle. False\n\nLean 4 formalization and proofs:\n\n-- Setup\nuniverse u\n\nconstant Animal : Type u\nconstant Rabbit Turtle Squirrel Near Cute Skittish Calm : Animal \u2192 Prop\nconstant Rockie : Animal\n\naxiom A1 : \u2200 x : Animal, Rabbit x \u2227 Near x \u2192 Cute x\naxiom A2 : \u2203 x : Animal, Turtle x \u2227 Near x\naxiom A3 : \u2200 x : Animal, Near x \u2192 (Rabbit x \u2228 Squirrel x)\naxiom A4 : \u2200 x : Animal, Skittish x \u2192 \u00ac Calm x\naxiom A5 : \u2200 x : Animal, Squirrel x \u2227 Near x \u2192 Skittish x\naxiom A6 : Near Rockie \u2227 Calm Rockie\n\n-- Derived facts about Rockie\nlemma rockie_near : Near Rockie :=\n  A6.left\n\nlemma rockie_calm : Calm Rockie :=\n  A6.right\n\nlemma rockie_not_squirrel : \u00ac Squirrel Rockie := by\n  intro hSq\n  have hSk : Skittish Rockie := A5 Rockie \u27e8hSq, rockie_near\u27e9\n  have hNotCalm : \u00ac Calm Rockie := A4 Rockie hSk\n  exact hNotCalm rockie_calm\n\nlemma rockie_rabbit : Rabbit Rockie := by\n  have h := A3 Rockie rockie_near\n  cases h with\n  | inl hRab => exact hRab\n  | inr hSq =>\n      exact False.elim (rockie_not_squirrel hSq)\n\nlemma rockie_cute : Cute Rockie :=\n  A1 Rockie \u27e8rockie_rabbit, rockie_near\u27e9\n\n-- Q1: Rockie is a turtle.\n-- Not derivable from the axioms; no proof or refutation provided.\n\n-- Q2: Rockie is not a turtle.\n-- Not derivable from the axioms; no proof or refutation provided.\n\n-- Q3: Rockie is a turtle or cute.\ntheorem Q3 : Turtle Rockie \u2228 Cute Rockie :=\n  Or.inr rockie_cute\n\n-- Q4: If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.\ntheorem Q4 : (\u00ac (Turtle Rockie \u2227 Squirrel Rockie)) \u2192 (Cute Rockie \u2228 Skittish Rockie) := by\n  intro _\n  exact Or.inl rockie_cute\n\n-- Useful lemma: Rockie is not skittish (since Rockie is calm and skittish \u2192 \u00ac calm)\nlemma rockie_not_skittish : \u00ac Skittish Rockie := by\n  intro hSk\n  have hNotCalm : \u00ac Calm Rockie := A4 Rockie hSk\n  exact hNotCalm rockie_calm\n\n-- Q5: If Rockie is cute and calm, then Rockie is a skittish turtle. (We prove the negation.)\ntheorem Q5_neg : \u00ac ((Cute Rockie \u2227 Calm Rockie) \u2192 (Skittish Rockie \u2227 Turtle Rockie)) := by\n  -- Provide a counterexample: Rockie is cute and calm, but not skittish.\n  apply by_contra\n  intro hImp\n  -- From hImp, feeding (Cute \u2227 Calm) yields (Skittish \u2227 Turtle), contradicting \u00acSkittish\n  have hPrem : Cute Rockie \u2227 Calm Rockie := \u27e8rockie_cute, rockie_calm\u27e9\n  have hConc : Skittish Rockie \u2227 Turtle Rockie := hImp hPrem\n  exact rockie_not_skittish hConc.left\n\nSummary of provability in Lean:\n- Q1: Unknown (neither provable nor refutable from the axioms).\n- Q2: Unknown (neither provable nor refutable from the axioms).\n- Q3: Provable (True).\n- Q4: Provable (True).\n- Q5: Its negation is provable (so the statement is False).\n\nOverall: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1361,
        "conclusion": "Rockie is a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1362,
        "conclusion": "Rockie is not a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1363,
        "conclusion": "Rockie is a turtle or cute.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1364,
        "conclusion": "If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1365,
        "conclusion": "If Rockie is cute and calm, then Rockie is a skittish turtle.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 184,
    "premises": "\"Stranger Things\" is a popular Netflix show.\nIf a Netflix show is popular, Karen will binge-watch it.\nIf and only if Karen binge-watches a Netflix show, she will download it.\nKaren does not download \"Black Mirror.\"\n\"Black Mirror\" is a Netflix show.\nIf Karen binge-watches a Netflix show, she will share it with Lisa.",
    "gpt_response": "Lean translation and proofs:\n\nuniverse u\n\nconstant Show : Type u\nconstant st : Show    -- \"Stranger Things\"\nconstant bm : Show    -- \"Black Mirror\"\n\n-- Predicates about shows (with respect to Karen and Lisa where relevant)\nconstant popular  : Show \u2192 Prop\nconstant netflix  : Show \u2192 Prop\nconstant binge    : Show \u2192 Prop          -- Karen binge-watches the show\nconstant download : Show \u2192 Prop          -- Karen downloads the show\nconstant share    : Show \u2192 Prop          -- Karen shares the show with Lisa\n\n-- Axioms from the textual context\naxiom popular_st : popular st\naxiom netflix_st : netflix st\naxiom pop_netflix_implies_binge : \u2200 s, (netflix s \u2227 popular s) \u2192 binge s\naxiom binge_iff_download_on_netflix : \u2200 s, netflix s \u2192 (binge s \u2194 download s)\naxiom not_download_bm : \u00ac download bm\naxiom netflix_bm : netflix bm\naxiom binge_implies_share_on_netflix : \u2200 s, netflix s \u2192 (binge s \u2192 share s)\n\n-- Q1: Karen will share \"Stranger Things\" with Lisa.\ntheorem Q1_share_st : share st := by\n  have hbinge : binge st := by\n    exact pop_netflix_implies_binge st \u27e8netflix_st, popular_st\u27e9\n  exact binge_implies_share_on_netflix st netflix_st hbinge\n\n-- Helper: derive \u00ac binge bm from the download biconditional and not_download_bm\nlemma not_binge_bm : \u00ac binge bm := by\n  intro hb\n  have hbiff : binge bm \u2194 download bm := binge_iff_download_on_netflix bm netflix_bm\n  have hd : download bm := (hbiff.mp) hb\n  exact not_download_bm hd\n\n-- Q2: \"Black Mirror\" is popular. We derive a contradiction, so it's false.\ntheorem Q2_not_popular_bm : \u00ac popular bm := by\n  intro hpop\n  have hb : binge bm := pop_netflix_implies_binge bm \u27e8netflix_bm, hpop\u27e9\n  exact not_binge_bm hb\n\n-- Q3: We cannot prove share bm nor its negation from the given axioms.\n-- We do know \u00ac binge bm, and only have (binge \u2192 share), so neither direction yields share bm or \u00ac share bm.\n\n\nAnswers:\n- Question 1: Yes, because Stranger Things is a popular Netflix show, so Karen binge-watches it, and then shares it with Lisa. True\n- Question 2: No, because if it were popular (and it is a Netflix show), Karen would binge-watch it, which would imply she downloaded it, contradicting that she did not download it. False\n- Question 3: Uncertain, because we only know that if Karen binge-watches a Netflix show, she shares it; here we know she does not binge-watch Black Mirror, but that does not imply she does not share it. Unknown\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 530,
        "conclusion": "Karen will share \"Stranger Things\" with Lisa.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 531,
        "conclusion": "\"Black Mirror\" is popular.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 532,
        "conclusion": "Karen will share \"Black Mirror\" with Lisa.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 232,
    "premises": "Beijing is the capital of the People's Republic of China. \nBeijing is the capital city of the world's most populous nation.\nBeijing is located in Northern China.\nBeijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nBeijing has hosted the Summer and Winter Olympics and the Summer and Winter Paralympics.\nMany of Beijing's 91 universities consistently rank among the best universities in the world.",
    "gpt_response": "Below is a Lean formalization of the given textual context, followed by formal statements and proofs (when possible) for each question.\n\nLean setup (shared context and axioms extracted from the text):\n- We model Beijing as a city and introduce predicates for the relevant properties.\n- We include the facts stated in the text as axioms.\n- We also include a natural geography axiom that a city located in Northern China is not located in Southern China.\n\n-- Universe and basic entities\nuniverse u\nconstant City : Type u\nconstant Beijing : City\n\n-- Predicates\nconstant CapitalOfPRC : City \u2192 Prop\nconstant CapitalOfMostPopulousNation : City \u2192 Prop\nconstant LocatedNorthernChina : City \u2192 Prop\nconstant LocatedSouthernChina : City \u2192 Prop\nconstant Hosted2008SummerOlympics : City \u2192 Prop\nconstant Hosted2008SummerParalympics : City \u2192 Prop\nconstant HostedWinterOlympics : City \u2192 Prop\nconstant HostedWinterParalympics : City \u2192 Prop\nconstant ManyTopUniversities : City \u2192 Prop\n\n-- Facts from the text\naxiom fact_capital_PRC : CapitalOfPRC Beijing\naxiom fact_capital_most_populous : CapitalOfMostPopulousNation Beijing\naxiom fact_loc_north : LocatedNorthernChina Beijing\naxiom fact_host_2008_summer_olympics : Hosted2008SummerOlympics Beijing\naxiom fact_host_2008_summer_paralympics : Hosted2008SummerParalympics Beijing\naxiom fact_host_winter_olympics : HostedWinterOlympics Beijing\naxiom fact_host_winter_paralympics : HostedWinterParalympics Beijing\naxiom fact_many_top_universities : ManyTopUniversities Beijing\n\n-- Background geography principle (disjointness of Northern vs Southern)\naxiom north_not_south : \u2200 c : City, LocatedNorthernChina c \u2192 \u00ac LocatedSouthernChina c\n\n\nQuestion 1\nNatural language claim: \u201cBeijing hosted both the 2008 Summer Olympics and the Winter Olympics.\u201d\n\nFormalization in Lean:\ndef Q1 : Prop := Hosted2008SummerOlympics Beijing \u2227 HostedWinterOlympics Beijing\n\nProof of Q1 from the axioms:\ntheorem Q1_true : Q1 :=\n  And.intro fact_host_2008_summer_olympics fact_host_winter_olympics\n\nConclusion for Q1: True\n\n\nQuestion 2\nNatural language claim: \u201cBeijing is located in southern China.\u201d\n\nFormalization in Lean:\ndef Q2 : Prop := LocatedSouthernChina Beijing\n\nFrom the text we have LocatedNorthernChina Beijing, and by the geography axiom, that implies not LocatedSouthernChina Beijing. Hence we can prove \u00acQ2.\n\ntheorem Q2_false : \u00ac Q2 :=\n  north_not_south Beijing fact_loc_north\n\nConclusion for Q2: False\n\n\nQuestion 3\nNatural language claim: \u201cBeijing is the second largest Chinese city.\u201d\n\nWe introduce the predicate but have no supporting facts in the provided text.\n\nconstant SecondLargestChineseCity : City \u2192 Prop\ndef Q3 : Prop := SecondLargestChineseCity Beijing\n\nThere is no information in the provided axioms to prove Q3 or its negation. Therefore, we cannot derive a proof of Q3 nor a proof of \u00acQ3 from the given context.\n\nConclusion for Q3: Unknown\n\nFinal answers:\n- Question 1: True\n- Question 2: False\n- Question 3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 657,
        "conclusion": "Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 658,
        "conclusion": "Beijing is located in southern China.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 659,
        "conclusion": "Beijing is the second largest Chinese city.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 452,
    "premises": "All aliens are extraterrestrials.\nIf someone is from Mars, then they are an alien.\nNo extraterrestrials are human.\nAll highly intelligent beings from Earth are humans.\nMarvin is a highly intelligent being.\nMarvin is either from Earth and from Mars, or he is from neither.\nIf Marvin is not from Earth, then Marvin is an extraterrestrial.",
    "gpt_response": "Here is a Lean 4 formalization of the scenario and proofs for what can be derived.\n\nWe model a domain of beings with predicates and a constant Marvin, and encode the given premises as hypotheses.\n\nnamespace Reasoning\n\nvariable (U : Type)\nvariable (Alien Extraterrestrial Human FromMars FromEarth HighlyIntelligent : U \u2192 Prop)\nvariable (Marvin : U)\n\n-- Premises\nvariable\n  (h1 : \u2200 x, Alien x \u2192 Extraterrestrial x)                                -- All aliens are extraterrestrials.\n  (h2 : \u2200 x, FromMars x \u2192 Alien x)                                        -- If someone is from Mars, then they are an alien.\n  (h3 : \u2200 x, Extraterrestrial x \u2192 \u00ac Human x)                              -- No extraterrestrials are human.\n  (h4 : \u2200 x, HighlyIntelligent x \u2227 FromEarth x \u2192 Human x)                 -- All highly intelligent beings from Earth are humans.\n  (h5 : HighlyIntelligent Marvin)                                         -- Marvin is highly intelligent.\n  (h6 : (FromEarth Marvin \u2227 FromMars Marvin) \u2228 (\u00ac FromEarth Marvin \u2227 \u00ac FromMars Marvin)) -- Marvin is either both from Earth and Mars, or from neither.\n  (h7 : \u00ac FromEarth Marvin \u2192 Extraterrestrial Marvin)                     -- If Marvin is not from Earth, then Marvin is an extraterrestrial.\n\n-- Useful derived facts\n\n-- \u00ac FromEarth Marvin\nlemma not_from_earth : \u00ac FromEarth Marvin := by\n  intro fe\n  -- From the exclusive-like disjunction, get FromMars if FromEarth holds\n  have fm : FromMars Marvin := by\n    cases h6 with\n    | inl h =>\n        exact h.right\n    | inr h =>\n        exact (h.left fe).elim\n  -- From intelligence and Earthness, Marvin is human\n  have hum : Human Marvin := h4 _ \u27e8h5, fe\u27e9\n  -- From Mars \u2192 Alien \u2192 Extraterrestrial\n  have al : Alien Marvin := h2 _ fm\n  have ex : Extraterrestrial Marvin := h1 _ al\n  -- No extraterrestrials are human: contradiction\n  have notHum : \u00ac Human Marvin := h3 _ ex\n  exact notHum hum\n\n-- \u00ac FromMars Marvin\nlemma not_from_mars : \u00ac FromMars Marvin := by\n  -- From the given disjunction and \u00acFromEarth, we must be in the right branch\n  have hneither : (\u00ac FromEarth Marvin \u2227 \u00ac FromMars Marvin) := by\n    cases h6 with\n    | inl h =>\n        exact False.elim ((not_from_earth) h.left)\n    | inr h =>\n        exact h\n  exact hneither.right\n\n-- Extraterrestrial Marvin (from \u00acFromEarth and h7)\nlemma extraterrestrial_marvin : Extraterrestrial Marvin :=\n  h7 (not_from_earth (U := U) (Alien := Alien) (Extraterrestrial := Extraterrestrial)\n                     (Human := Human) (FromMars := FromMars) (FromEarth := FromEarth)\n                     (HighlyIntelligent := HighlyIntelligent)\n                     (Marvin := Marvin) (h1 := h1) (h2 := h2) (h3 := h3) (h4 := h4) (h5 := h5) (h6 := h6) (h7 := h7))\n\n-- \u00ac Human Marvin\nlemma not_human : \u00ac Human Marvin :=\n  h3 _ (extraterrestrial_marvin (U := U) (Alien := Alien) (Extraterrestrial := Extraterrestrial)\n                               (Human := Human) (FromMars := FromMars) (FromEarth := FromEarth)\n                               (HighlyIntelligent := HighlyIntelligent)\n                               (Marvin := Marvin) (h1 := h1) (h2 := h2) (h3 := h3) (h4 := h4) (h5 := h5) (h6 := h6) (h7 := h7))\n\n-- Q2: Marvin is neither a human nor from Mars.\ntheorem Q2 : \u00ac Human Marvin \u2227 \u00ac FromMars Marvin :=\n  And.intro\n    (not_human (U := U) (Alien := Alien) (Extraterrestrial := Extraterrestrial)\n               (Human := Human) (FromMars := FromMars) (FromEarth := FromEarth)\n               (HighlyIntelligent := HighlyIntelligent)\n               (Marvin := Marvin) (h1 := h1) (h2 := h2) (h3 := h3) (h4 := h4) (h5 := h5) (h6 := h6) (h7 := h7))\n    (not_from_mars (U := U) (Alien := Alien) (Extraterrestrial := Extraterrestrial)\n                   (Human := Human) (FromMars := FromMars) (FromEarth := FromEarth)\n                   (HighlyIntelligent := HighlyIntelligent)\n                   (Marvin := Marvin) (h1 := h1) (h2 := h2) (h3 := h3) (h4 := h4) (h5 := h5) (h6 := h6) (h7 := h7))\n\n-- Q3: The negation of \"If Marvin is not from Mars, then Marvin is a human.\"\ntheorem Q3_neg : \u00ac (\u00ac FromMars Marvin \u2192 Human Marvin) := by\n  intro himp\n  have nfm : \u00ac FromMars Marvin :=\n    not_from_mars (U := U) (Alien := Alien) (Extraterrestrial := Extraterrestrial)\n                  (Human := Human) (FromMars := FromMars) (FromEarth := FromEarth)\n                  (HighlyIntelligent := HighlyIntelligent)\n                  (Marvin := Marvin) (h1 := h1) (h2 := h2) (h3 := h3) (h4 := h4) (h5 := h5) (h6 := h6) (h7 := h7)\n  have nh : \u00ac Human Marvin :=\n    not_human (U := U) (Alien := Alien) (Extraterrestrial := Extraterrestrial)\n              (Human := Human) (FromMars := FromMars) (FromEarth := FromEarth)\n              (HighlyIntelligent := HighlyIntelligent)\n              (Marvin := Marvin) (h1 := h1) (h2 := h2) (h3 := h3) (h4 := h4) (h5 := h5) (h6 := h6) (h7 := h7)\n  exact nh (himp nfm)\n\nend Reasoning\n\nAnswers:\n\n1) Marvin is an alien. Unknown\n\n2) Marvin is neither a human nor from Mars. True\n\n3) If Marvin is not from Mars, then Marvin is a human. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1301,
        "conclusion": "Marvin is an alien.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1302,
        "conclusion": "Marvin is neither a human nor from Mars.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1303,
        "conclusion": "If Marvin is not from Mars, then Marvin is a human.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 340,
    "premises": "Everyone at the mixer is a Grand Slam champion or an Oscar-nominated actor.\nEvery Grand Slam champion at the mixer is a professional tennis player.\nAll Oscar-nominated actors at the mixer are celebrities.\nAll professional tennis players at the mixer are athletes.\nIf a person at the mixer is a celebrity, then they are well paid.\nIf a person at the mixer is an athlete, then they are famous.\nAll well-paid people at the mixer live in tax havens.\nDjokovic is at the mixer: if Djokovic is a famous athlete, then Djokovic is well-paid.",
    "gpt_response": "Lean formalization and proofs:\n\nnamespace MixerLogic\n\nuniverse u\n\nconstant Person : Type u\nconstants\n  Mixer GrandSlamChampion OscarNominatedActor ProfessionalTennisPlayer\n  Celebrity Athlete WellPaid TaxHaven Famous : Person \u2192 Prop\n\nconstant Djokovic : Person\n\n-- Axioms from the text\naxiom A1 : \u2200 x, Mixer x \u2192 (GrandSlamChampion x \u2228 OscarNominatedActor x)\naxiom A2 : \u2200 x, Mixer x \u2192 GrandSlamChampion x \u2192 ProfessionalTennisPlayer x\naxiom A3 : \u2200 x, Mixer x \u2192 OscarNominatedActor x \u2192 Celebrity x\naxiom A4 : \u2200 x, Mixer x \u2192 ProfessionalTennisPlayer x \u2192 Athlete x\naxiom A5 : \u2200 x, Mixer x \u2192 Celebrity x \u2192 WellPaid x\naxiom A6 : \u2200 x, Mixer x \u2192 Athlete x \u2192 Famous x\naxiom A7 : \u2200 x, Mixer x \u2192 WellPaid x \u2192 TaxHaven x\n\n-- Djokovic is at the mixer\naxiom Dj_at : Mixer Djokovic\n\n-- Extra conditional: if Djokovic is a famous athlete, then Djokovic is well-paid\naxiom Dj_FA_implies_WP : (Famous Djokovic \u2227 Athlete Djokovic) \u2192 WellPaid Djokovic\n\n-- From the axioms, Djokovic lives in a tax haven\ntheorem Djokovic_tax_haven : TaxHaven Djokovic := by\n  have DJM : Mixer Djokovic := Dj_at\n  have disj := A1 Djokovic DJM\n  cases disj with\n  | inl djGSC =>\n      have djPTP : ProfessionalTennisPlayer Djokovic := A2 Djokovic DJM djGSC\n      have djAth : Athlete Djokovic := A4 Djokovic DJM djPTP\n      have djFam : Famous Djokovic := A6 Djokovic DJM djAth\n      have djWP  : WellPaid Djokovic := Dj_FA_implies_WP \u27e8djFam, djAth\u27e9\n      exact A7 Djokovic DJM djWP\n  | inr djONA =>\n      have djCel : Celebrity Djokovic := A3 Djokovic DJM djONA\n      have djWP  : WellPaid Djokovic := A5 Djokovic DJM djCel\n      exact A7 Djokovic DJM djWP\n\n-- Consequently, the statement \"Djokovic does not live in a tax haven\" is false\ntheorem not_not_Djokovic_tax_haven : \u00ac (\u00ac TaxHaven Djokovic) := by\n  intro h\n  exact h Djokovic_tax_haven\n\nend MixerLogic\n\nAnswers:\n1) Djokovic is a Grand Slam champion. Unknown\n2) Djokovic lives in a tax haven. True\n3) Djokovic does not live in a tax haven. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 893,
        "conclusion": "Djokovic is a Grand Slam champion.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 894,
        "conclusion": "Djokovic lives in a tax haven.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 895,
        "conclusion": "Djokovic does not live in a tax haven.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 96,
    "premises": "Diamond Mine is a professional wrestling stable formed in WWE.\nRoderick Strong leads Diamond Mine.\nDiamond Mine includes the Creed Brothers and Ivy Nile.\nImperium has a feud with Diamond Mine.",
    "gpt_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Entity : Type u\n\nconstants\n  (RoderickStrong DiamondMine CreedBrothers IvyNile Imperium : Entity)\n  (WrestlingStable : Entity \u2192 Prop)\n  (Leads : Entity \u2192 Entity \u2192 Prop)\n  (Includes : Entity \u2192 Entity \u2192 Prop)\n  (HasFeud : Entity \u2192 Entity \u2192 Prop)\n\naxioms\n  (h_stable : WrestlingStable DiamondMine)\n  (h_leads  : Leads RoderickStrong DiamondMine)\n  (h_incl1  : Includes DiamondMine CreedBrothers)\n  (h_incl2  : Includes DiamondMine IvyNile)\n  (h_feud   : HasFeud Imperium DiamondMine)\n\n-- Q1: There exists a professional wrestling stable led by Roderick Strong.\ntheorem Q1 :\n  \u2203 S, WrestlingStable S \u2227 Leads RoderickStrong S :=\nby\n  exact \u27e8DiamondMine, h_stable, h_leads\u27e9\n\n-- Q2: We cannot derive Leads RoderickStrong CreedBrothers (nor its negation) from the given axioms.\n\n-- Q3: There exists a professional wrestling stable that includes Ivy Nile\n--     with which Imperium has a feud; hence the negation in the question is false.\ntheorem exists_stable_with_ivy_feud :\n  \u2203 S, WrestlingStable S \u2227 Includes S IvyNile \u2227 HasFeud Imperium S :=\nby\n  exact \u27e8DiamondMine, h_stable, h_incl2, h_feud\u27e9\n\ntheorem Q3_false :\n  \u00ac (\u00ac \u2203 S, WrestlingStable S \u2227 Includes S IvyNile \u2227 HasFeud Imperium S) :=\nby\n  intro hneg\n  exact hneg exists_stable_with_ivy_feud\n\n\nAnswers:\n- Question 1: True\n- Question 2: Unknown\n- Question 3: False\n\nTrue, Unknown, False",
    "results": [
      {
        "question_num": 1,
        "example_id": 289,
        "conclusion": "Roderick Strong leads a professional wrestling stable.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 290,
        "conclusion": "Roderick Strong leads the Creed Brothers.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 291,
        "conclusion": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 219,
    "premises": "Symphony No. 9 is a music piece.\nComposers write music pieces.\nBeethoven wrote Symphony No. 9.\nVienna Music Society premiered Symphony No. 9.\nVienna Music Society is an orchestra.\nBeethoven leads the Vienna Music Society.\nOrchestras are led by conductors.",
    "gpt_response": "Lean code translation and proofs attempt:\n\n-- We model a simple domain of entities and predicates/relations.\nuniverse u\n\nconstant Entity : Type u\n\n-- Predicates\nconstant MusicPiece   : Entity \u2192 Prop\nconstant Composer     : Entity \u2192 Prop\nconstant Orchestra    : Entity \u2192 Prop\nconstant Conductor    : Entity \u2192 Prop\n\n-- Relations\nconstant writes    : Entity \u2192 Entity \u2192 Prop      -- person writes piece\nconstant premiered : Entity \u2192 Entity \u2192 Prop      -- organization premiered piece\nconstant leads     : Entity \u2192 Entity \u2192 Prop      -- person leads organization\n\n-- Named entities\nconstant Beethoven : Entity\nconstant VMS       : Entity                      -- Vienna Music Society\nconstant Sym9      : Entity                      -- Symphony No. 9\n\n-- Facts from the textual context\naxiom A1 : MusicPiece Sym9\naxiom A2 : \u2200 x, Composer x \u2192 \u2203 y, MusicPiece y \u2227 writes x y\naxiom A3 : writes Beethoven Sym9\naxiom A4 : premiered VMS Sym9\naxiom A5 : Orchestra VMS\naxiom A6 : leads Beethoven VMS\n-- Orchestras are led by conductors: if someone leads an orchestra, they are a conductor.\naxiom A7 : \u2200 p o, leads p o \u2192 Orchestra o \u2192 Conductor p\n\n-- Question 1: Is Beethoven a composer?\n-- From the given axioms, we cannot derive Composer Beethoven, nor its negation.\ntheorem Q1_cannot_prove_composer : \u00ac (False) := by\n  -- Placeholder to indicate we do not have a proof of Composer Beethoven or its negation.\n  -- We leave this as a trivial tautology to keep the environment consistent.\n  intro h; exact h\n\n-- Question 2: Some orchestras premiered music pieces.\ndef Q2_stmt : Prop := \u2203 o p, Orchestra o \u2227 MusicPiece p \u2227 premiered o p\n\ntheorem Q2_true : Q2_stmt := by\n  refine \u27e8VMS, Sym9, ?_, ?_, ?_\u27e9\n  \u00b7 exact A5\n  \u00b7 exact A1\n  \u00b7 exact A4\n\n-- Question 3: Beethoven is not a conductor.\ndef Q3_stmt : Prop := \u00ac Conductor Beethoven\n\n-- First show Beethoven is a conductor (from A6, A5, A7).\ntheorem beethoven_is_conductor : Conductor Beethoven :=\n  A7 Beethoven VMS A6 A5\n\n-- Therefore, the statement \"Beethoven is not a conductor\" is false.\ntheorem Q3_false : \u00ac Q3_stmt := by\n  -- Q3_stmt is \u00ac Conductor Beethoven, but we have Conductor Beethoven\n  intro h\n  exact h beethoven_is_conductor\n\n\nAnswers:\n- Q1: Beethoven is a composer. Unknown\n- Q2: Some orchestras premiered music pieces. True\n- Q3: Beethoven is not a conductor. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 621,
        "conclusion": "Beethoven is a composer.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 622,
        "conclusion": "Some orchestras premiered music pieces.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 623,
        "conclusion": "Beethoven is not a conductor.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 350,
    "premises": "All of Zaha Hadid's design styles that Max adores have interesting geometries.\nNo brutalist buildings that Max adores have interesting geometries.\nEvery style that Max adores is either Zaha Hadid's design style or Kelly Wearstler's design style. \nAll of Kelly Wearstler's design styles that Max adores are evocative.\nAll of Kelly Wearstler's design styles that Max adores are dreamy.\nIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative.",
    "gpt_response": "Here is a faithful first-order formalization. We use a single domain of objects (styles/designs), and unary predicates to mark properties.\n\nLean 4 code (translation of the premises and the three queried statements):\n\n-- Universe of things (styles/designs)\nuniverse u\nconstant Obj : Type u\n\n-- Predicates\nconstant Zaha Kelly Brutalist Interesting Evocative Dreamy DesignByMax Adored : Obj \u2192 Prop\n\n-- Premises\nconstant H1 : \u2200 x, Zaha x \u2227 Adored x \u2192 Interesting x\nconstant H2 : \u2200 x, Brutalist x \u2227 Adored x \u2192 \u00ac Interesting x\nconstant H3 : \u2200 x, Adored x \u2192 Zaha x \u2228 Kelly x\nconstant H4 : \u2200 x, Kelly x \u2227 Adored x \u2192 Evocative x\nconstant H5 : \u2200 x, Kelly x \u2227 Adored x \u2192 Dreamy x\nconstant H6 : \u2200 x, DesignByMax x \u2227 Adored x \u2227 Interesting x \u2192 Brutalist x \u2227 Evocative x\n\n-- The three questions, formalized as existential claims about some design by Max\ndef Q1 : Prop := \u2203 x, DesignByMax x \u2227 Brutalist x\ndef Q2 : Prop := \u2203 x, DesignByMax x \u2227 Evocative x \u2227 Dreamy x\ndef Q3 : Prop := \u2203 x, DesignByMax x \u2227 (Evocative x \u2228 Dreamy x)\n\n-- Note: From H1\u2013H6 alone, none of Q1, Q2, Q3 is derivable, nor is its negation.\n\n\nReasoning and answers:\n\n- About existence: The premises never assert that there exists any object that is a design by Max, nor any object that Max adores. So none of the existential statements Q1\u2013Q3 can be forced true from the premises alone. They also cannot be forced false, because the premises are consistent with a model where there is such an object (e.g., an adored Kelly design by Max that is evocative and dreamy but not interesting or brutalist).\n\n- Interaction of constraints:\n  - If an adored object is Zaha, H1 makes it interesting; if it is also a design by Max, H6 makes it brutalist and evocative; then H2 would forbid it from being interesting. Hence there cannot be an adored-by-Max Zaha object that is also a design by Max and interesting. This shows some combinations are ruled out, but it still does not create any existence.\n\nTherefore:\n\nQuestion 1: A design by Max is a brutalist building.\nAnswer: Unknown\n\nQuestion 2: A design by Max is evocative and dreamy.\nAnswer: Unknown\n\nQuestion 3: A design by Max is either evocative or dreamy.\nAnswer: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 927,
        "conclusion": "A design by Max is a brutalist building.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 928,
        "conclusion": "A design by Max is evocative and dreamy.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 929,
        "conclusion": "A design by Max is either evocative or dreamy.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 385,
    "premises": "If someone is ranked highly by the Women's Tennis Association, then they are one of the most active players in major tennis. \nEveryone who lost to Iga \u015awi\u0105tek at Roland Garros 2022 is ranked highly by the Women's Tennis Association.\nAll female tennis players at Roland Garros 2022 lost to Iga \u015awi\u0105tek.\nAll tennis players at Roland Garros 2022 are either female or male.\nAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal.\nIf Coco Gauff is ranked highly by the Women's Tennis Association or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nCoco Gauff is at Roland Garros 2022.",
    "gpt_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Person : Type u\n\n-- Predicates\nconstant AtRG FemaleRG MaleRG LostIga LostNadal HighRank MostActive : Person \u2192 Prop\n\n-- Individual\nconstant Coco : Person\n\n-- Axioms from the textual context\naxiom A1 : \u2200 x, HighRank x \u2192 MostActive x\naxiom A2 : \u2200 x, LostIga x \u2192 HighRank x\naxiom A3 : \u2200 x, FemaleRG x \u2192 LostIga x\naxiom A4 : \u2200 x, AtRG x \u2192 FemaleRG x \u2228 MaleRG x\naxiom A5 : \u2200 x, MaleRG x \u2192 LostNadal x\naxiom A6 : (HighRank Coco \u2228 LostNadal Coco) \u2192 \u00ac MaleRG Coco\naxiom A7 : AtRG Coco\n\n-- Useful derived facts\nlemma not_male_coco : \u00ac MaleRG Coco := by\n  intro hm\n  have hln : LostNadal Coco := A5 Coco hm\n  have hdisj : HighRank Coco \u2228 LostNadal Coco := Or.inr hln\n  have hnot : \u00ac MaleRG Coco := A6 hdisj\n  exact hnot hm\n\nlemma female_coco : FemaleRG Coco := by\n  have h := A4 Coco A7\n  cases h with\n  | inl hf => exact hf\n  | inr hm =>\n      have : False := by\n        have hln := A5 Coco hm\n        have hnot := A6 (Or.inr hln)\n        exact hnot hm\n      exact False.elim this\n\nlemma lost_iga_coco : LostIga Coco := A3 Coco female_coco\nlemma highrank_coco : HighRank Coco := A2 Coco lost_iga_coco\n\n-- Q1: Coco Gauff is among the most active Grand-Slam players.\ntheorem Q1_conclusion : MostActive Coco := A1 Coco highrank_coco\n\n-- Q3: We can prove the negation of the statement \u201c\u00ac(LostIga Coco \u2227 MostActive Coco)\u201d\n-- by proving the conjunction itself.\ntheorem both_iga_and_active : LostIga Coco \u2227 MostActive Coco :=\n  And.intro lost_iga_coco (A1 Coco (A2 Coco lost_iga_coco))\n\n\nAnswers:\n- Question 1: True\n- Question 2: Unknown\n- Question 3: False\n\nTrue, Unknown, False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1029,
        "conclusion": "Coco Gauff is among the most active Grand-Slam players.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1030,
        "conclusion": "Coco Gauff has lost to Rafael Nadal.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1031,
        "conclusion": "Coco Gauff is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 256,
    "premises": "All cats are mammals.\nSome pets are not mammals.",
    "gpt_response": "Lean translation and attempt:\n\nWe model a universe U with predicates Cat, Mammal, Pet : U \u2192 Prop.\n\nPremises:\n- H1: \u2200 x, Cat x \u2192 Mammal x        -- All cats are mammals\n- H2: \u2203 x, Pet x \u2227 \u00ac Mammal x       -- Some pets are not mammals\n\nClaim to decide:\n- C: \u2200 x, Pet x \u2192 \u00ac Cat x           -- No pets are cats\n\nIn general, C does not follow from H1 and H2. We can show this by constructing a countermodel in Lean where H1 and H2 hold but C fails.\n\nLean code:\n\nopen Classical\n\n-- A concrete countermodel showing the conclusion does not follow from the premises\ntheorem countermodel :\n  \u2203 (U : Type) (Cat Mammal Pet : U \u2192 Prop),\n    (\u2200 x, Cat x \u2192 Mammal x) \u2227\n    (\u2203 x, Pet x \u2227 \u00ac Mammal x) \u2227\n    \u00ac (\u2200 x, Pet x \u2192 \u00ac Cat x) := by\n  refine \u27e8Bool, (fun b => b = true), (fun b => b = true), (fun _ => True), ?_, ?_, ?_\u27e9\n  \u00b7 -- All cats are mammals\n    intro x hx; simpa [hx]\n  \u00b7 -- Some pet is not a mammal (take b = false)\n    refine \u27e8false, ?_, ?_\u27e9\n    \u00b7 exact True.intro\n    \u00b7 -- \u00ac (false = true)\n      intro h; cases h\n  \u00b7 -- The conclusion \"no pets are cats\" fails (since b = true is both a pet and a cat)\n    intro h\n    have hPt_imp := h true\n    have hPet : True := True.intro\n    have hCat : true = true := rfl\n    have : False := (hPt_imp hPet) hCat\n    exact this.elim\n\nExplanation:\n- This exhibits U = Bool with Mammal b := (b = true), Cat b := (b = true), Pet b := True.\n- Then H1 holds trivially, H2 holds by b = false, but C fails because b = true is both a pet and a cat.\n\nTherefore, from the given premises, the statement \u201cNo pets are cats\u201d is not determined.\n\nAnswer: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 700,
        "conclusion": "No pets are cats.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 159,
    "premises": "There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.",
    "gpt_response": "Lean translation and attempt:\n\n-- Seasons and people\ninductive Season\n| Spring | Summer | Fall | Winter\nderiving DecidableEq\n\nopen Season\n\nconstant Person : Type\nconstant Emma Mia James : Person\n\n-- Predicates and functions\nconstant Student : Person \u2192 Prop\nconstant WantsLongVacation : Person \u2192 Prop\nconstant favorite : Person \u2192 Season\n\n-- Premises\naxiom A1 : \u2200 s : Person, Student s \u2227 WantsLongVacation s \u2192 favorite s = Summer\naxiom A2 : favorite Emma = Summer\naxiom A3 : favorite Mia \u2260 favorite Emma\naxiom A4 : WantsLongVacation James\n\n-- A consequence we can prove: Mia\u2019s favorite is not Summer\nlemma mia_not_summer : favorite Mia \u2260 Summer := by\n  intro h\n  have : favorite Emma = Summer := A2\n  -- From h and A2, we get favorite Mia = favorite Emma, contradicting A3\n  have : favorite Mia = favorite Emma := by simpa [A2] using h\n  exact A3 this\n\n-- Target 1 (cannot be proved from given axioms without knowing James is a Student):\n-- theorem q1 : favorite James = Summer := by\n--   -- We would need Student James to use A1; not derivable from given axioms.\n--   sorry\n\n-- Target 2 (cannot be proved from given axioms; we only know Mia\u2019s favorite \u2260 Summer):\n-- theorem q2 : favorite Mia = Spring := by\n--   -- Not derivable; could be Fall or Winter as well.\n--   sorry\n\nAnswers:\n\nQuestion 1: Unknown\n\nQuestion 2: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 456,
        "conclusion": "James's favorite season is summer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 457,
        "conclusion": "Mia's favorite season is spring.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 343,
    "premises": "No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.",
    "gpt_response": "Lean translation and proof attempt:\n\n-- Types and predicates\nuniverse u\nconstant Obj : Type u\nconstant Digital : Obj \u2192 Prop\nconstant Analog : Obj \u2192 Prop\nconstant Printed : Obj \u2192 Prop\nconstant Streaming : Obj \u2192 Prop\nconstant Hardcover : Obj \u2192 Prop\nconstant e1984 : Obj\n\n-- Premises\naxiom H1 : \u2200 x : Obj, Digital x \u2192 \u00ac Analog x                          -- No digital media are analog\naxiom H2 : \u2200 x : Obj, Printed x \u2192 Analog x                           -- Every printed text is analog media\naxiom H3 : \u2200 x : Obj, Streaming x \u2192 Digital x                        -- All streaming services are digital media\naxiom H4 : \u2200 x : Obj, Hardcover x \u2192 Printed x                        -- If an object is a hardcover book, then it is printed text\naxiom H5 : Streaming e1984 \u2192 Hardcover e1984                         -- If 1984 is a streaming service, then 1984 is a hardcover book\n\n-- Consequences\n-- From Streaming e1984 we derive a contradiction, hence \u00ac Streaming e1984\ntheorem not_streaming_1984 : \u00ac Streaming e1984 := by\n  intro s\n  have d : Digital e1984 := H3 e1984 s\n  have hc : Hardcover e1984 := H5 s\n  have p : Printed e1984 := H4 e1984 hc\n  have a : Analog e1984 := H2 e1984 p\n  have na : \u00ac Analog e1984 := H1 e1984 d\n  exact na a\n\n-- Hence \"1984 is a streaming service\" is false, and \"1984 is not a streaming service\" is true\ntheorem q2_false : \u00ac Streaming e1984 := not_streaming_1984\ntheorem q3_true  : \u00ac Streaming e1984 := not_streaming_1984\n\n-- We cannot derive Printed e1984 from the premises (we only get Streaming \u2192 Printed and \u00acStreaming),\n-- nor can we derive \u00ac Printed e1984. Thus its truth value is undetermined from the given information.\n\n\nAnswers:\n- Question 1: 1984 is printed text. Unknown\n- Question 2: 1984 is a streaming service. False\n- Question 3: 1984 is not a streaming service. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 904,
        "conclusion": "1984 is printed text.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 905,
        "conclusion": "1984 is a streaming service.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 906,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 213,
    "premises": "All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.",
    "gpt_response": "Here is a Lean formalization of the scenario and proofs of what can be derived.\n\nuniverse u\n\nconstant Language : Type u\nconstant Romance : Language \u2192 Prop\nconstant IndoEuro : Language \u2192 Prop\nconstant Related : Language \u2192 Language \u2192 Prop\nconstant French Spanish German Basque : Language\n\n-- Premises:\n-- 1) All Romance languages are Indo-European.\naxiom A1 : \u2200 x, Romance x \u2192 IndoEuro x\n\n-- 2) Romance is a language family, and languages in a family are all related to each other.\n--    We specialize this to: any two distinct Romance languages are related.\naxiom A2 : \u2200 x y, Romance x \u2192 Romance y \u2192 x \u2260 y \u2192 Related x y\n\n-- 3) French and Spanish are Romance languages.\naxiom A3F : Romance French\naxiom A3S : Romance Spanish\n\n-- 4) German is related to Spanish.\naxiom A4 : Related German Spanish\n\n-- 5) Basque is not related to any other language (no relation from Basque to any distinct y).\naxiom A5 : \u2200 y, y \u2260 Basque \u2192 \u00ac Related Basque y\n\n-- Distinctness of the named languages (needed to use \u201cany other\u201d rigorously)\naxiom distinct_BF : Basque \u2260 French\naxiom distinct_BS : Basque \u2260 Spanish\n\n-- Q1 target: Basque is a Romance language. We prove its negation.\ntheorem Q1_false : \u00ac Romance Basque := by\n  intro hB\n  have hRF : Related Basque French :=\n    A2 Basque French hB A3F distinct_BF\n  -- Need French \u2260 Basque to use A5; derive from Basque \u2260 French\n  have hFB : French \u2260 Basque := ne_comm.mp distinct_BF\n  have hNRF : \u00ac Related Basque French := A5 French hFB\n  exact hNRF hRF\n\n-- Q3 target: French is an Indo-European language. Directly from A1 and A3F.\ntheorem Q3_true : IndoEuro French :=\n  A1 French A3F\n\n-- For Q2 (German is a Romance language), neither Romance German nor its negation\n-- follows from the given premises: being related to a Romance language does not imply being Romance.\n\n\nAnswers:\nQuestion 1: Basque is a Romance language. False\nQuestion 2: German is a Romance language. Unknown\nQuestion 3: French is an Indo-European language. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 608,
        "conclusion": "Basque is a Romance language.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 609,
        "conclusion": "German is a Romance language.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 610,
        "conclusion": "French is an Indo-European language.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 79,
    "premises": "Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.",
    "gpt_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Person : Type u\nconstant Team   : Type u\n\nconstant RL     : Person\nconstant Bayern : Team\n\n-- Predicates\nconstant Striker      : Person \u2192 Prop\nconstant SoccerPlayer : Person \u2192 Prop\nconstant PlaysFor     : Person \u2192 Team \u2192 Prop\nconstant LeftTeam     : Person \u2192 Team \u2192 Prop\nconstant Star         : Person \u2192 Prop\n\n-- Facts from the textual context\naxiom h_striker_RL : Striker RL\naxiom h_striker_imp_soccer : \u2200 x, Striker x \u2192 SoccerPlayer x\naxiom h_left_RL_Bayern : LeftTeam RL Bayern\naxiom h_leave_implies_not_play : \u2200 x t, LeftTeam x t \u2192 \u00ac PlaysFor x t\n\n-- Q1: Robert Lewandowski is a soccer player.\ntheorem Q1 : SoccerPlayer RL :=\n  h_striker_imp_soccer RL h_striker_RL\n\n-- Q2: Robert Lewandowski plays for Bayern Munchen.\ntheorem Q2 : \u00ac PlaysFor RL Bayern :=\nby\n  apply h_leave_implies_not_play\n  exact h_left_RL_Bayern\n\n-- Q3 (Robert Lewandowski is a star) is not derivable from the given axioms,\n-- and neither is its negation derivable from these axioms alone.\n\n\nAnswers:\n1) Yes. Robert Lewandowski is a soccer player. True\n2) No. He does not play for Bayern Munchen (he left, so he no longer plays for them). False\n3) Not determined by the given information. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 240,
        "conclusion": "Robert Lewandowski is a soccer player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 241,
        "conclusion": "Robert Lewandowski plays for Bayern Munchen.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 242,
        "conclusion": "Robert Lewandowski is a star.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 2,
    "premises": "Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.",
    "gpt_response": "Here is a Lean 4 formalization of the given context and the three questions, along with proofs where they are derivable from the premises.\n\nnamespace StatesCities\n\nuniverse u\n\n-- Basic types\nconstant City : Type u\nconstant State : Type u\n\n-- Predicates and relations\nconstant InState : City \u2192 State \u2192 Prop\ndef SameState (c\u2081 c\u2082 : City) : Prop := \u2203 s : State, InState c\u2081 s \u2227 InState c\u2082 s\n\n-- Named states and cities\nconstant Montana : State\n\nconstant Billings Butte Helena Missoula WhiteSulphurSprings StPierre Bismarck : City\nconstant Bristol Texarkana Texhoma UnionCity : City\n\n-- Exceptional cities (allowed to be in more than one state)\nconstant Exceptional : City \u2192 Prop\n\n-- Axioms extracted from the textual context\n\n-- Billings is in Montana\naxiom H_Billings_Montana : InState Billings Montana\n\n-- Montana includes Butte, Helena, Missoula\naxiom H_Butte_Montana   : InState Butte   Montana\naxiom H_Helena_Montana  : InState Helena  Montana\naxiom H_Missoula_Montana: InState Missoula Montana\n\n-- White Sulphur Springs and Butte are in the same state\naxiom H_WSS_Butte_same : SameState WhiteSulphurSprings Butte\n\n-- St Pierre is not in Montana\naxiom H_StPierre_not_Montana : \u00ac InState StPierre Montana\n\n-- Uniqueness of state for non-exceptional cities\naxiom H_unique_state_nonexceptional :\n  \u2200 c : City, (\u00ac Exceptional c) \u2192 \u2200 s\u2081 s\u2082 : State, InState c s\u2081 \u2192 InState c s\u2082 \u2192 s\u2081 = s\u2082\n\n-- The cities here (that matter to our proofs) are not exceptional\naxiom H_Butte_not_exceptional : \u00ac Exceptional Butte\naxiom H_StPierre_not_exceptional : \u00ac Exceptional StPierre\naxiom H_Missoula_not_exceptional : \u00ac Exceptional Missoula\n\n-- Question 1: Are Butte and St Pierre in the same state?\n-- Formal target: \u00ac SameState Butte StPierre\ntheorem Q1_false : \u00ac SameState Butte StPierre :=\nby\n  intro h\n  rcases h with \u27e8s, hB, hS\u27e9\n  -- By uniqueness for Butte (non-exceptional), any state Butte is in must be Montana.\n  have huniq := H_unique_state_nonexceptional Butte H_Butte_not_exceptional s Montana hB H_Butte_Montana\n  -- So s = Montana, hence StPierre would be in Montana, contradiction.\n  have : InState StPierre Montana := by simpa [huniq] using hS\n  exact H_StPierre_not_Montana this\n\n-- Question 2: Are St Pierre and Bismarck in the same state?\n-- With the given information, there is no premise about Bismarck's state, so this is not derivable either way.\n-- Hence we do not have a proof of SameState StPierre Bismarck nor of its negation from the provided axioms.\n\n-- Question 3: Is Montana home to the city of Missoula?\n-- Formal target: InState Missoula Montana\ntheorem Q3_true : InState Missoula Montana := H_Missoula_Montana\n\nend StatesCities\n\nAnswers:\n1) Butte and St Pierre are in the same state. Answer: False\n2) St Pierre and Bismarck are in the same state. Answer: Unknown\n3) Montana is home to the city of Missoula. Answer: True\n\nFalse\nUnknown\nTrue\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 4,
        "conclusion": "Butte and St Pierre are in the same state.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 5,
        "conclusion": "St Pierre and Bismarck are in the same state.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 6,
        "conclusion": "Montana is home to the city of Missoula.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 192,
    "premises": "International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.",
    "gpt_response": "Lean formalization attempt:\n\n-- We work in a simple first-order setting with persons and predicates\nuniverse u\nconstant Person : Type u\nconstant Mike : Person\n\n-- Predicates\nconstant InternationalStudent : Person \u2192 Prop\nconstant InUS : Person \u2192 Prop\nconstant HasF1 : Person \u2192 Prop\nconstant HasJ1 : Person \u2192 Prop\nconstant WantsWorkUS : Person \u2192 Prop\nconstant NeedsCPT : Person \u2192 Prop\nconstant NeedsOPT : Person \u2192 Prop\n\n-- Axioms from the text\n\n-- 1) Every international student in the US has either an F1 or a J1 visa.\naxiom intl_inUS_has_F1_or_J1 :\n  \u2200 p : Person, InternationalStudent p \u2227 InUS p \u2192 HasF1 p \u2228 HasJ1 p\n\n-- 2) Any international student in the US with an F1 visa who wants to work in the US\n--    needs to apply for CPT or OPT.\naxiom F1_workers_need_CPT_or_OPT :\n  \u2200 p : Person, InternationalStudent p \u2227 InUS p \u2227 HasF1 p \u2227 WantsWorkUS p \u2192 (NeedsCPT p \u2228 NeedsOPT p)\n\n-- 3) Mike is an international student.\naxiom Mike_is_international : InternationalStudent Mike\n\n-- 4) Mike needs to apply for CPT if he wants to work in the US.\naxiom Mike_wants_work_implies_needs_CPT : WantsWorkUS Mike \u2192 NeedsCPT Mike\n\n-- Note:\n-- We are NOT given InUS Mike, nor any statement that equates \u201cNeedsCPT if wants to work\u201d\n-- with having an F1 visa. Thus, we cannot derive HasF1 Mike, nor HasJ1 Mike, from the axioms.\n\n-- What we can prove: If Mike is in the US and has F1 and wants to work,\n-- then (trivially) he needs CPT or OPT, which is already covered by the axioms.\ntheorem consistency_check :\n  InUS Mike \u2227 HasF1 Mike \u2227 WantsWorkUS Mike \u2192 (NeedsCPT Mike \u2228 NeedsOPT Mike) :=\nby\n  intro h\n  rcases h with \u27e8hIn, hF1, hW\u27e9\n  have : InternationalStudent Mike \u2227 InUS Mike \u2227 HasF1 Mike \u2227 WantsWorkUS Mike :=\n    \u27e8Mike_is_international, hIn, hF1, hW\u27e9\n  exact F1_workers_need_CPT_or_OPT Mike this\n\n-- We cannot prove:\n-- theorem Q1 : HasF1 Mike := by\n--   -- Not derivable from the given axioms\n--   sorry\n-- theorem Q2 : HasJ1 Mike := by\n--   -- Not derivable from the given axioms\n--   sorry\n\nAnswers:\n- Question 1: Mike has an F1 visa. Unknown\n- Question 2: Mike has a J1 visa. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 548,
        "conclusion": "Mike has an F1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 549,
        "conclusion": "Mike has a J1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 442,
    "premises": "All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.",
    "gpt_response": "Here is a Lean 4 formalization of the premises and proofs for the three questions.\n\n-- Types and predicates\nconstant Animal : Type\nconstant BrownSwiss : Animal \u2192 Prop\nconstant Cow : Animal \u2192 Prop\nconstant Pet : Animal \u2192 Prop\nconstant Domesticated : Animal \u2192 Prop\nconstant Alligator : Animal \u2192 Prop\nconstant Ted : Animal\n\n-- Premises\naxiom ax1 : \u2200 x, BrownSwiss x \u2192 Cow x                         -- All Brown Swiss cattle are cows.\naxiom ax2 : \u2203 x, Pet x \u2227 BrownSwiss x                         -- Some pets are Brown Swiss cattle.\naxiom ax3 : \u2200 x, Cow x \u2192 Domesticated x                       -- All cows are domesticated animals.\naxiom ax4 : \u2200 x, Alligator x \u2192 \u00ac Domesticated x               -- Alligators are not domesticated animals.\naxiom ax5 : Alligator Ted                                     -- Ted is an alligator.\n\n-- Useful derived lemmas\nlemma not_dom_Ted : \u00ac Domesticated Ted :=\nby\n  have h := ax4 Ted\n  exact h ax5\n\nlemma not_BS_Ted : \u00ac BrownSwiss Ted :=\nby\n  intro hBS\n  have hCow : Cow Ted := ax1 Ted hBS\n  have hDom : Domesticated Ted := ax3 Ted hCow\n  exact not_dom_Ted hDom\n\n-- Q2: Ted is a pet and Brown Swiss cattle (this conjunction is false).\ntheorem Q2_false : \u00ac (Pet Ted \u2227 BrownSwiss Ted) :=\nby\n  intro h\n  exact not_BS_Ted h.right\n\n-- Q3: If Ted is a Brown Swiss cattle, then Ted is not a pet (this is true).\ntheorem Q3_true : BrownSwiss Ted \u2192 \u00ac Pet Ted :=\nby\n  intro hBS\n  -- From BrownSwiss Ted we derive a contradiction (Ted would be domesticated and not domesticated),\n  -- thus we can conclude anything, in particular \u00ac Pet Ted.\n  have hCow : Cow Ted := ax1 Ted hBS\n  have hDom : Domesticated Ted := ax3 Ted hCow\n  have hFalse : False := not_dom_Ted hDom\n  intro _\n  exact False.elim hFalse\n\nAnswers:\n- Question 1: Ted is a pet. Unknown\n- Question 2: Ted is a pet and Brown Swiss cattle. False\n- Question 3: If Ted is a Brown Swiss cattle, then Ted is not a pet. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1271,
        "conclusion": "Ted is a pet.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1272,
        "conclusion": "Ted is a pet and Brown Swiss cattle",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1273,
        "conclusion": "If Ted is a Brown Swiss cattle, then Ted is not a pet.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 234,
    "premises": "Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.",
    "gpt_response": "Lean translation and proofs:\n\n-- We model only the information explicitly given in the text.\nnamespace YaleFacts\n\nconstant Entity : Type\n\n-- Predicates\nconstant PrivateIvyLeagueResearchUniversity : Entity \u2192 Prop\nconstant MovedToNewHaven : Entity \u2192 Prop\nconstant ResidentialCollegeAtYale : Entity \u2192 Prop\nconstant HasLargestUniversityEndowment : Entity \u2192 Prop\n\n-- Constants for specific entities\nconstant Yale : Entity\nconstant PiersonCollege : Entity\n\n-- Facts from the textual context\naxiom hYalePILRU : PrivateIvyLeagueResearchUniversity Yale\naxiom hYaleMoved : MovedToNewHaven Yale\naxiom hPiersonIsResidentialAtYale : ResidentialCollegeAtYale PiersonCollege\n\n-- Q1: \u2203x, PrivateIvyLeagueResearchUniversity x \u2227 MovedToNewHaven x\ntheorem Q1 : \u2203 x, PrivateIvyLeagueResearchUniversity x \u2227 MovedToNewHaven x :=\n  \u27e8Yale, And.intro hYalePILRU hYaleMoved\u27e9\n\n-- Q2: HasLargestUniversityEndowment Yale\n-- We have no information sufficient to prove or refute this from the given axioms.\n-- Therefore, we do not provide a proof (nor a refutation) here.\n\n-- Q3: ResidentialCollegeAtYale PiersonCollege\ntheorem Q3 : ResidentialCollegeAtYale PiersonCollege := hPiersonIsResidentialAtYale\n\nend YaleFacts\n\nAnswers:\n1) True\n2) Unknown\n3) True\n\nTrue, Unknown, True",
    "results": [
      {
        "question_num": 1,
        "example_id": 663,
        "conclusion": "A private Ivy League research university moved to New Haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 664,
        "conclusion": "Yale University has the largest university endowment of any educational institution.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 665,
        "conclusion": "Pierson College is a residential college at Yale.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 120,
    "premises": "Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.",
    "gpt_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Series : Type\nconstant Person : Type\nconstant Title : Type\nconstant Channel : Type\n\nconstant Badults : Series\nconstant AndrewCollins : Person\nconstant SecretDudeSociety : Title\nconstant BBCThree : Channel\nconstant BBCTwo : Channel\n\n-- Predicates\nconstant working_title : Series \u2192 Title \u2192 Prop\nconstant script_editor : Series \u2192 Person \u2192 Prop\nconstant stars_members_of_pappys : Series \u2192 Prop\nconstant piloted_on : Series \u2192 Channel \u2192 Prop\n\n-- Facts from the text\naxiom ax1 : stars_members_of_pappys Badults\naxiom ax2 : piloted_on Badults BBCThree\naxiom ax3 : working_title Badults SecretDudeSociety\naxiom ax4 : script_editor Badults AndrewCollins\n\n-- Q1: \u2203 s, working_title s SecretDudeSociety \u2227 script_editor s AndrewCollins\ntheorem Q1 : \u2203 s, working_title s SecretDudeSociety \u2227 script_editor s AndrewCollins := by\n  refine \u27e8Badults, ?_\u27e9\n  exact And.intro ax3 ax4\n\n-- Q2 statement: No members of Pappy's have starred in a show piloting on BBC Two or BBC Three\ndef Q2 : Prop :=\n  \u00ac \u2203 s, stars_members_of_pappys s \u2227 (piloted_on s BBCTwo \u2228 piloted_on s BBCThree)\n\n-- We prove the negation of Q2 (i.e., Q2 is false) by exhibiting Badults\ntheorem not_Q2 : \u00ac Q2 := by\n  intro h\n  have ex : \u2203 s, stars_members_of_pappys s \u2227 (piloted_on s BBCTwo \u2228 piloted_on s BBCThree) := by\n    refine \u27e8Badults, ?_\u27e9\n    refine And.intro ax1 ?_\n    exact Or.inr ax2\n  exact h ex\n\nAnswers:\n\n1) Yes. Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\" (namely, Badults). True\n\n2) No. Badults stars members of Pappy's and was piloted on BBC Three, so the statement is contradicted. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 360,
        "conclusion": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 361,
        "conclusion": "No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 322,
    "premises": "All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.",
    "gpt_response": "Here is a Lean 4 formalization of the problem and proofs.\n\nLean code:\n\nsection\n\nuniverse u\n\nconstant Entity : Type u\nconstant Stock Growth Bought Suitable Mature Volatile : Entity \u2192 Prop\nconstant KO : Entity\n\n-- Premises\naxiom A1 : \u2200 x, (Stock x \u2227 Growth x) \u2192 Bought x\naxiom A2 : \u2200 x, Bought x \u2192 \u00ac Suitable x\naxiom A3 : \u2203 x, Stock x \u2227 Growth x\naxiom A4 : \u2200 x, (Stock x \u2227 Mature x) \u2192 Suitable x\naxiom A5 : Stock KO \u2227 Mature KO\n\n-- Useful derived facts\nlemma KO_stock : Stock KO := A5.left\nlemma KO_mature : Mature KO := A5.right\nlemma KO_suitable : Suitable KO := A4 KO \u27e8KO_stock, KO_mature\u27e9\n\nlemma not_KO_growth : \u00ac Growth KO := by\n  intro hG\n  have hB : Bought KO := A1 KO \u27e8KO_stock, hG\u27e9\n  have hNotS : \u00ac Suitable KO := A2 KO hB\n  exact hNotS KO_suitable\n\nlemma not_KO_bought : \u00ac Bought KO := by\n  intro hB\n  have hNotS : \u00ac Suitable KO := A2 KO hB\n  exact hNotS KO_suitable\n\n-- Question 1: KO is a stock.\n-- Provable directly from A5.\ntheorem Q1 : Stock KO := KO_stock\n\n-- Question 2: KO is a stock and a growth stock.\n-- This is false because KO is not a growth stock (as shown above).\ntheorem Q2_false : \u00ac (Stock KO \u2227 Growth KO) := by\n  intro h\n  exact not_KO_growth h.right\n\n-- Question 3: If KO is a growth stock or bought to earn profits from rapid price appreciation,\n-- then KO is neither a stock nor is its price volatile.\n-- The antecedent is impossible (both disjuncts are false), so the implication holds vacuously.\ntheorem Q3 : (Growth KO \u2228 Bought KO) \u2192 (\u00ac Stock KO \u2227 \u00ac Volatile KO) := by\n  intro h\n  cases h with\n  | inl hG => exact (False.elim ((not_KO_growth) hG))\n  | inr hB => exact (False.elim ((not_KO_bought) hB))\n\nend\n\nAnswers:\n\n1) True\n2) False\n3) True\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 819,
        "conclusion": "KO is a stock.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 820,
        "conclusion": "KO is a stock and a growth stock.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 821,
        "conclusion": "If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 83,
    "premises": "All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.",
    "gpt_response": "Lean code translation and proofs:\n\n-- We model entities (e.g., license plates) as elements of a type U\nsection\nvariable {U : Type} (Joe Tom : U)\nvariable (Begins34 Begins35 FromIstanbul : U \u2192 Prop)\n\n-- Axioms from the textual context\nvariable\n  (A1 : \u2200 x, FromIstanbul x \u2192 Begins34 x)                -- All plates from Istanbul begin with 34\n  (A2 : \u2200 x, \u00ac Begins34 x \u2192 \u00ac FromIstanbul x)            -- Plates not beginning with 34 are not from Istanbul\n  (A3 : FromIstanbul Joe)                                 -- Joe's plate is from Istanbul\n  (A4 : Begins35 Tom)                                     -- Tom's plate begins with 35\n  (A5 : \u2200 x, Begins35 x \u2192 \u00ac Begins34 x)                   -- If begins with 35 then not with 34\n\n-- Question 1: Joe's plate begins with 34\ntheorem q1 : Begins34 Joe :=\n  A1 Joe A3\n\n-- Question 2: Tom's plate is from Istanbul (we prove its negation)\ntheorem not_q2 : \u00ac FromIstanbul Tom :=\nby\n  have h1 : \u00ac Begins34 Tom := A5 Tom (A4)\n  exact A2 Tom h1\n\nend\n\nAnswers:\n- Question 1: True\n- Question 2: False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 253,
        "conclusion": "Joe's license plate begins with the number 34.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 254,
        "conclusion": "Tom's license plate is from Istanbul.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 368,
    "premises": "If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.",
    "gpt_response": "Lean formalization and proofs:\n\n-- Domain and predicates\nuniverse u\nconstant Person : Type\nconstants (S J M T E P D : Person \u2192 Prop)  -- at Mary's school, job, needs money, orders takeout, enjoys dining hall, picky, spends time in dining halls\nconstant h : Person\n\n-- Premises\nconstants\n  (h1 : \u2200 x, S x \u2227 J x \u2192 M x)                  -- If at Mary's school and works in student job, then needs money\n  (h2 : \u2200 x, S x \u2227 T x \u2192 J x)                  -- If at Mary's school and orders takeout, then works in student job\n  (h3 : \u2200 x, S x \u2192 (T x \u2228 E x))                -- If at Mary's school, then orders takeout or enjoys dining hall\n  (h4 : \u2200 x, S x \u2227 E x \u2192 \u00ac P x)                -- If at Mary's school and enjoys dining hall, then not picky\n  (h5 : \u2200 x, S x \u2227 E x \u2192 D x)                  -- If at Mary's school and enjoys dining hall, then spends time in dining halls\n  (hS : S h)                                   -- Hannah is at Mary's school\n  (hJ : J h)                                   -- Hannah works in student jobs on campus\n  (hImp : M h \u2192 (\u00ac P h \u2227 \u00ac M h))               -- If Hannah needs money, then she is not picky and does not need money\n\n-- Question 1: Hannah needs to earn money to help pay for her college tuition.\ntheorem q1 : M h :=\n  h1 h \u27e8hS, hJ\u27e9\n\n-- (Note: From hImp and q1 we also get \u00ac M h, so the premises are inconsistent.)\n\n-- Question 2: Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.\ntheorem q2 : S h \u2227 \u00ac P h \u2227 D h := by\n  have hm : M h := q1\n  have hnp : \u00ac P h := (hImp hm).left\n  have hnotm : \u00ac M h := (hImp hm).right\n  have absurd : False := hnotm hm\n  exact And.intro hS (And.intro hnp (False.elim absurd))\n\n-- Question 3: Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.\ntheorem q3 : S h \u2227 (\u00ac P h \u2228 (P h \u2192 D h)) := by\n  have hm : M h := q1\n  have hnp : \u00ac P h := (hImp hm).left\n  exact And.intro hS (Or.inl hnp)\n\n\nAnswers:\n- Q1: True\n- Q2: True\n- Q3: True\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 979,
        "conclusion": "Hannah needs to earn money to help pay for her college tuition.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 980,
        "conclusion": "Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 981,
        "conclusion": "Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 319,
    "premises": "No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.",
    "gpt_response": "Here is a Lean formalization of the problem and proofs of what can be derived.\n\nLean code:\n\n-- We work in classical logic for case analysis and contraposition\nopen Classical\n\nuniverse u\n\n-- Domain and predicates\nvariable (U : Type u)\nvariable (BakedSweet Spicy Cupcake MalaHotpot FromBBM : U \u2192 Prop)\nvariable (DTC : U)\n\n-- Axioms from the textual context\nvariable\n  (h1 : \u2200 x, BakedSweet x \u2192 \u00ac Spicy x)                -- No baked sweets are spicy\n  (h2 : \u2200 x, Cupcake x \u2192 BakedSweet x)                -- All cupcakes are baked sweets\n  (h3 : \u2200 x, MalaHotpot x \u2192 Spicy x)                  -- All mala hotpots are spicy\n  (h4 : \u2200 x, FromBBM x \u2192 Cupcake x)                   -- All products from BBM are cupcakes\n  (h5 : Spicy DTC \u2228 MalaHotpot DTC \u2228 \u00ac BakedSweet DTC) -- Dried Thai chilies: S \u2228 M \u2228 \u00acB\n\n-- Useful derived lemma: Spicy implies not BakedSweet (by contraposition of h1)\nlemma spicy_implies_not_baked (x : U) (hs : Spicy x) : \u00ac BakedSweet x := by\n  intro hb\n  have hnS : \u00ac Spicy x := h1 x hb\n  exact hnS hs\n\n-- From the disjunction about DTC, we can conclude DTC is not a baked sweet\nlemma not_baked_DTC : \u00ac BakedSweet DTC := by\n  rcases h5 with hS | hM | hNB\n  \u00b7 exact spicy_implies_not_baked U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5 DTC hS\n  \u00b7 have hS' : Spicy DTC := h3 DTC hM\n    exact spicy_implies_not_baked U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5 DTC hS'\n  \u00b7 exact hNB\n\n-- From not_baked_DTC and BBM\u2192Cupcake\u2192BakedSweet, we get DTC is not from BBM\nlemma not_fromBBM_DTC : \u00ac FromBBM DTC := by\n  intro hF\n  have hC : Cupcake DTC := h4 DTC hF\n  have hB : BakedSweet DTC := h2 DTC hC\n  exact not_baked_DTC U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5 hB\n\n-- Q1: Dried Thai chilies are products of Baked by Melissa. (False)\n-- We can prove the negation: \u00ac FromBBM DTC.\ntheorem Q1_false : \u00ac FromBBM DTC :=\n  not_fromBBM_DTC U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5\n\n-- Q2: Dried Thai chilies are not products of Baked by Melissa. (True)\ntheorem Q2_true : \u00ac FromBBM DTC :=\n  not_fromBBM_DTC U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5\n\n-- Q3: Dried Thai chilies are a mala hotpot. (Unknown: neither provable nor refutable from the given axioms)\n-- No theorem provided: both MalaHotpot DTC and \u00ac MalaHotpot DTC are consistent with the axioms.\n\n-- Q4: Dried Thai chilies are neither products of Baked by Melissa nor baked sweets. (True)\ntheorem Q4_true : \u00ac FromBBM DTC \u2227 \u00ac BakedSweet DTC := by\n  exact And.intro\n    (not_fromBBM_DTC U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5)\n    (not_baked_DTC U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5)\n\n-- Q5: Dried Thai chilies are cupcakes and products of Baked by Melissa. (False)\n-- Since \u00ac FromBBM DTC, the conjunction Cupcake DTC \u2227 FromBBM DTC is false.\ntheorem Q5_false : \u00ac (Cupcake DTC \u2227 FromBBM DTC) := by\n  intro h\n  exact (Q1_false U BakedSweet Spicy Cupcake MalaHotpot FromBBM DTC h1 h2 h3 h4 h5) h.right\n\n\nAnswers:\n1) False. True\n2) True. True\n3) Unknown. Unknown\n4) True. True\n5) False. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 805,
        "conclusion": "Dried Thai chilies are products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 806,
        "conclusion": "Dried Thai chilies are not products of Baked by Melissa.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 807,
        "conclusion": "Dried Thai chilies are a mala hotpot.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 4,
        "example_id": 808,
        "conclusion": "Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 809,
        "conclusion": "Dried Thai chilies are cupcakes and products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.4
  },
  {
    "story_id": 306,
    "premises": "If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.",
    "gpt_response": "Here is a Lean 4 formalization of the setting and proofs for Questions 1 and 2. Question 3 cannot be derived (nor can its negation) from the given premises.\n\n-- Lean 4 code\n\nuniverse u\n\nnamespace Restaurants\n\n-- Domain of discourse: restaurants\nconstant Restaurant : Type u\n\n-- Predicates\nconstant Listed : Restaurant \u2192 Prop               -- listed in Yelp\u2019s recommendations\nconstant ManyNeg : Restaurant \u2192 Prop              -- has received many negative reviews\nconstant RatingGT4 : Restaurant \u2192 Prop            -- rating greater than four\nconstant TakeOut : Restaurant \u2192 Prop              -- provides take-out service\nconstant Popular : Restaurant \u2192 Prop              -- popular among local residents\n\n-- A specific restaurant: the Hamden Plaza Subway store\nconstant hps : Restaurant\n\n-- Premises\naxiom listed_no_manyneg : \u2200 r : Restaurant, Listed r \u2192 \u00ac ManyNeg r\naxiom rating_implies_listed : \u2200 r : Restaurant, RatingGT4 r \u2192 Listed r\naxiom some_no_takeout_manyneg : \u2203 r : Restaurant, \u00ac TakeOut r \u2227 ManyNeg r\naxiom popular_implies_rating : \u2200 r : Restaurant, Popular r \u2192 RatingGT4 r\naxiom hps_rating_or_pop : RatingGT4 hps \u2228 Popular hps\n\nopen Classical\n\n-- From the last two axioms, we can deduce hps has rating > 4.\nlemma hps_has_rating : RatingGT4 hps :=\n  Or.elim hps_rating_or_pop\n    (fun hr => hr)\n    (fun hp => popular_implies_rating hps hp)\n\n-- Therefore hps is listed, hence has not received many negative reviews.\nlemma hps_not_manyneg : \u00ac ManyNeg hps :=\n  by\n    have hlisted : Listed hps := rating_implies_listed hps hps_has_rating\n    exact listed_no_manyneg hps hlisted\n\n-- Question 1:\n-- If hps provides take-out and receives many negative reviews,\n-- then its rating is greater than 4 and it does not provide take-out.\ntheorem Q1 :\n  (TakeOut hps \u2227 ManyNeg hps) \u2192 (RatingGT4 hps \u2227 \u00ac TakeOut hps) :=\nby\n  intro h\n  refine And.intro ?left ?right\n  \u00b7 -- left: RatingGT4 hps\n    exact hps_has_rating\n  \u00b7 -- right: \u00ac TakeOut hps\n    -- show TakeOut hps \u2192 False, using the contradiction with ManyNeg hps\n    intro _\n    exact hps_not_manyneg h.right\n\n-- Question 2:\n-- hps provides take-out service or does not receive many negative reviews.\ntheorem Q2 : TakeOut hps \u2228 \u00ac ManyNeg hps :=\n  Or.inr hps_not_manyneg\n\n-- Note on Question 3:\n-- From the given premises we cannot deduce \u00ac TakeOut hps, nor can we deduce TakeOut hps.\n-- Hence neither the statement nor its negation is provable from the assumptions.\n\nend Restaurants\n\nAnswers:\n- Question 1: True\n- Question 2: True\n- Question 3: Unknown\n\nTrue\nTrue\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 754,
        "conclusion": "If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 755,
        "conclusion": "The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 756,
        "conclusion": "The Hamden Plaza store does not provide take-out service.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 245,
    "premises": "In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.",
    "gpt_response": "Lean translation and proof attempt:\n\n-- Types\nuniverse u\nconstant Person : Type\nconstant Movie : Type\n\n-- Constants for entities\nconstant Digby    : Person\nconstant Nemesis  : Person\nconstant TSASDCC  : Movie   -- The Surprising Adventures of Sir Digby Chicken Caesar\n\n-- Predicates\nconstant SuperheroMovie : Movie \u2192 Prop\nconstant NamedAfter     : Movie \u2192 Person \u2192 Prop\nconstant InMovie        : Person \u2192 Movie \u2192 Prop\nconstant Good           : Person \u2192 Prop\nconstant Fights         : Person \u2192 Person \u2192 Prop\nconstant Wins           : Person \u2192 Prop\n\n-- Axioms extracted from the text\n-- 1. In superhero movies, the good guys always win.\naxiom good_guys_always_win :\n  \u2200 m, SuperheroMovie m \u2192 \u2200 p, InMovie p m \u2192 Good p \u2192 Wins p\n\n-- 2. The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\naxiom movie_is_super : SuperheroMovie TSASDCC\n\n-- 3. Sir Digby fights his nemesis.\naxiom digby_fights_nemesis : Fights Digby Nemesis\n\n-- 4. If a superhero movie is named after a character, that character is a good guy.\naxiom named_after_good :\n  \u2200 m p, SuperheroMovie m \u2192 NamedAfter m p \u2192 Good p\n\n-- 5. The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\naxiom movie_named_after_digby : NamedAfter TSASDCC Digby\n\n-- 6. If somebody wins a fight, the person they are fighting does not win.\n--    We model \"wins a fight\" as \"Fights x y \u2227 Wins x\".\naxiom win_fight_opponent_not_win :\n  \u2200 x y, Fights x y \u2192 Wins x \u2192 \u00ac Wins y\n\n-- 7. If a superhero movie is named after a character, that character is in the movie.\naxiom named_after_in_movie :\n  \u2200 m p, SuperheroMovie m \u2192 NamedAfter m p \u2192 InMovie p m\n\n-- Goal: Sir Digby\u2019s nemesis does not win.\ntheorem nemesis_does_not_win : \u00ac Wins Nemesis := by\n  have gd : Good Digby :=\n    named_after_good TSASDCC Digby movie_is_super movie_named_after_digby\n  have im : InMovie Digby TSASDCC :=\n    named_after_in_movie TSASDCC Digby movie_is_super movie_named_after_digby\n  have w : Wins Digby :=\n    good_guys_always_win TSASDCC movie_is_super Digby im gd\n  exact win_fight_opponent_not_win Digby Nemesis digby_fights_nemesis w\n\nAnswer: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 688,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 58,
    "premises": "Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.",
    "gpt_response": "Here is a Lean 4 formalization of the scenario and proofs for what follows.\n\nuniverse u\n\nconstant Person : Type\nconstant Book : Type\n\nconstant containsKnowledge : Book \u2192 Prop\nconstant gainsKnowledge : Person \u2192 Prop\nconstant smarter : Person \u2192 Prop\nconstant reads : Person \u2192 Book \u2192 Prop\n\nconstant Harry : Person\nconstant Walden : Book\n\n-- Axioms from the textual context\naxiom books_have_knowledge : \u2200 b : Book, containsKnowledge b\naxiom reading_gives_knowledge : \u2200 p : Person, \u2200 b : Book, reads p b \u2192 gainsKnowledge p\naxiom knowledge_makes_smarter : \u2200 p : Person, gainsKnowledge p \u2192 smarter p\naxiom harry_read_walden : reads Harry Walden\n\n-- Q1: Walden contains knowledge.\ntheorem Q1 : containsKnowledge Walden :=\n  books_have_knowledge Walden\n\n-- Q2: Harry is smarter than before.\ntheorem Q2 : smarter Harry :=\nby\n  have hk : gainsKnowledge Harry :=\n    reading_gives_knowledge Harry Walden harry_read_walden\n  exact knowledge_makes_smarter Harry hk\n\n-- Q3 would be the converse implication:\ndef Statement3 : Prop := \u2200 p : Person, smarter p \u2192 gainsKnowledge p\n-- This does not follow from the given axioms (and neither does its negation).\n\nAnswers:\n- Q1: True\n- Q2: True\n- Q3: Unknown\n\nTrue, True, Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 171,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 172,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 173,
        "conclusion": "A smarter person has gained knowledge.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 191,
    "premises": "A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.",
    "gpt_response": "Lean translation and attempt at proof:\n\n-- We model tasks and their properties\nuniverse u\nconstant Thing : Type u\n\nconstant Task       : Thing \u2192 Prop           -- NLP task\nconstant LG         : Thing \u2192 Prop           -- language generation\nconstant LU         : Thing \u2192 Prop           -- language understanding\nconstant OutputText : Thing \u2192 Prop           -- outputs a text sequence\n\nconstant MT : Thing                           -- machine translation\n\n-- Axioms from the textual context\naxioms\n  (ax1 : \u2200 x, Task x \u2192 (LG x \u2228 LU x))         -- every NLP task is either generation or understanding (possibly both)\n  (ax2 : \u2200 x, OutputText x \u2192 LG x)            -- if output is a text sequence, it is generation\n  (ax3 : Task MT)                              -- machine translation is an NLP task\n  (ax4 : OutputText MT)                        -- machine translation outputs a text sequence\n\n-- Question 1: Machine translation is a language generation task.\ntheorem Q1 : LG MT :=\n  ax2 MT ax4\n\n-- Question 2: Machine translation is a language understanding task.\n-- From the given axioms we have Task MT, hence LG MT \u2228 LU MT by ax1.\n-- Together with ax2 and ax4, we know LG MT holds. However, nothing given allows us to conclude LU MT,\n-- nor to refute it. Therefore, this statement is not derivable from the axioms.\n-- (No theorem provided; independence with respect to the given axioms.)\n\nAnswers:\n- Question 1: Machine translation is a language generation task. True\n- Question 2: Machine translation is a language understanding task. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 546,
        "conclusion": "Machine translation is a language generation task.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 547,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 166,
    "premises": "Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. ",
    "gpt_response": "Here is a faithful Lean 4 formalization of the given scenario, together with attempted proofs of the three questions. I model buildings, people, animals, rents, deposits, and the relevant policies.\n\nLean code:\n\nimport Mathlib.Data.Nat.Basic\n\nnamespace Scenario\n\n-- Basic domains\nconstant Person : Type\nconstant Animal : Type\nconstant Building : Type\n\n-- Constants for this story\nconstant Tom : Person\nconstant Fluffy : Animal\nconstant OliveGarden : Building\n\n-- Predicates and functions\nconstant Managed : Building \u2192 Prop\nconstant AllowsPets : Building \u2192 Prop\nconstant Cat : Animal \u2192 Prop\nconstant Pet : Animal \u2192 Prop\nconstant AllowedMoveInWithPet : Person \u2192 Building \u2192 Animal \u2192 Prop\nconstant MonthlyRent : Building \u2192 Nat\nconstant SecurityDeposit : Building \u2192 Nat\nconstant WillRent : Person \u2192 Building \u2192 Prop\n\n-- Facts from the text\n\n-- Pets are allowed in some managed buildings.\naxiom some_managed_allows_pets : \u2203 b : Building, Managed b \u2227 AllowsPets b\n\n-- A deposit is required to rent an apartment in a managed building.\n-- (We do not need to formalize mere \"requirement\" for these questions.)\n\n-- The security deposit can be either equal to the monthly rent at a managed building or more.\naxiom deposit_at_least_rent : \u2200 b : Building, Managed b \u2192 MonthlyRent b \u2264 SecurityDeposit b\n\n-- Fluffy is Tom's cat.\naxiom fluffy_is_a_cat : Cat Fluffy\n\n-- Cats are pets.\naxiom cats_are_pets : \u2200 a : Animal, Cat a \u2192 Pet a\n\n-- The Olive Garden is a managed building.\naxiom olive_is_managed : Managed OliveGarden\n\n-- The monthly rent at the Olive Garden is $2000.\naxiom olive_rent_2000 : MonthlyRent OliveGarden = 2000\n\n-- $2000 is more than $1500.\naxiom two_thousand_gt_1500 : 1500 < 2000\n\n-- Tom will rent an apartment in a managed building if he is allowed to move in with Fluffy,\n-- and the security deposit is no more than $1500.\naxiom tom_rents_if_allowed_and_deposit_small :\n  \u2200 b : Building, Managed b \u2192\n    (AllowedMoveInWithPet Tom b Fluffy \u2227 SecurityDeposit b \u2264 1500) \u2192\n    WillRent Tom b\n\n-- If a managed building allows pets, then people are allowed to move in with a pet.\naxiom allows_pets_implies_allowed_move_in :\n  \u2200 b : Building, Managed b \u2192 AllowsPets b \u2192\n    \u2200 p : Person, \u2200 a : Animal, Pet a \u2192 AllowedMoveInWithPet p b a\n\n-- Useful derived lemma: At Olive Garden, the deposit is at least 2000.\ntheorem deposit_at_least_2000 :\n  2000 \u2264 SecurityDeposit OliveGarden := by\n  have h1 : MonthlyRent OliveGarden \u2264 SecurityDeposit OliveGarden :=\n    deposit_at_least_rent OliveGarden olive_is_managed\n  simpa [olive_rent_2000] using h1\n\n-- Useful derived lemma: The deposit at Olive Garden is not \u2264 1500.\ntheorem deposit_not_le_1500 :\n  \u00ac (SecurityDeposit OliveGarden \u2264 1500) := by\n  -- From 1500 < 2000 and 2000 \u2264 deposit, we get 1500 < deposit, hence not (deposit \u2264 1500).\n  have hlt : 1500 < SecurityDeposit OliveGarden :=\n    Nat.lt_of_lt_of_le two_thousand_gt_1500 deposit_at_least_2000\n  exact Nat.not_le_of_lt hlt\n\n-- Question 3 target: \"The security deposit at the Olive Garden is either $2000 or more.\"\n-- This is naturally formalized as SecurityDeposit OliveGarden \u2265 2000, which we can prove.\ntheorem Q3 : 2000 \u2264 SecurityDeposit OliveGarden :=\n  deposit_at_least_2000\n\n-- For Question 2, to prove Tom is allowed to move into Olive Garden with Fluffy,\n-- we would need AllowsPets OliveGarden (plus Managed OliveGarden, which we have),\n-- then use cats_are_pets to show Fluffy is a Pet, and apply allows_pets_implies_allowed_move_in.\n-- But we only know that \"some\" managed building allows pets; we do not know it's Olive Garden.\n-- Hence we cannot derive AllowedMoveInWithPet Tom OliveGarden Fluffy from the given axioms.\n\n-- For Question 1, Tom's sufficient condition fails at Olive Garden because deposit \u2264 1500 is false,\n-- but that does not let us conclude \u00ac WillRent Tom OliveGarden (the rule is only one-way \"if\").\n-- So we cannot prove WillRent Tom OliveGarden nor its negation from the given axioms.\n\nend Scenario\n\nAnswers:\n\n1) Tom will rent an apartment in The Olive Garden.\nReasoning: The sufficient condition (allowed with Fluffy and deposit \u2264 1500) fails since the deposit at Olive Garden is \u2265 2000, but that does not imply he will not rent (no \u201conly if\u201d given). Therefore not provable either way. Unknown\n\n2) Tom is allowed to move into an apartment in The Olive Garden with Fluffy.\nReasoning: We only know some managed building allows pets; we do not know Olive Garden allows pets. Hence we cannot conclude allowance at Olive Garden. Unknown\n\n3) The security deposit at the Olive Garden is either $2000 or more.\nReasoning: From \u201cdeposit is at least the monthly rent\u201d and \u201crent at Olive Garden is $2000\u201d, we get deposit \u2265 $2000. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 476,
        "conclusion": "Tom will rent an apartment in The Olive Garden.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 477,
        "conclusion": "Tom is allowed to move into an apartment in The Olive Garden with Fluffy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 478,
        "conclusion": "The security deposit at the Olive Garden is either $2000 or more.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 352,
    "premises": "All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. ",
    "gpt_response": "Lean translation and proofs:\n\nuniverse u\n\nconstant Entity : Type u\nconstants\n  BusinessOrg LegalEntity Company PrivateCompany CreatedUnderLaw HasLegalObligations : Entity \u2192 Prop\nconstant H : Entity\n\naxioms\n  (A1 : \u2200 x, BusinessOrg x \u2192 LegalEntity x)\n  (A2 : \u2200 x, Company x \u2192 BusinessOrg x)\n  (A3 : \u2200 x, PrivateCompany x \u2192 Company x)\n  (A4 : \u2200 x, LegalEntity x \u2192 CreatedUnderLaw x)\n  (A5 : \u2200 x, LegalEntity x \u2192 HasLegalObligations x)\n  (A6 : CreatedUnderLaw H \u2192 \u00ac PrivateCompany H)\n\n-- Derived lemmas\nlemma private_implies_legal : \u2200 x, PrivateCompany x \u2192 LegalEntity x := by\n  intro x hx\n  exact A1 x (A2 x (A3 x hx))\n\nlemma private_implies_created : \u2200 x, PrivateCompany x \u2192 CreatedUnderLaw x := by\n  intro x hx\n  exact A4 x (private_implies_legal x hx)\n\nlemma private_implies_obligations : \u2200 x, PrivateCompany x \u2192 HasLegalObligations x := by\n  intro x hx\n  exact A5 x (private_implies_legal x hx)\n\n-- Key facts about H\nlemma not_private_H : \u00ac PrivateCompany H := by\n  intro hp\n  have hc : CreatedUnderLaw H := private_implies_created H hp\n  have hn : \u00ac PrivateCompany H := A6 hc\n  exact hn hp\n\n-- Q2: the conjunction is false\ntheorem q2_false : \u00ac (HasLegalObligations H \u2227 PrivateCompany H) := by\n  intro h\n  exact not_private_H h.right\n\n-- Q3: the implication is true (indeed, both disjuncts hold under the antecedent)\ntheorem q3_true : PrivateCompany H \u2192 (HasLegalObligations H \u2228 CreatedUnderLaw H) := by\n  intro hp\n  have hob : HasLegalObligations H := private_implies_obligations H hp\n  -- alternatively we could use CreatedUnderLaw H := private_implies_created H hp\n  exact Or.inl hob\n\n-- Q1 cannot be proved from the given axioms, nor can its negation, since we have no premise making H a legal entity (or otherwise linking H to obligations) without assuming it is a private company, which we showed is impossible. So Q1 remains undetermined here.\n\nAnswers:\n- Q1: We cannot derive that the Harvard Weekly Book Club has legal obligations, nor its negation, from the premises. Unknown\n- Q2: From the premises we derive \u00ac PrivateCompany H, so the conjunction \u201chas legal obligations and is a private company\u201d is false. False\n- Q3: If it is a private company, then it is a legal entity, hence both created under law and has legal obligations; therefore the \u201ceither \u2026 or \u2026\u201d statement holds. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 933,
        "conclusion": "The Harvard Weekly Book club has legal obligations.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 934,
        "conclusion": "The Harvard Weekly Book club has legal obligations and is a private company.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 935,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 472,
    "premises": "Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.",
    "gpt_response": "Here is a faithful formalization in Lean of the domain and assumptions, followed by attempted proofs of the three questions.\n\nLean formalization and attempts:\n\n-- We work classically\nopen Classical\n\nuniverse u\n\nconstant Entity : Type u\n\n-- Predicates\nconstant Animal : Entity \u2192 Prop\nconstant Vertebrate : Entity \u2192 Prop\nconstant Invertebrate : Entity \u2192 Prop\nconstant Backbone : Entity \u2192 Prop\nconstant ReproByMF : Entity \u2192 Prop\nconstant Bee : Entity \u2192 Prop\nconstant QueenBee : Entity \u2192 Prop\n\n-- Constant individual\nconstant Harry : Entity\n\n-- Axioms (from the textual context)\n-- 1. Animals are either invertebrates or vertebrates.\naxiom A1 : \u2200 x, Animal x \u2192 (Invertebrate x \u2228 Vertebrate x)\n\n-- 2. All animals with backbones reproduce by male-and-female mating.\naxiom A2 : \u2200 x, (Animal x \u2227 Backbone x) \u2192 ReproByMF x\n\n-- 3. All vertebrate animals have a backbone.\naxiom A3 : \u2200 x, Vertebrate x \u2192 Backbone x\n\n-- 4. All bees do not reproduce by male-and-female mating.\naxiom A4 : \u2200 x, Bee x \u2192 \u00ac ReproByMF x\n\n-- 5. All queen bees are bees.\naxiom A5 : \u2200 x, QueenBee x \u2192 Bee x\n\n-- 6. Harry is a bee.\naxiom A6 : Bee Harry\n\n-- Some easy consequences that might be useful\nlemma not_repro_Harry : \u00ac ReproByMF Harry :=\n  by\n    have : Bee Harry := A6\n    exact (A4 Harry) this\n\n-- Note: We do NOT have Animal Harry as an axiom, so we cannot trigger A1 or A2 on Harry.\n\n-- Question 1: Is Harry a queen bee?\n-- Target: QueenBee Harry\n-- This is not derivable from the axioms (and its negation is also not derivable).\n-- We leave it unprovable here.\ndef Q1 : Prop := QueenBee Harry\n-- We cannot prove Q1 nor \u00acQ1 from the given axioms.\n\n-- Question 2: Is Harry an invertebrate or a queen bee?\n-- Target: Invertebrate Harry \u2228 QueenBee Harry\ndef Q2 : Prop := Invertebrate Harry \u2228 QueenBee Harry\n-- We cannot prove Q2 nor its negation from the given axioms.\n\n-- Question 3: If (Harry is both a vertebrate and has a backbone) or (neither a vertebrate nor has a backbone),\n-- then Harry is neither an invertebrate nor a queen bee.\ndef Q3 : Prop :=\n  ((Vertebrate Harry \u2227 Backbone Harry) \u2228 (\u00ac Vertebrate Harry \u2227 \u00ac Backbone Harry))\n  \u2192 (\u00ac Invertebrate Harry \u2227 \u00ac QueenBee Harry)\n-- This implication also does not follow from the axioms, and its negation is not derivable.\n\nAnswers:\n\nQuestion 1: Unknown\nQuestion 2: Unknown\nQuestion 3: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1366,
        "conclusion": "Harry is a queen bee.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1367,
        "conclusion": "Harry is an invertebrate or a queen bee.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1368,
        "conclusion": "If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 379,
    "premises": "People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers",
    "gpt_response": "Lean translation and proofs:\n\n-- We work in classical logic\nset_option autoImplicit false\nuniverse u\nopen Classical\n\nconstant Person : Type\n\n-- Predicates\nconstant BornMultiple : Person \u2192 Prop\nconstant SpendTimeWithSibs : Person \u2192 Prop\nconstant HaveSibsBornTogether : Person \u2192 Prop\nconstant ComplainOften : Person \u2192 Prop\nconstant LiveAtHome : Person \u2192 Prop\nconstant LiveWithStrangers : Person \u2192 Prop\n\n-- Individual\nconstant Luke : Person\n\n-- Axioms from the text\naxiom A1 : \u2200 x : Person, BornMultiple x \u2192 SpendTimeWithSibs x\naxiom A2 : \u2200 x : Person, HaveSibsBornTogether x \u2192 BornMultiple x\naxiom A3 : \u2200 x : Person, ComplainOften x \u2192 HaveSibsBornTogether x\naxiom A4 : \u2200 x : Person, LiveAtHome x \u2192 \u00ac LiveWithStrangers x\naxiom A5 : \u2200 x : Person, SpendTimeWithSibs x \u2192 LiveAtHome x\n-- Disjunction about Luke\naxiom A6 : (BornMultiple Luke \u2227 LiveWithStrangers Luke) \u2228 (\u00ac BornMultiple Luke \u2227 \u00ac LiveWithStrangers Luke)\n\n-- Consequences about Luke\n\n-- Rule chain: BornMultiple \u2192 SpendTime \u2192 LiveAtHome \u2192 \u00ac LiveWithStrangers\nlemma born_multiple_implies_not_strangers (x : Person) :\n    BornMultiple x \u2192 \u00ac LiveWithStrangers x :=\nby\n  intro hbm\n  have hst : SpendTimeWithSibs x := A1 x hbm\n  have hhome : LiveAtHome x := A5 x hst\n  exact A4 x hhome\n\n-- From A6 and the above, deduce the second disjunct must hold\nlemma luke_not_born_multiple_and_not_strangers :\n    \u00ac BornMultiple Luke \u2227 \u00ac LiveWithStrangers Luke :=\nby\n  rcases A6 with h | h\n  \u00b7 rcases h with \u27e8hb, hs\u27e9\n    have : \u00ac LiveWithStrangers Luke := born_multiple_implies_not_strangers Luke hb\n    exact (this hs).elim\n  \u00b7 exact h\n\nlemma luke_not_born_multiple : \u00ac BornMultiple Luke :=\n  (luke_not_born_multiple_and_not_strangers).left\n\nlemma luke_not_live_with_strangers : \u00ac LiveWithStrangers Luke :=\n  (luke_not_born_multiple_and_not_strangers).right\n\n-- From ComplainOften \u2192 HaveSibsBornTogether \u2192 BornMultiple, and \u00ac BornMultiple Luke, we get \u00ac ComplainOften Luke\nlemma complain_implies_born_multiple (x : Person) :\n    ComplainOften x \u2192 BornMultiple x :=\nby\n  intro hc\n  exact A2 x (A3 x hc)\n\nlemma luke_not_complain_often : \u00ac ComplainOften Luke :=\nby\n  intro hc\n  have hb : BornMultiple Luke := complain_implies_born_multiple Luke hc\n  exact (luke_not_born_multiple hb).elim\n\n-- What we can (and cannot) prove for the questions:\n-- Q1 asks for SpendTimeWithSibs Luke. From the axioms we cannot derive SpendTimeWithSibs Luke,\n-- nor its negation, so it remains undetermined in this theory.\n-- Q2 asks for ComplainOften Luke. We proved \u00ac ComplainOften Luke.\n-- Q3 asks for (\u00ac BornMultiple Luke \u2227 \u00ac ComplainOften Luke). We proved both conjuncts.\n\n-- For convenience, we package Q2 and Q3:\ntheorem Q2_false : \u00ac ComplainOften Luke := luke_not_complain_often\ntheorem Q3_true : (\u00ac BornMultiple Luke \u2227 \u00ac ComplainOften Luke) :=\n  And.intro luke_not_born_multiple luke_not_complain_often\n\n\nAnswers:\n1) Luke spends a lot of time hanging out and playing with his siblings. Unknown\n2) Luke complains often about annoying siblings. False\n3) Luke is neither born in a multiple birth nor complains often about annoying siblings. True\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1011,
        "conclusion": "Luke spends a lot of time hanging out and playing with his siblings.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1012,
        "conclusion": "Luke complains often about annoying siblings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1013,
        "conclusion": "Luke is neither born in a multiple birth nor complains often about annoying siblings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 197,
    "premises": "It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.",
    "gpt_response": "Lean formalization and proofs:\n\nnamespace GRE\n\nuniverse u\n\nconstant Agent : Type u\nconstant Tom ETS : Agent\n\nconstant GREApplicant : Agent \u2192 Prop\nconstant ProvesHardship : Agent \u2192 Prop\nconstant LivesInSingleParentFamily : Agent \u2192 Prop\nconstant FewResources : Agent \u2192 Prop\nconstant ProvidesFinancialAid : Agent \u2192 Agent \u2192 Prop\n\nconstant Test : Type\nconstant GRE : Test\nconstant Cost : Test \u2192 Nat\n\n-- Premises\naxiom policy : \u2200 x, GREApplicant x \u2227 ProvesHardship x \u2192 ProvidesFinancialAid ETS x\naxiom hardship : \u2200 x, (LivesInSingleParentFamily x \u2228 FewResources x) \u2192 ProvesHardship x\naxiom tom_family : LivesInSingleParentFamily Tom\naxiom tom_resources : FewResources Tom\naxiom tom_app : GREApplicant Tom\naxiom cost_GRE : Cost GRE = 205\naxiom lt205_300 : 205 < 300\n\n-- Q1: ETS provides financial aid to Tom.\ndef Q1 : Prop := ProvidesFinancialAid ETS Tom\ntheorem Q1_true : Q1 := by\n  have hph : ProvesHardship Tom := by\n    exact hardship Tom (Or.inl tom_family)\n  exact policy Tom \u27e8tom_app, hph\u27e9\n\n-- Q2: It costs below US $300 to take the GRE test.\ndef Q2 : Prop := Cost GRE < 300\ntheorem Q2_true : Q2 := by\n  simpa [cost_GRE] using lt205_300\n\n-- Q3: No one taking the GRE test has financial aid provided to them by something.\ndef Q3 : Prop := \u2200 x, GREApplicant x \u2192 \u00ac \u2203 y, ProvidesFinancialAid y x\ntheorem Q3_false : \u00ac Q3 := by\n  intro h\n  have hx : GREApplicant Tom := tom_app\n  have hneg := h Tom hx\n  apply hneg\n  exact \u27e8ETS, Q1_true\u27e9\n\nend GRE\n\nAnswers:\n- Question 1: ETS provides financial aid to Tom. True\n- Question 2: It costs below US $300 to take the GRE test. True\n- Question 3: No one taking the GRE test has financial aid provided to them by something. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 560,
        "conclusion": "ETS provides financial aid to Tom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 561,
        "conclusion": "It costs below US $300 to take the GRE test.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 562,
        "conclusion": "No one taking the GRE test has financial aid provided to them by something.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 361,
    "premises": "If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly",
    "gpt_response": "Lean translation and attempt\n\nWe model people and predicates:\n- Spill x: x spills a lot of food on their clothing\n- Tidy x: x is notably tidy\n- Cleanly x: x is cleanly\n- Values x: x values order and spotlessness\n- Family x: x\u2019s family prioritizes order and spotlessness\n- Clumsy x: x is a clumsy foodie who goes out frequently to find new food restaurants to try\n- Peter: a specific person\n\nLean code:\n--------------------------------\nuniverse u\n\nconstant Person : Type\n\n-- Predicates\nconstant Spill   : Person \u2192 Prop\nconstant Tidy    : Person \u2192 Prop\nconstant Cleanly : Person \u2192 Prop\nconstant Values  : Person \u2192 Prop\nconstant Family  : Person \u2192 Prop\nconstant Clumsy  : Person \u2192 Prop\n\nconstant Peter : Person\n\n-- Axioms (from the textual context)\naxiom spill_imp_not_tidy   : \u2200 x : Person, Spill x \u2192 \u00ac Tidy x\naxiom clumsy_imp_spill     : \u2200 x : Person, Clumsy x \u2192 Spill x\naxiom cleanly_imp_tidy     : \u2200 x : Person, Cleanly x \u2192 Tidy x\naxiom values_imp_cleanly   : \u2200 x : Person, Values x \u2192 Cleanly x\naxiom family_imp_values    : \u2200 x : Person, Family x \u2192 Values x\naxiom peter_either         :\n  (Spill Peter \u2227 Cleanly Peter) \u2228 (\u00ac Spill Peter \u2227 \u00ac Cleanly Peter)\n\n-- Consequences we can prove\nlemma no_spill_and_cleanly (x : Person) : \u00ac (Spill x \u2227 Cleanly x) :=\nby\n  intro h\n  rcases h with \u27e8hxS, hxC\u27e9\n  have hxT : Tidy x := cleanly_imp_tidy x hxC\n  have hxNotT : \u00ac Tidy x := spill_imp_not_tidy x hxS\n  exact hxNotT hxT\n\nlemma peter_not_spill_and_not_cleanly : \u00ac Spill Peter \u2227 \u00ac Cleanly Peter :=\nby\n  rcases peter_either with h | h\n  \u00b7 exact False.elim (no_spill_and_cleanly Peter h)\n  \u00b7 exact h\n--------------------------------\n\nDiscussion:\n- From the axioms, (Spill x \u2227 Cleanly x) is impossible for any x, hence for Peter. Therefore, from the given disjunction about Peter, we can conclude \u00acSpill Peter \u2227 \u00acCleanly Peter.\n- However, Cleanly \u2192 Tidy does not let us infer anything from \u00acCleanly about Tidy; and Spill \u2192 \u00acTidy does not let us infer anything from \u00acSpill about Tidy.\n- We have no information connecting Peter to Clumsy or Family, so we cannot establish the disjunctions/equivalences in Q2 and Q3.\n\nAnswers:\n- Question 1: Peter is notably tidy. Unknown\n- Question 2: Peter is either a clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness. Unknown\n- Question 3: Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and is someone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness. Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 958,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 959,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 960,
        "conclusion": "Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 262,
    "premises": "All fir trees are evergreens.\nSome objects of worship are fir trees.",
    "gpt_response": "Lean translation and attempt:\n\nWe formalize:\n- Universe of discourse U : Type\n- Predicates: Fir, Evergreen, Worship : U \u2192 Prop\n- Premises:\n  1) h1 : \u2200 x, Fir x \u2192 Evergreen x\n  2) h2 : \u2203 x, Worship x \u2227 Fir x\n- Target statement (the \u201ctheorem\u201d to try to prove): \u2203 x, Evergreen x \u2227 \u00ac Worship x\n\nLean code:\n\n/- Setup -/\nuniverse u\n\nsection\n\nvariable {U : Type u} (Fir Evergreen Worship : U \u2192 Prop)\n\n-- Premises\nvariable (h1 : \u2200 x, Fir x \u2192 Evergreen x)\nvariable (h2 : \u2203 x, Worship x \u2227 Fir x)\n\n-- What we can derive: there exists an evergreen that is an object of worship.\nlemma exists_evergreen_and_worship :\n  \u2203 x, Evergreen x \u2227 Worship x :=\nby\n  rcases h2 with \u27e8x, hxW, hxF\u27e9\n  have hxE : Evergreen x := h1 x hxF\n  exact \u27e8x, And.intro hxE hxW\u27e9\n\n-- Target (claimed) conclusion: \u2203 x, Evergreen x \u2227 \u00ac Worship x\n-- This does not follow from the premises in general.\n\nend\n\n/- Countermodel to show non-entailment (h1 and h2 true while the target is false) -/\nsection Countermodel\n\n-- Take a one-element domain\ndef U\u2080 := Unit\n\n-- Interpret all three predicates as always true\ndef Fir\u2080 (_ : U\u2080) : Prop := True\ndef Evergreen\u2080 (_ : U\u2080) : Prop := True\ndef Worship\u2080 (_ : U\u2080) : Prop := True\n\n-- Premise 1 holds\ntheorem h1\u2080 : \u2200 x, Fir\u2080 x \u2192 Evergreen\u2080 x :=\nby\n  intro x hx\n  trivial\n\n-- Premise 2 holds (there exists x with Worship and Fir)\ntheorem h2\u2080 : \u2203 x, Worship\u2080 x \u2227 Fir\u2080 x :=\nby\n  refine \u27e8(), And.intro ?_ ?_\u27e9 <;> trivial\n\n-- The target conclusion is false in this model\ntheorem target_false_in_model : \u00ac (\u2203 x, Evergreen\u2080 x \u2227 \u00ac Worship\u2080 x) :=\nby\n  intro h\n  rcases h with \u27e8x, hxE, hxNotW\u27e9\n  -- But Worship\u2080 x is True by definition, contradiction\n  exact hxNotW trivial\n\nend\n\n-- Summary: From the premises we can derive that some evergreen is an object of worship,\n-- but there is a concrete model where the premises hold and the target conclusion fails.\n-- Therefore, the statement is not entailed by the premises.\n\nAnswer to Question 1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 706,
        "conclusion": "Some evergreens are not objects of worship.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 124,
    "premises": "The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.",
    "gpt_response": "Answers:\n1) True\n2) Unknown\n3) False\n\nLean 4 formalization and proofs:\n\n-- Types\nuniverse u\nconstant MountainRange : Type u\nconstant Mine : Type u\nconstant Person : Type u\n\n-- Predicates\nconstant InNM : MountainRange \u2192 Prop\nconstant InTX : MountainRange \u2192 Prop\nconstant Visited : Person \u2192 MountainRange \u2192 Prop\nconstant LocatedIn : Mine \u2192 MountainRange \u2192 Prop\nconstant Donated : Mine \u2192 Prop\n\n-- Constants for our entities\nconstant picuris : MountainRange\nconstant juan : Person\nconstant harding : Mine\n\n-- Assumptions from the textual context\naxiom nm_or_tx : InNM picuris \u2228 InTX picuris\naxiom visited_picuris : Visited juan picuris\naxiom located_harding_picuris : LocatedIn harding picuris\naxiom harding_donated : Donated harding\naxiom no_tx_with_donated_mine :\n  \u2200 (r : MountainRange), InTX r \u2192 \u00ac (\u2203 m : Mine, LocatedIn m r \u2227 Donated m)\n\n-- Derived facts\nlemma picuris_not_in_TX : \u00ac InTX picuris :=\nby\n  intro hTX\n  have hcontra : \u2203 m : Mine, LocatedIn m picuris \u2227 Donated m :=\n    \u27e8harding, And.intro located_harding_picuris harding_donated\u27e9\n  have : \u00ac (\u2203 m : Mine, LocatedIn m picuris \u2227 Donated m) :=\n    no_tx_with_donated_mine picuris hTX\n  exact this hcontra\n\nlemma picuris_in_NM : InNM picuris :=\nby\n  cases nm_or_tx with\n  | inl hnm => exact hnm\n  | inr htx => cases picuris_not_in_TX htx\n\n-- Q1: Juan visited a mountain range in New Mexico.\ntheorem Q1_true : \u2203 r : MountainRange, Visited juan r \u2227 InNM r :=\nby\n  exact \u27e8picuris, And.intro visited_picuris picuris_in_NM\u27e9\n\n-- Q2: Juan visited a mountain range in Texas.\n-- Not provable from given axioms (could be other visits unknown).\n-- We do not assert a theorem here.\n\n-- Q3: \u201cThe Harding Pegmatite Mine is not located in a mountain range in New Mexico.\u201d\n-- That statement is false. We prove its negation by exhibiting Picuris in NM containing the mine.\ntheorem Q3_negation_true : \u2203 r : MountainRange, LocatedIn harding r \u2227 InNM r :=\nby\n  exact \u27e8picuris, And.intro located_harding_picuris picuris_in_NM\u27e9\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 370,
        "conclusion": "Juan de Onate visited a mountain range in New Mexico.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 371,
        "conclusion": "Juan de Onate visited a mountain range in Texas.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 372,
        "conclusion": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 183,
    "premises": "If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.",
    "gpt_response": "Lean translation and attempted proofs:\n\n-- We model people, predicates, and the named individuals.\nuniverse u\n\nconstant Person : Type u\nconstant Man : Person \u2192 Prop\nconstant Taller : Person \u2192 Person \u2192 Prop          -- Taller x y means x is taller than y\nconstant CanBlock : Person \u2192 Person \u2192 Prop        -- CanBlock x y means x can block y's shooting\nconstant InMClass : Person \u2192 Prop                 -- InMClass y means y is in Michael's class\nconstant Jumps : Person \u2192 Prop                    -- Jumps y means y can jump when shooting\nconstant Great : Person \u2192 Prop                    -- Great y means y is a great shooter\n\nconstant Michael : Person\nconstant Peter : Person\nconstant Windy : Person\n\n-- Axioms extracted from the textual context.\n\n-- 1) If a man is taller than another man, the taller one can block the other's shooting.\naxiom H_man_block :\n  \u2200 {x y : Person}, Man x \u2192 Man y \u2192 Taller x y \u2192 CanBlock x y\n\n-- 2) Michael is a man who is taller than everyone else in his class.\naxiom H_Michael_man : Man Michael\naxiom H_Michael_taller_class :\n  \u2200 {y : Person}, InMClass y \u2192 y \u2260 Michael \u2192 Taller Michael y\n\n-- 3) Taller is transitive.\naxiom H_taller_trans :\n  \u2200 {x y z : Person}, Taller x y \u2192 Taller y z \u2192 Taller x z\n\n-- 4) Peter is a man who is taller than Michael.\naxiom H_Peter : Man Peter \u2227 Taller Peter Michael\n\n-- 5) Michael can block any shooting from a person as long as the person does not jump when shooting.\naxiom H_Michael_blocks_if_not_jump :\n  \u2200 {p : Person}, \u00ac Jumps p \u2192 CanBlock Michael p\n\n-- 6) Michael cannot block Windy's shooting.\naxiom H_Michael_cannot_block_Windy : \u00ac CanBlock Michael Windy\n\n-- 7) Every shooter who can jump when shooting is a great shooter.\naxiom H_jump_implies_great : \u2200 {p : Person}, Jumps p \u2192 Great p\n\n-- A useful derived lemma: Peter is taller than every member of Michael's class.\nlemma Peter_taller_of_Mclass {y : Person} (hc : InMClass y) : Taller Peter y := by\n  classical\n  by_cases h : y = Michael\n  \u00b7 -- y = Michael\n    simpa [h] using H_Peter.right\n  \u00b7 -- y \u2260 Michael\n    exact H_taller_trans H_Peter.right (H_Michael_taller_class hc h)\n\n-- Question 2: Windy is a great shooter.\n-- Proof: From \u00acCanBlock(Michael, Windy) and (\u00acJumps \u2192 CanBlock), we get Jumps Windy.\n-- Then by (Jumps \u2192 Great), Great Windy holds.\ntheorem Q2_Windy_is_great : Great Windy := by\n  classical\n  have hJ : Jumps Windy := by\n    by_contra hNJ\n    have : CanBlock Michael Windy := H_Michael_blocks_if_not_jump hNJ\n    exact H_Michael_cannot_block_Windy this\n  exact H_jump_implies_great hJ\n\n-- Question 1 and Question 3 are not provable from the given axioms alone:\n-- For Q1, although we can show Peter is taller than every member of Michael's class (lemma above),\n-- we have not assumed asymmetry of Taller, so we cannot refute the existence of someone taller than Peter.\n-- For Q3, we lack any height relation or gender info about Windy, so the blocking rule for \"man taller than man\"\n-- cannot be applied, and nothing else implies Peter can block Windy.\n\nAnswers:\n- Question 1: Peter is shorter than a man in Michael's class. Unknown\n- Question 2: Windy is a great shooter. True\n- Question 3: Peter can block Windy's shooting. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 527,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 528,
        "conclusion": "Windy is a great shooter.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 529,
        "conclusion": "Peter can block Windy's shooting.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 151,
    "premises": "Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.",
    "gpt_response": "Lean translation and attempt at proofs:\n\n-- Entities\nuniverse u\nconstant Place : Type\nconstant BarutinCove SnowIsland GreenwichIsland DeceptionIsland SouthShetlandIslands Antarctica Barutin : Place\n\n-- Predicates/relations\nconstant Cove : Place \u2192 Prop\nconstant Island : Place \u2192 Prop\nconstant BulgarianSettlement : Place \u2192 Prop\nconstant NamedAfter : Place \u2192 Place \u2192 Prop\nconstant LocatedIn : Place \u2192 Place \u2192 Prop\n\n-- Facts from the text\naxiom h1 : Cove BarutinCove\naxiom h2 : BulgarianSettlement Barutin\naxiom h3 : NamedAfter BarutinCove Barutin\naxiom h4 : LocatedIn BarutinCove SnowIsland\naxiom h5 : LocatedIn SnowIsland SouthShetlandIslands\naxiom h6 : LocatedIn GreenwichIsland SouthShetlandIslands\naxiom h7 : LocatedIn DeceptionIsland SouthShetlandIslands\naxiom h8 : LocatedIn Antarctica SouthShetlandIslands\n\n-- Transitivity of location\naxiom loc_trans : \u2200 {A B C : Place}, LocatedIn A B \u2192 LocatedIn B C \u2192 LocatedIn A C\n\n-- What we can prove from the above:\nlemma BarutinCove_in_SSI : LocatedIn BarutinCove SouthShetlandIslands :=\n  loc_trans h4 h5\n\n-- Note: From the given (somewhat unusual) premise h8 (Antarctica is located in the South Shetland Islands),\n-- we cannot deduce that South Shetland Islands are located in Antarctica, so we cannot place BarutinCove in Antarctica.\n\n-- Questions formalized:\n\n-- Q1: \u201cBarutin Cove is named after all islands in Antarctica.\u201d\n-- \u2200 i, Island i \u2227 LocatedIn i Antarctica \u2192 NamedAfter BarutinCove i\ndef Q1 : Prop := \u2200 i : Place, Island i \u2227 LocatedIn i Antarctica \u2192 NamedAfter BarutinCove i\n\n-- Q2: \u201cThere is at least one cove in Antarctica named after a place in Bulgaria (a Bulgarian settlement).\u201d\n-- \u2203 c y, Cove c \u2227 LocatedIn c Antarctica \u2227 BulgarianSettlement y \u2227 NamedAfter c y\ndef Q2 : Prop :=\n  \u2203 c y : Place, Cove c \u2227 LocatedIn c Antarctica \u2227 BulgarianSettlement y \u2227 NamedAfter c y\n\n-- Q3: \u201cBarutin Cove is not located in Antarctica.\u201d\n-- \u00ac LocatedIn BarutinCove Antarctica\ndef Q3 : Prop := \u00ac LocatedIn BarutinCove Antarctica\n\n-- Attempted proofs:\n-- From the provided axioms, Q1 cannot be derived (no info relating islands in Antarctica to being namesakes of Barutin Cove).\n-- Its negation also cannot be derived (we have no inhabited example of an island in Antarctica).\n-- Hence Q1 is not provable here.\n\n-- For Q2, we can prove existence in South Shetland Islands (using BarutinCove_in_SSI, h1, h2, h3),\n-- but not in Antarctica due to lack of a premise that South Shetland Islands \u2286 Antarctica.\n-- Hence Q2 is not provable (nor is its negation provable from these axioms).\n\n-- For Q3, we have no information to prove LocatedIn BarutinCove Antarctica or its negation.\n-- Hence Q3 is not provable (nor is its negation provable) from these axioms.\n\n\nAnswers:\n\n1) Unknown\n2) Unknown\n3) Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 439,
        "conclusion": "Barutin Cove is named after all islands in Antarctica.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 440,
        "conclusion": "There is at least one cove in Antarctica named after a place in Bulgaria.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 441,
        "conclusion": "Barutin Cove is not located in Antarctica.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 295,
    "premises": "Some affection is love.\nSome love is positive.",
    "gpt_response": "Lean translation and attempt:\n\nWe model a domain U with predicates Affection, Love, Positive : U \u2192 Prop.\nPremises:\n- h1 : \u2203 x, Affection x \u2227 Love x        -- \u201cSome affection is love.\u201d\n- h2 : \u2203 x, Love x \u2227 Positive x         -- \u201cSome love is positive.\u201d\nConclusion to prove:\n- \u2203 x, Affection x \u2227 Positive x         -- \u201cSome affection is positive.\u201d\n\nIn general, this does not follow from the premises (the witnesses for the two existentials may be different). We can show a countermodel in Lean.\n\nLean code:\n\nuniverse u\nopen Classical\n\n-- The (unprovable) target sequent:\ntheorem desired (U : Type u) (Affection Love Positive : U \u2192 Prop)\n  (h1 : \u2203 x, Affection x \u2227 Love x)\n  (h2 : \u2203 x, Love x \u2227 Positive x) :\n  \u2203 x, Affection x \u2227 Positive x := by\n  -- This is not derivable in general.\n  sorry\n\n-- Countermodel witnessing non-validity\ninductive Two | a | b deriving DecidableEq\nopen Two\n\nnamespace Counter\n\ndef Affection : Two \u2192 Prop\n| a => True\n| b => False\n\ndef Love : Two \u2192 Prop\n| _ => True\n\ndef Positive : Two \u2192 Prop\n| a => False\n| b => True\n\nlemma h1 : \u2203 x, Affection x \u2227 Love x := by\n  refine \u27e8a, And.intro trivial trivial\u27e9\n\nlemma h2 : \u2203 x, Love x \u2227 Positive x := by\n  refine \u27e8b, And.intro trivial trivial\u27e9\n\nlemma not_concl : \u00ac (\u2203 x, Affection x \u2227 Positive x) := by\n  intro h\n  rcases h with \u27e8x, hx\u27e9\n  cases x with\n  | a =>\n    rcases hx with \u27e8ha, hp\u27e9\n    cases hp\n  | b =>\n    rcases hx with \u27e8ha, hp\u27e9\n    cases ha\n\nend Counter\n\ntheorem not_valid :\n  \u00ac (\u2200 (U : Type) (Affection Love Positive : U \u2192 Prop),\n       (\u2203 x, Affection x \u2227 Love x) \u2192\n       (\u2203 x, Love x \u2227 Positive x) \u2192\n       (\u2203 x, Affection x \u2227 Positive x)) := by\n  intro h\n  have hconcl := h Two Counter.Affection Counter.Love Counter.Positive Counter.h1 Counter.h2\n  exact Counter.not_concl hconcl\n\nConclusion: The statement \u201cSome affection is positive\u201d is not entailed by the premises; it is consistent but not forced.\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 739,
        "conclusion": "Some affection is positive.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 315,
    "premises": "If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. ",
    "gpt_response": "Here is a Lean 4 formalization of the given context and the three questions. I include some derived consequences that do follow, and then (unsuccessfully) attempt to prove each queried statement; none of the three statements nor their negations are derivable from the premises.\n\nLean code (translation and attempted proofs):\n\nimport Std.Logic\n\nuniverse u\n\nconstant Car : Type u\n\n-- Predicates\nconstant TransportMultiplePassengers : Car \u2192 Prop\nconstant OneSeater                  : Car \u2192 Prop\nconstant TeslaModel3                : Car \u2192 Prop\nconstant SingleSeatElectricCar      : Car \u2192 Prop\nconstant SoloEV                     : Car \u2192 Prop\n\n-- A specific car: John's car\nconstant j : Car\n\n-- Axioms from the textual context\naxiom A1 : \u2200 x : Car, TransportMultiplePassengers x \u2192 \u00ac OneSeater x\naxiom A2 : \u2200 x : Car, TeslaModel3 x \u2192 TransportMultiplePassengers x\naxiom A3 : \u2200 x : Car, SingleSeatElectricCar x \u2192 OneSeater x\naxiom A4 : \u2200 x : Car, SoloEV x \u2192 SingleSeatElectricCar x\naxiom A5 : (\u00ac TeslaModel3 j) \u2192 ((\u00ac TeslaModel3 j) \u2228 SingleSeatElectricCar j)\n\n-- Some derived consequences that do follow\nlemma Tesla_not_oneSeater : \u2200 x, TeslaModel3 x \u2192 \u00ac OneSeater x :=\n  by\n    intro x hT\n    have hTMP : TransportMultiplePassengers x := A2 x hT\n    exact A1 x hTMP\n\nlemma SoloEV_oneSeater : \u2200 x, SoloEV x \u2192 OneSeater x :=\n  by\n    intro x hSolo\n    have hSSEC : SingleSeatElectricCar x := A4 x hSolo\n    exact A3 x hSSEC\n\n-- Question 1: Is John's car a Tesla Model 3?\n-- Attempt to prove: TeslaModel3 j\ntheorem Q1 : TeslaModel3 j :=\n  by\n    -- Not derivable from the given axioms\n    admit\n\n-- Attempt to prove its negation\ntheorem not_Q1 : \u00ac TeslaModel3 j :=\n  by\n    -- Also not derivable from the given axioms\n    admit\n\n-- Question 2: Is John's car a Solo EV?\n-- Attempt to prove: SoloEV j\ntheorem Q2 : SoloEV j :=\n  by\n    -- Not derivable from the given axioms\n    admit\n\n-- Attempt to prove its negation\ntheorem not_Q2 : \u00ac SoloEV j :=\n  by\n    -- Also not derivable from the given axioms\n    admit\n\n-- Question 3: Is it the case that John's car is not a Solo EV?\n-- Attempt to prove: \u00ac SoloEV j\ntheorem Q3 : \u00ac SoloEV j :=\n  by\n    -- Not derivable from the given axioms\n    admit\n\n-- Attempt to prove its negation\ntheorem not_Q3 : SoloEV j :=\n  by\n    -- Also not derivable from the given axioms\n    admit\n\nExplanations:\n- From the premises we can derive useful chains like:\n  - TeslaModel3 x \u2192 TransportMultiplePassengers x \u2192 \u00acOneSeater x.\n  - SoloEV x \u2192 SingleSeatElectricCar x \u2192 OneSeater x.\n- However, there is no premise that tells us anything specific about John\u2019s car being a Tesla Model 3 or a Solo EV.\n- The fifth premise (\u00acT(j)) \u2192 ((\u00acT(j)) \u2228 SSEC(j)) is a tautological implication and does not give new information about j.\n\nAnswers:\n- Question 1: Unknown\n- Question 2: Unknown\n- Question 3: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 786,
        "conclusion": "John's car is a Tesla Model 3.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 787,
        "conclusion": "John's car is a Solo EV.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 788,
        "conclusion": "John's car is not a Solo EV.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 467,
    "premises": "All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. ",
    "gpt_response": "Lean formalization and attempt at proofs:\n\nWe work in a first-order setting with a single universe of entities and the following predicates:\n- Pet x: x is Peter\u2019s pet\n- Mammal x\n- Animal x\n- Monkey x\n- Bird x\n- CanFly x\n- CanBreathe x\n- HasWings x\n\nConstant:\n- rock : entity\n\nAxioms encoded from the text:\n1. \u2200 x, Pet x \u2227 Mammal x \u2192 Animal x\n2. \u2200 x, Monkey x \u2192 Mammal x\n3. \u2200 x, Pet x \u2192 (Monkey x \u2228 Bird x)\n4. \u2200 x, Pet x \u2227 Bird x \u2192 CanFly x\n5. \u2200 x, Animal x \u2227 Pet x \u2192 CanBreathe x\n6. \u2200 x, Pet x \u2227 CanFly x \u2192 HasWings x\n7. Pet rock\n8. CanFly rock \u2228 Bird rock \u2228 \u00ac CanBreathe rock\n\nLean 4 code:\n\nnamespace PeterPets\n\nuniverse u\n\nconstant U : Sort u\n\n-- Predicates\nconstant Pet : U \u2192 Prop\nconstant Mammal : U \u2192 Prop\nconstant Animal : U \u2192 Prop\nconstant Monkey : U \u2192 Prop\nconstant Bird : U \u2192 Prop\nconstant CanFly : U \u2192 Prop\nconstant CanBreathe : U \u2192 Prop\nconstant HasWings : U \u2192 Prop\n\n-- Constant individual\nconstant rock : U\n\n-- Axioms from the text\naxiom A1 : \u2200 x, Pet x \u2227 Mammal x \u2192 Animal x\naxiom A2 : \u2200 x, Monkey x \u2192 Mammal x\naxiom A3 : \u2200 x, Pet x \u2192 (Monkey x \u2228 Bird x)\naxiom A4 : \u2200 x, Pet x \u2227 Bird x \u2192 CanFly x\naxiom A5 : \u2200 x, Animal x \u2227 Pet x \u2192 CanBreathe x\naxiom A6 : \u2200 x, Pet x \u2227 CanFly x \u2192 HasWings x\naxiom A7 : Pet rock\naxiom A8 : CanFly rock \u2228 Bird rock \u2228 \u00ac CanBreathe rock\n\n-- Some derived lemmas that the axioms do justify.\n\n-- If rock is a bird, then rock can fly.\nlemma rock_fly_of_bird : Bird rock \u2192 CanFly rock :=\nby\n  intro hBird\n  have : Pet rock \u2227 Bird rock := And.intro A7 hBird\n  exact A4 rock this\n\n-- If rock can fly, then rock has wings.\nlemma rock_wings_of_fly : CanFly rock \u2192 HasWings rock :=\nby\n  intro hFly\n  exact A6 rock (And.intro A7 hFly)\n\n-- If rock is a bird, then rock has wings (bird \u2192 fly \u2192 wings).\nlemma rock_wings_of_bird : Bird rock \u2192 HasWings rock :=\nby\n  intro hBird\n  exact rock_wings_of_fly (rock_fly_of_bird hBird)\n\n-- From the disjunction A8, we can derive that either rock has wings or \u00acCanBreathe rock.\nlemma wings_or_not_breathe :\n  HasWings rock \u2228 \u00ac CanBreathe rock :=\nby\n  -- A8: CanFly rock \u2228 Bird rock \u2228 \u00ac CanBreathe rock\n  rcases A8 with hFly | hBird | hNotBreathe\n  \u00b7 exact Or.inl (rock_wings_of_fly hFly)\n  \u00b7 exact Or.inl (rock_wings_of_bird hBird)\n  \u00b7 exact Or.inr hNotBreathe\n\n-- We cannot derive Monkey rock from the given axioms (independence not provable in Lean here).\n-- Similarly, we cannot derive HasWings rock, nor its negation, from the axioms alone.\n\nend PeterPets\n\nConclusions:\n\n- Question 1: Rock is a monkey.\nFrom Pet rock and axiom A3 we only get Monkey rock \u2228 Bird rock. Nothing rules out the Bird alternative, and nothing forces Monkey. Therefore Rock is a monkey is not entailed, nor is its negation. Answer: Unknown\n\n- Question 2: Rock has wings.\nFrom A8, if either CanFly rock or Bird rock holds, then Rock has wings (by A6 and A4). However, the third disjunct \u00acCanBreathe rock is consistent with the axioms and gives no information about wings. We cannot rule out this third case (we lack a way to deduce Animal rock to force CanBreathe rock). Thus we cannot conclude HasWings rock, nor its negation. Answer: Unknown\n\n- Question 3: Rock does not have wings.\nAs above, the first two disjuncts of A8 would imply Rock has wings, so we cannot conclude that Rock lacks wings. But we also cannot rule out the third disjunct, so we cannot refute that Rock lacks wings either. Answer: Unknown\n\nFinal answers:\n- Q1: Unknown\n- Q2: Unknown\n- Q3: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1348,
        "conclusion": "Rock is a monkey.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1349,
        "conclusion": "Rock has wings.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1350,
        "conclusion": "Rock does not have wings.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 330,
    "premises": "All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. ",
    "gpt_response": "Here is a faithful Lean formalization of the predicates and premises, followed by attempts to derive the four queried statements.\n\nLean formalization:\n\n-- We work in an arbitrary nonempty type of people, with a distinguished constant John.\nuniverse u\n\nconstant Person : Type u\nconstant John : Person\n\n-- Predicates:\n-- M x: x makes wedding plans\n-- E x: x is engaged\n-- I x: x invites others to come to their ceremony\n-- W x: x has a well-attended wedding\n-- L x: x has a larger family\n-- F x: x invites friends to their ceremony\nconstant M E I W L F : Person \u2192 Prop\n\n-- Axioms (from the textual context):\naxiom A1 : \u2200 x, M x \u2192 E x\naxiom A2 : \u2200 x, I x \u2192 M x\naxiom A3 : \u2200 x, W x \u2192 I x\naxiom A4 : \u2203 x, W x \u2227 L x\naxiom A5 : E John \u2192 \u00ac (F John \u2227 M John)\naxiom A6 : L John \u2192 (W John \u2228 F John)\n\n-- Useful derived facts:\nlemma I_implies_E : \u2200 x, I x \u2192 E x :=\nby\n  intro x hx\n  exact A1 x (A2 x hx)\n\nlemma W_implies_E : \u2200 x, W x \u2192 E x :=\nby\n  intro x hx\n  exact I_implies_E x (A3 x hx)\n\n-- Targets (questions):\n-- Q1: L John\n-- Q2: \u00ac L John\n-- Q3: E John\n-- Q4: (\u00ac L John) \u2227 (\u00ac I John)\n\n-- Attempts:\n-- From the given axioms, none of Q1\u2013Q4 (nor their negations) can be derived directly.\n-- In particular:\n-- \u2022 A4 only asserts the existence of some person with W \u2227 L, not necessarily John.\n-- \u2022 The chain W \u2192 I \u2192 M \u2192 E applies to whoever has W, but we have no premise that John has W.\n-- \u2022 A6 only gives that if L John then (W John \u2228 F John); this does not force L John.\n-- \u2022 A5 is a conditional that constrains John if he is engaged; it does not assert that he is engaged.\n\n-- Therefore, we cannot prove any of Q1\u2013Q4 or their negations from A1\u2013A6.\n\nExplanation and answers:\n\n- From A2 and A1, anyone who invites others (I x) is engaged (E x).\n- From A3, anyone with a well-attended wedding (W x) invites others (I x), hence is engaged (E x).\n- A4 gives existence of someone with both W and L, but does not identify that person as John.\n- A6 says: if John has a larger family (L John), then John either has a well-attended wedding (W John) or invites friends (F John). This does not establish L John.\n- A5 says: if John is engaged, then not (F John \u2227 M John). This does not establish that John is engaged.\n\nConsequently, none of the queried statements is derivable, and neither is any of their negations.\n\nQuestion 1: Unknown\nQuestion 2: Unknown\nQuestion 3: Unknown\nQuestion 4: Unknown\n\nUnknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 846,
        "conclusion": "John has a larger family.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 847,
        "conclusion": "John does not have a larger family.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 848,
        "conclusion": "John is engaged.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 849,
        "conclusion": "John neither has a larger family nor does he invite others to his wedding.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.25
  },
  {
    "story_id": 26,
    "premises": "Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.",
    "gpt_response": "Lean formalization and attempt:\n\n-- Universe and basic setup\nuniverse u\n\nconstant Creature : Type u\nconstant Platypus : Creature\nconstant Human : Creature\n\n-- Predicates\nconstant Mammal : Creature \u2192 Prop\nconstant Reptile : Creature \u2192 Prop\nconstant HasTeeth : Creature \u2192 Prop\n\n-- Given assumptions\naxiom some_mammal_with_teeth : \u2203 x : Creature, Mammal x \u2227 HasTeeth x\naxiom platypus_no_teeth : \u00ac HasTeeth Platypus\naxiom platypus_is_mammal : Mammal Platypus\naxiom human_has_teeth : HasTeeth Human\n\n-- Q1: Platypuses are mammals with no teeth.\ntheorem Q1 : Mammal Platypus \u2227 \u00ac HasTeeth Platypus :=\n  And.intro platypus_is_mammal platypus_no_teeth\n\n-- Q2: Platypuses are reptiles.\n-- Not derivable from the given assumptions, and neither is its negation.\n\n-- Q3: Humans are mammals.\n-- Not derivable from the given assumptions, and neither is its negation.\n\nAnswers:\n1) Platypuses are mammals with no teeth. True\n2) Platypuses are reptiles. Unknown\n3) Humans are mammals. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 74,
        "conclusion": "Platypuses are mammals with no teeth.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 75,
        "conclusion": "Platypuses are reptiles.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 76,
        "conclusion": "Humans are mammals.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 203,
    "premises": "Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.",
    "gpt_response": "Lean formalization and proofs:\n\n-- Entities and predicates\nuniverse u\nconstant Entity : Type\nconstant Plunger : Entity \u2192 Prop\nconstant Vacuum : Entity \u2192 Prop\nconstant Vampire : Entity \u2192 Prop\nconstant HouseholdAppliance : Entity \u2192 Prop\nconstant Sucks : Entity \u2192 Prop\n\n-- Named entities\nconstant space : Entity\nconstant duster : Entity\n\n-- Facts from the text\naxiom plungers_suck : \u2200 x, Plunger x \u2192 Sucks x\naxiom vacuums_suck  : \u2200 x, Vacuum x \u2192 Sucks x\naxiom vampires_suck : \u2200 x, Vampire x \u2192 Sucks x\naxiom space_is_vacuum : Vacuum space\naxiom duster_facts : HouseholdAppliance duster \u2227 \u00ac Sucks duster\n\n-- Question 1: Space sucks.\ntheorem Q1_space_sucks : Sucks space :=\n  (vacuums_suck space) space_is_vacuum\n\n-- Question 2: Space is a vampire.\n-- Not derivable from the given axioms, and its negation is also not derivable.\n\n-- Question 3: If something is a household appliance, it sucks. (This is false.)\ntheorem Q3_not_all_household_appliances_suck :\n  \u00ac (\u2200 x, HouseholdAppliance x \u2192 Sucks x) :=\nby\n  intro h\n  have hd : HouseholdAppliance duster := And.left duster_facts\n  have nd : \u00ac Sucks duster := And.right duster_facts\n  have sd : Sucks duster := h duster hd\n  exact nd sd\n\n\nAnswers:\n1) From vacuums_suck and space_is_vacuum, we conclude Sucks space. True\n2) There is no information linking being a vacuum to being a vampire, nor any information excluding it. Unknown\n3) The duster is a household appliance that does not suck, so the universal claim is false. False\n\nTrue\nUnknown\nFalse",
    "results": [
      {
        "question_num": 1,
        "example_id": 578,
        "conclusion": "Space sucks.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 579,
        "conclusion": "Space is a vampire.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 580,
        "conclusion": "If something is a household appliance, it sucks.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 131,
    "premises": "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.",
    "gpt_response": "Lean translation and proof attempt:\n\n-- We formalize the setting\nuniverse u\n\nconstant Algorithm : Type\n\n-- Learning categories (predicates on algorithms)\nconstant Supervised : Algorithm \u2192 Prop\nconstant Unsupervised : Algorithm \u2192 Prop\nconstant Reinforcement : Algorithm \u2192 Prop\n\n-- Property: requires labeled data\nconstant RequiresLabels : Algorithm \u2192 Prop\n\n-- The specific ML algorithm used to train the SOTA text summarization model\nconstant alg : Algorithm\n\n-- Assumptions from the textual context:\n\n-- 1) Categorization: every ML algorithm is (exactly one of) supervised, unsupervised, or reinforcement\naxiom partition :\n  \u2200 a : Algorithm, Supervised a \u2228 Unsupervised a \u2228 Reinforcement a\n\naxiom disjoint_SU : \u2200 a, \u00ac (Supervised a \u2227 Unsupervised a)\naxiom disjoint_SR : \u2200 a, \u00ac (Supervised a \u2227 Reinforcement a)\naxiom disjoint_UR : \u2200 a, \u00ac (Unsupervised a \u2227 Reinforcement a)\n\n-- 2) Unsupervised algorithms do not require labeled data\naxiom unsup_no_labels : \u2200 a, Unsupervised a \u2192 \u00ac RequiresLabels a\n\n-- 3) The ML algorithm used to train the SOTA model requires labeled data\naxiom alg_requires_labels : RequiresLabels alg\n\n-- 4) Reinforcement learning is not used to train the SOTA model\naxiom not_reinforcement_alg : \u00ac Reinforcement alg\n\n-- From these, we prove the two questions.\n\n-- Q1: Supervised learning is used to train the SOTA model.\ntheorem Q1_supervised_used : Supervised alg := by\n  -- First, show alg is not unsupervised (it requires labels, while unsupervised do not)\n  have not_unsup : \u00ac Unsupervised alg := by\n    intro hU\n    have hNL : \u00ac RequiresLabels alg := unsup_no_labels alg hU\n    exact hNL alg_requires_labels\n  -- Use the partition and exclusions to deduce supervised\n  have hpart := partition alg\n  rcases hpart with hS | hU | hR\n  \u00b7 exact hS\n  \u00b7 exact False.elim (not_unsup hU)\n  \u00b7 exact False.elim (not_reinforcement_alg hR)\n\n-- Q2: Unsupervised learning is used to train the SOTA model. (We show this is false.)\ntheorem Q2_unsupervised_used_false : \u00ac Unsupervised alg := by\n  intro hU\n  have hNL : \u00ac RequiresLabels alg := unsup_no_labels alg hU\n  exact hNL alg_requires_labels\n\n\nAnswers:\n- Question 1: True\n- Question 2: False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 388,
        "conclusion": "Supervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 389,
        "conclusion": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 460,
    "premises": "If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. ",
    "gpt_response": "Lean formalization and attempted proofs:\n\nimport Classical\n\nuniverse u\n\nconstant Thing : Type u\n\n-- Predicates\nconstant Appropriate : Thing \u2192 Prop\nconstant CW : Thing \u2192 Prop                      -- Children can watch without guidance\nconstant Contains : Thing \u2192 Prop                -- Contains excessive erotic and violent content\nconstant RatedGA : Thing \u2192 Prop                 -- Rated General Audience\nconstant FF : Thing \u2192 Prop                      -- Family-friendly animated film\nconstant Frozen : Thing \u2192 Prop                  -- In the Frozen series\nconstant Film : Thing \u2192 Prop\n\n-- Individual\nconstant hachi : Thing\n\n-- Given rules (axioms)\naxiom rule1 : \u2200 x, Appropriate x \u2192 CW x\naxiom rule2 : \u2200 x, Contains x \u2192 \u00ac CW x\naxiom rule3 : \u2200 x, RatedGA x \u2192 Appropriate x\naxiom rule4 : \u2200 x, FF x \u2192 RatedGA x\naxiom rule5 : \u2200 x, Frozen x \u2192 FF x\n\n-- Given facts\naxiom fact_film : Film hachi\naxiom fact_disj : FF hachi \u2228 Appropriate hachi\n\n-- Useful derived facts\nlemma appropriate_hachi : Appropriate hachi := by\n  cases fact_disj with\n  | inl h => exact rule3 _ (rule4 _ h)\n  | inr h => exact h\n\nlemma cw_hachi : CW hachi :=\n  rule1 _ appropriate_hachi\n\nlemma not_contains_hachi : \u00ac Contains hachi := by\n  intro hc\n  have hnotcw : \u00ac CW hachi := rule2 _ hc\n  exact hnotcw cw_hachi\n\n-- Simplifications for questions 2 and 3\nlemma q2_iff : (Contains hachi \u2228 Frozen hachi) \u2194 Frozen hachi := by\n  constructor\n  \u00b7 intro h\n    cases h with\n    | inl hc => exact False.elim (not_contains_hachi hc)\n    | inr hf => exact hf\n  \u00b7 intro hf\n    exact Or.inr hf\n\nlemma q3_iff :\n  ((Contains hachi \u2227 Frozen hachi) \u2228 (\u00ac Contains hachi \u2227 \u00ac Frozen hachi))\n  \u2194 \u00ac Frozen hachi := by\n  constructor\n  \u00b7 intro h\n    cases h with\n    | inl hcf =>\n        have hc := hcf.left\n        exact False.elim (not_contains_hachi hc)\n    | inr hnot => exact hnot.right\n  \u00b7 intro hnot\n    exact Or.inr \u27e8not_contains_hachi, hnot\u27e9\n\n-- Notes:\n-- We can prove Appropriate hachi and CW hachi, and hence \u00acContains hachi.\n-- However, we cannot derive RatedGA hachi, Frozen hachi, or \u00acFrozen hachi from the given axioms.\n\n\nAnswers:\n1) \"Hachi: A Dog's Tale\" is rated General Audience.\nConclusion: Unknown. From FF hachi \u2228 Appropriate hachi and FF \u2192 RatedGA \u2192 Appropriate, we can prove Appropriate hachi but not RatedGA hachi. Unknown\n\n2) \"Hachi: A Dog's Tale\" contains excessive erotic and violent content or is in the Frozen series (or both).\nConclusion: Unknown. We actually proved \u00acContains hachi, so this reduces to \u201cHachi is in the Frozen series,\u201d which is not derivable. Unknown\n\n3) \"Hachi: A Dog's Tale\" either contains excessive erotic and violent content and is in the Frozen series, or it neither contains excessive erotic and violent content nor is in the Frozen series.\nConclusion: Unknown. Using \u00acContains hachi, this reduces to \u201cnot in the Frozen series,\u201d which is not derivable. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1327,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1328,
        "conclusion": "\"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1329,
        "conclusion": "\"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 46,
    "premises": "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.",
    "gpt_response": "Lean translation and proof attempt:\n\n-- We model individuals as elements of a type \u03b9.\nuniverse u\nconstant \u03b9 : Type u\n\n-- Predicates\nconstant Animal : \u03b9 \u2192 Prop\nconstant Heck : \u03b9 \u2192 Prop\nconstant Aurochs : \u03b9 \u2192 Prop\nconstant Extinct : \u03b9 \u2192 Prop\nconstant BredBack : \u03b9 \u2192 Prop\nconstant ArtificialSelection : \u03b9 \u2192 Prop\nconstant Resembles : \u03b9 \u2192 \u03b9 \u2192 Prop\n\n-- Axioms from the textual context:\n\n-- 1) Breeding back is a form of artificial selection\naxiom ax1 : \u2200 x, BredBack x \u2192 ArtificialSelection x\n\n-- 2) Heck cattle are animals\naxiom ax2 : \u2200 x, Heck x \u2192 Animal x\n\n-- 3) Aurochs are animals\naxiom ax3 : \u2200 x, Aurochs x \u2192 Animal x\n\n-- 4) Heck cattle were bred back (we read this as: every Heck individual is a product of breeding back)\naxiom ax4 : \u2200 x, Heck x \u2192 BredBack x\n\n-- 5) There exist Heck cattle (existence suggested by the historical claim)\naxiom ax5 : \u2203 x, Heck x\n\n-- 6) Heck cattle resemble the aurochs (not needed for Q1, included for completeness)\naxiom ax6 : \u2200 x, Heck x \u2192 \u2200 y, Aurochs y \u2192 Resembles x y\n\n-- 7) Some animals to be bred back resemble extinct animals\n-- We model only the existence of some animal resembling some extinct animal.\naxiom ax7 : \u2203 x, Animal x \u2227 \u2203 y, Extinct y \u2227 Resembles x y\n\n-- Question 1 target: \u2203 x, Heck x \u2227 ArtificialSelection x\ntheorem Q1 : \u2203 x, Heck x \u2227 ArtificialSelection x := by\n  rcases ax5 with \u27e8h, hh\u27e9\n  have hb : BredBack h := ax4 h hh\n  have ha : ArtificialSelection h := ax1 h hb\n  exact \u27e8h, And.intro hh ha\u27e9\n\n-- Question 2 (Aurochs are extinct) cannot be derived from the given axioms.\n-- We neither have \u2200 x, Aurochs x \u2192 Extinct x nor its negation from the above,\n-- so we do not provide a proof.\n\nAnswers:\nQuestion 1: True\nQuestion 2: Unknown\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 133,
        "conclusion": "Some Heck cattle are artificially selected.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 134,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 483,
    "premises": "Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.",
    "gpt_response": "Lean 4 formalization and derived proofs:\n\n-- Domain and predicates\nuniverse u\n\nconstant Person : Type\nconstant CanRegister CanParticipate USCitizen TWCitizen RfOfficial GazpromManager : Person \u2192 Prop\nconstant Vladimir Ekaterina : Person\n\n-- Given premises\naxiom h1 : \u2200 x, CanRegister x \u2192 CanParticipate x\naxiom h2 : \u2200 x, USCitizen x \u2192 CanRegister x\naxiom h3 : \u2200 x, USCitizen x \u2228 TWCitizen x\naxiom h4 : \u2200 x, RfOfficial x \u2192 \u00ac TWCitizen x\naxiom h5a : \u00ac TWCitizen Vladimir\naxiom h5b : \u00ac GazpromManager Vladimir\naxiom h6  : CanRegister Ekaterina \u2228 RfOfficial Ekaterina\n\n-- Useful derived facts\n\nlemma vladimir_US : USCitizen Vladimir :=\nby\n  have disj := h3 Vladimir\n  cases disj with\n  | inl hu => exact hu\n  | inr ht => exact False.elim (h5a ht)\n\nlemma vladimir_participate : CanParticipate Vladimir :=\nby\n  apply h1\n  apply h2\n  exact vladimir_US\n\nlemma ekaterina_register : CanRegister Ekaterina :=\nby\n  cases h6 with\n  | inl hr => exact hr\n  | inr roff =>\n    have notTW : \u00ac TWCitizen Ekaterina := h4 _ roff\n    have disj := h3 Ekaterina\n    have us : USCitizen Ekaterina :=\n      by\n        cases disj with\n        | inl hu => exact hu\n        | inr ht => exact False.elim (notTW ht)\n    exact h2 _ us\n\nlemma ekaterina_participate : CanParticipate Ekaterina :=\nby\n  apply h1\n  exact ekaterina_register\n\n-- Q3: Ekaterina can participate in the 2024 US presidential election or is a manager at Gazprom.\ntheorem Q3_true : CanParticipate Ekaterina \u2228 GazpromManager Ekaterina :=\nby\n  exact Or.inl ekaterina_participate\n\n-- Q4: Ekaterina can participate in the 2024 US presidential election or Vladimir is a manager at Gazprom.\ntheorem Q4_true : CanParticipate Ekaterina \u2228 GazpromManager Vladimir :=\nby\n  exact Or.inl ekaterina_participate\n\n-- Q5: It is not true that Ekaterina can register to vote in the US and Vladimir can participate.\n-- We show the negation of that statement is provable by exhibiting the conjunction.\ntheorem Q5_negation_of_statement : (CanRegister Ekaterina \u2227 CanParticipate Vladimir) :=\nby\n  exact And.intro ekaterina_register vladimir_participate\n\n\nAnswers:\n\n1) Vladimir is a Russian federation official: Unknown\n2) Vladimir is not a Russian federation official: Unknown\n3) Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom: True\n4) Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom: True\n5) It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election: False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 1410,
        "conclusion": "Vladimir is a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1411,
        "conclusion": "Vladimir is not a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1412,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1413,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1414,
        "conclusion": "It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.4
  },
  {
    "story_id": 80,
    "premises": "New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.",
    "gpt_response": "Here is a Lean formalization of the given context and the three queries, together with the proof of Q1 and an explanation of why Q2 and Q3 cannot be derived from the axioms.\n\nLean code (Lean 4):\n\nuniverse u\n\n-- Basic domains\nconstant Book     : Type u\nconstant Publisher : Type u\nconstant Language  : Type u\n\n-- Predicates\nconstant PublishedBy    : Book \u2192 Publisher \u2192 Prop\nconstant InEnglish      : Book \u2192 Prop\nconstant TranslatedFrom : Book \u2192 Language \u2192 Prop\n\n-- Constants for our scenario\nconstant NVP    : Publisher                 -- New Vessel Press\nconstant NC     : Book                      -- Neapolitan Chronicles\nconstant PoF    : Book                      -- Palace of Flies\nconstant HP     : Book                      -- Harry Potter (mentioned in a query)\nconstant Italian : Language\n\n-- Axioms from the textual context:\n-- 1) All of New Vessel Press's published books are in English.\naxiom all_NVP_english : \u2200 b : Book, PublishedBy b NVP \u2192 InEnglish b\n\n-- 2) Neapolitan Chronicles is a book published by New Vessel Press.\naxiom NC_published : PublishedBy NC NVP\n\n-- 3) Neapolitan Chronicles was translated from Italian.\naxiom NC_from_Italian : TranslatedFrom NC Italian\n\n-- 4) Palace of Flies is a book published by New Vessel Press.\naxiom PoF_published : PublishedBy PoF NVP\n\n-- Question 1: Neapolitan Chronicles is an English book.\ntheorem Q1 : InEnglish NC :=\n  all_NVP_english NC NC_published\n\n-- Question 2: Harry Potter was published by New Vessel Press.\n-- Not derivable from the axioms; neither the statement nor its negation follows.\n\n-- Question 3: Palace of Flies was translated from Italian.\n-- Not derivable from the axioms; neither the statement nor its negation follows.\n\nAnswers:\n\n- Question 1: Neapolitan Chronicles is an English book.\n  From all_NVP_english and NC_published, we have InEnglish NC. True\n\n- Question 2: Harry Potter was published by New Vessel Press.\n  The premises say nothing about Harry Potter, so this cannot be concluded. Unknown\n\n- Question 3: Palace of Flies was translated from Italian.\n  We are told PoF was published by NVP (hence it\u2019s in English), but nothing about its source language. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 243,
        "conclusion": "Neapolitan Chronicles is an English book.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 244,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 245,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 363,
    "premises": "All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. ",
    "gpt_response": "Here is a faithful translation of the natural-language premises into Lean, along with derived consequences and proofs for Questions 2 and 3. For Question 1, neither the statement nor its negation is derivable from the given axioms.\n\nLean code:\n\nuniverse u\n\nconstant U : Type u\n\n-- Predicates\nconstant Hydrocarbon : U \u2192 Prop\nconstant Organic : U \u2192 Prop\nconstant Alkane : U \u2192 Prop\nconstant ChemicalCompound : U \u2192 Prop\nconstant ContainsCarbon : U \u2192 Prop\nconstant OneElement : U \u2192 Prop\n\n-- The designated object\nconstant mixture : U\n\n-- Axioms from the text\naxiom ax1 : \u2200 x, Hydrocarbon x \u2192 Organic x\naxiom ax2 : \u2200 x, Alkane x \u2192 Hydrocarbon x\naxiom ax3 : \u2200 x, Organic x \u2192 ChemicalCompound x\naxiom ax4 : \u2200 x, Organic x \u2192 ContainsCarbon x\naxiom ax5 : \u2200 x, ChemicalCompound x \u2192 \u00ac OneElement x\n-- \u201ceither both \u2026 or neither\u201d:\naxiom ax6 : (ChemicalCompound mixture \u2227 OneElement mixture) \u2228 (\u00ac ChemicalCompound mixture \u2227 \u00ac OneElement mixture)\n\n-- Basic consequences about the mixture\nlemma not_CC_mixture : \u00ac ChemicalCompound mixture := by\n  have h := ax6\n  cases h with\n  | inl h1 =>\n    -- h1 : ChemicalCompound mixture \u2227 OneElement mixture\n    have hcc : ChemicalCompound mixture := h1.left\n    have hone : OneElement mixture := h1.right\n    have : \u00ac OneElement mixture := ax5 mixture hcc\n    exact this.elim hone\n  | inr h2 =>\n    -- h2 : \u00ac ChemicalCompound mixture \u2227 \u00ac OneElement mixture\n    exact h2.left\n\nlemma not_one_mixture : \u00ac OneElement mixture := by\n  have h := ax6\n  cases h with\n  | inl h1 =>\n    -- As above this branch is impossible; derive contradiction and then anything\n    have hcc : ChemicalCompound mixture := h1.left\n    have hone : OneElement mixture := h1.right\n    have : \u00ac OneElement mixture := ax5 mixture hcc\n    exact this.elim hone\n  | inr h2 =>\n    exact h2.right\n\nlemma alkane_implies_CC : \u2200 x, Alkane x \u2192 ChemicalCompound x := by\n  intro x ha\n  exact ax3 x (ax1 x (ax2 x ha))\n\nlemma not_alkane_mixture : \u00ac Alkane mixture := by\n  intro hA\n  exact not_CC_mixture (alkane_implies_CC mixture hA)\n\n-- Q2: \u201cThe mixture is an alkane and contains carbon.\u201d This is false.\ntheorem Q2_false : \u00ac (Alkane mixture \u2227 ContainsCarbon mixture) := by\n  intro h\n  exact not_alkane_mixture h.left\n\n-- Q3: \u201cIf the mixture contains only one element or contains carbon,\n-- then the mixture is neither a chemical compound nor an alkane.\u201d This is true.\ntheorem Q3_true :\n  (OneElement mixture \u2228 ContainsCarbon mixture) \u2192\n  (\u00ac ChemicalCompound mixture \u2227 \u00ac Alkane mixture) := by\n  intro _\n  exact And.intro not_CC_mixture not_alkane_mixture\n\n-- Note: From the given axioms, we can neither prove ContainsCarbon mixture\n-- nor its negation, since we have no premise making the mixture organic (or otherwise relating it to carbon).\n\n\nAnswers:\n- Question 1: The mixture contains carbon. Unknown\n- Question 2: The mixture is an alkane and contains carbon. False\n- Question 3: If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 964,
        "conclusion": "The mixture contains carbon.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 965,
        "conclusion": "The mixture is an alkane and contains carbon.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 966,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 258,
    "premises": "All humans are mortal.\nAll Greeks are humans.",
    "gpt_response": "Lean translation and attempt:\n\nuniverse u\n\nconstant U : Type u\nconstant Human : U \u2192 Prop\nconstant Mortal : U \u2192 Prop\nconstant Greek : U \u2192 Prop\n\naxiom A1 : \u2200 x : U, Human x \u2192 Mortal x          -- All humans are mortal.\naxiom A2 : \u2200 x : U, Greek x \u2192 Human x           -- All Greeks are humans.\n\n-- From the axioms we can derive that all Greeks are mortal.\nlemma Greeks_are_mortal : \u2200 x : U, Greek x \u2192 Mortal x :=\n  fun x hg => A1 x (A2 x hg)\n\n-- If there exists a Greek, then some Greek is mortal.\ntheorem some_Greek_mortal_of_exists : (\u2203 x : U, Greek x) \u2192 (\u2203 x : U, Greek x \u2227 Mortal x) :=\n  fun \u27e8x, hxG\u27e9 => \u27e8x, And.intro hxG (Greeks_are_mortal x hxG)\u27e9\n\n-- However, without assuming the existence of a Greek, we cannot prove \u2203 x, Greek x \u2227 Mortal x\n-- from A1 and A2 alone, nor can we prove its negation. So the original statement\n-- \"Some Greeks are mortal\" is not derivable from the given premises.\n\nAnswer: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 702,
        "conclusion": "Some Greeks are mortal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 435,
    "premises": "None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.",
    "gpt_response": "Here is a Lean 4 formalization of the problem and proofs of the four queried statements.\n\nlean\nuniverse u\n\nconstant Student : Type u\nconstant WorkLibrary : Student \u2192 Prop\nconstant CS : Student \u2192 Prop\nconstant Job : Student \u2192 Prop\nconstant DB : Student \u2192 Prop\nconstant DavidClass : Student \u2192 Prop\nconstant Lab : Student \u2192 Prop\nconstant James : Student\n\naxiom A1 : \u2200 x : Student, WorkLibrary x \u2192 \u00ac CS x\naxiom A2 : \u2200 x : Student, Job x \u2192 WorkLibrary x\naxiom A3 : \u2200 x : Student, DB x \u2192 CS x\naxiom A4 : \u2200 x : Student, DavidClass x \u2192 DB x\naxiom A5 : \u2200 x : Student, Lab x \u2192 DavidClass x\naxiom A6 : Lab James\naxiom A7 : \u00ac (Lab James \u2228 Job James)\n\n-- Q1: James has a part-time job offered by the university.\ntheorem Q1 : Job James := by\n  have hNotLab : \u00ac Lab James := by\n    intro hL\n    exact A7 (Or.inl hL)\n  have hFalse : False := hNotLab A6\n  exact False.elim hFalse\n\n-- Q2: James does not have a part-time job offered by the university.\ntheorem Q2 : \u00ac Job James := by\n  intro hJ\n  exact A7 (Or.inr hJ)\n\n-- Q3: James either takes the database course or has a part-time job offered by the university.\ntheorem Q3 : DB James \u2228 Job James := by\n  have hDB : DB James := A4 (A5 A6)\n  exact Or.inl hDB\n\n-- Q4: James takes the database course.\ntheorem Q4 : DB James := by\n  exact A4 (A5 A6)\nend\n\nAnswers:\n- Q1: True\n- Q2: True\n- Q3: True\n- Q4: True\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 1244,
        "conclusion": "James has a part-time job offered by the university.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1245,
        "conclusion": "James does not have a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1246,
        "conclusion": "James either takes the database course or has a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1247,
        "conclusion": "James takes the database course.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 217,
    "premises": "If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.",
    "gpt_response": "Lean translation of the premises:\n- Let L, W, A, C, P be propositions meaning, respectively: George likes music, George wants to compose, George has access to a program, George can compose, George will compose.\n- Assumptions:\n  h1 : L \u2192 W\n  h2 : A \u2192 C\n  h3 : (C \u2227 W) \u2192 P\n\nQuestion 1: Target: (L \u2227 A) \u2192 P.\nLean proof sketch:\n- From L \u2227 A, get L and A.\n- From h1 and L, get W.\n- From h2 and A, get C.\n- From h3 and (C \u2227 W), get P.\n\nTherefore, the statement is provable.\n\nAnswer 1: True\n\nQuestion 2: Target: (\u00acP) \u2192 (\u00acC).\nFrom h3 we can contrapose to get \u00acP \u2192 \u00ac(C \u2227 W), which yields only \u00acP \u2192 (\u00acC \u2228 \u00acW). This does not entail \u00acC. Indeed, the premises are consistent with a situation where C is true, W is false, and P is false; in such a case \u00acP \u2192 \u00acC is false. On the other hand, if P is true, then \u00acP \u2192 \u00acC holds vacuously. Thus the statement is not derivable nor is its negation derivable from the given premises alone.\n\nAnswer 2: Unknown\n\nSummary of Lean attempts:\n- Q1 was proved from the premises. True\n- Q2 could neither be proved nor refuted from the premises. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 618,
        "conclusion": "If George likes music and has access to a program, he will compose.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 619,
        "conclusion": "If George will not compose, George can not compose.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 292,
    "premises": "A hawk never swims. \nSome birds are hawks.",
    "gpt_response": "Lean translation and proof:\n\n-- Domain and predicates\nuniverse u\nconstant U : Type u\nconstants Bird Hawk Swims : U \u2192 Prop\n\n-- Premises from the textual context\naxiom hawk_never_swims : \u2200 x : U, Hawk x \u2192 \u00ac Swims x          -- \"A hawk never swims.\"\naxiom some_birds_are_hawks : \u2203 x : U, Bird x \u2227 Hawk x          -- \"Some birds are hawks.\"\n\n-- Target statement for Question 1: \"All birds swim.\" i.e., \u2200 x, Bird x \u2192 Swims x\n-- We prove its negation from the premises.\ntheorem not_all_birds_swim : \u00ac (\u2200 x : U, Bird x \u2192 Swims x) := by\n  intro hAll\n  rcases some_birds_are_hawks with \u27e8x, hxB, hxH\u27e9\n  have hx_not_swims : \u00ac Swims x := hawk_never_swims x hxH\n  have hx_swims : Swims x := hAll x hxB\n  exact hx_not_swims hx_swims\n\n-- (Optional) Derived consequence: there exists a bird that does not swim.\ntheorem exists_bird_not_swimming : \u2203 x : U, Bird x \u2227 \u00ac Swims x := by\n  rcases some_birds_are_hawks with \u27e8x, hxB, hxH\u27e9\n  exact \u27e8x, hxB, hawk_never_swims x hxH\u27e9\n\nAnswer to Question 1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 736,
        "conclusion": "All birds swim.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 318,
    "premises": "Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.",
    "gpt_response": "Lean translation and attempted proofs:\n\n-- Entities and predicates\nconstant Show : Type\nconstant Monday8 : Show \u2192 Prop\nconstant Roses : Show \u2192 Prop\nconstant Bachelor : Show\nconstant Portrays : Show \u2192 Prop\nconstant Reality : Show \u2192 Prop\nconstant BreakingBad : Show\n\n-- Assumptions from the text\naxiom exists_monday8_rose : \u2203 s : Show, Monday8 s \u2227 Roses s\naxiom roses_is_bachelor : \u2200 s : Show, Roses s \u2192 s = Bachelor\naxiom bachelor_portrays : Portrays Bachelor\naxiom portrays_implies_reality : \u2200 s : Show, Portrays s \u2192 Reality s\naxiom not_reality_bb : \u00ac Reality BreakingBad\n\n-- Derived facts\nlemma roses_implies_reality (s : Show) : Roses s \u2192 Reality s := by\n  intro h\n  have hs : s = Bachelor := roses_is_bachelor s h\n  have : Portrays s := by simpa [hs] using bachelor_portrays\n  exact portrays_implies_reality s this\n\nlemma not_roses_bb : \u00ac Roses BreakingBad := by\n  intro h\n  have : Reality BreakingBad := roses_implies_reality BreakingBad h\n  exact not_reality_bb this\n\n-- Q2: Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.\n-- This asserts Roses BreakingBad \u2227 Monday8 BreakingBad, which is impossible since Roses BreakingBad is false.\ntheorem Q2_false : \u00ac (Roses BreakingBad \u2227 Monday8 BreakingBad) := by\n  intro h\n  exact not_roses_bb h.left\n\n-- Q3: If roses are given out during Breaking Bad, then it is on Monday at 8 pm.\n-- This is vacuously true because Roses BreakingBad is false.\ntheorem Q3_true : Roses BreakingBad \u2192 Monday8 BreakingBad := by\n  intro h\n  have : False := not_roses_bb h\n  exact this.elim\n\n-- Q1: We cannot derive Monday8 BreakingBad or its negation from the given premises.\n\nAnswers:\n- Question 1: Unknown\n- Question 2: False\n- Question 3: True\n\nUnknown\nFalse\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 802,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 803,
        "conclusion": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 804,
        "conclusion": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 107,
    "premises": "Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.",
    "gpt_response": "Lean translation and proofs:\n\n-- Entities and predicates\nconstant Person : Type\nconstant HeinrichSchmidt : Person\n\nconstant German : Person \u2192 Prop\nconstant Russian : Person \u2192 Prop\nconstant Politician : Person \u2192 Prop\nconstant MemberPrussian : Person \u2192 Prop\nconstant MemberNaziReichstag : Person \u2192 Prop\n\n-- Facts from the text\naxiom h_german : German HeinrichSchmidt\naxiom h_politician : Politician HeinrichSchmidt\naxiom h_prussian : MemberPrussian HeinrichSchmidt\naxiom h_reichstag : MemberNaziReichstag HeinrichSchmidt\n\n-- Question 1: Heinrich Schmidt was German or Russian or both.\ntheorem Q1 : German HeinrichSchmidt \u2228 Russian HeinrichSchmidt :=\n  Or.inl h_german\n-- Conclusion for Q1: True\n\n-- Question 2: Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.\ntheorem Q2 : \u2203 x, German x \u2227 Politician x \u2227 MemberPrussian x \u2227 MemberNaziReichstag x :=\n  \u27e8HeinrichSchmidt, \u27e8h_german, \u27e8h_politician, \u27e8h_prussian, h_reichstag\u27e9\u27e9\u27e9\u27e9\n-- Conclusion for Q2: True\n\n-- Question 3: No politicians are part of the Nazi Reichstag.\ndef NoPoliticiansInReichstag : Prop := \u2200 x, Politician x \u2192 \u00ac MemberNaziReichstag x\n\ntheorem not_Q3 : \u00ac NoPoliticiansInReichstag :=\nby\n  intro h\n  have : \u00ac MemberNaziReichstag HeinrichSchmidt := h HeinrichSchmidt h_politician\n  exact this h_reichstag\n-- Conclusion for Q3 (the statement is false): False\n\nAnswers:\n1) True\n2) True\n3) False",
    "results": [
      {
        "question_num": 1,
        "example_id": 323,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 324,
        "conclusion": "Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 325,
        "conclusion": "No politicians are part of the Nazi Reichstag.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 386,
    "premises": "If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.",
    "gpt_response": "Here is a Lean 4 formalization of the context and the three questions. I prove Q2 (the statement is true, vacuously, because its antecedent is contradictory with the premises) and I prove the negation of Q3 (so Q3 is false). Q1 cannot be derived nor refuted from the given premises.\n\n-- Lean 4 code\n\nuniverse u\n\nconstant \u03b1 : Type u\n\n-- Predicates\nconstant Deadly : \u03b1 \u2192 Prop\nconstant LowSurvival : \u03b1 \u2192 Prop\nconstant SevereCancer : \u03b1 \u2192 Prop\nconstant BileDuctCancer : \u03b1 \u2192 Prop\nconstant Cholangio : \u03b1 \u2192 Prop\nconstant MildFlu : \u03b1 \u2192 Prop\n\n-- A distinguished entity: colorectal cancer\nconstant colorectal : \u03b1\n\n-- Axioms from the textual context\naxiom ax1 : \u2200 x, Deadly x \u2192 LowSurvival x\naxiom ax2 : \u2200 x, SevereCancer x \u2192 Deadly x\naxiom ax3 : \u2200 x, BileDuctCancer x \u2192 SevereCancer x\naxiom ax4 : \u2200 x, Cholangio x \u2192 BileDuctCancer x\naxiom ax5 : \u2200 x, MildFlu x \u2192 LowSurvival x\naxiom ax6 : \u00ac (BileDuctCancer colorectal \u2227 LowSurvival colorectal)\n\n-- Useful derived lemma: bile duct cancer implies low survival\nlemma bileduct_implies_low : \u2200 x, BileDuctCancer x \u2192 LowSurvival x :=\n  by\n    intro x hB\n    exact ax1 x (ax2 x (ax3 x hB))\n\n-- From ax6 and the previous lemma, colorectal cannot be a bile duct cancer\nlemma not_bileduct_colorectal : \u00ac BileDuctCancer colorectal :=\n  by\n    intro hB\n    have hL : LowSurvival colorectal := bileduct_implies_low colorectal hB\n    exact ax6 \u27e8hB, hL\u27e9\n\n-- Also colorectal cannot be cholangiocarcinoma (since that implies bile duct)\nlemma not_cholangio_colorectal : \u00ac Cholangio colorectal :=\n  by\n    intro hC\n    have hB : BileDuctCancer colorectal := ax4 colorectal hC\n    exact not_bileduct_colorectal hB\n\n-- Q1: SevereCancer colorectal\n-- Not provable nor refutable from the given axioms (we give no theorem here).\n\n-- Q2: (BileDuct colorectal \u2228 Cholangio colorectal) \u2192 (BileDuct colorectal \u2227 MildFlu colorectal)\n-- This is vacuously true because the antecedent is false.\ntheorem Q2_true :\n    (BileDuctCancer colorectal \u2228 Cholangio colorectal) \u2192\n    (BileDuctCancer colorectal \u2227 MildFlu colorectal) :=\n  by\n    intro h\n    have hFalse : False :=\n      by\n        cases h with\n        | inl hB => exact not_bileduct_colorectal hB\n        | inr hC => exact not_cholangio_colorectal hC\n    exact False.elim hFalse\n\n-- Q3: ((Cholangio colorectal \u2227 MildFlu colorectal) \u2228 BileDuct colorectal \u2228 (Cholangio colorectal \u2227 MildFlu colorectal \u2227 BileDuct colorectal))\n-- This collapses to just BileDuct colorectal, which is false under the axioms; we prove its negation directly.\ntheorem Q3_false :\n    \u00ac ((Cholangio colorectal \u2227 MildFlu colorectal)\n       \u2228 BileDuctCancer colorectal\n       \u2228 (Cholangio colorectal \u2227 MildFlu colorectal \u2227 BileDuctCancer colorectal)) :=\n  by\n    intro h\n    cases h with\n    | inl hCM =>\n        have hB : BileDuctCancer colorectal := ax4 colorectal hCM.left\n        exact not_bileduct_colorectal hB\n    | inr h' =>\n        cases h' with\n        | inl hB => exact not_bileduct_colorectal hB\n        | inr hCMB =>\n            have hB : BileDuctCancer colorectal := hCMB.right\n            exact not_bileduct_colorectal hB\n\nAnswers:\n- Question 1: Unknown\n- Question 2: True\n- Question 3: False\n\nUnknown, True, False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1032,
        "conclusion": "Colorectal cancer is a kind of severe cancer",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1033,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1034,
        "conclusion": "Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 355,
    "premises": "All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.",
    "gpt_response": "Lean translation and attempted proof:\n\nuniverse u\n\nconstant Person : Type u\nconstants (S C H N D G : Person \u2192 Prop)  -- S: eats salads; C: very conscious; H: health-conscious home; N: fulfills nutrition; D: disregards physical well-being; G: visits gym daily\nconstant t : Person  -- Taylor\n\naxioms\n  (h1 : \u2200 x, S x \u2192 C x)\n  (h2 : \u2200 x, H x \u2192 S x)\n  (h3 : \u2200 x, N x \u2192 H x)\n  (h4 : \u2200 x, D x \u2192 \u00ac C x)\n  (h5 : \u2200 x, G x \u2192 N x)\n  (h6 : (H t \u2227 D t) \u2228 (\u00ac H t \u2227 \u00ac D t))  -- \u201ceither both, or neither\u201d\n\nlemma not_HD : \u00ac (H t \u2227 D t) := by\n  intro h\n  have ht : H t := h.left\n  have dt : D t := h.right\n  have st : S t := h2 t ht\n  have ct : C t := h1 t st\n  have nct : \u00ac C t := h4 t dt\n  exact nct ct\n\nlemma notH_notD : \u00ac H t \u2227 \u00ac D t := by\n  cases h6 with\n  | inl hhd =>\n      exact False.elim (not_HD hhd)   -- the first disjunct is impossible\n  | inr hnot =>\n      exact hnot\n\n-- From the lemmas we have proved:\n-- 1) \u00ac H t and \u00ac D t.\n-- Consequences:\n-- - We cannot derive S t (need H t or other info).\n-- - We cannot derive G t, nor \u00ac G t.\n-- - We can derive \u00ac H t, but know nothing about G t, so \u00ac H t \u2227 \u00ac G t is not provable.\n\nReasoning summary:\n- If H then S, and if S then C. If D then \u00acC. Hence H \u2227 D is impossible.\n- Given (H \u2227 D) \u2228 (\u00acH \u2227 \u00acD), only the second disjunct can hold, so \u00acH and \u00acD.\n- Nothing links \u00acH or \u00acD to S or G, so S t and G t remain undetermined; likewise \u00acG t is undetermined.\n\nAnswers:\n- Question 1: Taylor eats salads regularly. Unknown\n- Question 2: Taylor visits the gym at least once a day. Unknown\n- Question 3: Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 941,
        "conclusion": "Taylor eats salads regularly.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 942,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 943,
        "conclusion": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 51,
    "premises": "The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. ",
    "gpt_response": "Lean translation and proofs:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Entity : Type u\n\nconstants SummerOlympics WorldChampionships Tokyo UnitedStates : Entity\n\n-- Predicates\nconstant SportingEvent : Entity -> Prop\nconstant HeldIn : Entity -> Entity -> Prop\nconstant WonMostMedalsAtEvent : Entity -> Entity -> Prop\nconstant WonMostMedalsInCity : Entity -> Entity -> Prop\n\n-- Facts from the textual context\naxiom h1 : SportingEvent SummerOlympics\naxiom h2 : HeldIn SummerOlympics Tokyo\naxiom h3 : WonMostMedalsInCity UnitedStates Tokyo\n\n-- Bridge principle connecting location-based and event-based medal claims\naxiom medals_city_to_event {a e c : Entity} :\n  HeldIn e c -> WonMostMedalsInCity a c -> WonMostMedalsAtEvent a e\n\n-- Q1 statement\ndef Q1 : Prop := SportingEvent WorldChampionships\n-- Not provable (nor is its negation) from the given axioms.\n\n-- Q2 statement\ndef Q2 : Prop := \u00ac HeldIn SummerOlympics Tokyo\n\n-- We can prove the negation of Q2, so Q2 is false.\ntheorem Q2_false : \u00ac Q2 := by\n  intro hnot\n  exact hnot h2\n\n-- Q3 statement\ndef Q3 : Prop := WonMostMedalsAtEvent UnitedStates SummerOlympics\n\n-- We can prove Q3 from the bridge and facts.\ntheorem Q3_true : Q3 := by\n  exact medals_city_to_event h2 h3\n\nend Reasoning\n\nAnswers:\n1) We are not told anything about the world championships, so it does not follow from the context that it is a sporting event. Unknown\n2) The context says the last summer Olympic games was in Tokyo, so saying they were not in Tokyo contradicts the given facts. False\n3) Since the last summer Olympic games were in Tokyo and the United States won the most medals in Tokyo, it follows they won the most medals at the last summer Olympic games. True",
    "results": [
      {
        "question_num": 1,
        "example_id": 147,
        "conclusion": "The world championships is a sporting event.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 148,
        "conclusion": "The last summer Olympic games were not in Tokyo.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 149,
        "conclusion": "The United States won the most medals in the last summer Olympic games.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 259,
    "premises": "All horses have hooves.\nNo humans have hooves.",
    "gpt_response": "Lean translation and proof attempt:\n\n-- Universe of discourse\nuniverse u\nconstant U : Type u\n\n-- Predicates\nconstant Human : U \u2192 Prop\nconstant Horse : U \u2192 Prop\nconstant HasHooves : U \u2192 Prop\n\n-- Axioms from the text\naxiom horses_have_hooves : \u2200 x : U, Horse x \u2192 HasHooves x\naxiom humans_no_hooves  : \u2200 x : U, Human x \u2192 \u00ac HasHooves x\n\n-- Target statement (Question 1): \u2203 x, Human x \u2227 Horse x\n-- We prove its negation.\ntheorem no_human_is_horse : \u00ac (\u2203 x : U, Human x \u2227 Horse x) := by\n  intro h\n  rcases h with \u27e8x, hxH, hxHo\u27e9\n  have hh : HasHooves x := horses_have_hooves x hxHo\n  have nh : \u00ac HasHooves x := humans_no_hooves x hxH\n  exact nh hh\n\nConclusion for Question 1: Some humans are horses. Answer: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 703,
        "conclusion": "Some humans are horses.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 152,
    "premises": "Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.",
    "gpt_response": "Lean formalization and proof attempt:\n\n-- Types and basic functions\nconstant Person : Type\nconstant Airport : Type\nconstant from : Person \u2192 Airport\nconstant to : Person \u2192 Airport\n\n-- Constants for entities\nconstant LGA : Airport\nconstant Susan : Person\nconstant John : Person\n\n-- Axioms from the textual context\naxiom dep_ne_arr : \u2200 p : Person, from p \u2260 to p\naxiom sus_to : to Susan = LGA\naxiom john_from : from John = LGA\n\n-- Question 1 target: from Susan = LGA\n-- We can prove its negation.\ntheorem not_q1 : from Susan \u2260 LGA := by\n  intro h\n  have h1 : from Susan = to Susan := by\n    calc\n      from Susan = LGA := h\n      _ = to Susan := sus_to.symm\n  exact (dep_ne_arr Susan) h1\n\n-- Question 2 target: to John = LGA\n-- We can prove its negation.\ntheorem not_q2 : to John \u2260 LGA := by\n  intro h\n  have h1 : from John = to John := by\n    calc\n      from John = LGA := john_from\n      _ = to John := h.symm\n  exact (dep_ne_arr John) h1\n\nConclusions:\n- Q1 (Susan flies from LGA airport): From to Susan = LGA and from \u2260 to for any flight, it follows that from Susan \u2260 LGA. Therefore the statement is false. False\n- Q2 (John flies to LGA airport): From from John = LGA and from \u2260 to for any flight, it follows that to John \u2260 LGA. Therefore the statement is false. False\n\nTrue",
    "results": [
      {
        "question_num": 1,
        "example_id": 442,
        "conclusion": "Susan flies from LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 443,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 441,
    "premises": "No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.",
    "gpt_response": "Lean translation and proofs:\n\nuniverse u\n\nconstant Person : Type u\nconstant Nice Mean Grumpy AnimalLover PetOwner : Person \u2192 Prop\nconstant Tom : Person\n\naxiom A1 : \u2200 x : Person, Nice x \u2192 \u00ac Mean x                  -- No one nice to animals is mean to animals.\naxiom A2 : \u2203 x : Person, Grumpy x \u2227 Mean x                  -- Some grumpy people are mean to animals.\naxiom A3 : \u2200 x : Person, AnimalLover x \u2192 Nice x             -- All animal lovers are nice to animals.\naxiom A4 : \u2200 x : Person, PetOwner x \u2192 AnimalLover x         -- All pet owners love animals.\naxiom A5 : PetOwner Tom                                     -- Tom is a pet owner.\n\nlemma tom_animal_lover : AnimalLover Tom :=\n  A4 Tom A5\n\nlemma tom_nice : Nice Tom :=\n  A3 Tom tom_animal_lover\n\nlemma tom_not_mean : \u00ac Mean Tom :=\n  A1 Tom tom_nice\n\n-- Q1: Is Grumpy Tom provable?\n-- We cannot derive either Grumpy Tom or \u00ac Grumpy Tom from the given axioms.\n\n-- Q2: Tom is not both grumpy and mean to animals.\ntheorem q2 : \u00ac (Grumpy Tom \u2227 Mean Tom) :=\n  by\n    intro h\n    exact tom_not_mean h.right\n\n-- Q3: If Tom is not both grumpy and mean, then Tom is neither grumpy nor an animal lover.\n-- We prove the negation of this implication using that Tom is an animal lover.\ntheorem q3_false :\n  \u00ac ((\u00ac (Grumpy Tom \u2227 Mean Tom)) \u2192 (\u00ac Grumpy Tom \u2227 \u00ac AnimalLover Tom)) :=\n  by\n    intro h\n    have hconseq : \u00ac Grumpy Tom \u2227 \u00ac AnimalLover Tom := h q2\n    have hnotAL : \u00ac AnimalLover Tom := hconseq.right\n    exact hnotAL tom_animal_lover\n\n\nAnswers:\n- Question 1: Unknown\n- Question 2: True\n- Question 3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1268,
        "conclusion": "Tom is a grumpy person.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1269,
        "conclusion": "Tom is not both a grumpy person and mean to animals.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1270,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.0
  },
  {
    "story_id": 64,
    "premises": "A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.",
    "gpt_response": "Here is a Lean 4 formalization of the given context, together with proofs relevant to the three questions.\n\nLean code:\n\nuniverse u\n\n-- Types\nconstant Person : Type\nconstant Work : Type\nconstant Place : Type\n\n-- Predicates/relations\nconstant Novel : Work \u2192 Prop\nconstant Podcast : Work \u2192 Prop\nconstant WrittenBy : Work \u2192 Person \u2192 Prop\nconstant CreatedBy : Work \u2192 Person \u2192 Prop\nconstant NovelWriter : Person \u2192 Prop\nconstant American : Person \u2192 Prop\nconstant Writer : Person \u2192 Prop\nconstant BornIn : Person \u2192 Place \u2192 Prop\nconstant AmericanCity : Place \u2192 Prop\n\n-- Entities\nconstant DaniShapiro : Person\nconstant FamilyHistory : Work\nconstant FamilySecrets : Work\nconstant Boston : Place\n\n-- Axioms from the textual context\naxiom podcast_not_novel : \u2200 w, Podcast w \u2192 \u00ac Novel w\naxiom born_in_american_city_is_american : \u2200 p c, BornIn p c \u2192 AmericanCity c \u2192 American p\naxiom novel_written_implies_novel_writer : \u2200 w p, Novel w \u2192 WrittenBy w p \u2192 NovelWriter p\naxiom dani_american_writer : American DaniShapiro \u2227 Writer DaniShapiro\naxiom family_history_written_by_dani : WrittenBy FamilyHistory DaniShapiro\naxiom family_history_is_novel_2003 : Novel FamilyHistory\naxiom dani_created_family_secrets_podcast : Podcast FamilySecrets \u2227 CreatedBy FamilySecrets DaniShapiro\naxiom boston_is_american_city : AmericanCity Boston\n\n-- Q1: Dani Shapiro is a novel writer.\ntheorem Q1 : NovelWriter DaniShapiro := by\n  have hN : Novel FamilyHistory := family_history_is_novel_2003\n  have hW : WrittenBy FamilyHistory DaniShapiro := family_history_written_by_dani\n  exact novel_written_implies_novel_writer _ _ hN hW\n\n-- Q2: Family Secrets is a novel. We prove its negation instead.\ntheorem Q2_neg : \u00ac Novel FamilySecrets := by\n  have hP : Podcast FamilySecrets := (dani_created_family_secrets_podcast).left\n  exact podcast_not_novel _ hP\n\n-- Q3: Dani Shapiro was born in Boston. Not derivable from given data.\n-- We cannot prove BornIn DaniShapiro Boston, nor its negation, from the axioms.\n\n\nAnswers:\n1) Dani Shapiro is a novel writer. True\n2) Family Secrets is a novel. False\n3) Dani Shapiro was born in Boston. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 189,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 190,
        "conclusion": "Family Secrets is a novel.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 191,
        "conclusion": "Dani Shapiro was born in Boston.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 456,
    "premises": "Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.",
    "gpt_response": "Lean 4 formalization and proofs\n\n-- We formalize the domain and predicates\nuniverse u\nconstant Person : Type u\nconstants (A P JS L AM : Person \u2192 Prop) (yuri : Person)\n\n-- Axioms from the textual context\naxioms\n  (ex_nonA_P     : \u2203 x, P x \u2227 \u00ac A x)             -- Some professional basketball players are not American nationals\n  (P_implies_JS  : \u2200 x, P x \u2192 JS x)               -- All professional basketball players can do jump shots\n  (JS_implies_L  : \u2200 x, JS x \u2192 L x)               -- If someone can jump shots, they leap straight into the air\n  (L_implies_AM  : \u2200 x, L x \u2192 AM x)               -- If someone leaps straight into the air, they activate their leg muscles\n  (yuri_not_AM   : \u00ac AM yuri)                     -- Yuri does not activate his leg muscles\n\nopen Classical\n\n-- Derived facts about Yuri\nlemma yuri_not_L : \u00ac L yuri :=\n  mt (L_implies_AM yuri) yuri_not_AM\n\nlemma yuri_not_JS : \u00ac JS yuri :=\n  mt (JS_implies_L yuri) yuri_not_L\n\nlemma yuri_not_P : \u00ac P yuri :=\n  mt (P_implies_JS yuri) yuri_not_JS\n\n-- Q1: Yuri is an American national.\n-- From the given axioms, neither A yuri nor \u00ac A yuri is derivable.\n-- Hence we cannot prove this statement nor its negation.\n\n-- Q2: Yuri is not an American professional basketball player.\n-- We can prove \u00ac (A yuri \u2227 P yuri) since \u00ac P yuri.\ntheorem Q2 : \u00ac (A yuri \u2227 P yuri) :=\n  fun h => yuri_not_P h.right\n\n-- Q3: Yuri is an American professional basketball player.\n-- We cannot prove A yuri \u2227 P yuri; in fact we can prove its negation:\ntheorem Q3_neg : \u00ac (A yuri \u2227 P yuri) := Q2\n\n-- Q4: If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.\n-- This implication is false under the axioms because \u00ac L yuri is true while A yuri \u2227 P yuri is false.\ntheorem Q4_neg : \u00ac (\u00ac L yuri \u2192 (A yuri \u2227 P yuri)) :=\nby\n  -- to refute an implication, it suffices to give the antecedent and refute the consequent\n  intro h\n  have hAP : A yuri \u2227 P yuri := h yuri_not_L\n  exact Q2 hAP\n\n-- Q5: If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.\n-- This implication is false under the axioms because the antecedent holds (by Q2) while P yuri is false.\ntheorem Q5_neg : \u00ac (\u00ac (A yuri \u2227 P yuri) \u2192 P yuri) :=\nby\n  intro h\n  have : P yuri := h Q2\n  exact yuri_not_P this\n\n\nAnswers\n\n1) Yuri is an American national. Unknown\n2) Yuri is not an American professional basketball player. True\n3) Yuri is an American professional basketball player. False\n4) If Yuri does not leap straight into the air, then Yuri is an American professional basketball player. False\n5) If Yuri is not an American professional basketball player, then Yuri is a professional basketball player. False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1313,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 1314,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1315,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 4,
        "example_id": 1316,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1317,
        "conclusion": "If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.4
  },
  {
    "story_id": 280,
    "premises": "Events are either happy or sad.\nAt least one event is happy. ",
    "gpt_response": "Lean formalization and proof attempt\n\nInformal predicates and assumptions:\n- Universe: Event\n- Predicates: happy : Event \u2192 Prop, sad : Event \u2192 Prop\n- Assumptions:\n  1) Exhaustive: \u2200 e, happy e \u2228 sad e\n  2) Exclusive: \u2200 e, \u00ac(happy e \u2227 sad e)\n  3) At least one happy event: \u2203 e, happy e\n\nClaim to check (Q1): \u2200 e, sad e\n\nIn Lean:\n\nuniverse u\n\nvariable (Event : Type u) (happy sad : Event \u2192 Prop)\n\ntheorem not_all_events_are_sad\n  (exhaustive : \u2200 e : Event, happy e \u2228 sad e)\n  (exclusive : \u2200 e : Event, \u00ac (happy e \u2227 sad e))\n  (exists_happy : \u2203 e : Event, happy e) :\n  \u00ac (\u2200 e : Event, sad e) := by\n  intro all_sad\n  rcases exists_happy with \u27e8e\u2080, he\u2080\u27e9\n  have hs\u2080 : sad e\u2080 := all_sad e\u2080\n  exact (exclusive e\u2080) \u27e8he\u2080, hs\u2080\u27e9\n\nThis proves the negation of the statement \u201cAll events are sad,\u201d given the assumptions (in particular, using exclusivity of \u201ceither \u2026 or\u201d).\n\nAnswer to Q1: All events are sad. False\n\nFalse",
    "results": [
      {
        "question_num": 1,
        "example_id": 724,
        "conclusion": "All events are sad.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 140,
    "premises": "The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.",
    "gpt_response": "Lean 4 translation and proofs attempt:\n\n-- Entities\nuniverse u\nconstant Person : Type u\nconstant Steinhauer : Person\nconstant Descampe   : Person\n\n-- Predicates\nconstant Winner         : Person \u2192 Prop\nconstant Participated   : Person \u2192 Prop\nconstant OnLeaderboard  : Person \u2192 Prop\nconstant InSixWayTie    : Person \u2192 Prop\nconstant FromBelgium    : Person \u2192 Prop\n\n-- Axioms from the textual context\naxiom a1 : Winner Steinhauer\naxiom a2 : Participated Steinhauer\naxiom a3 : \u2203 x : Person, InSixWayTie x \u2227 FromBelgium x\naxiom a4 : FromBelgium Descampe \u2227 OnLeaderboard Descampe\naxiom a5 : \u2200 x : Person, OnLeaderboard x \u2192 Participated x\n-- \u201cOne six-way tie was on the leaderboard\u201d\naxiom a6 : \u2200 x : Person, InSixWayTie x \u2192 OnLeaderboard x\n\n-- Question 1 statement: \u00ac Winner Steinhauer\n-- We cannot prove this, but we can prove its negation (namely Winner Steinhauer) directly from a1.\ntheorem Q1_negation_of_statement : Winner Steinhauer := a1\n\n-- Alternatively, we can show \u00ac\u00acWinner Steinhauer\ntheorem Q1_not_not : \u00ac \u00ac Winner Steinhauer :=\nby\n  intro h\n  exact h a1\n\n-- Question 2 statement: InSixWayTie Descampe\n-- From the axioms we know:\n--   \u2022 \u2203x, InSixWayTie x \u2227 FromBelgium x      (a3)\n--   \u2022 FromBelgium Descampe                    (a4.left)\n--   \u2022 OnLeaderboard Descampe                  (a4.right)\n--   \u2022 InSixWayTie x \u2192 OnLeaderboard x         (a6)\n-- But nothing equates \u201cthe Belgian in the six-way tie\u201d with Descampe.\n-- Hence neither InSixWayTie Descampe nor its negation is derivable from these axioms.\n\nAnswers:\n1) Steinhauer was not the winner of the 1992 du Maurier Classic. False\n2) Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic. Unknown\n\nFinal status of proofs:\n- Q1: We proved the negation of the statement (Winner Steinhauer) from a1. Therefore: False\n- Q2: We could not prove the statement nor its negation from the given axioms. Therefore: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 411,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 412,
        "conclusion": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 459,
    "premises": "Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.",
    "gpt_response": "Lean 4 formalization and attempt:\n\nuniverse u\n\n-- Entities\nconstant Entity : Type u\nconstant Jane KiKi : Entity\n\n-- Predicates\nconstant Animal Dog Bark Jumps Legs Terricolous : Entity \u2192 Prop\nconstant Likes : Entity \u2192 Entity \u2192 Prop\n\n-- Axioms from the textual context\naxiom A1 : \u2200 x, Animal x \u2227 Bark x \u2192 \u00ac Likes Jane x\naxiom A2 : \u2200 x, Dog x \u2192 Animal x \u2227 Bark x\naxiom A3 : \u2200 x, Animal x \u2227 Jumps x \u2192 Likes Jane x\naxiom A4 : \u2200 x, Animal x \u2227 Legs x \u2192 Jumps x\naxiom A5 : \u2200 x, Animal x \u2227 Terricolous x \u2192 Legs x\naxiom A6 : Animal KiKi\naxiom A7 : (\u00ac Jumps KiKi \u2227 \u00ac Legs KiKi) \u2192 (Terricolous KiKi \u2228 Legs KiKi)\n\n-- Some derivable lemmas\nlemma terricolous_implies_legs (x : Entity) (hA : Animal x) :\n  Terricolous x \u2192 Legs x :=\nby intro ht; exact (A5 x) \u27e8hA, ht\u27e9\n\nlemma terricolous_implies_jumps (x : Entity) (hA : Animal x) :\n  Terricolous x \u2192 Jumps x :=\nby intro ht; exact (A4 x) \u27e8hA, terricolous_implies_legs x hA ht\u27e9\n\nlemma dog_implies_animal (x : Entity) : Dog x \u2192 Animal x :=\nby intro hd; exact (A2 x hd).left\n\nlemma dog_implies_barks (x : Entity) : Dog x \u2192 Bark x :=\nby intro hd; exact (A2 x hd).right\n\n-- Consequences for KiKi we can prove\nlemma terricolous_KiKi_implies_legs : Terricolous KiKi \u2192 Legs KiKi :=\nterr i colous_implies_legs KiKi A6\n\nlemma terricolous_KiKi_implies_jumps : Terricolous KiKi \u2192 Jumps KiKi :=\nterr i colous_implies_jumps KiKi A6\n\nlemma dog_KiKi_implies_barks : Dog KiKi \u2192 Bark KiKi :=\ndog_implies_barks KiKi\n\n-- None of the following are derivable from the axioms:\n-- 1) Terricolous KiKi\n-- 2) Dog KiKi \u2227 Bark KiKi\n-- 3) \u00ac Bark KiKi \u2227 \u00ac Dog KiKi\n-- and we also cannot derive their negations from the given axioms.\n\nAnswers:\n\nQuestion 1: KiKi is terricolous. Unknown\n\nQuestion 2: KiKi is a barking dog. Unknown\n\nQuestion 3: KiKi does not bark and he is not a dog. Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1324,
        "conclusion": "KiKi is terricolous.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1325,
        "conclusion": "KiKi is a barking dog.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1326,
        "conclusion": "KiKi does not bark and he is not a dog.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 101,
    "premises": "Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.",
    "gpt_response": "Lean formalization and proofs:\n\n-- Types and predicates\nuniverse u\nconstant Person : Type u\nconstant Club   : Type u\n\nconstant PlaysFor     : Person \u2192 Club \u2192 Prop\nconstant FootballClub : Club \u2192 Prop\nconstant Brazilian    : Person \u2192 Prop\nconstant LoanedTo     : Person \u2192 Club \u2192 Prop\n\n-- Entities\nconstant AiltonSilva Ailton : Person\nconstant Nautico Braga Fluminense : Club\n\n-- Facts from the context\naxiom h_alias  : Ailton = AiltonSilva\naxiom h_loan   : LoanedTo Ailton Braga\naxiom h_play   : PlaysFor AiltonSilva Nautico\naxiom h_brazil : Brazilian AiltonSilva\naxiom h_fc_N   : FootballClub Nautico\naxiom h_fc_B   : FootballClub Braga\naxiom h_fc_F   : FootballClub Fluminense\n\n-- Q1: \"No one playing for Nautico is Brazilian.\"\ndef Q1 : Prop := \u2200 p : Person, PlaysFor p Nautico \u2192 \u00ac Brazilian p\n\n-- We can refute Q1 with the counterexample AiltonSilva.\ntheorem Q1_false : \u00ac Q1 := by\n  intro h\n  have hb : \u00ac Brazilian AiltonSilva := h AiltonSilva h_play\n  exact hb h_brazil\n\n-- Q2: \"Ailton Silva does not play for a football club.\"\ndef Q2 : Prop := \u00ac \u2203 c : Club, FootballClub c \u2227 PlaysFor AiltonSilva c\n\n-- We can refute Q2 using Nautico.\ntheorem Q2_false : \u00ac Q2 := by\n  intro h\n  exact h \u27e8Nautico, h_fc_N, h_play\u27e9\n\n-- Q3: \"Ailton was not loaned out to a football club.\"\ndef Q3 : Prop := \u00ac \u2203 c : Club, FootballClub c \u2227 LoanedTo Ailton c\n\n-- We can refute Q3 using Braga.\ntheorem Q3_false : \u00ac Q3 := by\n  intro h\n  exact h \u27e8Braga, h_fc_B, h_loan\u27e9\n\n-- Q4: \"Ailton Silva played for Fluminense.\"\ndef Q4 : Prop := PlaysFor AiltonSilva Fluminense\n-- From the given facts, neither Q4 nor its negation is derivable.\n\n-- Q5: \"Ailton Silva was loaned out to a football club.\"\ndef Q5 : Prop := \u2203 c : Club, FootballClub c \u2227 LoanedTo AiltonSilva c\n\n-- We can prove Q5 using the alias and the loan to Braga.\ntheorem Q5_true : Q5 := by\n  have h_loan_silva : LoanedTo AiltonSilva Braga := by simpa [h_alias] using h_loan\n  exact \u27e8Braga, h_fc_B, h_loan_silva\u27e9\n\n\nAnswers:\n1) False\n2) False\n3) False\n4) Unknown\n5) True\n\nSince we proved the negations for Q1\u2013Q3, could not prove Q4 nor its negation, and proved Q5, the per-question results are as above.",
    "results": [
      {
        "question_num": 1,
        "example_id": 304,
        "conclusion": "No one playing for Nautico is Brazilian.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 305,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 306,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 307,
        "conclusion": "Ailton Silva played for Fluminense.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 5,
        "example_id": 308,
        "conclusion": "Ailton Silva was loaned out to a football club.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      }
    ],
    "story_accuracy": 0.6
  }
]