[
  {
    "story_id": 380,
    "premises": "People in this club who perform in school talent shows often attend and are very engaged with school events.\nPeople in this club either perform in school talent shows often or are inactive and disinterested community members.\nPeople in this club who chaperone high school dances are not students who attend the school.\nAll people in this club who are inactive and disinterested members of their community chaperone high school dances.\nAll young children and teenagers in this club who wish to further their academic careers and educational opportunities are students who attend the school. \nBonnie is in this club and she either both attends and is very engaged with school events and is a student who attends the school or is not someone who both attends and is very engaged with school events and is not a student who attends the school.",
    "model_response": "Lean translation and proof attempt:\n\nWe model a domain of people with predicates for the relevant properties, and Bonnie as a designated individual.\n\nLean setup:\n- Person : Type\n- InClub, PerformsOften, AttendsEngaged, Inactive, Chaperones, Student, YoungOrTeen, Wishes : Person \u2192 Prop\n- Bonnie : Person\n\nAssumptions translated from the text:\n1) \u2200 x, InClub x \u2227 PerformsOften x \u2192 AttendsEngaged x\n2) \u2200 x, InClub x \u2192 (PerformsOften x \u2228 Inactive x)\n3) \u2200 x, InClub x \u2227 Chaperones x \u2192 \u00ac Student x\n4) \u2200 x, InClub x \u2227 Inactive x \u2192 Chaperones x\n5) \u2200 x, InClub x \u2227 YoungOrTeen x \u2227 Wishes x \u2192 Student x\n6) InClub Bonnie\n7) (AttendsEngaged Bonnie \u2227 Student Bonnie) \u2228 (\u00ac AttendsEngaged Bonnie \u2227 \u00ac Student Bonnie)\n\nLean code:\n\nconstant Person : Type\n\nconstant InClub : Person \u2192 Prop\nconstant PerformsOften : Person \u2192 Prop\nconstant AttendsEngaged : Person \u2192 Prop\nconstant Inactive : Person \u2192 Prop\nconstant Chaperones : Person \u2192 Prop\nconstant Student : Person \u2192 Prop\nconstant YoungOrTeen : Person \u2192 Prop\nconstant Wishes : Person \u2192 Prop\n\nconstant Bonnie : Person\n\naxiom h1 : \u2200 x : Person, InClub x \u2227 PerformsOften x \u2192 AttendsEngaged x\naxiom h2 : \u2200 x : Person, InClub x \u2192 (PerformsOften x \u2228 Inactive x)\naxiom h3 : \u2200 x : Person, InClub x \u2227 Chaperones x \u2192 \u00ac Student x\naxiom h4 : \u2200 x : Person, InClub x \u2227 Inactive x \u2192 Chaperones x\naxiom h5 : \u2200 x : Person, InClub x \u2227 YoungOrTeen x \u2227 Wishes x \u2192 Student x\n\naxiom hbClub : InClub Bonnie\naxiom hbEquiv : (AttendsEngaged Bonnie \u2227 Student Bonnie) \u2228 (\u00ac AttendsEngaged Bonnie \u2227 \u00ac Student Bonnie)\n\n-- Useful derived facts\nlemma perform_implies_student : PerformsOften Bonnie \u2192 Student Bonnie := by\n  intro hP\n  have hA : AttendsEngaged Bonnie := h1 Bonnie \u27e8hbClub, hP\u27e9\n  cases hbEquiv with\n  | inl hAS => exact hAS.right\n  | inr hNS => exact False.elim (hNS.left hA)\n\nlemma student_or_inactive : Student Bonnie \u2228 Inactive Bonnie := by\n  have h := h2 Bonnie hbClub\n  cases h with\n  | inl hP => exact Or.inl (perform_implies_student hP)\n  | inr hI => exact Or.inr hI\n\n-- Question 2 statement and proof\n-- If ( (YoungOrTeen \u2227 Wishes \u2227 Chaperones) \u2228 \u00ac(YoungOrTeen \u2227 Wishes) ), then Student \u2228 Inactive.\ntheorem Q2 :\n  ((YoungOrTeen Bonnie \u2227 Wishes Bonnie \u2227 Chaperones Bonnie) \u2228 \u00ac (YoungOrTeen Bonnie \u2227 Wishes Bonnie))\n  \u2192 (Student Bonnie \u2228 Inactive Bonnie) := by\n  intro _\n  exact student_or_inactive\n\n-- For Question 3, the antecedent is derivable:\nlemma not_chap_imp_perform : (\u00ac Chaperones Bonnie) \u2192 PerformsOften Bonnie := by\n  intro hnot\n  have h := h2 Bonnie hbClub\n  cases h with\n  | inl hP => exact hP\n  | inr hI =>\n      have hCh : Chaperones Bonnie := h4 Bonnie \u27e8hbClub, hI\u27e9\n      exact False.elim (hnot hCh)\n\nlemma ant3_true : Chaperones Bonnie \u2228 ((\u00ac Chaperones Bonnie) \u2192 PerformsOften Bonnie) := by\n  exact Or.inr not_chap_imp_perform\n\nNotes on the three questions:\n- Q1 (Bonnie performs often): From InClub Bonnie, we get PerformsOften \u2228 Inactive. Inactive implies Chaperones, which implies \u00acStudent, hence \u00acAttendsEngaged by Bonnie\u2019s given equivalence. Since PerformsOften implies AttendsEngaged, the two disjuncts are incompatible, but nothing forces either one; thus we cannot determine PerformsOften Bonnie. Unknown.\n- Q2: As proved in Lean (theorem Q2), independent of the antecedent, InClub Bonnie entails Student \u2228 Inactive. True.\n- Q3: The antecedent is provable (lemma ant3_true), but the consequent (YoungOrTeen \u2227 Wishes \u2227 Inactive) is neither entailed nor refutable from the given information. Therefore the implication cannot be proved or disproved. Unknown.\n\nANSWERS:\n1: Unknown\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1014,
        "conclusion": "Bonnie performs in school talent shows often.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1015,
        "conclusion": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1016,
        "conclusion": "If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 426,
    "premises": "All employees who schedule a meeting with their customers will go to the company building today. \nEveryone who has lunch in the company building schedules meetings with their customers. \nEmployees have lunch either in the company building or at home.\nIf an employee has lunch at home, they are working remotely from home.\nAll employees who are in other countries work remotely from home. \nNo managers work remotely from home. \nJames will appear in the company today if and only if he is a manager.",
    "model_response": "Lean translation and attempt:\n\nWe model a domain of persons with predicates:\n- Employee, Sched, Go, Lc (lunch in company), Lh (lunch at home), R (works remotely from home), Abroad, Manager : Person \u2192 Prop\n- james : Person\n\nAxioms (from the text):\n1. \u2200x, Employee x \u2227 Sched x \u2192 Go x\n2. \u2200x, Lc x \u2192 Sched x\n3. \u2200x, Employee x \u2192 Lc x \u2228 Lh x\n4. \u2200x, Employee x \u2227 Lh x \u2192 R x\n5. \u2200x, Employee x \u2227 Abroad x \u2192 R x\n6. \u2200x, Manager x \u2192 \u00ac R x\n7. Go james \u2194 Manager james\n\nGoals:\n- Q1: Lc james\n- Q2: \u00ac Lc james\n- Q3: ((Manager james \u2228 Abroad james) \u2192 \u00ac (Lh james \u2228 R james)) \u2227 ((Lh james \u2228 R james) \u2192 (\u00ac Manager james \u2227 \u00ac Abroad james))\n\nAttempted proofs:\n- Q1 cannot be derived: the axioms relating lunch locations apply only to employees, and we are not given that james is an employee. A2 alone (Lc \u2192 Sched) does not force Lc james.\n- Q2 cannot be derived for the same reason; there is no axiom implying \u00acLc james.\n- Q3 cannot be derived: from Manager james we get \u00acR james (A6), but we cannot conclude \u00acLh james without also knowing james is an employee (A4\u2019s antecedent). Likewise, from Lh james \u2228 R james we cannot conclude \u00acManager james or \u00acAbroad james without additional employee information. Moreover, the statement is not forced by the axioms; for example, a model where james is a manager, not an employee, has lunch at home, and does not work remotely satisfies all axioms but falsifies Q3. The negation of Q3 is also not derivable from the axioms.\n\nTherefore, none of the three are provable nor is any negation provable.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1208,
        "conclusion": "James has lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1209,
        "conclusion": "James does not have lunch in the company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1210,
        "conclusion": "If James is either a manager or in other countries,  then James does not either has lunch at home or work remotely from home. If James either has lunch at home or works remotely from home, then he is neither a manager nor does he work in other countries. [contrapositive is more natural]",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 198,
    "premises": "When the Monkeypox virus occurs in a being, it may get Monkeypox. \nMonkeypox virus can occur in certain animals.\nHumans are mammals.\nMammals are animals.\nSymptoms of Monkeypox include fever, headache, muscle pains, and tiredness. \nPeople feel tired when they get the flu.",
    "model_response": "Lean formalization and attempt:\n\nWe introduce a type of beings and predicates/propositions corresponding to the statements.\n\n- Being : Type\n- Animal, Mammal, Human, Person : Being \u2192 Prop\n- CanOccurMonkeypoxVirus, OccursMonkeypoxVirus, MayGetMonkeypox, GetsFlu, FeelsTired : Being \u2192 Prop\n- Symptom: an inductive type with constructors fever, headache, muscle_pains, tiredness, coughing\n- SymptomOfMonkeypox : Symptom \u2192 Prop\n\nAxioms from the text:\n\n1) Humans are mammals; mammals are animals:\n   \u2200 x, Human x \u2192 Mammal x\n   \u2200 x, Mammal x \u2192 Animal x\n\n2) Monkeypox virus can occur in certain animals:\n   \u2203 x, Animal x \u2227 CanOccurMonkeypoxVirus x\n\n3) When the Monkeypox virus occurs in a being, it may get Monkeypox (modeled as a weak implication to a separate predicate MayGetMonkeypox):\n   \u2200 x, OccursMonkeypoxVirus x \u2192 MayGetMonkeypox x\n\n4) People feel tired when they get the flu:\n   \u2200 x, Person x \u2192 (GetsFlu x \u2192 FeelsTired x)\n\n5) Symptoms of Monkeypox include fever, headache, muscle pains, tiredness:\n   SymptomOfMonkeypox fever\n   SymptomOfMonkeypox headache\n   SymptomOfMonkeypox muscle_pains\n   SymptomOfMonkeypox tiredness\n\nNo axiom is given for coughing.\n\nLean sketch:\n\nuniverse u\n\nconstant Being : Type u\nconstant Animal Mammal Human Person : Being \u2192 Prop\n\naxiom humans_are_mammals : \u2200 x, Human x \u2192 Mammal x\naxiom mammals_are_animals : \u2200 x, Mammal x \u2192 Animal x\n\nconstant CanOccurMonkeypoxVirus OccursMonkeypoxVirus MayGetMonkeypox GetsFlu FeelsTired : Being \u2192 Prop\naxiom exists_animal_can_occur : \u2203 x, Animal x \u2227 CanOccurMonkeypoxVirus x\naxiom occurs_implies_may_get : \u2200 x, OccursMonkeypoxVirus x \u2192 MayGetMonkeypox x\naxiom people_flu_tired : \u2200 x, Person x \u2192 (GetsFlu x \u2192 FeelsTired x)\n\ninductive Symptom where\n| fever\n| headache\n| muscle_pains\n| tiredness\n| coughing\n\nopen Symptom\n\nconstant SymptomOfMonkeypox : Symptom \u2192 Prop\naxiom symp_fever : SymptomOfMonkeypox fever\naxiom symp_headache : SymptomOfMonkeypox headache\naxiom symp_muscle_pains : SymptomOfMonkeypox muscle_pains\naxiom symp_tiredness : SymptomOfMonkeypox tiredness\n\n-- Q1: There is an animal.\ntheorem Q1_true : \u2203 x, Animal x := by\n  rcases exists_animal_can_occur with \u27e8a, haAnimal, _\u27e9\n  exact \u27e8a, haAnimal\u27e9\n-- Proven: True.\n\n-- Q2: No one gets the flu. Formalize as \u2200 x, \u00ac GetsFlu x (or restricted to persons).\n-- Not derivable from given axioms; no proof or refutation available here. Unknown.\n\n-- Q3: Symptoms of Monkeypox include coughing. Formalize as SymptomOfMonkeypox Symptom.coughing.\n-- Not given; neither provable nor is its negation provable from the axioms. Unknown.\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 563,
        "conclusion": "There is an animal.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 564,
        "conclusion": "No one gets the flu.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 565,
        "conclusion": "Symptoms of Monkeypox include coughing.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 20,
    "premises": "A Japanese game company created the game the Legend of Zelda.\nAll games on the Top 10 list are made by Japanese game companies.\nIf a game sells more than one million copies, then it will be included in the Top 10 list.\nThe Legend of Zelda sold more than one million copies.",
    "model_response": "Lean formalization and proof attempt:\n\n-- Types and basic predicates\nuniverse u\nconstant Game : Type u\nconstant Company : Type u\nconstant JapaneseCompany : Company \u2192 Prop\nconstant Created : Company \u2192 Game \u2192 Prop\nconstant OnTop10 : Game \u2192 Prop\nconstant SoldOver1M : Game \u2192 Prop\n\n-- Specific games\nconstant Zelda : Game\nconstant FIFA22 : Game\n\n-- Assumptions from the text\naxiom A1 : \u2203 c : Company, JapaneseCompany c \u2227 Created c Zelda\naxiom A2 : \u2200 g : Game, OnTop10 g \u2192 \u2203 c : Company, JapaneseCompany c \u2227 Created c g\naxiom A3 : \u2200 g : Game, SoldOver1M g \u2192 OnTop10 g\naxiom A4 : SoldOver1M Zelda\n\n-- Derived notion\ndef JapaneseMade (g : Game) : Prop := \u2203 c : Company, JapaneseCompany c \u2227 Created c g\n\n-- Q1: The Legend of Zelda is on the Top 10 list.\n-- Proof: from A4 and A3.\ntheorem Q1 : OnTop10 Zelda := A3 Zelda A4\n\n-- Q2: FIFA 22 is made by a Japanese video game company.\n-- Statement:\ndef Q2stmt : Prop := JapaneseMade FIFA22\n-- From the given axioms, neither Q2stmt nor its negation can be derived.\n\n-- Q3: The Legend of Zelda is not on the Top 10 list.\ndef Q3stmt : Prop := \u00ac OnTop10 Zelda\n-- We can prove the negation of Q3stmt using Q1.\ntheorem not_Q3 : \u00ac Q3stmt := by\n  intro h\n  exact h Q1\n\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 57,
        "conclusion": "The Legend of Zelda is on the Top 10 list.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 58,
        "conclusion": "FIFA 22 is made by a Japanese video game company.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 59,
        "conclusion": "The Legend of Zelda is not on the Top 10 list.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 282,
    "premises": "All squares are four-sided.\nAll four-sided things are shapes. ",
    "model_response": "Lean formalization and proof sketch:\n\n- Universe and predicates:\n  - Domain U : Type\n  - Predicates: Square FourSided Shape : U \u2192 Prop\n- Premises:\n  - h1 : \u2200 x, Square x \u2192 FourSided x\n  - h2 : \u2200 x, FourSided x \u2192 Shape x\n- Goal:\n  - \u2200 x, Square x \u2192 Shape x\n\nLean code:\n\n/- Domain and predicates -/\nvariable {U : Type} {Square FourSided Shape : U \u2192 Prop}\n\n/- Premises imply conclusion -/\ntheorem squares_are_shapes\n  (h1 : \u2200 x, Square x \u2192 FourSided x)\n  (h2 : \u2200 x, FourSided x \u2192 Shape x) :\n  \u2200 x, Square x \u2192 Shape x :=\nby\n  intro x hx\n  exact h2 x (h1 x hx)\n\nThis completes the proof, so the statement is True.\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 726,
        "conclusion": "All squares are shapes.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 471,
    "premises": "All rabbits that can be spotted near the campus are cute. \nSome turtles can be spotted near the campus. \nThe only animals that can be spotted near the campus are rabbits and squirrels.\nIf something is skittish, then it is not calm.\nAll the squirrels that can be spotted near the campus are skittish.\nRockie can be spotted near the campus, and it is calm.",
    "model_response": "Lean formalization and proof sketch:\n\n- Domain: a type U of animals; predicates Rabbit, Squirrel, Turtle, Near, Cute, Skittish, Calm : U \u2192 Prop; constant Rockie : U.\n\nAxioms from the text:\n1. A1: \u2200 x, Rabbit x \u2227 Near x \u2192 Cute x\n2. A2: \u2203 x, Turtle x \u2227 Near x\n3. A3: \u2200 x, Near x \u2192 (Rabbit x \u2228 Squirrel x)\n4. A4: \u2200 x, Skittish x \u2192 \u00ac Calm x\n5. A5: \u2200 x, Squirrel x \u2227 Near x \u2192 Skittish x\n6. A6: Near Rockie \u2227 Calm Rockie\n\nDerived facts:\n- Near Rockie and Calm Rockie from A6.\n- \u00ac Squirrel Rockie: if Squirrel Rockie, then by A5 and Near Rockie, Skittish Rockie; by A4, \u00ac Calm Rockie, contradicting Calm Rockie.\n- From A3 and \u00ac Squirrel Rockie, we get Rabbit Rockie; with A1 and Near Rockie, Cute Rockie.\n- \u00ac Skittish Rockie: from A4 and Calm Rockie.\n\nAnswers:\n- Q1 (Rockie is a turtle): Not derivable; also its negation not derivable from the axioms. Unknown.\n- Q2 (Rockie is not a turtle): Also not derivable. Unknown.\n- Q3 (Rockie is a turtle or cute): True, since Cute Rockie is provable.\n- Q4 (If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish): True, since Cute Rockie is provable unconditionally.\n- Q5 (If Rockie is cute and calm, then Rockie is a skittish turtle): False. We have Cute Rockie \u2227 Calm Rockie, but \u00ac Skittish Rockie, so the consequent fails; hence the implication is false.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1361,
        "conclusion": "Rockie is a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1362,
        "conclusion": "Rockie is not a turtle.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1363,
        "conclusion": "Rockie is a turtle or cute.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1364,
        "conclusion": "If Rockie is not both a turtle and a squirrel, then Rockie is either cute or skittish.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1365,
        "conclusion": "If Rockie is cute and calm, then Rockie is a skittish turtle.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 184,
    "premises": "\"Stranger Things\" is a popular Netflix show.\nIf a Netflix show is popular, Karen will binge-watch it.\nIf and only if Karen binge-watches a Netflix show, she will download it.\nKaren does not download \"Black Mirror.\"\n\"Black Mirror\" is a Netflix show.\nIf Karen binge-watches a Netflix show, she will share it with Lisa.",
    "model_response": "Lean formalization and attempt:\n\n-- We model shows, two specific shows, and predicates about them.\nnamespace Reasoning\n\nconstant Show : Type\nconstant ST BM : Show\n\nconstant Popular : Show \u2192 Prop\nconstant NetflixShow : Show \u2192 Prop\nconstant Binge : Show \u2192 Prop          -- Karen binge-watches the show\nconstant Download : Show \u2192 Prop       -- Karen downloads the show\nconstant ShareWithLisa : Show \u2192 Prop  -- Karen shares the show with Lisa\n\n-- Axioms extracted from the text\naxiom ST_pop : Popular ST\naxiom ST_nf  : NetflixShow ST\n\n-- If a Netflix show is popular, Karen will binge-watch it.\naxiom ax1 : \u2200 s, NetflixShow s \u2227 Popular s \u2192 Binge s\n\n-- For any Netflix show, Karen downloads it iff she binge-watches it.\naxiom ax2 : \u2200 s, NetflixShow s \u2192 (Download s \u2194 Binge s)\n\n-- Karen does not download Black Mirror.\naxiom BM_not_dl : \u00ac Download BM\n\n-- Black Mirror is a Netflix show.\naxiom BM_nf : NetflixShow BM\n\n-- If Karen binge-watches a Netflix show, she will share it with Lisa.\naxiom ax3 : \u2200 s, NetflixShow s \u2192 Binge s \u2192 ShareWithLisa s\n\n-- Q1: Karen will share Stranger Things with Lisa. (Provable: True)\ntheorem Q1 : ShareWithLisa ST := by\n  have hb : Binge ST := ax1 ST \u27e8ST_nf, ST_pop\u27e9\n  exact ax3 ST ST_nf hb\n\n-- Q2: Black Mirror is popular. (Provable negation: False)\ntheorem Q2 : \u00ac Popular BM := by\n  intro hpop\n  have hiff : Download BM \u2194 Binge BM := ax2 BM BM_nf\n  have hb2d : Binge BM \u2192 Download BM := Iff.mpr hiff\n  exact BM_not_dl (hb2d (ax1 BM \u27e8BM_nf, hpop\u27e9))\n\n-- Helpful derived fact: from ax2 and BM_not_dl we get \u00ac Binge BM.\ntheorem not_binge_BM : \u00ac Binge BM := by\n  have hiff : Download BM \u2194 Binge BM := ax2 BM BM_nf\n  have hb2d : Binge BM \u2192 Download BM := Iff.mpr hiff\n  intro hb\n  exact BM_not_dl (hb2d hb)\n\n-- Q3: Karen will share Black Mirror with Lisa. (Not derivable; also its negation not derivable from given axioms)\n-- We only have (Netflix \u2227 Binge) \u2192 Share, and we derived \u00acBinge BM, but we have no axiom Share \u2192 Binge.\n-- Hence neither ShareWithLisa BM nor \u00acShareWithLisa BM follows from the axioms.\n\nend Reasoning\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 530,
        "conclusion": "Karen will share \"Stranger Things\" with Lisa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 531,
        "conclusion": "\"Black Mirror\" is popular.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 532,
        "conclusion": "Karen will share \"Black Mirror\" with Lisa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 232,
    "premises": "Beijing is the capital of the People's Republic of China. \nBeijing is the capital city of the world's most populous nation.\nBeijing is located in Northern China.\nBeijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nBeijing has hosted the Summer and Winter Olympics and the Summer and Winter Paralympics.\nMany of Beijing's 91 universities consistently rank among the best universities in the world.",
    "model_response": "Lean formalization and proofs:\n\n-- Types and constants\nconstant City : Type\nconstant Beijing : City\n\n-- Predicates\nconstant HostedSummer2008 : City \u2192 Prop\nconstant HostedWinterOlympics : City \u2192 Prop\nconstant LocatedNorth : City \u2192 Prop\nconstant LocatedSouth : City \u2192 Prop\nconstant SecondLargestCity : City \u2192 Prop\n\n-- Axioms from the text\naxiom ax_hosted_2008_summer : HostedSummer2008 Beijing\naxiom ax_hosted_winter : HostedWinterOlympics Beijing\naxiom ax_located_north : LocatedNorth Beijing\n-- General geographic exclusivity (North and South are disjoint)\naxiom ax_north_implies_not_south : \u2200 c : City, LocatedNorth c \u2192 \u00ac LocatedSouth c\n\n-- Q1: \"Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.\"\n-- Proof: both conjuncts are given by axioms.\ntheorem Q1 : HostedSummer2008 Beijing \u2227 HostedWinterOlympics Beijing :=\nAnd.intro ax_hosted_2008_summer ax_hosted_winter\n\n-- Q2: \"Beijing is located in southern China.\"\n-- We cannot prove this, but we can prove its negation from ax_located_north and exclusivity.\ntheorem not_Q2 : \u00ac LocatedSouth Beijing :=\n(ax_north_implies_not_south Beijing) ax_located_north\n\n-- Q3: \"Beijing is the second largest Chinese city.\"\n-- No information provided to prove or refute this.\n-- Hence neither the statement nor its negation is derivable from the given axioms.\n\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 657,
        "conclusion": "Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 658,
        "conclusion": "Beijing is located in southern China.",
        "ground_truth": "Uncertain",
        "prediction": "False",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 659,
        "conclusion": "Beijing is the second largest Chinese city.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 452,
    "premises": "All aliens are extraterrestrials.\nIf someone is from Mars, then they are an alien.\nNo extraterrestrials are human.\nAll highly intelligent beings from Earth are humans.\nMarvin is a highly intelligent being.\nMarvin is either from Earth and from Mars, or he is from neither.\nIf Marvin is not from Earth, then Marvin is an extraterrestrial.",
    "model_response": "Lean formalization and proof attempt:\n\nuniverse u\n\nconstant Being : Type u\nconstant Alien Extraterrestrial Human HI FromEarth FromMars : Being \u2192 Prop\nconstant Marvin : Being\n\naxiom alien_implies_et : \u2200 x, Alien x \u2192 Extraterrestrial x\naxiom fromMars_implies_alien : \u2200 x, FromMars x \u2192 Alien x\naxiom no_et_are_human : \u2200 x, Extraterrestrial x \u2192 \u00ac Human x\naxiom hi_earth_human : \u2200 x, HI x \u2227 FromEarth x \u2192 Human x\naxiom hi_Marvin : HI Marvin\naxiom M_both_or_neither :\n  (FromEarth Marvin \u2227 FromMars Marvin) \u2228 (\u00ac FromEarth Marvin \u2227 \u00ac FromMars Marvin)\naxiom notEarth_implies_et_M : \u00ac FromEarth Marvin \u2192 Extraterrestrial Marvin\n\nlemma M_not_E_and_M : \u00ac (FromEarth Marvin \u2227 FromMars Marvin) := by\n  intro h\n  have hE : FromEarth Marvin := h.left\n  have hM : FromMars Marvin := h.right\n  have hH : Human Marvin := by\n    have : HI Marvin \u2227 FromEarth Marvin := And.intro hi_Marvin hE\n    exact hi_earth_human Marvin this\n  have hET : Extraterrestrial Marvin := by\n    have hA : Alien Marvin := fromMars_implies_alien Marvin hM\n    exact alien_implies_et Marvin hA\n  have hNotH : \u00ac Human Marvin := no_et_are_human Marvin hET\n  exact hNotH hH\n\nlemma M_notE_and_notM : \u00ac FromEarth Marvin \u2227 \u00ac FromMars Marvin := by\n  have h := M_both_or_neither\n  cases h with\n  | inl hboth =>\n      exact False.elim (M_not_E_and_M hboth)\n  | inr hneither => exact hneither\n\nlemma M_notMars : \u00ac FromMars Marvin := (M_notE_and_notM).right\nlemma M_notEarth : \u00ac FromEarth Marvin := (M_notE_and_notM).left\nlemma M_ET : Extraterrestrial Marvin := notEarth_implies_et_M M_notEarth\nlemma M_notHuman : \u00ac Human Marvin := no_et_are_human Marvin M_ET\n\n-- Q2: proved true\ntheorem Q2 : \u00ac Human Marvin \u2227 \u00ac FromMars Marvin :=\n  And.intro M_notHuman M_notMars\n\n-- Q3: proved false by proving its negation\ntheorem Q3_false : \u00ac (\u00ac FromMars Marvin \u2192 Human Marvin) := by\n  intro h\n  have : Human Marvin := h M_notMars\n  exact M_notHuman this\n\n-- Q1: Neither provable nor refutable from the given axioms.\n\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1301,
        "conclusion": "Marvin is an alien.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1302,
        "conclusion": "Marvin is neither a human nor from Mars.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1303,
        "conclusion": "If Marvin is not from Mars, then Marvin is a human.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 340,
    "premises": "Everyone at the mixer is a Grand Slam champion or an Oscar-nominated actor.\nEvery Grand Slam champion at the mixer is a professional tennis player.\nAll Oscar-nominated actors at the mixer are celebrities.\nAll professional tennis players at the mixer are athletes.\nIf a person at the mixer is a celebrity, then they are well paid.\nIf a person at the mixer is an athlete, then they are famous.\nAll well-paid people at the mixer live in tax havens.\nDjokovic is at the mixer: if Djokovic is a famous athlete, then Djokovic is well-paid.",
    "model_response": "Lean formalization and proof attempts:\n\n```\nnamespace Mixer\n\nuniverse u\nconstant Person : Type u\n\n-- Predicates\nconstant At : Person \u2192 Prop\nconstant GSC : Person \u2192 Prop                  -- Grand Slam champion\nconstant ONA : Person \u2192 Prop                  -- Oscar-nominated actor\nconstant ProTennis : Person \u2192 Prop\nconstant Celebrity : Person \u2192 Prop\nconstant Athlete : Person \u2192 Prop\nconstant WellPaid : Person \u2192 Prop\nconstant Famous : Person \u2192 Prop\nconstant TaxHaven : Person \u2192 Prop\n\n-- Constant individual\nconstant djokovic : Person\n\n-- Axioms from the textual context\naxiom H1 : \u2200 x, At x \u2192 (GSC x \u2228 ONA x)\naxiom H2 : \u2200 x, At x \u2192 (GSC x \u2192 ProTennis x)\naxiom H3 : \u2200 x, At x \u2192 (ONA x \u2192 Celebrity x)\naxiom H4 : \u2200 x, At x \u2192 (ProTennis x \u2192 Athlete x)\naxiom H5 : \u2200 x, At x \u2192 (Celebrity x \u2192 WellPaid x)\naxiom H6 : \u2200 x, At x \u2192 (Athlete x \u2192 Famous x)\naxiom H7 : \u2200 x, At x \u2192 (WellPaid x \u2192 TaxHaven x)\n\n-- Djokovic-specific facts\naxiom H8a : At djokovic\naxiom H8b : (Famous djokovic \u2227 Athlete djokovic) \u2192 WellPaid djokovic\n\n-- Helpful lemmas\nlemma famous_of_athlete_at {x} (hxAt : At x) (hAth : Athlete x) : Famous x :=\n  (H6 x hxAt) hAth\n\nlemma athlete_of_gsc_at {x} (hxAt : At x) (hG : GSC x) : Athlete x :=\n  let hPT := (H2 x hxAt) hG\n  (H4 x hxAt) hPT\n\n-- Djokovic is well-paid (by cases on H1 and using H8b in the GSC branch)\nlemma wellPaid_djokovic : WellPaid djokovic :=\nby\n  have hdisj : GSC djokovic \u2228 ONA djokovic := H1 djokovic H8a\n  cases hdisj with\n  | inl hG =>\n      have hA : Athlete djokovic := athlete_of_gsc_at H8a hG\n      have hF : Famous djokovic := famous_of_athlete_at H8a hA\n      exact H8b \u27e8hF, hA\u27e9\n  | inr hO =>\n      have hC : Celebrity djokovic := (H3 djokovic H8a) hO\n      exact (H5 djokovic H8a) hC\n\n-- Q2: Djokovic lives in a tax haven (provable)\ntheorem q2 : TaxHaven djokovic :=\n  (H7 djokovic H8a) wellPaid_djokovic\n\n-- Q3: \"Djokovic does not live in a tax haven\" is false\ntheorem q3_false : \u00ac (\u00ac TaxHaven djokovic) :=\nby\n  intro h\n  exact h q2\n\n-- Q1 remains undecided: we have only H1 djokovic H8a : GSC djokovic \u2228 ONA djokovic\n\nend Mixer\n```\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 893,
        "conclusion": "Djokovic is a Grand Slam champion.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 894,
        "conclusion": "Djokovic lives in a tax haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 895,
        "conclusion": "Djokovic does not live in a tax haven.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 96,
    "premises": "Diamond Mine is a professional wrestling stable formed in WWE.\nRoderick Strong leads Diamond Mine.\nDiamond Mine includes the Creed Brothers and Ivy Nile.\nImperium has a feud with Diamond Mine.",
    "model_response": "Lean formalization and attempt:\n\nWe model entities and predicates:\n- Entity : Type\n- Stable : Entity \u2192 Prop\n- leads : Entity \u2192 Entity \u2192 Prop\n- includes : Entity \u2192 Entity \u2192 Prop\n- feud_with : Entity \u2192 Entity \u2192 Prop\n\nConstants:\n- DiamondMine, RoderickStrong, CreedBrothers, IvyNile, Imperium : Entity\n\nAxioms from the text:\n- hStable : Stable DiamondMine\n- hLeads : leads RoderickStrong DiamondMine\n- hIncCB : includes DiamondMine CreedBrothers\n- hIncIN : includes DiamondMine IvyNile\n- hFeud : feud_with Imperium DiamondMine\n\nLean code:\n\nuniverse u\n\nconstant Entity : Type u\n\nconstant Stable : Entity \u2192 Prop\nconstant leads : Entity \u2192 Entity \u2192 Prop\nconstant includes : Entity \u2192 Entity \u2192 Prop\nconstant feud_with : Entity \u2192 Entity \u2192 Prop\n\nconstant DiamondMine : Entity\nconstant RoderickStrong : Entity\nconstant CreedBrothers : Entity\nconstant IvyNile : Entity\nconstant Imperium : Entity\n\naxiom hStable : Stable DiamondMine\naxiom hLeads : leads RoderickStrong DiamondMine\naxiom hIncCB : includes DiamondMine CreedBrothers\naxiom hIncIN : includes DiamondMine IvyNile\naxiom hFeud : feud_with Imperium DiamondMine\n\n-- Q1: \u2203 s, Stable s \u2227 leads RoderickStrong s\ntheorem Q1_true : \u2203 s, Stable s \u2227 leads RoderickStrong s :=\n  \u27e8DiamondMine, And.intro hStable hLeads\u27e9\n-- Proven: True\n\n-- Q2: leads RoderickStrong CreedBrothers\ndef Q2_stmt : Prop := leads RoderickStrong CreedBrothers\n-- Not derivable from given axioms; no proof or disproof provided (Unknown)\n\n-- Q3: \u00ac \u2203 s, Stable s \u2227 includes s IvyNile \u2227 feud_with Imperium s\ndef Q3_stmt : Prop := \u00ac \u2203 s, Stable s \u2227 includes s IvyNile \u2227 feud_with Imperium s\n\n-- We can prove the negation of Q3_stmt by exhibiting DiamondMine as a witness:\ntheorem Q3_neg_of_stmt : \u2203 s, Stable s \u2227 includes s IvyNile \u2227 feud_with Imperium s :=\n  \u27e8DiamondMine, And.intro hStable (And.intro hIncIN hFeud)\u27e9\n\ntheorem Q3_false : \u00ac Q3_stmt :=\n  fun h => h Q3_neg_of_stmt\n-- Hence the original Q3 statement is False.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 289,
        "conclusion": "Roderick Strong leads a professional wrestling stable.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 290,
        "conclusion": "Roderick Strong leads the Creed Brothers.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 291,
        "conclusion": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 219,
    "premises": "Symphony No. 9 is a music piece.\nComposers write music pieces.\nBeethoven wrote Symphony No. 9.\nVienna Music Society premiered Symphony No. 9.\nVienna Music Society is an orchestra.\nBeethoven leads the Vienna Music Society.\nOrchestras are led by conductors.",
    "model_response": "Lean formalization and attempt at proofs:\n\nuniverse u\nconstant Entity : Type u\n\n-- Predicates\nconstant MusicPiece : Entity \u2192 Prop\nconstant Composer : Entity \u2192 Prop\nconstant Orchestra : Entity \u2192 Prop\nconstant Conductor : Entity \u2192 Prop\n\n-- Relations\nconstant Wrote : Entity \u2192 Entity \u2192 Prop\nconstant Premiered : Entity \u2192 Entity \u2192 Prop\nconstant Leads : Entity \u2192 Entity \u2192 Prop\n\n-- Constants\nconstant Beethoven : Entity\nconstant Symphony9 : Entity\nconstant ViennaMusicSociety : Entity\n\n-- Axioms from the textual context\naxiom sym9_is_music : MusicPiece Symphony9\naxiom composers_write : \u2200 c, Composer c \u2192 \u2203 m, MusicPiece m \u2227 Wrote c m\naxiom beethoven_wrote_sym9 : Wrote Beethoven Symphony9\naxiom vms_premiered_sym9 : Premiered ViennaMusicSociety Symphony9\naxiom vms_is_orchestra : Orchestra ViennaMusicSociety\naxiom beethoven_leads_vms : Leads Beethoven ViennaMusicSociety\naxiom leaders_of_orchestras_are_conductors :\n  \u2200 x o, Leads x o \u2192 Orchestra o \u2192 Conductor x\n\n-- Q2: Some orchestras premiered music pieces.\ntheorem Q2_true : \u2203 o m, Orchestra o \u2227 MusicPiece m \u2227 Premiered o m :=\n  \u27e8ViennaMusicSociety, Symphony9, vms_is_orchestra, sym9_is_music, vms_premiered_sym9\u27e9\n\n-- Q3: Beethoven is not a conductor (we prove its negation by showing he is a conductor).\nlemma beethoven_is_conductor : Conductor Beethoven :=\n  leaders_of_orchestras_are_conductors Beethoven ViennaMusicSociety\n    beethoven_leads_vms vms_is_orchestra\n\n-- Hence the statement \"Beethoven is not a conductor\" is false.\ntheorem Q3_false : \u00ac (\u00ac Conductor Beethoven) :=\n  fun h => h beethoven_is_conductor\n\n-- Q1: Beethoven is a composer.\n-- From the given axioms we have only (Composer c \u2192 \u2203 m, MusicPiece m \u2227 Wrote c m)\n-- and Wrote Beethoven Symphony9, which does not suffice to derive Composer Beethoven.\n-- Therefore Q1 is not derivable from the given information, nor is its negation.\n\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 621,
        "conclusion": "Beethoven is a composer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 622,
        "conclusion": "Some orchestras premiered music pieces.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 623,
        "conclusion": "Beethoven is not a conductor.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 350,
    "premises": "All of Zaha Hadid's design styles that Max adores have interesting geometries.\nNo brutalist buildings that Max adores have interesting geometries.\nEvery style that Max adores is either Zaha Hadid's design style or Kelly Wearstler's design style. \nAll of Kelly Wearstler's design styles that Max adores are evocative.\nAll of Kelly Wearstler's design styles that Max adores are dreamy.\nIf a design by Max that he adores has interesting geometries, then the design is a brutalist building and evocative.",
    "model_response": "Lean formalization and attempt:\n\nuniverse u\nconstant U : Type u\n\n-- Predicates\nconstant Design : U \u2192 Prop        -- design by Max\nconstant Adores : U \u2192 Prop        -- Max adores it\nconstant Brutalist : U \u2192 Prop\nconstant Interesting : U \u2192 Prop\nconstant Evocative : U \u2192 Prop\nconstant Dreamy : U \u2192 Prop\nconstant Zaha : U \u2192 Prop          -- Zaha Hadid's design style\nconstant Kelly : U \u2192 Prop         -- Kelly Wearstler's design style\n\n-- Premises\nconstant h1 : \u2200 x:U, Zaha x \u2227 Adores x \u2192 Interesting x\nconstant h2 : \u2200 x:U, Brutalist x \u2227 Adores x \u2192 \u00ac Interesting x\nconstant h3 : \u2200 x:U, Adores x \u2192 (Zaha x \u2228 Kelly x)\nconstant h4 : \u2200 x:U, Kelly x \u2227 Adores x \u2192 Evocative x\nconstant h5 : \u2200 x:U, Kelly x \u2227 Adores x \u2192 Dreamy x\nconstant h6 : \u2200 x:U, Design x \u2227 Adores x \u2227 Interesting x \u2192 Brutalist x \u2227 Evocative x\n\n-- Useful consequence: a design by Max that he adores cannot be interesting\nlemma no_interesting_adored_design : \u2200 x:U, Design x \u2227 Adores x \u2227 Interesting x \u2192 False :=\nbegin\n  intro x, intro h,\n  have hb : Brutalist x := (h6 x h).left,\n  have hni : \u00ac Interesting x := h2 x \u27e8hb, h.2.1\u27e9,\n  exact hni h.2.2,\nend\n\n-- Questions encoded\ndef Q1 : Prop := \u2203 x:U, Design x \u2227 Brutalist x\ndef Q2 : Prop := \u2203 x:U, Design x \u2227 Evocative x \u2227 Dreamy x\ndef Q3 : Prop := \u2203 x:U, Design x \u2227 (Evocative x \u2228 Dreamy x)\n\n-- Attempted proofs:\n-- From the given premises, there is no information guaranteeing the existence of any design by Max,\n-- nor linking \"Design\" to \"Adores\" unconditionally. Thus Q1, Q2, and Q3 cannot be proved.\n-- Likewise, the negations \u00acQ1, \u00acQ2, \u00acQ3 also cannot be derived from the premises.\n\nConclusion: None of the three statements can be determined from the premises.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 927,
        "conclusion": "A design by Max is a brutalist building.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 928,
        "conclusion": "A design by Max is evocative and dreamy.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 929,
        "conclusion": "A design by Max is either evocative or dreamy.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 385,
    "premises": "If someone is ranked highly by the Women's Tennis Association, then they are one of the most active players in major tennis. \nEveryone who lost to Iga \u015awi\u0105tek at Roland Garros 2022 is ranked highly by the Women's Tennis Association.\nAll female tennis players at Roland Garros 2022 lost to Iga \u015awi\u0105tek.\nAll tennis players at Roland Garros 2022 are either female or male.\nAll male tennis players at Roland Garros in 2022 lost to Rafael Nadal.\nIf Coco Gauff is ranked highly by the Women's Tennis Association or lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nCoco Gauff is at Roland Garros 2022.",
    "model_response": "Lean formalization and attempt:\n\n-- Universe of discourse: persons/players\nuniverse u\nconstant Person : Type u\nconstant Coco : Person\n\n-- Predicates\nconstant Ranked : Person \u2192 Prop            -- ranked highly by the WTA\nconstant Active : Person \u2192 Prop            -- among the most active players in major tennis\nconstant LostIga : Person \u2192 Prop           -- lost to Iga \u015awi\u0105tek at Roland Garros 2022\nconstant FemaleRG : Person \u2192 Prop          -- female tennis player at Roland Garros 2022\nconstant MaleRG : Person \u2192 Prop            -- male tennis player at Roland Garros 2022\nconstant PlayerRG : Person \u2192 Prop          -- tennis player at Roland Garros 2022\nconstant LostNadal : Person \u2192 Prop         -- lost to Rafael Nadal\n\n-- Axioms from the textual context\naxiom ax1 : \u2200 x, Ranked x \u2192 Active x\naxiom ax2 : \u2200 x, LostIga x \u2192 Ranked x\naxiom ax3 : \u2200 x, FemaleRG x \u2192 LostIga x\naxiom ax4 : \u2200 x, PlayerRG x \u2192 (FemaleRG x \u2228 MaleRG x)\naxiom ax5 : \u2200 x, MaleRG x \u2192 LostNadal x\naxiom ax6 : (Ranked Coco \u2228 LostNadal Coco) \u2192 \u00ac (MaleRG Coco)\naxiom ax7 : PlayerRG Coco\n\n-- Deductions\nlemma not_male_Coco : \u00ac MaleRG Coco := by\n  intro hm\n  have hln : LostNadal Coco := ax5 Coco hm\n  have hante : Ranked Coco \u2228 LostNadal Coco := Or.inr hln\n  have hnm : \u00ac MaleRG Coco := ax6 hante\n  exact hnm hm\n\nlemma female_Coco : FemaleRG Coco := by\n  have hdisj : FemaleRG Coco \u2228 MaleRG Coco := ax4 Coco ax7\n  cases hdisj with\n  | inl hf => exact hf\n  | inr hm => exact False.elim (not_male_Coco hm)\n\nlemma lostIga_Coco : LostIga Coco := ax3 Coco female_Coco\nlemma ranked_Coco : Ranked Coco := ax2 Coco lostIga_Coco\nlemma active_Coco : Active Coco := ax1 Coco ranked_Coco\n\n-- Q1: Coco is among the most active Grand-Slam players.\ntheorem Q1 : Active Coco := active_Coco  -- True\n\n-- Q3: The statement \"\u00ac (LostIga Coco \u2227 Active Coco)\" is false,\n-- since we can prove both conjuncts.\nlemma both_Coco : LostIga Coco \u2227 Active Coco := And.intro lostIga_Coco active_Coco\ntheorem Q3_false : \u00ac (\u00ac (LostIga Coco \u2227 Active Coco)) := by\n  intro h\n  exact h both_Coco  -- Therefore, the original statement is False.\n\n-- Q2: We cannot derive LostNadal Coco nor its negation from the axioms above.\n\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1029,
        "conclusion": "Coco Gauff is among the most active Grand-Slam players.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1030,
        "conclusion": "Coco Gauff has lost to Rafael Nadal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1031,
        "conclusion": "Coco Gauff is not both a player who lost to Iga \u015awi\u0105tek at Roland Garros 2022 and one of the most active players in major tennis.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 256,
    "premises": "All cats are mammals.\nSome pets are not mammals.",
    "model_response": "Lean translation and attempt:\n\n- Universe of discourse: U\n- Predicates: Cat : U \u2192 Prop, Mammal : U \u2192 Prop, Pet : U \u2192 Prop\n- Premises:\n  1. \u2200 x, Cat x \u2192 Mammal x          -- All cats are mammals.\n  2. \u2203 x, Pet x \u2227 \u00ac Mammal x        -- Some pets are not mammals.\n- Claim to test: \u2200 x, Pet x \u2192 \u00ac Cat x  -- No pets are cats.\n\nLean code sketch:\n\nuniverse u\nvariable {U : Type u}\nvariables (Cat Pet Mammal : U \u2192 Prop)\nvariable (h1 : \u2200 x, Cat x \u2192 Mammal x)\nvariable (h2 : \u2203 x, Pet x \u2227 \u00ac Mammal x)\n\n-- Target (what the question asks): \u2200 x, Pet x \u2192 \u00ac Cat x\n\n-- What we can prove from the premises:\ntheorem exists_pet_not_cat : \u2203 x, Pet x \u2227 \u00ac Cat x := by\n  rcases h2 with \u27e8x, hxPet, hxNotMammal\u27e9\n  have hxNotCat : \u00ac Cat x := by\n    exact mt (h1 x) hxNotMammal   -- from Cat x \u2192 Mammal x and \u00ac Mammal x, infer \u00ac Cat x\n  exact \u27e8x, hxPet, hxNotCat\u27e9\n\nCommentary:\n- From the premises we can derive that there exists at least one pet that is not a cat.\n- However, this does not suffice to prove the universal statement that no pets are cats.\n- We also cannot derive the negation (that there exists a pet that is a cat) from the premises.\n- Therefore, the truth of \u201cNo pets are cats\u201d is not determined by the given information.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 700,
        "conclusion": "No pets are cats.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 159,
    "premises": "There are four seasons in a year: Spring, Summer, Fall, and Winter.\nAll students who want to have a long vacation have summer as their favorite season.\nEmma's favorite season is summer.\nMia's favorite season is not the same as Emma's. \nJames wants to have a long vacation.",
    "model_response": "Lean translation and attempt:\n\n-- Types and basic symbols\ninductive Season where\n| Spring | Summer | Fall | Winter\nderiving DecidableEq\n\nconstant Person : Type\nconstant emma mia james : Person\n\n-- Each person has exactly one favorite season\nconstant favorite : Person \u2192 Season\n\n-- Predicates\nconstant Student : Person \u2192 Prop\nconstant WantsLongVacation : Person \u2192 Prop\n\n-- Axioms from the text\naxiom rule_students_who_want_have_summer :\n  \u2200 x : Person, Student x \u2227 WantsLongVacation x \u2192 favorite x = Season.Summer\n\naxiom emma_fav_summer : favorite emma = Season.Summer\naxiom mia_fav_neq_emma : favorite mia \u2260 favorite emma\naxiom james_wants_long_vacation : WantsLongVacation james\n\n-- Useful lemma derivable from the axioms\nlemma mia_not_summer : favorite mia \u2260 Season.Summer := by\n  intro h\n  have h\u2081 : favorite mia = favorite emma := by\n    simpa [emma_fav_summer] using h\n  exact mia_fav_neq_emma h\u2081\n\n-- Q1: Is favorite james = Summer?\n-- Attempt: From the rule, we would need Student james \u2227 WantsLongVacation james.\n-- We only have WantsLongVacation james, no information that james is a Student.\n-- So we cannot prove favorite james = Summer, nor can we prove its negation.\n-- Therefore: Unknown.\n\n-- Q2: Is favorite mia = Spring?\n-- From mia_fav_neq_emma and emma_fav_summer, we get favorite mia \u2260 Summer (lemma above).\n-- But with four seasons, not Summer does not imply Spring (could be Fall or Winter).\n-- We cannot prove favorite mia = Spring, nor its negation from the given axioms.\n-- Therefore: Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 456,
        "conclusion": "James's favorite season is summer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 457,
        "conclusion": "Mia's favorite season is spring.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 343,
    "premises": "No digital media are analog.\nEvery printed text is analog media.\nAll streaming services are digital media.\nIf an object is a hardcover book, then it is printed text.\nIf 1984 is a streaming service, then 1984 is a hardcover book.",
    "model_response": "Lean formalization and proof attempt:\n\nWe model entities and predicates:\n- Entity: the domain of objects.\n- Digital, Analog, PrintedText, StreamingService, HardcoverBook: predicates on Entity.\n- book1984: a constant for \u201c1984\u201d.\n\nAssumptions from the text:\n1. \u2200x, Digital x \u2192 \u00ac Analog x\n2. \u2200x, PrintedText x \u2192 Analog x\n3. \u2200x, StreamingService x \u2192 Digital x\n4. \u2200x, HardcoverBook x \u2192 PrintedText x\n5. StreamingService book1984 \u2192 HardcoverBook book1984\n\nLean code:\n\nuniverse u\n\nconstant Entity : Type u\nconstant Digital : Entity \u2192 Prop\nconstant Analog : Entity \u2192 Prop\nconstant PrintedText : Entity \u2192 Prop\nconstant StreamingService : Entity \u2192 Prop\nconstant HardcoverBook : Entity \u2192 Prop\nconstant book1984 : Entity\n\naxiom no_digital_are_analog : \u2200 x, Digital x \u2192 \u00ac Analog x\naxiom printed_are_analog : \u2200 x, PrintedText x \u2192 Analog x\naxiom streaming_are_digital : \u2200 x, StreamingService x \u2192 Digital x\naxiom hardcover_are_printed : \u2200 x, HardcoverBook x \u2192 PrintedText x\naxiom streaming1984_implies_hardcover1984 : StreamingService book1984 \u2192 HardcoverBook book1984\n\n-- Key consequence: 1984 is not a streaming service.\ntheorem not_streaming_1984 : \u00ac StreamingService book1984 := by\n  intro hstream\n  have hd : Digital book1984 := streaming_are_digital book1984 hstream\n  have hh : HardcoverBook book1984 := streaming1984_implies_hardcover1984 hstream\n  have hp : PrintedText book1984 := hardcover_are_printed book1984 hh\n  have ha : Analog book1984 := printed_are_analog book1984 hp\n  have hna : \u00ac Analog book1984 := no_digital_are_analog book1984 hd\n  exact hna ha\n\n-- From the premises alone, we cannot derive PrintedText book1984, nor its negation.\n-- But we can prove Q2 is false (since its negation holds) and Q3 is true.\n\ntheorem q2_false : \u00ac StreamingService book1984 := not_streaming_1984\ntheorem q3_true : \u00ac StreamingService book1984 := not_streaming_1984\n\nConclusions:\n- Q1 (1984 is printed text): Cannot be derived; also cannot derive its negation. Unknown.\n- Q2 (1984 is a streaming service): Its negation is provable, so False.\n- Q3 (1984 is not a streaming service): Provable, so True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 904,
        "conclusion": "1984 is printed text.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 905,
        "conclusion": "1984 is a streaming service.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 906,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 213,
    "premises": "All Romance languages are Indo-European languages.\nRomance languages are a language family.\nAll languages within a language family are related to each other.\nFrench and Spanish are both Romance languages.\nGerman is related to Spanish.\nBasque is not related to any other language.",
    "model_response": "Lean formalization and attempt:\n\n- Entities and predicates:\n  - Type: Language\n  - Constants: French, Spanish, German, Basque : Language\n  - Predicates:\n    - Romance, IndoEuro : Language \u2192 Prop\n    - Related : Language \u2192 Language \u2192 Prop\n    - IsFamily : (Language \u2192 Prop) \u2192 Prop\n  - Axioms from the text:\n    - romance_subset_indo : \u2200 x, Romance x \u2192 IndoEuro x\n    - romance_is_family : IsFamily Romance\n    - all_in_family_related : \u2200 F, IsFamily F \u2192 \u2200 x y, F x \u2192 F y \u2192 Related x y\n    - FrenchRomance : Romance French\n    - SpanishRomance : Romance Spanish\n    - GermanRelatedSpanish : Related German Spanish\n    - Basque_isolate : \u2200 y, y \u2260 Basque \u2192 \u00ac Related Basque y\n    - Basque_ne_Spanish : Basque \u2260 Spanish  [distinctness used to apply isolation]\n\n- Proof sketches:\n  - Q1 (Basque is a Romance language) is false:\n    If Romance Basque, then since Romance is a family and Spanish is Romance, we get Related Basque Spanish. But Basque_isolate with Basque_ne_Spanish yields \u00ac Related Basque Spanish. Contradiction. Hence \u00ac Romance Basque.\n  - Q2 (German is a Romance language) is not derivable:\n    We only have that members of a language family are related; we do not have the converse. German being related to Spanish does not imply German is Romance. No axiom rules out German being Romance either. Hence Unknown.\n  - Q3 (French is an Indo-European language) is true:\n    From FrenchRomance and romance_subset_indo.\n\nLean 4 code (sketch):\n\nuniverse u\n\nconstant Language : Type u\nconstants French Spanish German Basque : Language\n\ndef Family := Language \u2192 Prop\n\nconstant Related : Language \u2192 Language \u2192 Prop\nconstant Romance : Family\nconstant IndoEuro : Family\n\nconstant IsFamily : Family \u2192 Prop\n\naxiom all_in_family_related : \u2200 F, IsFamily F \u2192 \u2200 x y, F x \u2192 F y \u2192 Related x y\naxiom romance_is_family : IsFamily Romance\naxiom romance_subset_indo : \u2200 x, Romance x \u2192 IndoEuro x\n\naxiom FrenchRomance : Romance French\naxiom SpanishRomance : Romance Spanish\n\naxiom GermanRelatedSpanish : Related German Spanish\n\naxiom Basque_isolate : \u2200 y, y \u2260 Basque \u2192 \u00ac Related Basque y\naxiom Basque_ne_Spanish : Basque \u2260 Spanish\n\ntheorem Q1_false : \u00ac Romance Basque := by\n  intro hBasqueRom\n  have hRel : Related Basque Spanish :=\n    all_in_family_related Romance romance_is_family Basque Spanish hBasqueRom SpanishRomance\n  have hNotRel : \u00ac Related Basque Spanish :=\n    Basque_isolate Spanish Basque_ne_Spanish\n  exact hNotRel hRel\n\ntheorem Q3_true : IndoEuro French :=\n  romance_subset_indo French FrenchRomance\n\nResults:\n- Q1 proved False.\n- Q2 undecidable from given axioms (no proof of either side).\n- Q3 proved True.\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 608,
        "conclusion": "Basque is a Romance language.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 609,
        "conclusion": "German is a Romance language.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 610,
        "conclusion": "French is an Indo-European language.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 79,
    "premises": "Robert Lewandowski is a striker.\nStrikers are soccer players.\nRobert Lewandowski left Bayern Munchen.\nIf a player leaves a team they no longer play for that team.",
    "model_response": "Lean formalization and proof attempts:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Person : Type u\nconstant Team : Type u\n\nconstant RL : Person\nconstant BM : Team\n\nconstant Striker : Person \u2192 Prop\nconstant SoccerPlayer : Person \u2192 Prop\nconstant PlaysFor : Person \u2192 Team \u2192 Prop\nconstant Left : Person \u2192 Team \u2192 Prop\nconstant Star : Person \u2192 Prop\n\naxiom h1 : Striker RL\naxiom h2 : \u2200 p : Person, Striker p \u2192 SoccerPlayer p\naxiom h3 : Left RL BM\naxiom h4 : \u2200 p : Person, \u2200 t : Team, Left p t \u2192 \u00ac PlaysFor p t\n\n-- Q1: Robert Lewandowski is a soccer player.\ntheorem Q1_true : SoccerPlayer RL := h2 RL h1\n\n-- Q2: Robert Lewandowski plays for Bayern Munchen.\ndef Q2_stmt : Prop := PlaysFor RL BM\ntheorem Q2_false : \u00ac Q2_stmt := by\n  unfold Q2_stmt\n  exact h4 RL BM h3\n\n-- Q3: Robert Lewandowski is a star.\ndef Q3_stmt : Prop := Star RL\n-- No derivation available from given axioms.\n\nend Reasoning\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 240,
        "conclusion": "Robert Lewandowski is a soccer player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 241,
        "conclusion": "Robert Lewandowski plays for Bayern Munchen.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 242,
        "conclusion": "Robert Lewandowski is a star.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 2,
    "premises": "Billings is a city in the state of Montana in U.S.\nThe state of Montana includes the cities of Butte, Helena, and Missoula.\nWhite Sulphur Springs and Butte are cities in the same state in U.S.\nThe city of St Pierre is not in the state of Montana.\nAny city in Butte is not in St Pierre.\nA city can only be in one state in U.S.  except for Bristol, Texarkana, Texhoma and Union City.",
    "model_response": "Lean formalization and proofs:\n\n- Sorts and predicates:\n  - Entity: everything (cities and states)\n  - City : Entity \u2192 Prop\n  - State : Entity \u2192 Prop\n  - In : Entity \u2192 Entity \u2192 Prop  (generic containment; when second arg is a state, it means \u201ccity is in that state\u201d)\n\n- Constants for entities: Billings, Montana, Butte, Helena, Missoula, WhiteSulphurSprings, StPierre, Bristol, Texarkana, Texhoma, UnionCity, Bismarck.\n\n- Axioms from the text:\n  - Billings is a city; Montana is a state; Billings \u2208 Montana.\n  - Butte, Helena, Missoula are cities; each is in Montana.\n  - White Sulphur Springs is a city and is in the same state as Butte: \u2203 s, State s \u2227 In WSS s \u2227 In Butte s.\n  - St Pierre is a city and \u00ac In StPierre Montana.\n  - Any city in Butte is not in St Pierre: \u2200 c, City c \u2192 In c Butte \u2192 \u00ac In c StPierre. (not used in the proofs below)\n  - Uniqueness of a city\u2019s state except for the four exceptions:\n    \u2200 c s1 s2, City c \u2192 State s1 \u2192 State s2 \u2192 In c s1 \u2192 In c s2 \u2192\n      c \u2260 Bristol \u2192 c \u2260 Texarkana \u2192 c \u2260 Texhoma \u2192 c \u2260 UnionCity \u2192 s1 = s2.\n  - Distinctness needed to apply uniqueness to Butte:\n    Butte \u2260 Bristol, Butte \u2260 Texarkana, Butte \u2260 Texhoma, Butte \u2260 UnionCity.\n\n- Definition:\n  same_state x y := \u2203 s, State s \u2227 In x s \u2227 In y s.\n\n- Proofs:\n  1) Q1 (Butte and St Pierre are in the same state) is False.\n     Proof sketch: Assume same_state Butte StPierre via some state s. Since Butte \u2208 Montana and Butte is not an exception, uniqueness forces s = Montana, hence StPierre \u2208 Montana, contradicting \u00ac In StPierre Montana.\n\n  2) Q2 (St Pierre and Bismarck are in the same state) is unprovable from the given axioms: we have no facts about Bismarck and only know StPierre is not in Montana; there could be some other state containing both, or not. So neither the statement nor its negation is derivable.\n\n  3) Q3 (Montana is home to the city of Missoula) is True by the axiom In Missoula Montana.\n\nLean code:\n\nnamespace World\n\nconstant Entity : Type\nconstant City : Entity \u2192 Prop\nconstant State : Entity \u2192 Prop\nconstant In : Entity \u2192 Entity \u2192 Prop\n\nconstants\n  Billings Montana Butte Helena Missoula WhiteSulphurSprings StPierre\n  Bristol Texarkana Texhoma UnionCity Bismarck : Entity\n\naxiom Billings_city : City Billings\naxiom Montana_state : State Montana\naxiom Billings_in_Montana : In Billings Montana\n\naxiom Butte_city : City Butte\naxiom Helena_city : City Helena\naxiom Missoula_city : City Missoula\naxiom Butte_in_Montana : In Butte Montana\naxiom Helena_in_Montana : In Helena Montana\naxiom Missoula_in_Montana : In Missoula Montana\n\naxiom WSS_city : City WhiteSulphurSprings\naxiom WSS_same_state_as_Butte :\n  \u2203 s, State s \u2227 In WhiteSulphurSprings s \u2227 In Butte s\n\naxiom StPierre_city : City StPierre\naxiom StPierre_not_in_Montana : \u00ac In StPierre Montana\n\naxiom any_city_in_Butte_not_in_StPierre :\n  \u2200 c, City c \u2192 In c Butte \u2192 \u00ac In c StPierre\n\naxiom city_unique_state_except_4 :\n  \u2200 c s1 s2, City c \u2192 State s1 \u2192 State s2 \u2192 In c s1 \u2192 In c s2 \u2192\n    c \u2260 Bristol \u2192 c \u2260 Texarkana \u2192 c \u2260 Texhoma \u2192 c \u2260 UnionCity \u2192 s1 = s2\n\naxioms Butte_ne_Bristol : Butte \u2260 Bristol\n       Butte_ne_Texarkana : Butte \u2260 Texarkana\n       Butte_ne_Texhoma : Butte \u2260 Texhoma\n       Butte_ne_UnionCity : Butte \u2260 UnionCity\n\ndef same_state (x y : Entity) : Prop :=\n  \u2203 s, State s \u2227 In x s \u2227 In y s\n\ntheorem Q1_false : \u00ac same_state Butte StPierre := by\n  intro h\n  rcases h with \u27e8s, hs, hButte, hSt\u27e9\n  have huniq := city_unique_state_except_4 Butte s Montana\n                 Butte_city hs Montana_state hButte Butte_in_Montana\n                 Butte_ne_Bristol Butte_ne_Texarkana Butte_ne_Texhoma Butte_ne_UnionCity\n  have : In StPierre Montana := by simpa [huniq] using hSt\n  exact StPierre_not_in_Montana this\n\n-- Q2 is not derivable from the axioms (neither provable nor refutable here).\n\ntheorem Q3_true : In Missoula Montana := Missoula_in_Montana\n\nend World\n\nANSWERS:\n1: False\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 4,
        "conclusion": "Butte and St Pierre are in the same state.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 5,
        "conclusion": "St Pierre and Bismarck are in the same state.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 6,
        "conclusion": "Montana is home to the city of Missoula.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 192,
    "premises": "International students in the US have either an F1 visa or a J1 visa.\nAn international student in the US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nMike is an international student.\nMike needs to apply for CPT if he wants to work in the US.",
    "model_response": "Lean formalization and attempt\n\nWe model the domain:\n\n- Persons and a distinguished individual Mike.\n- Predicates:\n  - InternationalUS : Person \u2192 Prop\n  - International : Person \u2192 Prop\n  - F1, J1 : Person \u2192 Prop\n  - WantsWorkUS : Person \u2192 Prop\n  - NeedsCPT, NeedsOPT : Person \u2192 Prop\n\nAxioms from the text:\n\n- A1 (International students in the US have either F1 or J1):\n  \u2200 x, InternationalUS x \u2192 (F1 x \u2228 J1 x)\n\n- A2 (If an international student in the US has F1 and wants to work in the US, then they need CPT or OPT):\n  \u2200 x, InternationalUS x \u2227 F1 x \u2227 WantsWorkUS x \u2192 (NeedsCPT x \u2228 NeedsOPT x)\n\n- A3 (Mike is an international student):\n  International Mike\n\n- A4 (Mike needs CPT if he wants to work in the US):\n  WantsWorkUS Mike \u2192 NeedsCPT Mike\n\nGoals:\n\n- Q1: F1 Mike\n- Q2: J1 Mike\n\nLean sketch:\n\nconstant Person : Type\nconstant Mike : Person\n\nconstant InternationalUS : Person \u2192 Prop\nconstant International : Person \u2192 Prop\nconstant F1 : Person \u2192 Prop\nconstant J1 : Person \u2192 Prop\nconstant WantsWorkUS : Person \u2192 Prop\nconstant NeedsCPT : Person \u2192 Prop\nconstant NeedsOPT : Person \u2192 Prop\n\naxiom A1 : \u2200 x, InternationalUS x \u2192 (F1 x \u2228 J1 x)\naxiom A2 : \u2200 x, InternationalUS x \u2227 F1 x \u2227 WantsWorkUS x \u2192 (NeedsCPT x \u2228 NeedsOPT x)\naxiom A3 : International Mike\naxiom A4 : WantsWorkUS Mike \u2192 NeedsCPT Mike\n\n-- Attempt Q1: F1 Mike\n-- From A1 we would need InternationalUS Mike to get F1 Mike \u2228 J1 Mike, but we do not have InternationalUS Mike.\n-- From A2 we would need InternationalUS Mike \u2227 F1 Mike \u2227 WantsWorkUS Mike to conclude something about CPT/OPT, not F1 itself.\n-- A4 is a conditional about CPT, independent of F1/J1 status by the given axioms.\n-- Therefore Q1 is not provable from A1\u2013A4, nor is \u00acQ1 provable.\n\n-- Attempt Q2: J1 Mike\n-- Symmetric reasoning to Q1; J1 Mike is also not provable, and neither is its negation.\n\nConclusion of the attempt:\n\n- We cannot prove F1 Mike from the given axioms, and we also cannot prove \u00acF1 Mike.\n- We cannot prove J1 Mike from the given axioms, and we also cannot prove \u00acJ1 Mike.\n\nTherefore, both statements are logically undetermined from the provided information.\n\nANSWERS:\n1: Unknown\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 548,
        "conclusion": "Mike has an F1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 549,
        "conclusion": "Mike has a J1 visa.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 442,
    "premises": "All Brown Swiss cattle are cows.\nSome pets are Brown Swiss Cattle.\nAll cows are domesticated animals.\nAlligators are not domesticated animals.\nTed is an alligator.",
    "model_response": "Lean formalization and proof attempts\n\nTranslation of predicates and entities:\n- Entity: the domain of discourse (animals/things mentioned)\n- Pet : Entity \u2192 Prop\n- BrownSwiss : Entity \u2192 Prop\n- Cow : Entity \u2192 Prop\n- Domesticated : Entity \u2192 Prop\n- Alligator : Entity \u2192 Prop\n- Ted : Entity\n\nAxioms (from the text):\n- ax1: \u2200 x, BrownSwiss x \u2192 Cow x\n- ax2: \u2203 x, Pet x \u2227 BrownSwiss x\n- ax3: \u2200 x, Cow x \u2192 Domesticated x\n- ax4: \u2200 x, Alligator x \u2192 \u00acDomesticated x\n- ax5: Alligator Ted\n\nLean code:\nuniverse u\n\nconstant Entity : Type u\n\nconstant Pet : Entity \u2192 Prop\nconstant BrownSwiss : Entity \u2192 Prop\nconstant Cow : Entity \u2192 Prop\nconstant Domesticated : Entity \u2192 Prop\nconstant Alligator : Entity \u2192 Prop\nconstant Ted : Entity\n\naxiom ax1 : \u2200 x, BrownSwiss x \u2192 Cow x\naxiom ax2 : \u2203 x, Pet x \u2227 BrownSwiss x\naxiom ax3 : \u2200 x, Cow x \u2192 Domesticated x\naxiom ax4 : \u2200 x, Alligator x \u2192 \u00ac Domesticated x\naxiom ax5 : Alligator Ted\n\nlemma not_dom_Ted : \u00ac Domesticated Ted := by\n  have h := ax4 Ted\n  exact h ax5\n\nlemma not_cow_Ted : \u00ac Cow Ted := by\n  intro hCow\n  have hDom : Domesticated Ted := ax3 Ted hCow\n  exact not_dom_Ted hDom\n\nlemma not_BS_Ted : \u00ac BrownSwiss Ted := by\n  intro hBS\n  have hCow : Cow Ted := ax1 Ted hBS\n  exact not_cow_Ted hCow\n\n-- Q1: We cannot derive Pet Ted nor its negation from the given axioms.\n\n-- Q2: \"Ted is a pet and Brown Swiss cattle\" is false (we prove its negation).\ntheorem Q2_neg : \u00ac (Pet Ted \u2227 BrownSwiss Ted) := by\n  intro h\n  have hBS : BrownSwiss Ted := h.right\n  exact not_BS_Ted hBS\n\n-- Q3: If Ted is a Brown Swiss cattle, then Ted is not a pet.\ntheorem Q3 : BrownSwiss Ted \u2192 \u00ac Pet Ted := by\n  intro hBS\n  have hCow : Cow Ted := ax1 Ted hBS\n  have hDom : Domesticated Ted := ax3 Ted hCow\n  have hF : False := not_dom_Ted hDom\n  intro _; exact hF\n\nCommentary on the three questions:\n- Q1 (Ted is a pet): Not derivable; no axioms link being an alligator with being a pet (or not a pet). Unknown.\n- Q2 (Ted is a pet and Brown Swiss cattle): We proved \u00acBrownSwiss Ted, hence the conjunction is impossible. False (we can prove the negation).\n- Q3 (If Ted is a Brown Swiss cattle, then Ted is not a pet): Provable, since BrownSwiss Ted would force Domesticated Ted, contradicting that alligators are not domesticated; from that contradiction we can derive \u00acPet Ted. True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1271,
        "conclusion": "Ted is a pet.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1272,
        "conclusion": "Ted is a pet and Brown Swiss cattle",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1273,
        "conclusion": "If Ted is a Brown Swiss cattle, then Ted is not a pet.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 234,
    "premises": "Yale University is a private Ivy League research university.\nYale University moved to New Haven in 1716.\nYale university's endowment was valued at $42.3 billion.\nA list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.",
    "model_response": "Lean translation and attempt at proofs:\n\n-- Entities\nuniverse u\nconstant Entity : Type\nconstant Yale : Entity\nconstant NewHaven : Entity\nconstant BenjaminFranklinCollege : Entity\nconstant BerkeleyCollege : Entity\nconstant BranfordCollege : Entity\nconstant DavenportCollege : Entity\nconstant EzraStilesCollege : Entity\nconstant GraceHopperCollege : Entity\nconstant JonathanEdwardsCollege : Entity\nconstant MorseCollege : Entity\nconstant PauliMurrayCollege : Entity\nconstant PiersonCollege : Entity\nconstant SaybrookCollege : Entity\nconstant SillimanCollege : Entity\nconstant TimothyDwightCollege : Entity\nconstant TrumbullCollege : Entity\n\n-- Predicates\nconstant PrivateIvyLeagueResearchUniversity : Entity \u2192 Prop\nconstant MovedTo : Entity \u2192 Entity \u2192 Prop\nconstant ResidentialCollegeAtYale : Entity \u2192 Prop\nconstant EndowmentValuedAt423b : Entity \u2192 Prop\nconstant LargestUniversityEndowment : Entity \u2192 Prop\n\n-- Facts from the textual context\naxiom Yale_is_PrivateIvyLeagueResearchUniversity : PrivateIvyLeagueResearchUniversity Yale\naxiom Yale_moved_to_NewHaven : MovedTo Yale NewHaven\naxiom Yale_endowment_423b : EndowmentValuedAt423b Yale\n\naxiom BenjaminFranklin_is_RC : ResidentialCollegeAtYale BenjaminFranklinCollege\naxiom Berkeley_is_RC : ResidentialCollegeAtYale BerkeleyCollege\naxiom Branford_is_RC : ResidentialCollegeAtYale BranfordCollege\naxiom Davenport_is_RC : ResidentialCollegeAtYale DavenportCollege\naxiom EzraStiles_is_RC : ResidentialCollegeAtYale EzraStilesCollege\naxiom GraceHopper_is_RC : ResidentialCollegeAtYale GraceHopperCollege\naxiom JonathanEdwards_is_RC : ResidentialCollegeAtYale JonathanEdwardsCollege\naxiom Morse_is_RC : ResidentialCollegeAtYale MorseCollege\naxiom PauliMurray_is_RC : ResidentialCollegeAtYale PauliMurrayCollege\naxiom Pierson_is_RC : ResidentialCollegeAtYale PiersonCollege\naxiom Saybrook_is_RC : ResidentialCollegeAtYale SaybrookCollege\naxiom Silliman_is_RC : ResidentialCollegeAtYale SillimanCollege\naxiom TimothyDwight_is_RC : ResidentialCollegeAtYale TimothyDwightCollege\naxiom Trumbull_is_RC : ResidentialCollegeAtYale TrumbullCollege\n\n-- Q1: \u201cA private Ivy League research university moved to New Haven.\u201d\n-- Formalization: \u2203 x, PrivateIvyLeagueResearchUniversity x \u2227 MovedTo x NewHaven\ntheorem Q1 : \u2203 x, PrivateIvyLeagueResearchUniversity x \u2227 MovedTo x NewHaven :=\n  \u27e8Yale, And.intro Yale_is_PrivateIvyLeagueResearchUniversity Yale_moved_to_NewHaven\u27e9\n\n-- Q2: \u201cYale University has the largest university endowment of any educational institution.\u201d\n-- Formalization: LargestUniversityEndowment Yale\n-- From the given facts, we only know EndowmentValuedAt423b Yale.\n-- There is no information connecting EndowmentValuedAt423b to LargestUniversityEndowment,\n-- nor any comparative data about other institutions. Hence we cannot prove this,\n-- nor its negation, from the provided axioms alone.\ndef Q2_stmt : Prop := LargestUniversityEndowment Yale\n-- Not provable or disprovable from the given assumptions.\n\n-- Q3: \u201cPierson College is a residential college at Yale.\u201d\n-- Formalization: ResidentialCollegeAtYale PiersonCollege\ntheorem Q3 : ResidentialCollegeAtYale PiersonCollege := Pierson_is_RC\n\nANSWERS:\n1: True\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 663,
        "conclusion": "A private Ivy League research university moved to New Haven.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 664,
        "conclusion": "Yale University has the largest university endowment of any educational institution.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 665,
        "conclusion": "Pierson College is a residential college at Yale.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 120,
    "premises": "Badults is a British Sitcom series starring members of Pappy's.\nBadults was piloted in July 2013 on BBC Three.\nThe Working title \"The Secret Dude Society\" was used for Badults.\nAndrew Collins was the script editor for Badults.",
    "model_response": "Lean translation and proof attempt\n\nEntities and predicates\n- Types:\n  - Show: television series\n  - Person: people\n  - Title: working titles\n- Constants:\n  - Badults : Show\n  - AndrewCollins : Person\n  - SDS : Title  (the working title \"The Secret Dude Society\")\n- Predicates:\n  - StarsPappys : Show \u2192 Prop            (the show stars members of Pappy's)\n  - PilotedOnBBCTwo : Show \u2192 Prop\n  - PilotedOnBBCThree : Show \u2192 Prop\n  - WorkingTitle : Show \u2192 Title \u2192 Prop\n  - ScriptEditor : Person \u2192 Show \u2192 Prop\n\nFacts from the context\n- StarsPappys Badults\n- PilotedOnBBCThree Badults\n- WorkingTitle Badults SDS\n- ScriptEditor AndrewCollins Badults\n\nLean code\nconstant Show : Type\nconstant Person : Type\nconstant Title : Type\n\nconstant Badults : Show\nconstant AndrewCollins : Person\nconstant SDS : Title  -- \"The Secret Dude Society\"\n\nconstant StarsPappys : Show \u2192 Prop\nconstant PilotedOnBBCTwo : Show \u2192 Prop\nconstant PilotedOnBBCThree : Show \u2192 Prop\nconstant WorkingTitle : Show \u2192 Title \u2192 Prop\nconstant ScriptEditor : Person \u2192 Show \u2192 Prop\n\naxiom h1 : StarsPappys Badults\naxiom h2 : PilotedOnBBCThree Badults\naxiom h3 : WorkingTitle Badults SDS\naxiom h4 : ScriptEditor AndrewCollins Badults\n\n-- Claim 1: Andrew Collins was the script editor for a series with working title \"The Secret Dude Society\".\ndef Claim1 : Prop := \u2203 s : Show, ScriptEditor AndrewCollins s \u2227 WorkingTitle s SDS\n\ntheorem Claim1_true : Claim1 := by\n  exact \u27e8Badults, And.intro h4 h3\u27e9\n\n-- Claim 2: No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.\ndef Claim2 : Prop := \u00ac \u2203 s : Show, StarsPappys s \u2227 (PilotedOnBBCTwo s \u2228 PilotedOnBBCThree s)\n\n-- We produce a counterexample (Badults), so Claim 2 is false.\ntheorem exists_pappys_on_bbc2or3 :\n  \u2203 s : Show, StarsPappys s \u2227 (PilotedOnBBCTwo s \u2228 PilotedOnBBCThree s) := by\n  exact \u27e8Badults, And.intro h1 (Or.inr h2)\u27e9\n\ntheorem not_Claim2 : \u00ac Claim2 := by\n  intro h\n  exact h exists_pappys_on_bbc2or3\n\nConclusion\n- Claim 1 is provable (True).\n- Claim 2 is refutable; its negation is provable (False).\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 360,
        "conclusion": "Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\".",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 361,
        "conclusion": "No members of Pappy's have starred in a show piloting on BBC Two or BBC Three.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 322,
    "premises": "All growth stocks are bought to earn profits from rapid price appreciation.\nIf the stock price is bought to earn profits from rapid price appreciation, then it is not suitable for a retirement fund.\nSome stocks are growth stocks.\nAll mature stocks are suitable for a retirement fund.\nKO is a mature stock.",
    "model_response": "Lean formalization and proofs:\n\nWe model entities and predicates:\n- Stock, Growth, Mature, Suitable, BoughtRapid, Volatile : Entity \u2192 Prop\n- KO : Entity\n\nAxioms from the text:\n- A1: \u2200 x, Growth x \u2192 BoughtRapid x\n- A2: \u2200 x, BoughtRapid x \u2192 \u00ac Suitable x\n- A3: \u2203 x, Stock x \u2227 Growth x\n- A4: \u2200 x, (Stock x \u2227 Mature x) \u2192 Suitable x\n- A5_stock: Stock KO\n- A5_mature: Mature KO\n\nLean code:\n\nnamespace Reasoning\n\nuniverse u\nconstant Entity : Type u\nconstant Stock : Entity \u2192 Prop\nconstant Growth : Entity \u2192 Prop\nconstant Mature : Entity \u2192 Prop\nconstant Suitable : Entity \u2192 Prop\nconstant BoughtRapid : Entity \u2192 Prop\nconstant Volatile : Entity \u2192 Prop\nconstant KO : Entity\n\naxioms\n  (A1 : \u2200 x, Growth x \u2192 BoughtRapid x)\n  (A2 : \u2200 x, BoughtRapid x \u2192 \u00ac Suitable x)\n  (A3 : \u2203 x, Stock x \u2227 Growth x)\n  (A4 : \u2200 x, (Stock x \u2227 Mature x) \u2192 Suitable x)\n  (A5_stock : Stock KO)\n  (A5_mature : Mature KO)\n\nlemma KO_suitable : Suitable KO :=\n  A4 KO \u27e8A5_stock, A5_mature\u27e9\n\nlemma KO_not_boughtRapid : \u00ac BoughtRapid KO :=\nby\n  intro hBR\n  have hns : \u00ac Suitable KO := A2 KO hBR\n  exact hns KO_suitable\n\nlemma KO_not_growth : \u00ac Growth KO :=\nby\n  intro hG\n  exact KO_not_boughtRapid (A1 KO hG)\n\n-- Q1: KO is a stock.\ntheorem Q1 : Stock KO := A5_stock\n\n-- Q2: KO is a stock and a growth stock (this is false).\ntheorem Q2_false : \u00ac (Stock KO \u2227 Growth KO) :=\nby\n  intro h\n  exact KO_not_growth h.right\n\n-- Q3: If KO is a growth stock or bought for rapid appreciation,\n-- then KO is neither a stock nor volatile (true vacuously).\ntheorem Q3 : (Growth KO \u2228 BoughtRapid KO) \u2192 (\u00ac Stock KO \u2227 \u00ac Volatile KO) :=\nby\n  intro h\n  have : False :=\n    h.elim\n      (fun hg => KO_not_growth hg)\n      (fun hbr => KO_not_boughtRapid hbr)\n  exact this.elim\n\nend Reasoning\n\nConclusions:\n- Q1 is provable (Stock KO).\n- Q2 is false since we can prove KO is not a growth stock.\n- Q3 is true vacuously because the antecedent (Growth KO \u2228 BoughtRapid KO) is false.\n\nANSWERS:\n1: True\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 819,
        "conclusion": "KO is a stock.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 820,
        "conclusion": "KO is a stock and a growth stock.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 821,
        "conclusion": "If KO is a growth stock or bought to earn profits from rapid price appreciation, then KO is neither a stock nor is its price volatile.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 83,
    "premises": "All vehicle registration plates in Istanbul begin with the number 34.\nPlates that do not begin with the number 34 are not from Istanbul. \nJoe's vehicle registration plate is from Istanbul. \nTom's license plate begins with the number 35. \nIf a license plate begins with the number 35, then it does not begin with the number 34.",
    "model_response": "Lean formalization and proof attempt:\n\nuniverse u\n\nconstant Plate : Type u\nconstant Joe : Plate\nconstant Tom : Plate\n\nconstant begins34 : Plate \u2192 Prop\nconstant begins35 : Plate \u2192 Prop\nconstant fromIstanbul : Plate \u2192 Prop\n\n-- Premises from the text\naxiom ax1 : \u2200 p : Plate, fromIstanbul p \u2192 begins34 p\naxiom ax2 : \u2200 p : Plate, \u00ac begins34 p \u2192 \u00ac fromIstanbul p\naxiom axJoe : fromIstanbul Joe\naxiom axTom35 : begins35 Tom\naxiom ax35not34 : \u2200 p : Plate, begins35 p \u2192 \u00ac begins34 p\n\n-- Q1: Joe's license plate begins with the number 34.\ntheorem Q1 : begins34 Joe :=\n  ax1 Joe axJoe\n\n-- Q2 (target statement would be: fromIstanbul Tom), but we can prove its negation.\ntheorem not_Q2 : \u00ac fromIstanbul Tom :=\nby\n  have hnot34 : \u00ac begins34 Tom := (ax35not34 Tom) axTom35\n  exact (ax2 Tom) hnot34\n\nWe proved Q1 directly. For Q2, we proved its negation, so the statement is false.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 253,
        "conclusion": "Joe's license plate begins with the number 34.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 254,
        "conclusion": "Tom's license plate is from Istanbul.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 368,
    "premises": "If people at Mary's school work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nIf people at Mary's school order takeout frequently in college, then they work in student jobs on campus.\nPeople at Mary's school order takeout frequently in college or enjoy the dining hall meals and recipes.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they are not picky eaters.\nIf people at Mary's school enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nHannah is at Mary's school.\nHannah works in student jobs on campus and if she needs to earn money to help pay for her college tuition, then she is neither picky nor needs to earn money to help pay for her college tuition.",
    "model_response": "Lean formalization and proofs sketch:\n\n- Types and predicates:\n  Person : Type\n  At : Person \u2192 Prop                      -- is at Mary's school\n  Works : Person \u2192 Prop                   -- works in student jobs on campus\n  Needs : Person \u2192 Prop                   -- needs to earn money to help pay tuition\n  Orders : Person \u2192 Prop                  -- orders takeout frequently in college\n  Enjoys : Person \u2192 Prop                  -- enjoys dining hall meals and recipes\n  Picky : Person \u2192 Prop                   -- is a picky eater\n  Dines : Person \u2192 Prop                   -- spends a lot of time eating/catching up in dining halls\n  H : Person                              -- Hannah\n\n- Axioms from the text:\n  A1: \u2200 x, At x \u2227 Works x \u2192 Needs x\n  A2: \u2200 x, At x \u2227 Orders x \u2192 Works x\n  A3: \u2200 x, At x \u2192 (Orders x \u2228 Enjoys x)\n  A4: \u2200 x, At x \u2227 Enjoys x \u2192 \u00ac Picky x\n  A5: \u2200 x, At x \u2227 Enjoys x \u2192 Dines x\n  A6: At H\n  A7a: Works H\n  A7b: Needs H \u2192 (\u00ac Picky H \u2227 \u00ac Needs H)\n\n- Derived facts:\n  needs_H: Needs H\n    from A1 with A6 and A7a.\n  not_needs_H: \u00ac Needs H\n    from A7b: Needs H \u2192 (\u00acPicky H \u2227 \u00acNeeds H), hence Needs H \u2192 \u00acNeeds H, and thus \u00acNeeds H (since (p \u2192 \u00acp) \u27f9 \u00acp).\n  not_picky_H: \u00ac Picky H\n    from A7b applied to needs_H.\n  false_from_contra: False\n    from not_needs_H needs_H.\n\n- Question 1: Needs H is directly proved (needs_H). Hence provable.\n\n- Question 2: We need At H \u2227 \u00acPicky H \u2227 Dines H.\n  At H is A6. \u00acPicky H is not_picky_H. Dines H follows by ex falso (False.elim false_from_contra).\n  Hence provable in Lean.\n\n- Question 3: We need At H \u2227 (\u00acPicky H \u2228 (Picky H \u2192 Dines H)).\n  At H is A6. The left disjunct \u00acPicky H holds (not_picky_H), so the disjunction holds. Hence provable.\n\nANSWERS:\n1: True\n2: True\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 979,
        "conclusion": "Hannah needs to earn money to help pay for her college tuition.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 980,
        "conclusion": "Hannah is at Mary's school and she is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 981,
        "conclusion": "Hannah is at Mary's school and she either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 319,
    "premises": "No baked sweets are spicy.\nAll cupcakes are baked sweets.\nAll mala hotpots are spicy.\nAll products from Baked by Melissa are cupcakes.\nDried Thai chilies are spicy or mala hotpots or not baked sweets.",
    "model_response": "Lean formalization and proofs:\n\nWe work over a universe U of entities with predicates:\n- BakedSweet, Spicy, Cupcake, MalaHotpot, BBM : U \u2192 Prop\n- DTC : U is the entity \u201cDried Thai chilies\u201d\n\nAssumptions from the context:\n1. h1: \u2200 x, BakedSweet x \u2192 \u00ac Spicy x\n2. h2: \u2200 x, Cupcake x \u2192 BakedSweet x\n3. h3: \u2200 x, MalaHotpot x \u2192 Spicy x\n4. h4: \u2200 x, BBM x \u2192 Cupcake x\n5. h5: Spicy DTC \u2228 MalaHotpot DTC \u2228 \u00ac BakedSweet DTC\n\nLean code:\n\nsection\n\nvariable {U : Type}\nvariables (BakedSweet Spicy Cupcake MalaHotpot BBM : U \u2192 Prop) (DTC : U)\nvariable (h1 : \u2200 x, BakedSweet x \u2192 \u00ac Spicy x)\nvariable (h2 : \u2200 x, Cupcake x \u2192 BakedSweet x)\nvariable (h3 : \u2200 x, MalaHotpot x \u2192 Spicy x)\nvariable (h4 : \u2200 x, BBM x \u2192 Cupcake x)\nvariable (h5 : Spicy DTC \u2228 MalaHotpot DTC \u2228 \u00ac BakedSweet DTC)\n\n-- Key derived facts\ntheorem not_baked_DTC : \u00ac BakedSweet DTC := by\n  intro hb\n  have hns : \u00ac Spicy DTC := h1 DTC hb\n  apply Or.elim h5\n  \u00b7 intro hs\n    exact hns hs\n  \u00b7 intro rest\n    apply Or.elim rest\n    \u00b7 intro hm\n      exact hns (h3 DTC hm)\n    \u00b7 intro hnotb\n      exact hnotb hb\n\ntheorem not_cupcake_DTC : \u00ac Cupcake DTC := by\n  intro hc\n  have hb : BakedSweet DTC := h2 DTC hc\n  exact (not_baked_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5) hb\n\ntheorem not_BBM_DTC : \u00ac BBM DTC := by\n  intro hbbm\n  have hc : Cupcake DTC := h4 DTC hbbm\n  exact (not_cupcake_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5) hc\n\n-- Q1: DTC are products of Baked by Melissa. (False: we prove \u00ac BBM DTC.)\ntheorem Q1_false : \u00ac BBM DTC :=\n  not_BBM_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5\n\n-- Q2: DTC are not products of Baked by Melissa. (True.)\ntheorem Q2_true : \u00ac BBM DTC :=\n  not_BBM_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5\n\n-- Q3: DTC are a mala hotpot. (Unknown: neither provable nor refutable from given assumptions.)\n\n-- Q4: DTC are neither products of BBM nor baked sweets. (True.)\ntheorem Q4_true : \u00ac BBM DTC \u2227 \u00ac BakedSweet DTC :=\n  And.intro\n    (not_BBM_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5)\n    (not_baked_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5)\n\n-- Q5: DTC are cupcakes and products of BBM. (False: we prove its negation.)\ntheorem Q5_false : \u00ac (Cupcake DTC \u2227 BBM DTC) := by\n  intro h\n  have hbbm : BBM DTC := h.right\n  exact (not_BBM_DTC BakedSweet Spicy Cupcake MalaHotpot BBM DTC h1 h2 h3 h4 h5) hbbm\n\nend\n\nConclusions from the Lean development:\n- Q1: proved the negation (so False).\n- Q2: proved the statement (so True).\n- Q3: no derivation of either side (so Unknown).\n- Q4: proved the statement (so True).\n- Q5: proved the negation (so False).\n\nANSWERS:\n1: False\n2: True\n3: Unknown\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 805,
        "conclusion": "Dried Thai chilies are products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 806,
        "conclusion": "Dried Thai chilies are not products of Baked by Melissa.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 807,
        "conclusion": "Dried Thai chilies are a mala hotpot.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 808,
        "conclusion": "Dried Thai chilies are neither products of Baked by Melissa nor baked sweets.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 809,
        "conclusion": "Dried Thai chilies are cupcakes and products of Baked by Melissa.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 306,
    "premises": "If a restaurant is listed in Yelp\u2019s recommendations, then the restaurant has not received many negative reviews.\nAll restaurants with a rating greater than four are listed in Yelp\u2019s recommendations.\nSome restaurants that do not provide take-out service receive many negative reviews.\nAll restaurants that are popular among local residents have ratings greater than four.\nThe Hamden Plaza Subway store has a rating greater than four, or it is popular among local residents.",
    "model_response": "Here is a Lean formalization of the problem and proofs for what can be derived.\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Restaurant : Type u\nconstant L N T R P : Restaurant \u2192 Prop\nconstant s : Restaurant\n\n-- Premises\naxiom ax1 : \u2200 x, L x \u2192 \u00ac N x\naxiom ax2 : \u2200 x, R x \u2192 L x\naxiom ax3 : \u2203 x, \u00ac T x \u2227 N x\naxiom ax4 : \u2200 x, P x \u2192 R x\naxiom ax5 : R s \u2228 P s\n\n-- Deductions about s\nlemma R_s : R s := by\n  cases ax5 with\n  | inl rs => exact rs\n  | inr ps => exact ax4 s ps\n\nlemma notN_s : \u00ac N s := by\n  have Ls : L s := ax2 s R_s\n  exact ax1 s Ls\n\n-- Question 1\ntheorem Q1 : (T s \u2227 N s) \u2192 (R s \u2227 \u00ac T s) := by\n  intro h\n  have ns : N s := h.right\n  have contra : False := notN_s ns\n  have rs : R s := R_s\n  have nts : \u00ac T s := by\n    intro ts\n    exact False.elim contra\n  exact And.intro rs nts\n\n-- Question 2\ntheorem Q2 : T s \u2228 \u00ac N s := Or.inr notN_s\n\n-- Question 3 cannot be derived from the premises.\n\nend Reasoning\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 754,
        "conclusion": "If the Hamden Plaza Subway store provides take-out service and receives many negative reviews, then its rating is greater than 4 and it does not provide take-out service.",
        "ground_truth": "False",
        "prediction": "True",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 755,
        "conclusion": "The Hamden Plaza Subway store provides take-out service or does not receive many negative reviews.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 756,
        "conclusion": "The Hamden Plaza store does not provide take-out service.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 245,
    "premises": "In superhero movies, the good guys always win.\nThe Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nGood guys fight bad guys and vice versa.\nSir Digby fights his nemesis.\nIf a superhero movie is named after a character, that character is a good guy.\nThe Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nIf somebody wins a fight, the person they are fighting does not win.\nIf a superhero movie is named after a character, that character is in the movie.",
    "model_response": "Lean formalization and proof sketch:\n\n- Types:\n  - Person, Movie\n\n- Predicates/relations:\n  - SuperheroMovie : Movie \u2192 Prop\n  - NamedAfter : Movie \u2192 Person \u2192 Prop\n  - InMovie : Person \u2192 Movie \u2192 Prop\n  - GoodGuy, BadGuy : Person \u2192 Prop\n  - FightsIn : Person \u2192 Person \u2192 Movie \u2192 Prop\n  - WinsIn : Person \u2192 Person \u2192 Movie \u2192 Prop\n\n- Axioms from the text:\n  1) good_guys_always_win:\n     \u2200 m, SuperheroMovie m \u2192\n     \u2200 p q, InMovie p m \u2192 GoodGuy p \u2192 FightsIn p q m \u2192 WinsIn p q m\n  2) fights_are_asymmetric:\n     \u2200 p q m, WinsIn p q m \u2192 \u00ac WinsIn q p m\n  3) good_guys_fight_bad_guys:\n     \u2200 p q m, InMovie p m \u2192 InMovie q m \u2192 GoodGuy p \u2192 BadGuy q \u2192 FightsIn p q m\n  4) bad_guys_fight_good_guys:\n     \u2200 p q m, InMovie p m \u2192 InMovie q m \u2192 BadGuy p \u2192 GoodGuy q \u2192 FightsIn p q m\n  5) named_after_good:\n     \u2200 m p, SuperheroMovie m \u2192 NamedAfter m p \u2192 GoodGuy p\n  6) named_after_in_movie:\n     \u2200 m p, SuperheroMovie m \u2192 NamedAfter m p \u2192 InMovie p m\n\n- Constants/facts from the text:\n  - Digby : Person, Nemesis : Person, TSASDCC : Movie\n  - is_superhero_movie : SuperheroMovie TSASDCC\n  - named_after_digby : NamedAfter TSASDCC Digby\n  - digby_fights_nemesis : FightsIn Digby Nemesis TSASDCC\n\nLean proof:\n\nuniverse u\n\nconstant Person : Type\nconstant Movie : Type\n\nconstants\n  SuperheroMovie : Movie \u2192 Prop\n  NamedAfter : Movie \u2192 Person \u2192 Prop\n  InMovie : Person \u2192 Movie \u2192 Prop\n  GoodGuy : Person \u2192 Prop\n  BadGuy : Person \u2192 Prop\n  FightsIn : Person \u2192 Person \u2192 Movie \u2192 Prop\n  WinsIn : Person \u2192 Person \u2192 Movie \u2192 Prop\n\naxioms\n  good_guys_always_win :\n    \u2200 m, SuperheroMovie m \u2192\n    \u2200 p q, InMovie p m \u2192 GoodGuy p \u2192 FightsIn p q m \u2192 WinsIn p q m\n  fights_are_asymmetric :\n    \u2200 p q m, WinsIn p q m \u2192 \u00ac WinsIn q p m\n  good_guys_fight_bad_guys :\n    \u2200 p q m, InMovie p m \u2192 InMovie q m \u2192 GoodGuy p \u2192 BadGuy q \u2192 FightsIn p q m\n  bad_guys_fight_good_guys :\n    \u2200 p q m, InMovie p m \u2192 InMovie q m \u2192 BadGuy p \u2192 GoodGuy q \u2192 FightsIn p q m\n  named_after_good :\n    \u2200 m p, SuperheroMovie m \u2192 NamedAfter m p \u2192 GoodGuy p\n  named_after_in_movie :\n    \u2200 m p, SuperheroMovie m \u2192 NamedAfter m p \u2192 InMovie p m\n\nconstants\n  Digby : Person\n  Nemesis : Person\n  TSASDCC : Movie\n\naxioms\n  is_superhero_movie : SuperheroMovie TSASDCC\n  named_after_digby : NamedAfter TSASDCC Digby\n  digby_fights_nemesis : FightsIn Digby Nemesis TSASDCC\n\ntheorem nemesis_does_not_win :\n  \u00ac WinsIn Nemesis Digby TSASDCC :=\nby\n  have hGood : GoodGuy Digby :=\n    named_after_good TSASDCC Digby is_superhero_movie named_after_digby\n  have hIn : InMovie Digby TSASDCC :=\n    named_after_in_movie TSASDCC Digby is_superhero_movie named_after_digby\n  have hWin : WinsIn Digby Nemesis TSASDCC :=\n    good_guys_always_win TSASDCC is_superhero_movie Digby Nemesis hIn hGood digby_fights_nemesis\n  exact (fights_are_asymmetric Digby Nemesis TSASDCC hWin)\n\nConclusion: The statement \u201cSir Digby\u2019s nemesis does not win\u201d follows. True\n\nANSWERS:\n1: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 688,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 58,
    "premises": "Books contain tons of knowledge.\nWhen a person reads a book, that person gains knowledge. \nIf a person gains knowledge, they become smarter.\nHarry read the book \u201cWalden\u201d by Henry Thoreau.",
    "model_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Person : Type u\nconstant Book : Type u\n\nconstant Reads : Person \u2192 Book \u2192 Prop\nconstant GainsKnowledge : Person \u2192 Prop\nconstant Smarter : Person \u2192 Prop\nconstant ContainsKnowledge : Book \u2192 Prop\n\n-- Knowledge base\naxiom books_contain_knowledge : \u2200 b : Book, ContainsKnowledge b\naxiom reading_gives_knowledge : \u2200 p : Person, \u2200 b : Book, Reads p b \u2192 GainsKnowledge p\naxiom knowledge_makes_smarter : \u2200 p : Person, GainsKnowledge p \u2192 Smarter p\n\n-- Facts about Harry and Walden\nconstant harry : Person\nconstant walden : Book\naxiom harry_read_walden : Reads harry walden\n\n-- Q1: Walden contains knowledge.\ntheorem Q1 : ContainsKnowledge walden :=\n  books_contain_knowledge walden\n\n-- Q2: Harry is smarter than before.\ntheorem Q2 : Smarter harry :=\n  knowledge_makes_smarter harry (reading_gives_knowledge harry walden harry_read_walden)\n\n-- Q3: A smarter person has gained knowledge. Not derivable from the given axioms.\n-- Target would be: \u2200 p : Person, Smarter p \u2192 GainsKnowledge p\n-- Neither this statement nor its negation follows from the current axioms.\n\nANSWERS:\n1: True\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 171,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 172,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 173,
        "conclusion": "A smarter person has gained knowledge.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 191,
    "premises": "A natural language processing task can be categorized as either a language generation task or a language understanding task.\nIf the output of a natural language processing task is a text sequence, then it is a language generation task.\nMachine translation is a natural language processing task.\nThe output of machine translation is a text sequence.",
    "model_response": "Lean formalization and attempt:\n\nuniverse u\n\nconstant Task : Type u\nconstant NLP : Task \u2192 Prop\nconstant Gen : Task \u2192 Prop\nconstant Und : Task \u2192 Prop\nconstant OutText : Task \u2192 Prop\nconstant MT : Task\n\naxioms\n  (H1 : \u2200 t, NLP t \u2192 (Gen t \u2228 Und t))          -- A NLP task is either generation or understanding (not assumed exclusive)\n  (H2 : \u2200 t, OutText t \u2192 Gen t)                 -- If output is a text sequence, then it is generation\n  (H3 : NLP MT)                                  -- Machine translation is an NLP task\n  (H4 : OutText MT)                              -- The output of machine translation is a text sequence\n\n-- Q1: Machine translation is a language generation task.\ntheorem Q1 : Gen MT := H2 MT H4\n\n-- Q2: Machine translation is a language understanding task.\n-- From H1 and H3 we only know Gen MT \u2228 Und MT, and from H2 and H4 we know Gen MT.\n-- This does not entail Und MT, nor its negation, without an exclusivity axiom.\n-- Therefore neither Und MT nor \u00acUnd MT is derivable from the given axioms.\n\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 546,
        "conclusion": "Machine translation is a language generation task.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 547,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.5
  },
  {
    "story_id": 166,
    "premises": "Pets are allowed in some managed buildings.\nA deposit is required to rent an apartment in a managed building.\nThe security deposit can be either equal to the monthly rent at a managed building or more.\nFluffy is Tom's cat.\nCats are pets.\nThe Olive Garden is a managed building.\nThe monthly rent at the Olive Garden is $2000.\n$2000 is more than $1500.\nTom will rent an apartment in a managed building if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nIf a managed building allows pets, then people are allowed to move in with a pet. ",
    "model_response": "Lean formalization and analysis:\n\nTypes and constants:\n- Person, Animal, Building : Type\n- Tom : Person\n- Fluffy : Animal\n- OliveGarden : Building\n\nPredicates and functions:\n- Managed : Building \u2192 Prop\n- AllowsPets : Building \u2192 Prop\n- Pet : Animal \u2192 Prop\n- Cat : Animal \u2192 Prop\n- Owns : Person \u2192 Animal \u2192 Prop\n- AllowedMoveInWith : Person \u2192 Animal \u2192 Building \u2192 Prop\n- WillRentAt : Person \u2192 Building \u2192 Prop\n- rent : Building \u2192 Nat\n- deposit : Building \u2192 Nat\n\nAxioms from the text:\n1. \u2203 b, Managed b \u2227 AllowsPets b\n2. \u2200 b, Managed b \u2192 deposit b \u2265 rent b\n3. Owns Tom Fluffy \u2227 Cat Fluffy\n4. \u2200 a, Cat a \u2192 Pet a\n5. Managed OliveGarden\n6. rent OliveGarden = 2000\n7. 2000 > 1500\n8. \u2200 b, Managed b \u2192 AllowsPets b \u2192 \u2200 p a, Pet a \u2192 AllowedMoveInWith p a b\n9. \u2200 b, Managed b \u2192 AllowedMoveInWith Tom Fluffy b \u2192 deposit b \u2264 1500 \u2192 WillRentAt Tom b\n\nTargets:\n- Q1: WillRentAt Tom OliveGarden\n- Q2: AllowedMoveInWith Tom Fluffy OliveGarden\n- Q3: deposit OliveGarden \u2265 2000\n\nProof attempts:\n- Q3: From (2) with b = OliveGarden and (5), deposit OliveGarden \u2265 rent OliveGarden. Using (6), conclude deposit OliveGarden \u2265 2000. This is provable.\n- Q2: To prove AllowedMoveInWith Tom Fluffy OliveGarden from (8), we would need AllowsPets OliveGarden and Pet Fluffy. While Pet Fluffy follows from (3) and (4), we do not have AllowsPets OliveGarden; we only know there exists some managed building that allows pets (1). So neither Q2 nor its negation is derivable. Unknown.\n- Q1: From (9), if AllowedMoveInWith Tom Fluffy OliveGarden and deposit OliveGarden \u2264 1500, then WillRentAt Tom OliveGarden. We cannot show the antecedent: we do not have AllowedMoveInWith Tom Fluffy OliveGarden (as above), and in fact deposit OliveGarden \u2265 2000 from Q3, so deposit \u2264 1500 is false. However (9) is only a sufficient condition; its failure does not imply he will not rent. Thus neither Q1 nor its negation is derivable. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 476,
        "conclusion": "Tom will rent an apartment in The Olive Garden.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 477,
        "conclusion": "Tom is allowed to move into an apartment in The Olive Garden with Fluffy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 478,
        "conclusion": "The security deposit at the Olive Garden is either $2000 or more.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 0.6666666666666666
  },
  {
    "story_id": 352,
    "premises": "All business organizations are legal entities.\nAll companies are business organizations.\nAll private companies are companies.\nAll legal entities are created under law. \nAll legal entities have legal obligations.\nIf the Harvard Weekly Book Club is created under law, then it is not a private company. ",
    "model_response": "Lean formalization and proofs attempt:\n\nuniverse u\n\nconstant Entity : Type u\n\n-- Predicates\nconstant BusinessOrg : Entity \u2192 Prop\nconstant Company : Entity \u2192 Prop\nconstant PrivateCompany : Entity \u2192 Prop\nconstant LegalEntity : Entity \u2192 Prop\nconstant CreatedUnderLaw : Entity \u2192 Prop\nconstant HasLegalObligations : Entity \u2192 Prop\n\n-- The Harvard Weekly Book Club\nconstant H : Entity\n\n-- Axioms\naxiom A1 : \u2200 x, BusinessOrg x \u2192 LegalEntity x\naxiom A2 : \u2200 x, Company x \u2192 BusinessOrg x\naxiom A3 : \u2200 x, PrivateCompany x \u2192 Company x\naxiom A4 : \u2200 x, LegalEntity x \u2192 CreatedUnderLaw x\naxiom A5 : \u2200 x, LegalEntity x \u2192 HasLegalObligations x\naxiom A6 : CreatedUnderLaw H \u2192 \u00ac PrivateCompany H\n\n-- Derived chains\nlemma pc_to_company {x} (hpc : PrivateCompany x) : Company x := A3 x hpc\nlemma company_to_bo {x} (hc : Company x) : BusinessOrg x := A2 x hc\nlemma bo_to_le {x} (hbo : BusinessOrg x) : LegalEntity x := A1 x hbo\nlemma le_to_cu {x} (hle : LegalEntity x) : CreatedUnderLaw x := A4 x hle\nlemma le_to_lo {x} (hle : LegalEntity x) : HasLegalObligations x := A5 x hle\n\nlemma pc_to_le {x} (hpc : PrivateCompany x) : LegalEntity x :=\n  bo_to_le (company_to_bo (pc_to_company hpc))\n\nlemma pc_to_cu {x} (hpc : PrivateCompany x) : CreatedUnderLaw x :=\n  le_to_cu (pc_to_le hpc)\n\nlemma pc_to_lo {x} (hpc : PrivateCompany x) : HasLegalObligations x :=\n  le_to_lo (pc_to_le hpc)\n\n-- H cannot be a private company\ntheorem not_pc_H : \u00ac PrivateCompany H := by\n  intro hpc\n  have hcu : CreatedUnderLaw H := pc_to_cu hpc\n  have hnpc : \u00ac PrivateCompany H := A6 hcu\n  exact hnpc hpc\n\n-- Q2 is false: the conjunction cannot hold\ntheorem Q2_false : \u00ac (HasLegalObligations H \u2227 PrivateCompany H) := by\n  intro hconj\n  exact not_pc_H hconj.right\n\n-- Q3 is true: private company implies (LO or CU) in fact both\ntheorem Q3_true : PrivateCompany H \u2192 (HasLegalObligations H \u2228 CreatedUnderLaw H) := by\n  intro hpc\n  have hlo : HasLegalObligations H := pc_to_lo hpc\n  exact Or.inl hlo\n\nRemarks:\n- Q1 (HasLegalObligations H) is not derivable from the axioms, nor is its negation; we lack any premise making H a legal entity or otherwise forcing it to have legal obligations.\n- Q2 is refutable because PrivateCompany H is impossible (not_pc_H).\n- Q3 is provable since PrivateCompany H implies LegalEntity H, hence both HasLegalObligations H and CreatedUnderLaw H.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 933,
        "conclusion": "The Harvard Weekly Book club has legal obligations.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 934,
        "conclusion": "The Harvard Weekly Book club has legal obligations and is a private company.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 935,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 472,
    "premises": "Animals are either invertebrates or vertebrates.\nAll animals with backbones reproduce by male-and-female mating. \nAll vertebrate animals have a backbone.\nAll bees do not reproduce by male-and-female mating.\nAll queen bees are bees.\nHarry is a bee.",
    "model_response": "Lean translation and analysis:\n\nWe model a single-sorted first-order setting with the following predicates on a domain U:\n- Animal, Invertebrate, Vertebrate, Backbone, MF (reproduces by male-and-female mating), Bee, QueenBee : U \u2192 Prop\n- A constant harry : U\n\nAxioms, formalizing the textual context:\n1. A1: \u2200 x, Animal x \u2192 (Invertebrate x \u2228 Vertebrate x)\n2. A2: \u2200 x, (Animal x \u2227 Backbone x) \u2192 MF x\n3. A3: \u2200 x, Vertebrate x \u2192 Backbone x\n4. A4: \u2200 x, Bee x \u2192 \u00ac MF x\n5. A5: \u2200 x, QueenBee x \u2192 Bee x\n6. A6: Bee harry\n\nImmediate consequences:\n- From A6 and A4: \u00ac MF harry.\n- There is no given axiom linking Bee to Animal, so we cannot conclude Animal harry.\n- From A3 we have Vertebrate x \u2192 Backbone x, but there is no axiom Vertebrate x \u2192 Animal x.\n\nQuestion 1: \u201cHarry is a queen bee.\u201d\n- From A5 we only have QueenBee \u2192 Bee, not the converse, and no other information forces QueenBee harry. We also cannot derive \u00ac QueenBee harry from the axioms.\n- Hence neither QueenBee harry nor its negation is derivable from A1\u2013A6.\n\nQuestion 2: \u201cHarry is an invertebrate or a queen bee.\u201d\n- We cannot use A1 (Animal \u2192 Invertebrate \u2228 Vertebrate) without knowing Animal harry.\n- We also cannot derive QueenBee harry from Bee harry.\n- The disjunction may be true in some models (e.g., if QueenBee harry holds) and false in others (e.g., if neither Invertebrate harry nor QueenBee harry holds while Animal harry is false so A1 does not apply). Thus neither the statement nor its negation is derivable.\n\nQuestion 3: \u201cIf Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.\u201d\n- Formalize the antecedent as:\n  ((Vertebrate harry \u2227 Animal harry \u2227 Backbone harry) \u2228 (\u00ac Vertebrate harry \u2227 \u00ac(Animal harry \u2227 Backbone harry)))\n  and the consequent as (\u00ac Invertebrate harry \u2227 \u00ac QueenBee harry).\n- This implication is not entailed by the axioms. For consistency witness making it false, take a model with:\n  Bee harry = true, QueenBee harry = true, MF harry = false, Animal harry = true, Invertebrate harry = true, Vertebrate harry = false, Backbone harry = false.\n  All axioms A1\u2013A6 hold, the antecedent is true, and the consequent is false; so the implication is false in this model.\n- Its negation is also not entailed (e.g., set QueenBee and Invertebrate both false; then the consequent is true and the implication holds). Thus neither the implication nor its negation is derivable from A1\u2013A6.\n\nConclusion in Lean-proof terms:\n- Q1: cannot be proved; its negation also cannot be proved \u2192 Unknown.\n- Q2: cannot be proved; its negation also cannot be proved \u2192 Unknown.\n- Q3: cannot be proved; its negation also cannot be proved \u2192 Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1366,
        "conclusion": "Harry is a queen bee.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1367,
        "conclusion": "Harry is an invertebrate or a queen bee.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1368,
        "conclusion": "If Harry is either both a vertebrate and an animal with a backbone, or neither a vertebrate nor an animal with a backbone, then Harry is neither an invertebrate nor a queen bee.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 379,
    "premises": "People who are born in a multiple birth with siblings spend a lot of time hanging out with and playing with their siblings.\nIf people have siblings who were born together, then they were born in a multiple birth.\nIf people complain often about annoying siblings, then they have siblings who were born together.\nIf people live at home, then they do not live with strangers.\nIf people spend a lot of time hanging out with and playing with their siblings, then they often live at home. \nLuke either is a baby born in a multiple birth and live with strangers, or is not a baby born in a multiple birth and does not live with strangers",
    "model_response": "Lean formalization and proof attempt:\n\nWe model persons and predicates:\n- MB x: x was born in a multiple birth\n- SBT x: x has siblings who were born together\n- Spend x: x spends a lot of time hanging out/playing with siblings\n- Complains x: x complains often about annoying siblings\n- Home x: x lives at home\n- Strangers x: x lives with strangers\n- Luke: a constant person\n\nAxioms from the text:\n1. \u2200x, MB x \u2192 Spend x\n2. \u2200x, SBT x \u2192 MB x\n3. \u2200x, Complains x \u2192 SBT x\n4. \u2200x, Home x \u2192 \u00ac Strangers x\n5. \u2200x, Spend x \u2192 Home x\n6. (MB Luke \u2227 Strangers Luke) \u2228 (\u00ac MB Luke \u2227 \u00ac Strangers Luke)\n\nLean (informal sketch, but standard Lean 4 code can prove the results below):\n\n- From 1 and 5 and 4, MB x \u2192 Spend x \u2192 Home x \u2192 \u00ac Strangers x.\n- Therefore, MB Luke \u2227 Strangers Luke is impossible. Using 6 and ex falso on the left disjunct, we obtain the right disjunct: \u00ac MB Luke \u2227 \u00ac Strangers Luke.\n- From 3 and 2, Complains Luke \u2192 MB Luke. With \u00ac MB Luke, we conclude \u00ac Complains Luke (modus tollens).\n\nConclusions:\n- Q1 (Spend Luke): From \u00ac MB Luke we cannot conclude \u00ac Spend Luke (no contrapositive of 1 is given), and we also cannot conclude Spend Luke. Hence Unknown.\n- Q2 (Complains Luke): We proved \u00ac Complains Luke, so the statement \u201cLuke complains often ...\u201d is False.\n- Q3 (\u00ac MB Luke \u2227 \u00ac Complains Luke): Both conjuncts were proved, so True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1011,
        "conclusion": "Luke spends a lot of time hanging out and playing with his siblings.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1012,
        "conclusion": "Luke complains often about annoying siblings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1013,
        "conclusion": "Luke is neither born in a multiple birth nor complains often about annoying siblings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 197,
    "premises": "It costs $205 to take the GRE test, which is cheaper than $300.\nETS provides financial aid to those GRE applicants who prove economic hardship.\nThose living in single-parent families or having few resources available to them can prove economic hardship.\nTom lives in a single-parent family.\nTom's dad has been out of work, and Tom has few resources available to them. \nTom is applying to take the GRE test.",
    "model_response": "Lean formalization and proof attempt:\n\nWe model:\n- Person, Entity types; Tom : Person; ETS : Entity\n- gre_applicant : Person \u2192 Prop for \u201cGRE applicant\u201d (used to interpret \u201ctaking the GRE test\u201d in the questions)\n- provides : Entity \u2192 Person \u2192 Prop for \u201cprovides financial aid to\u201d\n- proves_econ_hardship, single_parent, few_resources : Person \u2192 Prop\n- gre_cost : Nat\n\nAxioms from the text:\n- policy: \u2200 p, gre_applicant p \u2227 proves_econ_hardship p \u2192 provides ETS p\n- econ_rule: \u2200 p, single_parent p \u2228 few_resources p \u2192 proves_econ_hardship p\n- tom_single: single_parent Tom\n- tom_few: few_resources Tom\n- tom_applicant: gre_applicant Tom\n- cost_is_205: gre_cost = 205\n- cost_lt_300: gre_cost < 300\n\nProofs:\n- From tom_single (or tom_few) and econ_rule, Tom proves economic hardship; with tom_applicant and policy, ETS provides aid to Tom.\n- From cost_lt_300, the GRE cost is below 300.\n- Define Q3_stmt := \u2200 p, gre_applicant p \u2192 \u2200 e, \u00ac provides e p. Using Tom and ETS as witnesses together with the first proof, we derive a contradiction; hence \u00ac Q3_stmt.\n\nLean 4 code:\n\nuniverse u\n\nconstant Person : Type u\nconstant Entity : Type u\n\nconstant Tom : Person\nconstant ETS : Entity\n\nconstant gre_applicant : Person \u2192 Prop\nconstant provides : Entity \u2192 Person \u2192 Prop\nconstant proves_econ_hardship : Person \u2192 Prop\nconstant single_parent : Person \u2192 Prop\nconstant few_resources : Person \u2192 Prop\n\nconstant gre_cost : Nat\n\naxiom policy :\n  \u2200 p : Person, gre_applicant p \u2227 proves_econ_hardship p \u2192 provides ETS p\n\naxiom econ_rule :\n  \u2200 p : Person, single_parent p \u2228 few_resources p \u2192 proves_econ_hardship p\n\naxiom tom_single : single_parent Tom\naxiom tom_few : few_resources Tom\naxiom tom_applicant : gre_applicant Tom\n\naxiom cost_is_205 : gre_cost = 205\naxiom cost_lt_300 : gre_cost < 300\n\ntheorem Q1_Tom_gets_aid : provides ETS Tom := by\n  have hhard : proves_econ_hardship Tom := by\n    exact econ_rule Tom (Or.inl tom_single)\n  exact policy Tom \u27e8tom_applicant, hhard\u27e9\n\ntheorem Q2_cost_below_300 : gre_cost < 300 := cost_lt_300\n\ndef Q3_stmt : Prop := \u2200 p : Person, gre_applicant p \u2192 \u2200 e : Entity, \u00ac provides e p\n\ntheorem not_Q3_stmt : \u00ac Q3_stmt := by\n  intro H\n  have hprov : provides ETS Tom := Q1_Tom_gets_aid\n  have hga : gre_applicant Tom := tom_applicant\n  have hno := H Tom hga ETS\n  exact hno hprov\n\nConclusions:\n- Q1 is provable (True).\n- Q2 is provable (True).\n- Q3\u2019s statement is refutable; we proved its negation (False).\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 560,
        "conclusion": "ETS provides financial aid to Tom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 561,
        "conclusion": "It costs below US $300 to take the GRE test.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 562,
        "conclusion": "No one taking the GRE test has financial aid provided to them by something.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 361,
    "premises": "If people spill a lot of food on their clothing, then they are not notably tidy.\nAll clumsy foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nIf people are cleanly, then they are notably tidy.\nIf people value order and spotlessness, then they are cleanly.\nAll people whose families prioritize order and spotlessness themselves value order and spotlessness.\nPeter is either a person who spills a lot of food on his clothing and is cleanly, or a person who does not spill a lot of food on his clothing and is not cleanly",
    "model_response": "Lean translation and proof attempt:\n\nEntities and predicates:\n- Person : Type\n- Spill : Person \u2192 Prop  -- spills a lot of food on clothing\n- Tidy  : Person \u2192 Prop  -- notably tidy\n- Cleanly : Person \u2192 Prop\n- ValueOrder : Person \u2192 Prop  -- values order and spotlessness\n- FP : Person \u2192 Prop  -- family prioritizes order and spotlessness\n- C : Person \u2192 Prop  -- clumsy foodie who goes out frequently to find new restaurants\n\nAxioms from the text:\n1. \u2200 x, Spill x \u2192 \u00ac Tidy x\n2. \u2200 x, C x \u2192 Spill x\n3. \u2200 x, Cleanly x \u2192 Tidy x\n4. \u2200 x, ValueOrder x \u2192 Cleanly x\n5. \u2200 x, FP x \u2192 ValueOrder x\n6. Peter satisfies: (Spill Peter \u2227 Cleanly Peter) \u2228 (\u00acSpill Peter \u2227 \u00acCleanly Peter)\n\nLean developments (sketch):\n- From (1) and (3), we get \u2200 x, \u00ac(Spill x \u2227 Cleanly x). Hence the first disjunct in (6) is impossible, so the second must hold: \u00acSpill Peter \u2227 \u00acCleanly Peter.\n- From \u00acSpill Peter and (2), contraposition gives \u00acC Peter.\n- From \u00acCleanly Peter and (4), (5), contraposition gives \u00acFP Peter.\n\nConsequences for the questions:\n- Q1 (Tidy Peter): From \u00acSpill and \u00acCleanly we cannot derive Tidy Peter nor \u00acTidy Peter using the given axioms. Unknown.\n- Q2 (C Peter \u2228 FP Peter): We proved \u00acC Peter and \u00acFP Peter, hence \u00ac(C Peter \u2228 FP Peter). Therefore Q2 is False.\n- Q3 ((C \u2227 FP) \u2228 (\u00acC \u2227 \u00acFP)): We have \u00acC and \u00acFP, so the right disjunct holds. Therefore Q3 is True.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 958,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 959,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 960,
        "conclusion": "Peter is either both a clumsy foodie who goes out frequently to find new food restaurants to try and issomeone whose family prioritizes order and spotlessness, or he neither is a clumsy foodie who goes out frequently to find new food restaurants to try nor does his family prioritize order and spotlessness.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 262,
    "premises": "All fir trees are evergreens.\nSome objects of worship are fir trees.",
    "model_response": "Lean formalization and analysis:\n\nWe model a domain of objects U with predicates:\n- Fir : U \u2192 Prop    -- \"is a fir tree\"\n- Evergreen : U \u2192 Prop    -- \"is an evergreen\"\n- Worship : U \u2192 Prop    -- \"is an object of worship\"\n\nPremises:\n- h1: \u2200 x, Fir x \u2192 Evergreen x       -- All fir trees are evergreens\n- h2: \u2203 x, Worship x \u2227 Fir x         -- Some objects of worship are fir trees\n\nTarget statement:\n- concl: \u2203 x, Evergreen x \u2227 \u00ac Worship x    -- Some evergreens are not objects of worship\n\nAttempt to derive concl from h1 and h2 fails: from h2 we get some x that is both Worship and Fir, and by h1, that x is Evergreen, yielding \u2203 x, Evergreen x \u2227 Worship x, not the desired \u2203 x, Evergreen x \u2227 \u00ac Worship x.\n\nTo substantiate that the target is not derivable and that its negation is also not derivable from the premises, we provide two concrete models in Lean.\n\nModel A (premises hold, conclusion false):\n- U1 := Unit\n- Fir1 u := True\n- Evergreen1 u := True\n- Worship1 u := True\nThen h1 and h2 hold, but \u00ac (\u2203 x, Evergreen1 x \u2227 \u00ac Worship1 x).\n\nModel B (premises hold, conclusion true):\n- Define a two-element type:\n  inductive Two | a | b\n- Fir2 a := True, Fir2 b := False\n- Evergreen2 _ := True\n- Worship2 a := True, Worship2 b := False\nThen h1 and h2 hold, and \u2203 x, Evergreen2 x \u2227 \u00ac Worship2 x (take x = b).\n\nLean code:\n\nnamespace Q1\n\ninductive Two : Type\n| a | b\nopen Two\n\n-- Model A: all predicates True on Unit\ndef U1 := Unit\ndef Fir1 : U1 \u2192 Prop := fun _ => True\ndef Evergreen1 : U1 \u2192 Prop := fun _ => True\ndef Worship1 : U1 \u2192 Prop := fun _ => True\n\nlemma prem1_1 : \u2200 x, Fir1 x \u2192 Evergreen1 x := by intro x _; trivial\nlemma prem2_1 : \u2203 x, Worship1 x \u2227 Fir1 x := \u27e8(), And.intro trivial trivial\u27e9\nlemma not_concl_1 : \u00ac (\u2203 x, Evergreen1 x \u2227 \u00ac Worship1 x) := by\n  intro h; rcases h with \u27e8x, _, hxnotW\u27e9; exact hxnotW trivial\n\n-- Model B: Two with a-only fir and worship\ndef Fir2 : Two \u2192 Prop\n| a => True\n| b => False\n\ndef Evergreen2 : Two \u2192 Prop := fun _ => True\n\ndef Worship2 : Two \u2192 Prop\n| a => True\n| b => False\n\nlemma prem1_2 : \u2200 x, Fir2 x \u2192 Evergreen2 x := by intro _ _; trivial\nlemma prem2_2 : \u2203 x, Worship2 x \u2227 Fir2 x := \u27e8a, And.intro trivial trivial\u27e9\nlemma concl_2 : \u2203 x, Evergreen2 x \u2227 \u00ac Worship2 x := \u27e8b, And.intro trivial (by intro h; cases h)\u27e9\n\n-- Therefore the sequent is not valid, and neither is its negation\nexample : \u00ac (\u2200 (U : Type) (Fir Evergreen Worship : U \u2192 Prop),\n  (\u2200 x, Fir x \u2192 Evergreen x) \u2192 (\u2203 x, Worship x \u2227 Fir x) \u2192 (\u2203 x, Evergreen x \u2227 \u00ac Worship x)) := by\n  intro h\n  have h' := h U1 Fir1 Evergreen1 Worship1 prem1_1 prem2_1\n  exact not_concl_1 h'\n\nexample : \u00ac (\u2200 (U : Type) (Fir Evergreen Worship : U \u2192 Prop),\n  (\u2200 x, Fir x \u2192 Evergreen x) \u2192 (\u2203 x, Worship x \u2227 Fir x) \u2192 \u00ac (\u2203 x, Evergreen x \u2227 \u00ac Worship x)) := by\n  intro h\n  have h' := h Two Fir2 Evergreen2 Worship2 prem1_2 prem2_2\n  exact h' concl_2\n\nend Q1\n\nConclusion: The statement \u201cSome evergreens are not objects of worship\u201d is not entailed by the premises, nor is its negation; hence its truth is uncertain given the information.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 706,
        "conclusion": "Some evergreens are not objects of worship.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 124,
    "premises": "The Picuris Mountains are a mountain range in New Mexico or Texas.\nJuan de Onate visited the Picuris Mountains.\nThe Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nThere are no mountain ranges in texas that have mines that have been donated.",
    "model_response": "Lean formalization and attempt to prove:\n\nuniverse u\n\n-- Types\nconstant MountainRange : Type\nconstant Mine : Type\nconstant Person : Type\n\n-- Entities\nconstant Picuris : MountainRange\nconstant Harding : Mine\nconstant Juan : Person\n\n-- Predicates\nconstant InNM : MountainRange \u2192 Prop\nconstant InTX : MountainRange \u2192 Prop\nconstant LocatedIn : Mine \u2192 MountainRange \u2192 Prop\nconstant Donated : Mine \u2192 Prop\nconstant Visited : Person \u2192 MountainRange \u2192 Prop\n\n-- Assumptions from the textual context\naxiom Picuris_in_NM_or_TX : InNM Picuris \u2228 InTX Picuris\naxiom Juan_visited_Picuris : Visited Juan Picuris\naxiom Harding_located_in_Picuris : LocatedIn Harding Picuris\naxiom Harding_donated : Donated Harding\naxiom no_TX_range_has_donated_mine :\n  \u2200 (r : MountainRange) (m : Mine), InTX r \u2192 LocatedIn m r \u2192 Donated m \u2192 False\n\n-- Derived facts\nlemma Picuris_not_in_TX : \u00ac InTX Picuris := by\n  intro htx\n  exact no_TX_range_has_donated_mine Picuris Harding htx Harding_located_in_Picuris Harding_donated\n\nlemma Picuris_in_NM : InNM Picuris := by\n  cases Picuris_in_NM_or_TX with\n  | inl hnm => exact hnm\n  | inr htx =>\n    exact False.elim (no_TX_range_has_donated_mine Picuris Harding htx Harding_located_in_Picuris Harding_donated)\n\n-- Questions as propositions\ndef Q1 : Prop := \u2203 r : MountainRange, InNM r \u2227 Visited Juan r\ndef Q2 : Prop := \u2203 r : MountainRange, InTX r \u2227 Visited Juan r\ndef Q3 : Prop := \u00ac \u2203 r : MountainRange, InNM r \u2227 LocatedIn Harding r\n\n-- Proofs\ntheorem Q1_true : Q1 := by\n  refine Exists.intro Picuris ?_\n  exact And.intro Picuris_in_NM Juan_visited_Picuris\n-- Therefore, Q1 is True.\n\ntheorem exists_nm_location_for_harding : \u2203 r : MountainRange, InNM r \u2227 LocatedIn Harding r := by\n  exact \u27e8Picuris, And.intro Picuris_in_NM Harding_located_in_Picuris\u27e9\n\ntheorem not_Q3 : \u00ac Q3 := by\n  intro h\n  exact h exists_nm_location_for_harding\n-- Therefore, Q3 is False.\n\n-- For Q2 (\u2203 r, InTX r \u2227 Visited Juan r), from the given information we can neither prove it nor its negation.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 370,
        "conclusion": "Juan de Onate visited a mountain range in New Mexico.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 371,
        "conclusion": "Juan de Onate visited a mountain range in Texas.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 372,
        "conclusion": "The Harding Pegmatite Mine is not located in a mountain range in New Mexico.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 183,
    "premises": "If a man is taller than another man, the taller one can block the other's shooting.\nMichael is a man who is taller than everyone else in his class.\nIf person x is taller than person y, and person y is taller than person z, then x is taller than z\nPeter is a man who is taller than Michael.\nMichael can block any shooting from a person as long as the person does not jump when shooting.\nMichael cannot block Windy's shooting.\nEvery shooter who can jump when shooting is a great shooter.",
    "model_response": "Lean formalization and attempt at proofs:\n\nWe model people and predicates:\n- Person: type of individuals\n- Michael, Peter, Windy: constants of type Person\n- Man, Shooter, GreatShooter, InClass: Person \u2192 Prop\n- Taller: Person \u2192 Person \u2192 Prop\n- Jumps: Person \u2192 Prop\n- CanBlock: Person \u2192 Person \u2192 Prop\n\nAxioms from the text (plus standard properties of \u201ctaller than\u201d):\n- man_michael: Man Michael\n- man_peter: Man Peter\n- taller_trans: \u2200 {x y z}, Taller x y \u2192 Taller y z \u2192 Taller x z\n- taller_irrefl: \u2200 x, \u00ac Taller x x  -- irreflexivity of \u201ctaller than\u201d\n- block_if_taller_men: \u2200 x y, Man x \u2192 Man y \u2192 Taller x y \u2192 CanBlock x y\n- michael_taller_than_class: \u2200 x, InClass x \u2192 Taller Michael x\n- peter_taller_than_michael: Taller Peter Michael\n- michael_blocks_if_not_jump: \u2200 x, \u00ac Jumps x \u2192 CanBlock Michael x\n- michael_cannot_block_windy: \u00ac CanBlock Michael Windy\n- shooter_windy: Shooter Windy\n- great_if_shooter_and_jump: \u2200 x, Shooter x \u2192 Jumps x \u2192 GreatShooter x\n\nLean proofs sketch:\n\n1) Q1: \u201cPeter is shorter than a man in Michael's class\u201d means \u2203 x, Man x \u2227 InClass x \u2227 Taller x Peter.\nAssume such x. Then:\n- From InClass x, michael_taller_than_class gives Taller Michael x.\n- From Taller x Peter and peter_taller_than_michael and taller_trans, get Taller x Michael.\n- From Taller x Michael and Taller Michael x and taller_trans, get Taller x x, contradicting taller_irrefl.\nHence \u00ac \u2203 x, Man x \u2227 InClass x \u2227 Taller x Peter. So Q1 is False.\n\n2) Q2: From michael_cannot_block_windy and michael_blocks_if_not_jump, by modus tollens we get Jumps Windy. Given shooter_windy and great_if_shooter_and_jump, conclude GreatShooter Windy. So Q2 is True.\n\n3) Q3: We have no information relating Peter\u2019s height to Windy nor Windy\u2019s being a man, so block_if_taller_men cannot be applied, and we cannot derive either CanBlock Peter Windy or its negation from the axioms. So Q3 is Unknown.\n\nANSWERS:\n1: False\n2: True\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 527,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 528,
        "conclusion": "Windy is a great shooter.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 529,
        "conclusion": "Peter can block Windy's shooting.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 151,
    "premises": "Barutin Cove is a cove named after the Bulgarian settlement of Barutin.\nBarutin Cove is on the southwest coast of Snow Island.\nSnow Island, Greenwich Island, and Deception Island are located in the South Shetland Islands.\nAntarctica is located on the South Shetland Islands. \nIf place A is located in place B and place B is located in place C, then place A is located in place C.",
    "model_response": "Lean translation and attempt:\n\nWe model places and the relations/predicates we need.\n\nuniverse u\n\nconstant Place : Type u\n\n-- Predicates and relations\nconstant Cove : Place \u2192 Prop\nconstant Island : Place \u2192 Prop\nconstant LocatedIn : Place \u2192 Place \u2192 Prop\nconstant NamedAfter : Place \u2192 Place \u2192 Prop\nconstant BulgarianPlace : Place \u2192 Prop\n\n-- Entities\nconstant BarutinCove : Place\nconstant SnowIsland : Place\nconstant GreenwichIsland : Place\nconstant DeceptionIsland : Place\nconstant SouthShetlandIslands : Place\nconstant Antarctica : Place\nconstant BarutinSettlement : Place\n\n-- Facts from the context\naxiom barutin_cove_is_cove : Cove BarutinCove\naxiom barutin_cove_named_barutin : NamedAfter BarutinCove BarutinSettlement\naxiom barutin_settlement_bulgarian : BulgarianPlace BarutinSettlement\n\naxiom barutin_cove_in_snow : LocatedIn BarutinCove SnowIsland\naxiom snow_in_ssi : LocatedIn SnowIsland SouthShetlandIslands\naxiom greenwich_in_ssi : LocatedIn GreenwichIsland SouthShetlandIslands\naxiom deception_in_ssi : LocatedIn DeceptionIsland SouthShetlandIslands\n\n-- Note the (given) direction:\naxiom antarctica_in_ssi : LocatedIn Antarctica SouthShetlandIslands\n\n-- Transitivity of location\naxiom located_in_trans : \u2200 {A B C : Place}, LocatedIn A B \u2192 LocatedIn B C \u2192 LocatedIn A C\n\n-- Optional: mark the three named islands as islands\naxiom snow_is_island : Island SnowIsland\naxiom greenwich_is_island : Island GreenwichIsland\naxiom deception_is_island : Island DeceptionIsland\n\n-- A small derivation we can do:\ntheorem barutin_cove_in_ssi : LocatedIn BarutinCove SouthShetlandIslands :=\n  located_in_trans barutin_cove_in_snow snow_in_ssi\n\n-- Questions formalized:\n\n-- Q1: \"Barutin Cove is named after all islands in Antarctica.\"\ndef Q1 : Prop :=\n  \u2200 x : Place, Island x \u2227 LocatedIn x Antarctica \u2192 NamedAfter BarutinCove x\n\n-- Q2: \"There is at least one cove in Antarctica named after a place in Bulgaria.\"\ndef Q2 : Prop :=\n  \u2203 c : Place, Cove c \u2227 LocatedIn c Antarctica \u2227 \u2203 p : Place, BulgarianPlace p \u2227 NamedAfter c p\n\n-- Q3: \"Barutin Cove is not located in Antarctica.\"\ndef Q3 : Prop := \u00ac LocatedIn BarutinCove Antarctica\n\n-- Attempted proofs assessment:\n-- From the given axioms, we can derive LocatedIn BarutinCove SouthShetlandIslands,\n-- but we have no axiom that SouthShetlandIslands is located in Antarctica.\n-- Instead, we have the reverse: LocatedIn Antarctica SouthShetlandIslands.\n-- Thus we cannot derive LocatedIn BarutinCove Antarctica, nor its negation.\n-- Consequently:\n-- - Q1 cannot be proved (no information about any island located in Antarctica)\n--   and its negation cannot be proved either. Unknown.\n-- - Q2 cannot be proved (we cannot show any cove is in Antarctica),\n--   and its negation also cannot be proved. Unknown.\n-- - Q3 cannot be proved (as above), and its negation also cannot be proved. Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 439,
        "conclusion": "Barutin Cove is named after all islands in Antarctica.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 440,
        "conclusion": "There is at least one cove in Antarctica named after a place in Bulgaria.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 441,
        "conclusion": "Barutin Cove is not located in Antarctica.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 295,
    "premises": "Some affection is love.\nSome love is positive.",
    "model_response": "Lean translation and attempt:\n\n- Universe of discourse: U : Type\n- Predicates:\n  - Affection : U \u2192 Prop\n  - Love : U \u2192 Prop\n  - Positive : U \u2192 Prop\n- Premises:\n  - h1 : \u2203 x, Affection x \u2227 Love x        -- \u201cSome affection is love.\u201d\n  - h2 : \u2203 x, Love x \u2227 Positive x         -- \u201cSome love is positive.\u201d\n- Goal to prove:\n  - \u2203 x, Affection x \u2227 Positive x         -- \u201cSome affection is positive.\u201d\n\nLean attempt (cannot be proven in general):\n\nuniverse u\n\nvariable {U : Type u} (Affection Love Positive : U \u2192 Prop)\n\ntheorem some_affection_positive\n  (h1 : \u2203 x, Affection x \u2227 Love x)\n  (h2 : \u2203 x, Love x \u2227 Positive x) :\n  \u2203 x, Affection x \u2227 Positive x := by\n  -- Not derivable in general: the witnesses for the two existentials may differ.\n  sorry\n\nCountermodel in Lean showing the conclusion does not follow from the premises:\n\nexample :\n  \u2203 (U : Type) (Affection Love Positive : U \u2192 Prop),\n    (\u2203 x, Affection x \u2227 Love x) \u2227\n    (\u2203 x, Love x \u2227 Positive x) \u2227\n    \u00ac (\u2203 x, Affection x \u2227 Positive x) := by\n  let U := Bool\n  let Affection : U \u2192 Prop := fun b => b = true\n  let Love : U \u2192 Prop := fun _ => True\n  let Positive : U \u2192 Prop := fun b => b = false\n  refine \u27e8U, Affection, Love, Positive, ?_\u27e9\n  refine \u27e8?h1, ?h2, ?hnot\u27e9\n  \u00b7 exact \u27e8true, by simp [Affection, Love]\u27e9\n  \u00b7 exact \u27e8false, by simp [Love, Positive]\u27e9\n  \u00b7 intro hx\n    rcases hx with \u27e8x, hxA, hxP\u27e9\n    cases x\n    \u00b7 simpa [Affection] using hxA\n    \u00b7 simpa [Positive] using hxP\n\nConclusion: The statement \u201cSome affection is positive\u201d is not entailed by the premises, nor is its negation entailed. Therefore, its truth value is uncertain given the information.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 739,
        "conclusion": "Some affection is positive.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 315,
    "premises": "If something can transport multiple passengers, then they are not one-seaters.\nAll Tesla Model 3 can transport multiple passengers.\nAll single-seat electric cars are one-seaters.\nAll Solo EV cars are single-seat electric cars. \nIf John's car is not a Tesla Model 3, then John's car is not a Tesla Model 3 or a single-seat electric car. ",
    "model_response": "Lean formalization and attempt at proofs:\n\n-- We disable autoImplicit to make all binder types explicit\nset_option autoImplicit false\n\nuniverse u\n\n-- Domain of discourse\nconstant Car : Type u\n\n-- Predicates\nconstant Tesla3 : Car \u2192 Prop\nconstant TransportMulti : Car \u2192 Prop\nconstant OneSeater : Car \u2192 Prop\nconstant SingleSeatEV : Car \u2192 Prop\nconstant SoloEV : Car \u2192 Prop\n\n-- Individual\nconstant john : Car\n\n-- Axioms from the text\naxiom ax1 : \u2200 x : Car, TransportMulti x \u2192 \u00ac OneSeater x\naxiom ax2 : \u2200 x : Car, Tesla3 x \u2192 TransportMulti x\naxiom ax3 : \u2200 x : Car, SingleSeatEV x \u2192 OneSeater x\naxiom ax4 : \u2200 x : Car, SoloEV x \u2192 SingleSeatEV x\naxiom ax5 : \u00ac Tesla3 john \u2192 (\u00ac Tesla3 john \u2228 SingleSeatEV john)\n\n-- Derived consequences\nlemma tesla3_not_oneSeater (x : Car) : Tesla3 x \u2192 \u00ac OneSeater x := by\n  intro hT\n  have hTM : TransportMulti x := ax2 x hT\n  exact ax1 x hTM\n\nlemma soloEV_oneSeater (x : Car) : SoloEV x \u2192 OneSeater x := by\n  intro hS\n  have hSE : SingleSeatEV x := ax4 x hS\n  exact ax3 x hSE\n\n-- They cannot both be Tesla3 and SoloEV (consistency check)\nlemma not_both_tesla3_and_soloEV_john : \u00ac (Tesla3 john \u2227 SoloEV john) := by\n  intro h\n  rcases h with \u27e8hT, hS\u27e9\n  have h1 : \u00ac OneSeater john := tesla3_not_oneSeater john hT\n  have h2 : OneSeater john := soloEV_oneSeater john hS\n  exact h1 h2\n\n-- The given implication ax5 is a tautology (doesn't add info)\nlemma ax5_is_tautology : \u00ac Tesla3 john \u2192 (\u00ac Tesla3 john \u2228 SingleSeatEV john) := by\n  intro h; exact Or.inl h\n\n-- Targets:\ndef Q1 : Prop := Tesla3 john\ndef Q2 : Prop := SoloEV john\ndef Q3 : Prop := \u00ac SoloEV john\n\n-- None of Q1, Q2, or Q3 is derivable from the axioms above.\n-- We can derive incompatibility (not both Tesla3 and SoloEV), but nothing forces either side.\n\nReasoning summary:\n- From Tesla3 \u21d2 TransportMulti \u21d2 \u00ac OneSeater, and SoloEV \u21d2 SingleSeatEV \u21d2 OneSeater, we get that John\u2019s car cannot be both Tesla3 and SoloEV, but we have no premise that tells us whether John\u2019s car is Tesla3 or SoloEV.\n- The clause \u201cif John\u2019s car is not a Tesla Model 3, then (not Tesla Model 3) or (single-seat electric car)\u201d is a tautology of the form A \u2192 (A \u2228 B) and provides no new information.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 786,
        "conclusion": "John's car is a Tesla Model 3.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 787,
        "conclusion": "John's car is a Solo EV.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 788,
        "conclusion": "John's car is not a Solo EV.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 467,
    "premises": "All of Peter's pets that are mammals are also animals.\nAll monkeys are mammals. \nPeter's pets are all either monkeys or birds. \nPeter's birds can fly.\nAll animals that are Peter's pets can breathe.\nIf Peter's pet can fly, then it has wings.\nRock is Peter's pet.\nRock can fly, or Rock is a bird, or Rock cannot breathe. ",
    "model_response": "Lean translation and attempt to prove:\n\n-- We formalize the domain, predicates, entity, and premises.\nuniverse u\n\nconstant U : Type u\nconstant Pet Mammal Animal Monkey Bird CanFly CanBreathe HasWings : U \u2192 Prop\nconstant Rock : U\n\naxiom ax1 : \u2200 x : U, Pet x \u2227 Mammal x \u2192 Animal x\naxiom ax2 : \u2200 x : U, Monkey x \u2192 Mammal x\naxiom ax3 : \u2200 x : U, Pet x \u2192 (Monkey x \u2228 Bird x)\naxiom ax4 : \u2200 x : U, Pet x \u2227 Bird x \u2192 CanFly x\naxiom ax5 : \u2200 x : U, Animal x \u2227 Pet x \u2192 CanBreathe x\naxiom ax6 : \u2200 x : U, Pet x \u2227 CanFly x \u2192 HasWings x\naxiom ax7 : Pet Rock\naxiom ax8 : CanFly Rock \u2228 Bird Rock \u2228 \u00ac CanBreathe Rock\n\n-- Q2: Rock has wings.\n-- We prove HasWings Rock unconditionally from the axioms.\nlemma Rock_hasWings : HasWings Rock := by\n  have hPet : Pet Rock := ax7\n  -- Analyze the given disjunction: CanFly Rock \u2228 Bird Rock \u2228 \u00ac CanBreathe Rock\n  exact\n    match ax8 with\n    | Or.inl hFly =>\n      ax6 Rock \u27e8hPet, hFly\u27e9\n    | Or.inr (Or.inl hBird) =>\n      let hFly := ax4 Rock \u27e8hPet, hBird\u27e9\n      ax6 Rock \u27e8hPet, hFly\u27e9\n    | Or.inr (Or.inr hNotBreathe) =>\n      -- From Pet Rock, we know Monkey Rock \u2228 Bird Rock.\n      -- If Monkey Rock, then Rock can breathe, contradicting hNotBreathe.\n      -- Hence Bird Rock holds; then Rock can fly; hence Rock has wings.\n      have hMB : Monkey Rock \u2228 Bird Rock := ax3 Rock hPet\n      have hBird' : Bird Rock :=\n        match hMB with\n        | Or.inl hMonkey =>\n          let hMammal := ax2 Rock hMonkey\n          let hAnimal := ax1 Rock \u27e8hPet, hMammal\u27e9\n          let hBreathe := ax5 Rock \u27e8hAnimal, hPet\u27e9\n          False.elim (hNotBreathe hBreathe)\n        | Or.inr hBird => hBird\n      let hFly := ax4 Rock \u27e8hPet, hBird'\u27e9\n      ax6 Rock \u27e8hPet, hFly\u27e9\n\n-- Q3: Rock does not have wings.\n-- Its negation is exactly HasWings Rock, which we proved above.\n-- Therefore, the statement of Q3 is false.\nlemma Rock_not_hasWings_false : \u00ac HasWings Rock \u2192 False :=\n  fun h => h Rock_hasWings\n\n-- Q1: Rock is a monkey.\n-- From the given axioms, this is not derivable (nor is its negation),\n-- since Pet Rock only yields Monkey Rock \u2228 Bird Rock, and nothing rules out the Bird case\n-- nor forces the Monkey case, and monkeys and birds are not stated to be disjoint.\n\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1348,
        "conclusion": "Rock is a monkey.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1349,
        "conclusion": "Rock has wings.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1350,
        "conclusion": "Rock does not have wings.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 330,
    "premises": "All people who make wedding plans are people who are engaged.\nAll people who invite others to come to their ceremony make wedding plans.\nAnyone who has a well-attended wedding invites others to come to their ceremony.\nSome people that have well-attended weddings have larger families.\nIf John is engaged, then John does not invite friends to their ceremony and make wedding plans.\nIf John has a larger family, then either John has a well-attended wedding or invites friends to their ceremony. ",
    "model_response": "Lean formalization and attempt:\n\nWe model people as a type Person with predicates:\n- MakesPlans, Engaged, InvitesOthers, InvitesFriends, WellAttended, LargerFamily : Person \u2192 Prop\n- a constant John : Person\n\nAxioms (from the text):\n1. \u2200x, MakesPlans x \u2192 Engaged x\n2. \u2200x, InvitesOthers x \u2192 MakesPlans x\n3. \u2200x, WellAttended x \u2192 InvitesOthers x\n4. \u2203x, WellAttended x \u2227 LargerFamily x\n5. Engaged John \u2192 (\u00ac InvitesFriends John \u2227 MakesPlans John)\n6. LargerFamily John \u2192 (WellAttended John \u2228 InvitesFriends John)\n\nSome derived facts we can prove:\n- For John, Engaged John \u2194 MakesPlans John:\n  \u2022 Engaged John \u2192 MakesPlans John by (5).\n  \u2022 MakesPlans John \u2192 Engaged John by (1).\n- \u2200x, WellAttended x \u2192 Engaged x by chaining (3) \u2192 (2) \u2192 (1).\n- In particular, WellAttended John \u2192 Engaged John, hence WellAttended John \u2192 \u00acInvitesFriends John by (5).\n\nAttempted goals:\n\nQ1: LargerFamily John.\n- Not derivable from the axioms. It is consistent both that John has a larger family and that he does not. Axiom (4) only asserts the existence of someone (not necessarily John) with a well-attended wedding and a larger family. Axiom (6) gives only a conditional from LargerFamily John, not the antecedent.\n\nQ2: \u00ac LargerFamily John.\n- Also not derivable. No axiom rules out LargerFamily John.\n\nQ3: Engaged John.\n- Not derivable. We can show that WellAttended John implies Engaged John, and that Engaged John is equivalent to MakesPlans John for John, but we have no premise making either antecedent true for John.\n\nQ4: \u00acLargerFamily John \u2227 \u00acInvitesOthers John.\n- Not derivable. There is no axiom implying either \u00acLargerFamily John or \u00acInvitesOthers John. In fact, if John had a well-attended wedding, then InvitesOthers John would follow by (3).\n\nConclusion: None of the four statements can be proved or refuted from the given axioms in this formalization.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown\n4: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 846,
        "conclusion": "John has a larger family.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 2,
        "example_id": 847,
        "conclusion": "John does not have a larger family.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 848,
        "conclusion": "John is engaged.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 849,
        "conclusion": "John neither has a larger family nor does he invite others to his wedding.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.25
  },
  {
    "story_id": 26,
    "premises": "Some mammals have teeth.\nPlatypuses have no teeth.\nPlatypuses are mammals. \nHumans have teeth.",
    "model_response": "Lean formalization and attempt:\n\nWe model two individuals: P for platypus and H for human. Predicates: Mammal, Reptile, HasTeeth.\n\nPremises:\n- some_mammals_have_teeth: \u2203 x, Mammal x \u2227 HasTeeth x\n- platypus_no_teeth: \u00ac HasTeeth P\n- platypus_mammal: Mammal P\n- human_teeth: HasTeeth H\n\nLean code:\n\n-- Lean 4\nuniverse u\n\nconstant Animal : Type u\nconstant P : Animal -- platypus\nconstant H : Animal -- human\n\nconstant Mammal : Animal \u2192 Prop\nconstant Reptile : Animal \u2192 Prop\nconstant HasTeeth : Animal \u2192 Prop\n\naxiom some_mammals_have_teeth : \u2203 x, Mammal x \u2227 HasTeeth x\naxiom platypus_no_teeth : \u00ac HasTeeth P\naxiom platypus_mammal : Mammal P\naxiom human_teeth : HasTeeth H\n\n-- Q1: Platypuses are mammals with no teeth: Mammal P \u2227 \u00acHasTeeth P\ntheorem Q1 : Mammal P \u2227 \u00ac HasTeeth P :=\n  And.intro platypus_mammal platypus_no_teeth\n\n-- Q2: Platypuses are reptiles: Reptile P\n-- Not provable from the given premises, and we also cannot prove its negation.\n\n-- Q3: Humans are mammals: Mammal H\n-- Not provable from the given premises, and we also cannot prove its negation.\n\nTherefore:\n- Q1 is provable (True).\n- Q2 is not derivable nor refutable from the premises (Unknown).\n- Q3 is not derivable nor refutable from the premises (Unknown).\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 74,
        "conclusion": "Platypuses are mammals with no teeth.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 75,
        "conclusion": "Platypuses are reptiles.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 76,
        "conclusion": "Humans are mammals.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 203,
    "premises": "Plungers suck.\nVacuums suck.\nVampires suck.\nSpace is a vacuum.\nA duster is a household appliance that doesn't suck.",
    "model_response": "Lean formalization and attempt:\n\n- Domain: U (things)\n- Predicates: Plunger, Vacuum, Vampire, HouseholdAppliance, Sucks : U \u2192 Prop\n- Constants: Space, Duster : U\n- Axioms:\n  1) \u2200 x, Plunger x \u2192 Sucks x\n  2) \u2200 x, Vacuum x \u2192 Sucks x\n  3) \u2200 x, Vampire x \u2192 Sucks x\n  4) Vacuum Space\n  5) HouseholdAppliance Duster\n  6) \u00ac Sucks Duster\n\nLean-style proofs:\n- Q1 (Space sucks):\n  from (2) and (4): vacuums_suck Space space_is_vacuum : Sucks Space. Proven.\n\n- Q2 (Space is a vampire):\n  No axioms relate Vacuum to Vampire. Neither Vampire Space nor its negation is derivable from the given axioms. Unknown.\n\n- Q3 (If something is a household appliance, it sucks):\n  Let Statement3 := \u2200 x, HouseholdAppliance x \u2192 Sucks x.\n  From (5) and (6), assuming Statement3 yields Sucks Duster, contradicting \u00ac Sucks Duster. Hence \u00ac Statement3. We can prove the negation, so the statement is false.\n\nANSWERS:\n1: True\n2: Unknown\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 578,
        "conclusion": "Space sucks.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 579,
        "conclusion": "Space is a vampire.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 580,
        "conclusion": "If something is a household appliance, it sucks.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 131,
    "premises": "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nUnsupervised learning algorithms do not require labeled data.\nThe state-of-the-art text summarization model is trained with machine learning algorithms.\nReinforcement learning is not used to train the state-of-the-art text summarization model.\nThe Machine Learning algorithm for training text summarization models requires labeled data.",
    "model_response": "Lean formalization and attempt:\n\nWe model the single algorithm used to train the state-of-the-art (SOTA) text summarization model as alg.\n\nuniverse u\n\nconstant Algorithm : Type u\nconstant Supervised : Algorithm \u2192 Prop\nconstant Unsupervised : Algorithm \u2192 Prop\nconstant Reinforcement : Algorithm \u2192 Prop\nconstant RequiresLabeled : Algorithm \u2192 Prop\nconstant alg : Algorithm\n\n-- Premises encoded from the text:\n-- 1) ML algorithms fall into exactly these three categories (we only need exhaustiveness for alg).\naxiom categories_exhaustive_for_alg : Supervised alg \u2228 Unsupervised alg \u2228 Reinforcement alg\n-- 2) Unsupervised learning algorithms do not require labeled data.\naxiom unsupervised_no_labels : \u2200 a, Unsupervised a \u2192 \u00ac RequiresLabeled a\n-- 3) Reinforcement learning is not used to train the SOTA model.\naxiom not_reinforcement_used : \u00ac Reinforcement alg\n-- 4) The ML algorithm for training text summarization models requires labeled data.\naxiom requires_labels_alg : RequiresLabeled alg\n\n-- Consequences:\n-- From (2) and (4), alg cannot be unsupervised.\nlemma not_unsupervised_alg : \u00ac Unsupervised alg := by\n  intro hU\n  have h := unsupervised_no_labels alg hU\n  exact h requires_labels_alg\n\n-- From exhaustiveness (1), excluding unsupervised and reinforcement by the above and (3), alg must be supervised.\nlemma supervised_alg : Supervised alg := by\n  have h := categories_exhaustive_for_alg\n  rcases h with hS | hUR\n  \u00b7 exact hS\n  \u00b7 rcases hUR with hU | hR\n    \u00b7 exact False.elim (not_unsupervised_alg hU)\n    \u00b7 exact False.elim (not_reinforcement_used hR)\n\n-- Therefore:\n-- Question 1 (Supervised alg) is provable: True.\n-- Question 2 (Unsupervised alg) is refutable via not_unsupervised_alg: False.\n\nANSWERS:\n1: True\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 388,
        "conclusion": "Supervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 389,
        "conclusion": "Unsupervised learning is used to train the state-of-the-art text summarization model.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 460,
    "premises": "If a film is appropriate for people of all ages, then children can watch it without guidance from parents.\nIf a film contains excessive erotic and violent content, children cannot watch it without guidance from their parents.\nIf a film is rated General Audience, then it is appropriate for people of all ages.\nAll family-friendly animated films are rated General Audience.\nAll movies in the Frozen series are family-friendly animated films.\n\u201cHachi: A dog\u2019s Tale\u201d is a film.\n\u201cHachi: A dog\u2019s Tale\u201d  is either a family-friendly animated film or is appropriate for people of all ages. ",
    "model_response": "Lean formalization and attempt:\n\n-- Universe of items (films)\nuniverse u\nconstant Item : Type u\n\n-- Predicates\nconstant Film : Item \u2192 Prop\nconstant AppropriateAllAges : Item \u2192 Prop\nconstant ChildrenCanWatchWithoutGuidance : Item \u2192 Prop\nconstant ExcessiveEroticViolentContent : Item \u2192 Prop\nconstant RatedGA : Item \u2192 Prop\nconstant FamilyFriendlyAnimated : Item \u2192 Prop\nconstant FrozenSeries : Item \u2192 Prop\n\n-- Constant for the specific film\nconstant Hachi : Item\n\n-- Axioms from the textual context\naxiom ax1 : \u2200 x, AppropriateAllAges x \u2192 ChildrenCanWatchWithoutGuidance x\naxiom ax2 : \u2200 x, ExcessiveEroticViolentContent x \u2192 \u00ac ChildrenCanWatchWithoutGuidance x\naxiom ax3 : \u2200 x, RatedGA x \u2192 AppropriateAllAges x\naxiom ax4 : \u2200 x, FamilyFriendlyAnimated x \u2192 RatedGA x\naxiom ax5 : \u2200 x, FrozenSeries x \u2192 FamilyFriendlyAnimated x\naxiom ax6 : Film Hachi\naxiom ax7 : FamilyFriendlyAnimated Hachi \u2228 AppropriateAllAges Hachi\n\n-- Derived facts\nlemma Hachi_appropriate : AppropriateAllAges Hachi :=\nby\n  cases ax7 with\n  | inl hFam =>\n      have hGA : RatedGA Hachi := ax4 Hachi hFam\n      exact ax3 Hachi hGA\n  | inr hApp =>\n      exact hApp\n\nlemma Hachi_children_can_watch : ChildrenCanWatchWithoutGuidance Hachi :=\nby\n  exact ax1 Hachi Hachi_appropriate\n\nlemma Hachi_not_excessive : \u00ac ExcessiveEroticViolentContent Hachi :=\nby\n  intro hEx\n  have hNotCW : \u00ac ChildrenCanWatchWithoutGuidance Hachi := ax2 Hachi hEx\n  exact hNotCW Hachi_children_can_watch\n\n-- Notes toward the questions:\n-- Q1 asks for RatedGA Hachi. From ax7 we get AppropriateAllAges Hachi (as shown),\n-- but ax3 is only one-way (RatedGA \u2192 Appropriate), so we cannot derive RatedGA Hachi.\n-- Neither its negation is derivable from the given axioms. Hence Unknown.\n\n-- Q2 asks for ExcessiveEroticViolentContent Hachi \u2228 FrozenSeries Hachi.\n-- We proved \u00ac ExcessiveEroticViolentContent Hachi, but we have no information to prove\n-- FrozenSeries Hachi or its negation. Thus the disjunction is not provable nor refutable. Unknown.\n\n-- Q3 asks for (ExcessiveEroticViolentContent Hachi \u2227 FrozenSeries Hachi) \u2228 (\u00acExcessiveEroticViolentContent Hachi \u2227 \u00acFrozenSeries Hachi).\n-- Using Hachi_not_excessive, this reduces to False \u2228 (True \u2227 \u00acFrozenSeries Hachi), i.e., \u00acFrozenSeries Hachi,\n-- which we cannot prove or refute from the axioms. Hence Unknown.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1327,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1328,
        "conclusion": "\"Hachi: A dog's Tale\" contains excessive erotic and violent content or is in the \"Frozen\" series or both.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1329,
        "conclusion": "\"Hachi: A dog's Tale\" either contains excessive erotic and violent content and is a film in the \"Frozen\" series, or it neither contains excessive erotic and violent content nor is a film in the \"Frozen\" series.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 46,
    "premises": "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals.\nHeck cattle were bred back in the 1920s to resemble the aurochs.\nHeck cattle are animals.\nAurochs are animals.\nSome animals to be bred back resemble extinct animals.",
    "model_response": "Lean formalization and attempt:\n\nuniverse u\n\nconstant U : Type u\n\n-- Predicates on entities\nconstant Animal : U \u2192 Prop\nconstant HeckCattle : U \u2192 Prop\nconstant Aurochs : U \u2192 Prop\nconstant Extinct : U \u2192 Prop\nconstant BredBack : U \u2192 Prop\nconstant ArtificiallySelected : U \u2192 Prop\nconstant Resembles : U \u2192 U \u2192 Prop\n\n-- Axioms from the textual context\n-- 1) Breeding back is a form of artificial selection\naxiom ax1 : \u2200 x, BredBack x \u2192 ArtificiallySelected x\n-- 2) Heck cattle were bred back (in the 1920s)\naxiom ax2 : \u2203 x, HeckCattle x \u2227 BredBack x\n-- 3) Heck cattle are animals\naxiom ax3 : \u2200 x, HeckCattle x \u2192 Animal x\n-- 4) Aurochs are animals\naxiom ax4 : \u2200 x, Aurochs x \u2192 Animal x\n-- 5) Some animals to be bred back resemble extinct animals\naxiom ax5 : \u2203 x y, Animal x \u2227 BredBack x \u2227 Extinct y \u2227 Animal y \u2227 Resembles x y\n\n-- Q1: Some Heck cattle are artificially selected.\ntheorem Q1 : \u2203 x, HeckCattle x \u2227 ArtificiallySelected x := by\n  obtain \u27e8x, hx, hb\u27e9 := ax2\n  have ha : ArtificiallySelected x := ax1 x hb\n  exact \u27e8x, And.intro hx ha\u27e9\n-- Proven: True\n\n-- Q2: Aurochs are extinct. (Formalized as \u2200 y, Aurochs y \u2192 Extinct y.)\n-- This does not follow from the given axioms, nor does its negation.\n-- Hence: Unknown\n\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 133,
        "conclusion": "Some Heck cattle are artificially selected.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 134,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 483,
    "premises": "Everyone who can register to vote in the United States can participate in the 2024 United States presidential election.\nIf someone has United States citizenship, then they can register to vote in the United States.\nA person either has United States citizenship or Taiwanese citizenship.\nNo Russian Federation officials hold Taiwanese citizenship. \nVladimir neither holds Taiwanese citizenship nor is he a manager at Gazprom. \nEkaterina she can register to vote in the United States, or she is a Russian federation official.",
    "model_response": "Lean formalization and proof attempts:\n\nWe model people as a type Person with individuals Vladimir and Ekaterina. Predicates:\n- CanRegisterUS : Person \u2192 Prop\n- CanParticipate2024 : Person \u2192 Prop\n- USCitizen : Person \u2192 Prop\n- TaiwaneseCitizen : Person \u2192 Prop\n- RussianFederationOfficial : Person \u2192 Prop\n- ManagerGazprom : Person \u2192 Prop\n\nAxioms from the context:\n1. \u2200 x, CanRegisterUS x \u2192 CanParticipate2024 x\n2. \u2200 x, USCitizen x \u2192 CanRegisterUS x\n3. \u2200 x, USCitizen x \u2228 TaiwaneseCitizen x\n4. \u2200 x, RussianFederationOfficial x \u2192 \u00ac TaiwaneseCitizen x\n5. \u00ac TaiwaneseCitizen Vladimir \u2227 \u00ac ManagerGazprom Vladimir\n6. CanRegisterUS Ekaterina \u2228 RussianFederationOfficial Ekaterina\n\nLean code:\n\nuniverse u\n\nconstant Person : Type\nconstant Vladimir Ekaterina : Person\n\nconstant CanRegisterUS : Person \u2192 Prop\nconstant CanParticipate2024 : Person \u2192 Prop\nconstant USCitizen : Person \u2192 Prop\nconstant TaiwaneseCitizen : Person \u2192 Prop\nconstant RussianFederationOfficial : Person \u2192 Prop\nconstant ManagerGazprom : Person \u2192 Prop\n\naxiom h1 : \u2200 x, CanRegisterUS x \u2192 CanParticipate2024 x\naxiom h2 : \u2200 x, USCitizen x \u2192 CanRegisterUS x\naxiom h3 : \u2200 x, USCitizen x \u2228 TaiwaneseCitizen x\naxiom h4 : \u2200 x, RussianFederationOfficial x \u2192 \u00ac TaiwaneseCitizen x\naxiom h5 : \u00ac TaiwaneseCitizen Vladimir \u2227 \u00ac ManagerGazprom Vladimir\naxiom h6 : CanRegisterUS Ekaterina \u2228 RussianFederationOfficial Ekaterina\n\nlemma v_not_TW : \u00ac TaiwaneseCitizen Vladimir := And.left h5\nlemma v_not_manager : \u00ac ManagerGazprom Vladimir := And.right h5\n\nlemma v_US : USCitizen Vladimir := by\n  have disj := h3 Vladimir\n  have ntw := v_not_TW\n  cases disj with\n  | inl hUS => exact hUS\n  | inr hTW => exact False.elim (ntw hTW)\n\nlemma v_reg : CanRegisterUS Vladimir := h2 Vladimir v_US\nlemma v_part : CanParticipate2024 Vladimir := h1 Vladimir v_reg\n\nlemma e_reg : CanRegisterUS Ekaterina := by\n  cases h6 with\n  | inl hreg => exact hreg\n  | inr hOff =>\n      have ntw : \u00ac TaiwaneseCitizen Ekaterina := h4 Ekaterina hOff\n      have disj := h3 Ekaterina\n      have us : USCitizen Ekaterina := by\n        cases disj with\n        | inl hUS => exact hUS\n        | inr hTW => exact False.elim (ntw hTW)\n      exact h2 Ekaterina us\n\nlemma e_part : CanParticipate2024 Ekaterina := h1 Ekaterina e_reg\n\n-- Q3: Ekaterina can participate in the 2024 election or is a manager at Gazprom.\ntheorem Q3_true : CanParticipate2024 Ekaterina \u2228 ManagerGazprom Ekaterina :=\n  Or.inl e_part\n\n-- Q4: Ekaterina can participate in the 2024 election or Vladimir is a manager at Gazprom.\ntheorem Q4_true : CanParticipate2024 Ekaterina \u2228 ManagerGazprom Vladimir :=\n  Or.inl e_part\n\n-- Q5: It is not true that Ekaterina can register to vote and Vladimir can participate.\n-- We show the negation is false by proving the conjunction holds.\ntheorem Q5_neg_of_statement : CanRegisterUS Ekaterina \u2227 CanParticipate2024 Vladimir :=\n  And.intro e_reg v_part\n\n-- For Q1 and Q2 (about Vladimir being/not being an RF official), neither the statement nor its negation\n-- is derivable from the given axioms.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: True\n4: True\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1410,
        "conclusion": "Vladimir is a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1411,
        "conclusion": "Vladimir is not a Russian federation official",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1412,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1413,
        "conclusion": "Ekaterina can participate in the 2024 United States presidential election or Vladimir is a manager at Gazprom.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1414,
        "conclusion": "It is not true that Ekaterina can register to vote in the United States and Vladimir can participate in the 2024 United States presidential election.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 80,
    "premises": "New Vessel Press is a publishing house specializing in translating foreign literature into English.\nAll of New Vessel Press's published books are in English.\nNeapolitan Chronicles is a book published by New Vessel Press.\nNeapolitan Chronicles was translated from Italian.\nPalace of Flies is a book published by New Vessel Press.",
    "model_response": "Lean formalization and attempt:\n\n-- Types and constants\nconstant Book : Type\nconstant NeapolitanChronicles : Book\nconstant PalaceOfFlies : Book\nconstant HarryPotter : Book\n\n-- Predicates\nconstant PublishedByNVP : Book \u2192 Prop\nconstant English : Book \u2192 Prop\nconstant TranslatedFromItalian : Book \u2192 Prop\n\n-- Axioms from the context\naxiom all_nvp_books_english : \u2200 b, PublishedByNVP b \u2192 English b\naxiom nc_published : PublishedByNVP NeapolitanChronicles\naxiom nc_translated_it : TranslatedFromItalian NeapolitanChronicles\naxiom pf_published : PublishedByNVP PalaceOfFlies\n\n-- Q1: Neapolitan Chronicles is an English book\ntheorem q1 : English NeapolitanChronicles :=\n  all_nvp_books_english NeapolitanChronicles nc_published\n\n-- Q2: Harry Potter was published by New Vessel Press\n-- Not provable from the given axioms, and its negation is also not derivable.\n\n-- Q3: Palace of Flies was translated from Italian\n-- Not provable from the given axioms, and its negation is also not derivable.\n-- We can prove it is in English:\ntheorem pf_english : English PalaceOfFlies :=\n  all_nvp_books_english PalaceOfFlies pf_published\n\nANSWERS:\n1: True\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 243,
        "conclusion": "Neapolitan Chronicles is an English book.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 244,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 245,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 363,
    "premises": "All hydrocarbons are organic compounds .\nAll alkanes are hydrocarbons\nAll organic compounds are chemical compounds.\nAll organic compounds contain carbon.\nNo chemical compounds contain only one element.\nThe mixture either both is a chemical compound and contains only one element, or neither. ",
    "model_response": "ANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 964,
        "conclusion": "The mixture contains carbon.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 965,
        "conclusion": "The mixture is an alkane and contains carbon.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 966,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 258,
    "premises": "All humans are mortal.\nAll Greeks are humans.",
    "model_response": "Lean formalization and attempt:\n\nWe model a domain U with predicates Human, Greek, Mortal : U \u2192 Prop and assumptions:\n- h1: \u2200 x, Human x \u2192 Mortal x\n- h2: \u2200 x, Greek x \u2192 Human x\n\nFrom these, we can derive only that all Greeks are mortal, i.e., \u2200 x, Greek x \u2192 Mortal x. To conclude that some Greek is mortal, we would also need an existence assumption \u2203 x, Greek x.\n\nLean code:\n\nuniverse u\n\nsection\nvariable {U : Type u}\nvariable (Human Greek Mortal : U \u2192 Prop)\nvariable (h1 : \u2200 x, Human x \u2192 Mortal x)\nvariable (h2 : \u2200 x, Greek x \u2192 Human x)\n\n-- All Greeks are mortal (derivable)\nlemma greek_implies_mortal : \u2200 x, Greek x \u2192 Mortal x := by\n  intro x hx\n  exact h1 x (h2 x hx)\n\n-- If some Greek exists, then some mortal Greek exists (derivable)\ntheorem ex_greek_then_ex_mortal_greek :\n  (\u2203 x, Greek x) \u2192 \u2203 x, Greek x \u2227 Mortal x := by\n  intro \u27e8x, hx\u27e9\n  refine \u27e8x, ?_\u27e9\n  exact And.intro hx (h1 x (h2 x hx))\nend\n\n-- Independence demonstration via two concrete models\n\n-- Model 0: no Greeks exist; premises hold; existential is false\ndef U0 := PUnit\ndef Human0 : U0 \u2192 Prop := fun _ => False\ndef Greek0 : U0 \u2192 Prop := fun _ => False\ndef Mortal0 : U0 \u2192 Prop := fun _ => False\n\nlemma h1_0 : \u2200 x, Human0 x \u2192 Mortal0 x := by\n  intro x hx; cases hx\nlemma h2_0 : \u2200 x, Greek0 x \u2192 Human0 x := by\n  intro x hx; cases hx\n\nlemma not_ex_mortal_greek_in_model0 : \u00ac \u2203 x, Greek0 x \u2227 Mortal0 x := by\n  intro h; rcases h with \u27e8x, hx\u27e9\n  rcases hx with \u27e8hg, hm\u27e9\n  cases hg\n\n-- Model 1: a Greek exists; premises hold; existential is true\ndef Human1 : PUnit \u2192 Prop := fun _ => True\ndef Greek1 : PUnit \u2192 Prop := fun _ => True\ndef Mortal1 : PUnit \u2192 Prop := fun _ => True\n\nlemma h1_1 : \u2200 x, Human1 x \u2192 Mortal1 x := by\n  intro x hx; trivial\nlemma h2_1 : \u2200 x, Greek1 x \u2192 Human1 x := by\n  intro x hx; trivial\n\nlemma ex_mortal_greek_in_model1 : \u2203 x, Greek1 x \u2227 Mortal1 x := by\n  refine \u27e8PUnit.unit, ?_\u27e9\n  exact And.intro trivial trivial\n\nConclusion:\n- From the given premises alone, we cannot prove \u2203 x, Greek x \u2227 Mortal x.\n- We also cannot prove its negation from the premises alone.\n- Therefore, the truth of \u201cSome Greeks are mortal\u201d is not entailed; it is uncertain without an existence premise.\n\nANSWERS:\n1: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 702,
        "conclusion": "Some Greeks are mortal.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 435,
    "premises": "None of the students who currently work in the library are from the computer science department. \nAll of the students with part-time jobs offered by the university currently work in the library. \nAll of the students who are taking the database course are from the computer science department. \nAll of the students taking a class with Professor David are taking the database course. \nAll students working in the lab are taking a class with Professor David.\nJames is a student working in the lab. \nJames doesn't work in the lab or have a part-time job offered by the university.",
    "model_response": "Lean formalization and proofs:\n\nuniverse u\n\nconstant Person : Type u\n\n-- Predicates\nconstant WorksInLibrary : Person \u2192 Prop\nconstant FromCS : Person \u2192 Prop\nconstant UniPTJob : Person \u2192 Prop\nconstant TakesDB : Person \u2192 Prop\nconstant TakesWithDavid : Person \u2192 Prop\nconstant WorksInLab : Person \u2192 Prop\n\n-- Individual\nconstant James : Person\n\n-- Premises\naxiom A1 : \u2200 x, WorksInLibrary x \u2192 \u00ac FromCS x\naxiom A2 : \u2200 x, UniPTJob x \u2192 WorksInLibrary x\naxiom A3 : \u2200 x, TakesDB x \u2192 FromCS x\naxiom A4 : \u2200 x, TakesWithDavid x \u2192 TakesDB x\naxiom A5 : \u2200 x, WorksInLab x \u2192 TakesWithDavid x\naxiom A6 : WorksInLab James\n-- Natural-language \u201cor\u201d taken as disjunction over the two clauses\naxiom A7 : \u00ac WorksInLab James \u2228 \u00ac UniPTJob James\n\n-- Derived facts\nlemma james_takes_db : TakesDB James := by\n  have htd : TakesWithDavid James := A5 James A6\n  exact A4 James htd\n\nlemma james_from_cs : FromCS James := A3 James james_takes_db\n\nlemma not_uniPT : \u00ac UniPTJob James := by\n  intro hpt\n  have hLib : WorksInLibrary James := A2 James hpt\n  have notCS : \u00ac FromCS James := A1 James hLib\n  exact notCS james_from_cs\n\n-- Answers to questions\n-- Q1: James has a university part-time job. We prove its negation.\nlemma Q1 : \u00ac UniPTJob James := not_uniPT\n\n-- Q2: James does not have a university part-time job. We prove it.\nlemma Q2 : \u00ac UniPTJob James := not_uniPT\n\n-- Q3: James either takes DB or has a university part-time job. We prove the disjunction via the left disjunct.\nlemma Q3 : TakesDB James \u2228 UniPTJob James := Or.inl james_takes_db\n\n-- Q4: James takes the database course. We proved this above.\nlemma Q4 : TakesDB James := james_takes_db\n\nANSWERS:\n1: False\n2: True\n3: True\n4: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 1244,
        "conclusion": "James has a part-time job offered by the university.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1245,
        "conclusion": "James does not have a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1246,
        "conclusion": "James either takes the database course or has a part-time job offered by the university.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1247,
        "conclusion": "James takes the database course.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.75
  },
  {
    "story_id": 217,
    "premises": "If George likes music, he wants to compose.\nIf George has access to a program, he can compose.\nIf George can compose and wants to compose, he will compose.",
    "model_response": "Lean translation and attempt:\n\nWe model the domain with propositions:\n- L: George likes music\n- W: George wants to compose\n- A: George has access to a program\n- C: George can compose\n- P: George will compose\n\nAssumptions:\n- h1: L \u2192 W\n- h2: A \u2192 C\n- h3: (C \u2227 W) \u2192 P\n\nGoal 1: (L \u2227 A) \u2192 P\nProof in Lean:\n-- Variables and assumptions\nvariable (L W A C P : Prop)\nvariable (h1 : L \u2192 W) (h2 : A \u2192 C) (h3 : C \u2227 W \u2192 P)\n\ntheorem Q1 : (L \u2227 A) \u2192 P := by\n  intro h\n  rcases h with \u27e8hl, ha\u27e9\n  have hw : W := h1 hl\n  have hc : C := h2 ha\n  exact h3 \u27e8hc, hw\u27e9\n\nThis is provable.\n\nGoal 2: (\u00acP) \u2192 \u00acC\nWe cannot derive this from the assumptions. What we can derive is the contrapositive form of h3:\n(\u00acP) \u2192 (\u00acC \u2228 \u00acW)\nProof in Lean:\ntheorem Q2_we_can_prove : (\u00ac P) \u2192 (\u00ac C \u2228 \u00ac W) := by\n  intro hnP\n  have hnot : \u00ac (C \u2227 W) := by\n    intro hCW\n    exact hnP (h3 hCW)\n  classical\n  by_cases hc : C\n  \u00b7 right\n    intro hw\n    exact hnot \u27e8hc, hw\u27e9\n  \u00b7 left; exact hc\n\nSince (\u00acP) \u2192 \u00acC does not follow and its negation also cannot be proved from the given assumptions, the status of Question 2 is Unknown.\n\nANSWERS:\n1: True\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 618,
        "conclusion": "If George likes music and has access to a program, he will compose.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 619,
        "conclusion": "If George will not compose, George can not compose.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 292,
    "premises": "A hawk never swims. \nSome birds are hawks.",
    "model_response": "Lean formalization and proof attempt:\n\n- Domain: a type U of individuals.\n- Predicates: Bird, Hawk, Swim : U \u2192 Prop.\n- Premises:\n  1) \u2200 x, Hawk x \u2192 \u00ac Swim x  (hawks never swim)\n  2) \u2203 x, Bird x \u2227 Hawk x    (some birds are hawks)\n- Claim being evaluated: \u2200 x, Bird x \u2192 Swim x (all birds swim)\n\nLean code:\n\nuniverse u\n\nconstant U : Type u\nconstant Bird Hawk Swim : U \u2192 Prop\n\naxiom hawk_never_swims : \u2200 x : U, Hawk x \u2192 \u00ac Swim x\naxiom some_birds_are_hawks : \u2203 x : U, Bird x \u2227 Hawk x\n\ntheorem Q1_false : \u00ac (\u2200 x : U, Bird x \u2192 Swim x) := by\n  intro hAll\n  rcases some_birds_are_hawks with \u27e8a, haB, haH\u27e9\n  have hSwim : Swim a := hAll a haB\n  have hNot : \u00ac Swim a := hawk_never_swims a haH\n  exact hNot hSwim\n\nExplanation: From the existence of a bird that is a hawk and the fact that hawks never swim, we obtain a bird that does not swim, contradicting \u201call birds swim.\u201d Thus we have proved the negation of the statement.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 736,
        "conclusion": "All birds swim.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 318,
    "premises": "Some show airing at 8 pm on Monday gives out roses on TV.\nIf a show gives out roses on TV, then the show is an episode of The Bachelor.\nThe Bachelor portrays the lives of real people.\nAll shows portraying the lives of real people are reality TV shows.\nBreaking Bad is a show.\nBreaking Bad is not a reality TV show.",
    "model_response": "Lean formalization and attempt:\n\n- Domain: Show\n- Predicates:\n  - Monday8 : Show \u2192 Prop  // \u201cairs at 8 pm on Monday\u201d\n  - GivesRoses : Show \u2192 Prop  // \u201cgives out roses on TV\u201d\n  - EpisodeOfBachelor : Show \u2192 Prop  // \u201cis an episode of The Bachelor\u201d\n  - PortraysReal : Show \u2192 Prop  // \u201cportrays the lives of real people\u201d\n  - RealityTV : Show \u2192 Prop  // \u201cis a reality TV show\u201d\n- Constants:\n  - BreakingBad : Show\n\nAxioms from the text:\n1) \u2203 s, Monday8 s \u2227 GivesRoses s\n2) \u2200 s, GivesRoses s \u2192 EpisodeOfBachelor s\n3) Interpretation of \u201cThe Bachelor portrays the lives of real people\u201d: episodes of The Bachelor portray the lives of real people:\n   \u2200 s, EpisodeOfBachelor s \u2192 PortraysReal s\n4) \u2200 s, PortraysReal s \u2192 RealityTV s\n5) \u00ac RealityTV BreakingBad\n\nLean 4 code:\n\nuniverse u\n\nconstant Show : Type u\n\nconstants\n  Monday8 : Show \u2192 Prop\n  GivesRoses : Show \u2192 Prop\n  EpisodeOfBachelor : Show \u2192 Prop\n  PortraysReal : Show \u2192 Prop\n  RealityTV : Show \u2192 Prop\n  BreakingBad : Show\n\naxioms\n  exists_mon8_roses : \u2203 s : Show, Monday8 s \u2227 GivesRoses s\n  gives_implies_episode : \u2200 s, GivesRoses s \u2192 EpisodeOfBachelor s\n  episode_portrays_real : \u2200 s, EpisodeOfBachelor s \u2192 PortraysReal s\n  portrays_implies_reality : \u2200 s, PortraysReal s \u2192 RealityTV s\n  breakingbad_not_reality : \u00ac RealityTV BreakingBad\n\nlemma roses_implies_reality (s : Show) : GivesRoses s \u2192 RealityTV s :=\n  fun h => (portrays_implies_reality s) ((episode_portrays_real s) ((gives_implies_episode s) h))\n\ntheorem no_roses_breakingbad : \u00ac GivesRoses BreakingBad :=\n  fun h => breakingbad_not_reality (roses_implies_reality BreakingBad h)\n\n-- Q2: BB is a TV show in which roses are given out on Monday at 8 pm\n-- We show its negation holds, hence the statement is False.\ntheorem Q2_neg : \u00ac (Monday8 BreakingBad \u2227 GivesRoses BreakingBad) :=\n  fun h => no_roses_breakingbad h.right\n\n-- Q3: If roses are given out during BB, then it is on Monday at 8 pm\n-- This is vacuously true since BB cannot give out roses.\ntheorem Q3 : GivesRoses BreakingBad \u2192 Monday8 BreakingBad :=\n  fun h => False.elim (no_roses_breakingbad h)\n\nComments on provability:\n- Q1 (\u201cMonday8 BreakingBad\u201d) is neither derivable nor refutable from the axioms: there is no information linking Monday8 to Breaking Bad except through roses, and we proved \u00acGivesRoses BreakingBad; but that does not prohibit Monday8 BreakingBad by itself. Thus Unknown.\n- Q2 is False because it entails GivesRoses BreakingBad, which contradicts \u00acRealityTV BreakingBad via the given rules.\n- Q3 is True (vacuously), since \u00acGivesRoses BreakingBad.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 802,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 803,
        "conclusion": "Breaking Bad is a TV show in which roses are given out on Monday at 8 pm.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 804,
        "conclusion": "If roses are given out during Breaking Bad, then it is on Monday at 8 pm.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 107,
    "premises": "Heinrich Schmidt was a German politician. \nHeinrich Schmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.",
    "model_response": "Lean formalization and proofs:\n\nWe model individuals and predicates:\n- Person: type of people\n- HS: the individual Heinrich Schmidt\n- German, Russian, Politician: predicates on Person\n- MemberPrussianSP: membership in the Prussian State Parliament\n- MemberNaziReichstag: membership in the Nazi Reichstag\n\nFacts from the context:\n- HS is German and a Politician\n- HS is a member of both the Prussian State Parliament and the Nazi Reichstag\n\nLean code:\n\nuniverse u\n\nconstant Person : Type u\nconstant HS : Person\n\nconstant German : Person \u2192 Prop\nconstant Russian : Person \u2192 Prop\nconstant Politician : Person \u2192 Prop\nconstant MemberPrussianSP : Person \u2192 Prop\nconstant MemberNaziReichstag : Person \u2192 Prop\n\naxiom HS_German : German HS\naxiom HS_Politician : Politician HS\naxiom HS_Prussian : MemberPrussianSP HS\naxiom HS_Nazi : MemberNaziReichstag HS\n\n-- Q1: HS was German or Russian or both\ntheorem Q1_true : German HS \u2228 Russian HS \u2228 (German HS \u2227 Russian HS) :=\n  Or.inl HS_German\n-- Proven, so True.\n\n-- Q2: Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag\ntheorem Q2_true : \u2203 x, German x \u2227 Politician x \u2227 MemberPrussianSP x \u2227 MemberNaziReichstag x := by\n  refine \u27e8HS, ?_\u27e9\n  exact And.intro HS_German (And.intro HS_Politician (And.intro HS_Prussian HS_Nazi))\n-- Proven, so True.\n\n-- Q3: No politicians are part of the Nazi Reichstag\ndef Q3_stmt : Prop := \u2200 x, Politician x \u2192 \u00ac MemberNaziReichstag x\n\n-- We prove the negation (i.e., Q3 is false) by providing HS as a counterexample\ntheorem Q3_false : \u00ac Q3_stmt := by\n  intro h\n  have : \u00ac MemberNaziReichstag HS := h HS HS_Politician\n  exact this HS_Nazi\n-- Negation is provable, so the original statement is False.\n\nANSWERS:\n1: True\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 323,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 324,
        "conclusion": "Some German politician was part of both the Prussian State Parliament and the Nazi Reichstag.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 325,
        "conclusion": "No politicians are part of the Nazi Reichstag.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 386,
    "premises": "If something is a deadly disease, then it comes with a low survival rate. \nSevere cancers are deadly diseases.\nBile duct cancer is a severe form cancer. \nAll Cholangiocarcinoma is bile duct cancer.\nMild flu comes with a low survival rate.\nColorectal cancer is not both a bile duct cancer and with a low survival rate.",
    "model_response": "Lean formalization and attempt at proofs:\n\nWe model diseases as a type, with predicates for properties and kinds of diseases, and a constant for colorectal cancer.\n\n- Deadly x \u2192 Low x\n- Severe x \u2192 Deadly x\n- BDC x \u2192 Severe x\n- Chol x \u2192 BDC x\n- MildFlu x \u2192 Low x\n- \u00ac(BDC colorectal \u2227 Low colorectal)\n\nFrom these we derive:\n- For any x, BDC x \u2192 Low x (by chaining the first three axioms).\n- Hence \u00acBDC colorectal (otherwise we would have both BDC and Low for colorectal, contradicting the last axiom).\n- Hence \u00acChol colorectal (since Chol \u2192 BDC).\n\nWith \u00acBDC colorectal and \u00acChol colorectal, the antecedent of Q2 is impossible, making Q2 vacuously true. For Q3, since \u00acChol colorectal, any statement that conjunctively requires Chol colorectal is false.\n\nLean 4 sketch:\n\nnamespace Reasoning\n\nuniverse u\n\nconstant Disease : Type u\n\nconstant Deadly : Disease \u2192 Prop\nconstant Low : Disease \u2192 Prop\nconstant Severe : Disease \u2192 Prop\nconstant BDC : Disease \u2192 Prop\nconstant Chol : Disease \u2192 Prop\nconstant MildFlu : Disease \u2192 Prop\n\nconstant colorectal : Disease\n\naxioms\n  (H1 : \u2200 x, Deadly x \u2192 Low x)\n  (H2 : \u2200 x, Severe x \u2192 Deadly x)\n  (H3 : \u2200 x, BDC x \u2192 Severe x)\n  (H4 : \u2200 x, Chol x \u2192 BDC x)\n  (H5 : \u2200 x, MildFlu x \u2192 Low x)\n  (H6 : \u00ac (BDC colorectal \u2227 Low colorectal))\n\nlemma bdc_to_low (x : Disease) : BDC x \u2192 Low x := by\n  intro hb\n  exact H1 x (H2 x (H3 x hb))\n\nlemma not_bdc_col : \u00ac BDC colorectal := by\n  intro hb\n  have hl : Low colorectal := bdc_to_low colorectal hb\n  exact H6 \u27e8hb, hl\u27e9\n\nlemma not_chol_col : \u00ac Chol colorectal := by\n  intro hc\n  have hb : BDC colorectal := H4 colorectal hc\n  exact not_bdc_col hb\n\n-- Q1: Severe colorectal? Neither provable nor refutable from given axioms.\n\ntheorem Q2_true : (BDC colorectal \u2228 Chol colorectal) \u2192 (BDC colorectal \u2227 MildFlu colorectal) := by\n  intro h\n  have : False := by\n    cases h with\n    | inl hb => exact not_bdc_col hb\n    | inr hc => exact not_bdc_col (H4 colorectal hc)\n  exact False.elim this\n\ntheorem Q3_false :\n  \u00ac ((Chol colorectal \u2227 (MildFlu colorectal \u2228 BDC colorectal)) \u2228\n     (Chol colorectal \u2227 MildFlu colorectal \u2227 BDC colorectal)) := by\n  intro h\n  cases h with\n  | inl h1 => exact not_chol_col h1.left\n  | inr h2 => exact not_chol_col h2.left\n\nend Reasoning\n\nConclusions:\n- Q1 cannot be proved or refuted from the premises.\n- Q2 is provable (vacuously true because the antecedent is impossible).\n- Q3 is refutable; we proved its negation.\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1032,
        "conclusion": "Colorectal cancer is a kind of severe cancer",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1033,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1034,
        "conclusion": "Colorectal cancer is a form of Cholangiocarcinoma and it is a kind of mild flu or a kind of bile duct cancer, or all of the above.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 355,
    "premises": "All people who eat salads regularly are very conscious about their health and eating habits.\nAll people who grew up in health-conscious childhood homes eat salads regularly.\nAll people who fulfill their daily nutritional intakes grew up in health-conscious childhood homes.\nAll people who disregard their physical well-being are not very conscious about their health and eating habits.\nIf people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nTaylor either grew up in a health-conscious childhood home and disregard her physical well-being, or she did neither.",
    "model_response": "Lean formalization and attempt:\n\n-- We model the domain and predicates.\nset_option autoImplicit false\n\nuniverse u\nconstant Person : Type u\nconstant R C H F D G : Person \u2192 Prop  -- eats salads regularly, very conscious, grew up in health-conscious home, fulfills daily nutrition, disregards well-being, visits gym daily\nconstant taylor : Person\n\n-- Axioms from the text\naxiom hR_C    : \u2200 x, R x \u2192 C x\naxiom hH_R    : \u2200 x, H x \u2192 R x\naxiom hF_H    : \u2200 x, F x \u2192 H x\naxiom hD_notC : \u2200 x, D x \u2192 \u00ac C x\naxiom hG_F    : \u2200 x, G x \u2192 F x\naxiom taylor_either : (H taylor \u2227 D taylor) \u2228 (\u00ac H taylor \u2227 \u00ac D taylor)\n\n-- Derivations:\n-- 1) H \u2227 D is impossible (it yields C \u2227 \u00acC)\nlemma not_H_and_D : \u00ac (H taylor \u2227 D taylor) := by\n  intro h\n  have ht : H taylor := h.left\n  have dt : D taylor := h.right\n  have rt : R taylor := hH_R taylor ht\n  have ct : C taylor := hR_C taylor rt\n  have nct : \u00ac C taylor := hD_notC taylor dt\n  exact nct ct\n\n-- 2) Therefore the given disjunction forces the second case: \u00acH \u2227 \u00acD\nlemma notH_and_notD : \u00ac H taylor \u2227 \u00ac D taylor := by\n  cases taylor_either with\n  | inl hhd =>\n      exact False.elim (not_H_and_D hhd)\n  | inr hnn =>\n      exact hnn\n\n-- 3) From G \u2192 F \u2192 H and \u00acH, we get \u00acG (modus tollens)\nlemma notG : \u00ac G taylor := by\n  intro gt\n  have ft : F taylor := hG_F taylor gt\n  have ht : H taylor := hF_H taylor ft\n  exact (notH_and_notD.left) ht\n\n-- Consequences matching the questions:\n-- Q2 is false (we proved \u00acG taylor)\ntheorem Q2_neg : \u00ac G taylor := notG\n\n-- Q3 is true (we have \u00acH taylor and \u00acG taylor)\ntheorem Q3 : \u00ac H taylor \u2227 \u00ac G taylor := And.intro notH_and_notD.left notG\n\n-- For Q1 (R taylor), neither R taylor nor \u00ac R taylor follows from the axioms above.\n\nReasoning summary:\n- From H \u2192 R \u2192 C and D \u2192 \u00acC, H \u2227 D is impossible. Thus, Taylor must satisfy \u00acH \u2227 \u00acD.\n- From G \u2192 F \u2192 H and \u00acH, we conclude \u00acG. Hence Q2 is false, and Q3 (\u00acH \u2227 \u00acG) is true.\n- Nothing in the premises lets us derive R or \u00acR from \u00acH and the other facts; thus Q1 is undetermined.\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 941,
        "conclusion": "Taylor eats salads regularly.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 942,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 943,
        "conclusion": "Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 51,
    "premises": "The summer Olympic games is a sporting event. \nThe last summer Olympic games was in Tokyo.\nThe United States won the most medals in Tokyo. ",
    "model_response": "Lean analysis:\n\nWe model entities and predicates:\n- Types: Event, Place, Country\n- Constants: SummerOlympics, LastSummerOlympics, WorldChampionships, TokyoOlympics : Event; Tokyo : Place; UnitedStates : Country\n- Predicates: SportingEvent : Event \u2192 Prop; HeldIn : Event \u2192 Place \u2192 Prop; WonMostMedalsAt : Country \u2192 Event \u2192 Prop\n\nFacts from the text:\n- h1: SportingEvent SummerOlympics\n- h2: HeldIn LastSummerOlympics Tokyo\n- h2_eq: LastSummerOlympics = TokyoOlympics\n- h3: WonMostMedalsAt UnitedStates TokyoOlympics\n\nInterpretation note: \u201cThe United States won the most medals in Tokyo\u201d is formalized as h3, i.e., at the Tokyo Olympics event. The statement \u201cThe last summer Olympic games was in Tokyo\u201d is captured via h2 and, for alignment, via h2_eq identifying the last Summer Olympics with the Tokyo Olympics event.\n\nGoals and proofs:\n- Q1: SportingEvent WorldChampionships. There is no information connecting WorldChampionships to SportingEvent; neither the statement nor its negation is derivable from the given facts. Unknown.\n\n- Q2: \u00ac HeldIn LastSummerOlympics Tokyo. From h2 we can prove the negation of this statement:\n  q2_neg: HeldIn LastSummerOlympics Tokyo := h2\n  Hence the original statement is false.\n\n- Q3: WonMostMedalsAt UnitedStates LastSummerOlympics. Using equality h2_eq and h3:\n  q3: WonMostMedalsAt UnitedStates LastSummerOlympics\n      by rewriting h3 along h2_eq.\n\nTherefore:\n- Q1: Unknown (unprovable and irrefutable from given facts)\n- Q2: False (we can prove its negation)\n- Q3: True (we can prove the statement)\n\nANSWERS:\n1: Unknown\n2: False\n3: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 147,
        "conclusion": "The world championships is a sporting event.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 148,
        "conclusion": "The last summer Olympic games were not in Tokyo.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 149,
        "conclusion": "The United States won the most medals in the last summer Olympic games.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 259,
    "premises": "All horses have hooves.\nNo humans have hooves.",
    "model_response": "Lean translation and proof:\n\nWe model a domain U with predicates Human, Horse, HasHooves. The premises are:\n- \u2200 x, Horse x \u2192 HasHooves x\n- \u2200 x, Human x \u2192 \u00ac HasHooves x\n\nThe query statement is:\n- SomeHumansAreHorses := \u2203 x, Human x \u2227 Horse x\n\nLean code:\n\nvariable (U : Type)\nvariable (Human Horse HasHooves : U \u2192 Prop)\n\naxiom all_horses_have_hooves : \u2200 x, Horse x \u2192 HasHooves x\naxiom no_humans_have_hooves : \u2200 x, Human x \u2192 \u00ac HasHooves x\n\ndef SomeHumansAreHorses : Prop := \u2203 x, Human x \u2227 Horse x\n\ntheorem no_human_is_horse : \u00ac SomeHumansAreHorses U Human Horse HasHooves :=\nby\n  intro h\n  rcases h with \u27e8x, hx\u27e9\n  have h_hooves : HasHooves x := all_horses_have_hooves x hx.2\n  have h_no_hooves : \u00ac HasHooves x := no_humans_have_hooves x hx.1\n  exact h_no_hooves h_hooves\n\nWe have proven the negation of the statement \u201cSome humans are horses,\u201d so the statement is false.\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 703,
        "conclusion": "Some humans are horses.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 152,
    "premises": "Susan flies to LGA airport.\nThe departure and arrival can not be at the same airport.\nJohn flies from LGA airport.",
    "model_response": "Lean formalization and proof attempt:\n\n-- We model people, airports, and the flies-to/from predicates.\nuniverse u\n\nnamespace FlightNL\n\ninductive Person\n| Susan\n| John\nderiving DecidableEq\n\ninductive Airport\n| LGA\nderiving DecidableEq\n\nopen Person Airport\n\n-- Predicates\nconstant FliesTo   : Person \u2192 Airport \u2192 Prop\nconstant FliesFrom : Person \u2192 Airport \u2192 Prop\n\n-- Axiom: departure and arrival cannot be the same airport (for a given person/flight).\naxiom not_same_airport : \u2200 p a, \u00ac (FliesFrom p a \u2227 FliesTo p a)\n\n-- Facts from the text\naxiom Susan_to_LGA : FliesTo Susan LGA\naxiom John_from_LGA : FliesFrom John LGA\n\n-- The statements in question\ndef Q1_stmt : Prop := FliesFrom Susan LGA\ndef Q2_stmt : Prop := FliesTo John LGA\n\n-- We prove the negations of both statements using the incompatibility axiom.\ntheorem Q1_neg : \u00ac Q1_stmt :=\nby\n  intro hfrom\n  have h := not_same_airport Susan LGA\n  exact h \u27e8hfrom, Susan_to_LGA\u27e9\n\ntheorem Q2_neg : \u00ac Q2_stmt :=\nby\n  intro hto\n  have h := not_same_airport John LGA\n  exact h \u27e8John_from_LGA, hto\u27e9\n\nend FlightNL\n\nFrom the above, we have proved the negations of both queried statements.\n\nANSWERS:\n1: False\n2: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 442,
        "conclusion": "Susan flies from LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 443,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 441,
    "premises": "No one nice to animals is also mean to animals.\nSome grumpy people are mean to animals.\nAll animal lovers are nice to animals.\nAll pet owners love animals.\nTom is a pet owner.",
    "model_response": "Lean formalization and attempt:\n\n-- We model the domain, predicates, individual, and premises.\nuniverse u\n\nnamespace Reasoning\n\nconstant Person : Type u\nconstant Tom : Person\n\nconstant Nice Mean Grumpy AnimalLover PetOwner : Person \u2192 Prop\n\naxiom H1 : \u2200 x, Nice x \u2192 \u00ac Mean x                       -- No one nice to animals is also mean to animals.\naxiom H2 : \u2203 x, Grumpy x \u2227 Mean x                        -- Some grumpy people are mean to animals.\naxiom H3 : \u2200 x, AnimalLover x \u2192 Nice x                   -- All animal lovers are nice to animals.\naxiom H4 : \u2200 x, PetOwner x \u2192 AnimalLover x               -- All pet owners love animals.\naxiom H5 : PetOwner Tom                                  -- Tom is a pet owner.\n\n-- Derived facts about Tom\nlemma Tom_animalLover : AnimalLover Tom := H4 Tom H5\nlemma Tom_nice : Nice Tom := H3 Tom Tom_animalLover\nlemma Tom_not_mean : \u00ac Mean Tom := H1 Tom Tom_nice\n\n-- Q1: \"Tom is a grumpy person.\" We cannot prove or refute from the premises.\ndef Q1_stmt : Prop := Grumpy Tom\n\n-- Q2: \"Tom is not both a grumpy person and mean to animals.\" This is provable.\ntheorem Q2_true : \u00ac (Grumpy Tom \u2227 Mean Tom) := by\n  intro h\n  have hm : Mean Tom := h.right\n  exact Tom_not_mean hm\n\n-- Q3: \"If Tom is not both grumpy and mean to animals, then Tom is neither grumpy nor an animal lover.\"\ndef Q3_stmt : Prop := (\u00ac (Grumpy Tom \u2227 Mean Tom)) \u2192 (\u00ac Grumpy Tom \u2227 \u00ac AnimalLover Tom)\n\n-- We prove the negation of Q3_stmt using that Tom is an animal lover and not mean.\ntheorem Q3_false : \u00ac Q3_stmt := by\n  intro h\n  have hAnte : \u00ac (Grumpy Tom \u2227 Mean Tom) := Q2_true\n  have hConseq : \u00ac Grumpy Tom \u2227 \u00ac AnimalLover Tom := h hAnte\n  have hAL : AnimalLover Tom := Tom_animalLover\n  exact hConseq.right hAL\n\nend Reasoning\n\nSummary of what was proved:\n- Q1: neither provable nor refutable from the premises (Unknown).\n- Q2: proved true.\n- Q3: proved false (we proved the negation of the given implication).\n\nANSWERS:\n1: Unknown\n2: True\n3: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1268,
        "conclusion": "Tom is a grumpy person.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1269,
        "conclusion": "Tom is not both a grumpy person and mean to animals.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1270,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 64,
    "premises": "A podcast is not a novel.\nIf a person is born in American City, the person is American.\nIf a book is a novel and it is written by a person, then the person is a novel writer.\nDani Shapiro is an American writer.\nFamily History is written by Dani Shapiro.\nFamily History is a novel written in 2003.\nDani Shapiro created a podcast called Family Secrets.\nBoston is an American city.",
    "model_response": "Lean formalization and proofs sketch:\n\n-- Sorts\nconstant Person : Type\nconstant Work : Type\nconstant City : Type\n\n-- Entities\nconstant DaniShapiro : Person\nconstant FamilyHistory : Work\nconstant FamilySecrets : Work\nconstant Boston : City\n\n-- Predicates/relations\nconstant Podcast : Work \u2192 Prop\nconstant Novel : Work \u2192 Prop\nconstant WrittenBy : Work \u2192 Person \u2192 Prop\nconstant NovelWriter : Person \u2192 Prop\nconstant American : Person \u2192 Prop\nconstant Writer : Person \u2192 Prop\nconstant BornIn : Person \u2192 City \u2192 Prop\nconstant AmericanCity : City \u2192 Prop\nconstant Created : Person \u2192 Work \u2192 Prop\n\n-- Axioms from the text\naxiom podcast_not_novel : \u2200 w, Podcast w \u2192 \u00ac Novel w\naxiom born_in_american_city_implies_american : \u2200 p c, BornIn p c \u2192 AmericanCity c \u2192 American p\naxiom novel_written_by_implies_novel_writer : \u2200 b p, Novel b \u2192 WrittenBy b p \u2192 NovelWriter p\n\n-- Facts from the text\naxiom Dani_is_American_writer : American DaniShapiro \u2227 Writer DaniShapiro\naxiom FH_written_by_Dani : WrittenBy FamilyHistory DaniShapiro\naxiom FH_is_novel : Novel FamilyHistory\naxiom DS_created_FS : Podcast FamilySecrets \u2227 Created DaniShapiro FamilySecrets\naxiom Boston_is_American_city : AmericanCity Boston\n\n-- Q1: Dani Shapiro is a novel writer.\ntheorem Q1 : NovelWriter DaniShapiro :=\n  novel_written_by_implies_novel_writer FamilyHistory DaniShapiro FH_is_novel FH_written_by_Dani\n-- Proven: True\n\n-- Q2: Family Secrets is a novel.\ntheorem Q2_neg : \u00ac Novel FamilySecrets :=\nby\n  rcases DS_created_FS with \u27e8hpod, _\u27e9\n  exact podcast_not_novel FamilySecrets hpod\n-- Proven negation: False\n\n-- Q3: Dani Shapiro was born in Boston.\n-- Not derivable from given premises; no proof of BornIn DaniShapiro Boston, nor its negation.\n-- Status: Unknown\n\nANSWERS:\n1: True\n2: False\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 189,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 190,
        "conclusion": "Family Secrets is a novel.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 191,
        "conclusion": "Dani Shapiro was born in Boston.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 456,
    "premises": "Some professional basketball players are not American nationals.\nAll professional basketball players can do jump shots.\nIf someone can jump shots, they leap straight into the air.\nIf someone leaps straight into the air, they activate their leg muscles. \nYuri does not activate his leg muscles.",
    "model_response": "Lean formalization and attempt:\n\nWe model:\n- Person : Type\n- A x := x is an American national\n- P x := x is a professional basketball player\n- J x := x can do jump shots\n- L x := x leaps straight into the air\n- M x := x activates leg muscles\n- y : Person is Yuri\n\nAxioms from the text:\n- h1: \u2203 x, P x \u2227 \u00ac A x\n- h2: \u2200 x, P x \u2192 J x\n- h3: \u2200 x, J x \u2192 L x\n- h4: \u2200 x, L x \u2192 M x\n- h5: \u00ac M y\n\nLean code:\n\nsection\n\nuniverse u\nconstant Person : Type u\nconstants (A P J L M : Person \u2192 Prop)\nconstant y : Person\n\naxioms\n  (h1 : \u2203 x, P x \u2227 \u00ac A x)\n  (h2 : \u2200 x, P x \u2192 J x)\n  (h3 : \u2200 x, J x \u2192 L x)\n  (h4 : \u2200 x, L x \u2192 M x)\n  (h5 : \u00ac M y)\n\nlemma not_L_y : \u00ac L y := by\n  intro Ly\n  have My : M y := h4 y Ly\n  exact h5 My\n\nlemma not_J_y : \u00ac J y := by\n  intro Jy\n  exact not_L_y (h3 y Jy)\n\nlemma not_P_y : \u00ac P y := by\n  intro Py\n  exact not_J_y (h2 y Py)\n\n-- Q1 (A y) is not derivable from the axioms; no proof here.\n\n-- Q2: Yuri is not an American professional basketball player: \u00ac(A y \u2227 P y)\ntheorem q2 : \u00ac (A y \u2227 P y) := by\n  intro h\n  exact not_P_y h.right\n\n-- Q3: Yuri is an American professional basketball player is false\ntheorem q3_false : \u00ac (A y \u2227 P y) := q2\n\n-- Q4: If \u00acL y then A y \u2227 P y is false\ntheorem q4_false : \u00ac ((\u00ac L y) \u2192 (A y \u2227 P y)) := by\n  intro hImp\n  have hAP : A y \u2227 P y := hImp not_L_y\n  exact q2 hAP\n\n-- Q5: If \u00ac(A y \u2227 P y) then P y is false\ntheorem q5_false : \u00ac (\u00ac (A y \u2227 P y) \u2192 P y) := by\n  intro hImp\n  have hP : P y := hImp q2\n  exact not_P_y hP\n\nend\n\nConclusions from the proofs:\n- From \u00acM y and the chain of implications, we derived \u00acL y, \u00acJ y, and \u00acP y.\n- Q1 (A y) is not determined by the premises (Unknown).\n- Q2 is true since \u00acP y implies \u00ac(A y \u2227 P y).\n- Q3 is false since A y \u2227 P y contradicts \u00acP y.\n- Q4 is false because \u00acL y holds, yet A y \u2227 P y does not.\n- Q5 is false because \u00ac(A y \u2227 P y) holds while P y does not.\n\nANSWERS:\n1: Unknown\n2: True\n3: False\n4: False\n5: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 1313,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1314,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "True",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 1315,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 1316,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 1317,
        "conclusion": "If Yuri is not an American professional basketball player, then Yuri is a professional basketball player.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 280,
    "premises": "Events are either happy or sad.\nAt least one event is happy. ",
    "model_response": "Lean translation and proof attempt:\n\n-- We model events and their properties\nuniverse u\nconstant Event : Type u\nconstant Happy Sad : Event \u2192 Prop\n\n-- Translation of \"Events are either happy or sad\" as an exclusive or:\naxiom cover : \u2200 e : Event, Happy e \u2228 Sad e\naxiom exclusive : \u2200 e : Event, \u00ac (Happy e \u2227 Sad e)\n\n-- Translation of \"At least one event is happy.\"\naxiom exists_happy : \u2203 e : Event, Happy e\n\n-- Target statement: \"All events are sad.\" We will prove its negation.\ntheorem not_all_events_are_sad : \u00ac (\u2200 e : Event, Sad e) := by\n  intro allSad\n  obtain \u27e8e, heHappy\u27e9 := exists_happy\n  have heSad : Sad e := allSad e\n  have both : Happy e \u2227 Sad e := \u27e8heHappy, heSad\u27e9\n  exact (exclusive e) both\n\n-- Conclusion: We have proved the negation of \"All events are sad.\"\n\nANSWERS:\n1: False",
    "results": [
      {
        "question_num": 1,
        "example_id": 724,
        "conclusion": "All events are sad.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 140,
    "premises": "The winner of the 1992 du Maurier Classic was Steinhauer.\nSteinhauer participated in the 1992 du Maurier Classic.\nOne six-way tie was on the leaderboard, and one person in the six-way tie was from Belgium.\nDescampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nAll people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.",
    "model_response": "Lean formalization and attempt:\n\nconstant Person : Type\nconstant Event : Type\n\nconstant E1992 : Event\nconstant Steinhauer : Person\nconstant Descampe : Person\n\nconstant Winner : Event \u2192 Person \u2192 Prop\nconstant Participated : Event \u2192 Person \u2192 Prop\nconstant OnLeaderboard : Event \u2192 Person \u2192 Prop\nconstant FromBelgium : Person \u2192 Prop\nconstant InSixWayTie : Event \u2192 Person \u2192 Prop\n\n-- Axioms from the text\naxiom winner_1992 : Winner E1992 Steinhauer\naxiom steinhauer_participated_1992 : Participated E1992 Steinhauer\naxiom tie_members_on_leaderboard : \u2200 p : Person, InSixWayTie E1992 p \u2192 OnLeaderboard E1992 p\naxiom exists_belgian_in_tie : \u2203 p : Person, InSixWayTie E1992 p \u2227 FromBelgium p\naxiom descampe_belgian_and_on_leaderboard : FromBelgium Descampe \u2227 OnLeaderboard E1992 Descampe\naxiom leaderboard_participated : \u2200 p : Person, OnLeaderboard E1992 p \u2192 Participated E1992 p\n\n-- Q1: \"Steinhauer was not the winner of the 1992 du Maurier Classic.\"\n-- We prove the negation of the claim.\ntheorem Q1_negation_of_claim : Winner E1992 Steinhauer := winner_1992\ntheorem Q1_claim_is_false : (\u00ac Winner E1992 Steinhauer) \u2192 False := by\n  intro h\n  exact h winner_1992\n\n-- Q2: \"Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.\"\n-- From the axioms, this cannot be proved nor can its negation be proved.\n\n-- A derived but unused fact: Descampe participated.\ntheorem descampe_participated : Participated E1992 Descampe := by\n  have hOn : OnLeaderboard E1992 Descampe := (descampe_belgian_and_on_leaderboard).right\n  exact leaderboard_participated Descampe hOn\n\nANSWERS:\n1: False\n2: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 411,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 412,
        "conclusion": "Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      }
    ],
    "story_accuracy": 1.0
  },
  {
    "story_id": 459,
    "premises": "Jane does not like any animals that bark.\nAll dogs are animals that bark.\nJane likes all animals that jump.\nIf an animal has legs, then it jumps.\nIf an animal is terricolous, then it has legs. \nKiKi is an animal.\nIf KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.",
    "model_response": "Lean formalization and attempt:\n\nWe model a single universe of entities with predicates for Animal, Dog, Barks, Jumps, Legs, Terricolous, and a binary Likes. We introduce constants jane and kiki and encode the premises.\n\n-- Lean 4 code (sketch)\n\nuniverse u\nconstant U : Type u\n\n-- entities\nconstant jane kiki : U\n\n-- predicates\nconstant Animal Barks Dog Jumps Legs Terricolous : U \u2192 Prop\nconstant Likes : U \u2192 U \u2192 Prop\n\n-- premises\naxiom h1 : \u2200 x : U, Animal x \u2227 Barks x \u2192 \u00ac Likes jane x\naxiom h2 : \u2200 x : U, Dog x \u2192 Animal x \u2227 Barks x\naxiom h3 : \u2200 x : U, Animal x \u2227 Jumps x \u2192 Likes jane x\naxiom h4 : \u2200 x : U, Animal x \u2227 Legs x \u2192 Jumps x\naxiom h5 : \u2200 x : U, Animal x \u2227 Terricolous x \u2192 Legs x\naxiom h6 : Animal kiki\naxiom h7 : (\u00ac Jumps kiki \u2227 \u00ac Legs kiki) \u2192 (Terricolous kiki \u2228 Legs kiki)\n\n-- some derivable consequences (but none settle the questions)\nlemma terricolous_implies_likes : Terricolous kiki \u2192 Likes jane kiki :=\nby\n  intro hk\n  have hk_legs : Legs kiki := (h5 kiki) \u27e8h6, hk\u27e9\n  have hk_jumps : Jumps kiki := (h4 kiki) \u27e8h6, hk_legs\u27e9\n  exact (h3 kiki) \u27e8h6, hk_jumps\u27e9\n\nlemma dog_implies_barks : Dog kiki \u2192 Barks kiki :=\nby\n  intro hk\n  exact (h2 kiki hk).2\n\nlemma dog_implies_not_likes : Dog kiki \u2192 \u00ac Likes jane kiki :=\nby\n  intro hk\n  have : Animal kiki \u2227 Barks kiki := h2 kiki hk\n  exact (h1 kiki) this\n\n-- An inconsistency if kiki were both a dog and terricolous\nlemma not_dog_and_terricolous : \u00ac (Dog kiki \u2227 Terricolous kiki) :=\nby\n  intro h\n  rcases h with \u27e8hk_dog, hk_terr\u27e9\n  have : Likes jane kiki := terricolous_implies_likes hk_terr\n  have : False := (dog_implies_not_likes hk_dog) this\n  exact this.elim\n\n-- However, none of the following are derivable from the axioms:\n-- 1) Terricolous kiki\n-- 2) Dog kiki \u2227 Barks kiki\n-- 3) \u00ac Barks kiki \u2227 \u00ac Dog kiki\n-- and neither are their negations, given the current premises.\n\nConclusion of the attempt:\n- Q1 (Terricolous kiki): cannot be proved or refuted from the premises.\n- Q2 (Dog kiki \u2227 Barks kiki): cannot be proved or refuted from the premises.\n- Q3 (\u00acBarks kiki \u2227 \u00acDog kiki): cannot be proved or refuted from the premises.\n\nANSWERS:\n1: Unknown\n2: Unknown\n3: Unknown",
    "results": [
      {
        "question_num": 1,
        "example_id": 1324,
        "conclusion": "KiKi is terricolous.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 1325,
        "conclusion": "KiKi is a barking dog.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false
      },
      {
        "question_num": 3,
        "example_id": 1326,
        "conclusion": "KiKi does not bark and he is not a dog.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false
      }
    ],
    "story_accuracy": 0.3333333333333333
  },
  {
    "story_id": 101,
    "premises": "Ailton Silva, born in 1995, is commonly known as Ailton.\nAilton is a football player who was loaned out to Braga.\nAilton Silva is a Brazilian footballer who plays for N\u00e1utico.\nN\u00e1utico is a football club along with Braga.\nFluminense is a football club.",
    "model_response": "Lean formalization and proofs\n\nWe introduce an entity type and predicates to model the facts.\n\n- Entity: the domain of entities (people or clubs)\n- PlaysFor : Entity \u2192 Entity \u2192 Prop\n- LoanedTo : Entity \u2192 Entity \u2192 Prop\n- FootballClub : Entity \u2192 Prop\n- Brazilian : Entity \u2192 Prop\n\nConstants:\n- Ailton, AiltonSilva, Braga, Nautico, Fluminense : Entity\n\nAxioms from the text:\n- h_alias : Ailton = AiltonSilva\n- h_brazil : Brazilian AiltonSilva\n- h_plays_nautico : PlaysFor AiltonSilva Nautico\n- h_fc_nautico : FootballClub Nautico\n- h_fc_braga : FootballClub Braga\n- h_fc_flu : FootballClub Fluminense\n- h_loan_braga : LoanedTo Ailton Braga\n\nLean code (sketch):\n\nuniverse u\n\nconstant Entity : Type u\n\nconstant Ailton : Entity\nconstant AiltonSilva : Entity\nconstant Braga : Entity\nconstant Nautico : Entity\nconstant Fluminense : Entity\n\nconstant PlaysFor : Entity \u2192 Entity \u2192 Prop\nconstant LoanedTo : Entity \u2192 Entity \u2192 Prop\nconstant FootballClub : Entity \u2192 Prop\nconstant Brazilian : Entity \u2192 Prop\n\naxiom h_alias : Ailton = AiltonSilva\naxiom h_brazil : Brazilian AiltonSilva\naxiom h_plays_nautico : PlaysFor AiltonSilva Nautico\naxiom h_fc_nautico : FootballClub Nautico\naxiom h_fc_braga : FootballClub Braga\naxiom h_fc_flu : FootballClub Fluminense\naxiom h_loan_braga : LoanedTo Ailton Braga\n\n-- Q1: \"No one playing for Nautico is Brazilian.\"\n-- Formal: \u2200 x, PlaysFor x Nautico \u2192 \u00ac Brazilian x\ntheorem q1_false : \u00ac (\u2200 x, PlaysFor x Nautico \u2192 \u00ac Brazilian x) := by\n  intro h\n  have hnot : \u00ac Brazilian AiltonSilva := h AiltonSilva h_plays_nautico\n  exact hnot h_brazil\n\n-- Q2: \"Ailton Silva does not play for a football club.\"\n-- Formal: \u00ac \u2203 c, FootballClub c \u2227 PlaysFor AiltonSilva c\ntheorem q2_false : \u00ac (\u00ac \u2203 c, FootballClub c \u2227 PlaysFor AiltonSilva c) := by\n  intro h\n  apply h\n  exact \u27e8Nautico, And.intro h_fc_nautico h_plays_nautico\u27e9\n\n-- Q3: \"Ailton was not loaned out to a football club.\"\n-- Formal: \u00ac \u2203 c, FootballClub c \u2227 LoanedTo Ailton c\ntheorem q3_false : \u00ac (\u00ac \u2203 c, FootballClub c \u2227 LoanedTo Ailton c) := by\n  intro h\n  apply h\n  exact \u27e8Braga, And.intro h_fc_braga h_loan_braga\u27e9\n\n-- Q4: \"Ailton Silva played for Fluminense.\"\n-- Formal: PlaysFor AiltonSilva Fluminense\n-- Not derivable from the given axioms, and its negation is also not derivable.\n-- Therefore: Unknown.\n\n-- Q5: \"Ailton Silva was loaned out to a football club.\"\n-- Formal: \u2203 c, FootballClub c \u2227 LoanedTo AiltonSilva c\ntheorem q5_true : \u2203 c, FootballClub c \u2227 LoanedTo AiltonSilva c := by\n  have hloan_silva : LoanedTo AiltonSilva Braga := by\n    simpa [h_alias] using h_loan_braga\n  exact \u27e8Braga, And.intro h_fc_braga hloan_silva\u27e9\n\nConclusions:\n- Q1 is False (proved \u00acstatement).\n- Q2 is False (proved \u00acstatement).\n- Q3 is False (proved \u00acstatement).\n- Q4 is Unknown (neither provable nor disprovable from given axioms).\n- Q5 is True (proved statement).\n\nANSWERS:\n1: False\n2: False\n3: False\n4: Unknown\n5: True",
    "results": [
      {
        "question_num": 1,
        "example_id": 304,
        "conclusion": "No one playing for Nautico is Brazilian.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 2,
        "example_id": 305,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 3,
        "example_id": 306,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "False",
        "correct": true
      },
      {
        "question_num": 4,
        "example_id": 307,
        "conclusion": "Ailton Silva played for Fluminense.",
        "ground_truth": "Uncertain",
        "prediction": "Unknown",
        "correct": true
      },
      {
        "question_num": 5,
        "example_id": 308,
        "conclusion": "Ailton Silva was loaned out to a football club.",
        "ground_truth": "Uncertain",
        "prediction": "True",
        "correct": false
      }
    ],
    "story_accuracy": 0.8
  }
]