{
  "config": {
    "api_key": "REDACTED",
    "model": "gpt-5",
    "dataset": "both",
    "folio_file": "data/folio_original/folio-validation.json",
    "multi_dir": "data/multi_logi_original/data",
    "mode": "keep_none",
    "keep_n": 1,
    "num_samples": 50,
    "concurrency": 10,
    "output_dir": "results/memorization_test",
    "seed": 42
  },
  "timestamp": "20251204_092823",
  "results": {
    "folio": [
      {
        "example_id": 802,
        "story_id": 318,
        "conclusion": "Breaking Bad is on Monday at 8 pm.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1302,
        "story_id": 452,
        "conclusion": "Marvin is neither a human nor from Mars.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 7,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 563,
        "story_id": 198,
        "conclusion": "There is an animal.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1315,
        "story_id": 456,
        "conclusion": "Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 819,
        "story_id": 322,
        "conclusion": "KO is a stock.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1271,
        "story_id": 442,
        "conclusion": "Ted is a pet.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 4,
        "story_id": 2,
        "conclusion": "Butte and St Pierre are in the same state.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 291,
        "story_id": 96,
        "conclusion": "Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1314,
        "story_id": 456,
        "conclusion": "Yuri is not an American professional basketball player.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 659,
        "story_id": 232,
        "conclusion": "Beijing is the second largest Chinese city.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 942,
        "story_id": 355,
        "conclusion": "Taylor visits the gym at least once a day.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 305,
        "story_id": 101,
        "conclusion": "Ailton Silva does not play for a football club.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1327,
        "story_id": 460,
        "conclusion": "\"Hachi: A dog's Tale\" is rated General Audience.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 7,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 531,
        "story_id": 184,
        "conclusion": "\"Black Mirror\" is popular.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 245,
        "story_id": 80,
        "conclusion": "Palace of Flies was translated from Italian.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 959,
        "story_id": 361,
        "conclusion": "Peter is either a  clumsy foodie who goes out frequently to find new food restaurants to try or he is someone whose family prioritizes order and spotlessness.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 565,
        "story_id": 198,
        "conclusion": "Symptoms of Monkeypox include coughing.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 564,
        "story_id": 198,
        "conclusion": "No one gets the flu.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 532,
        "story_id": 184,
        "conclusion": "Karen will share \"Black Mirror\" with Lisa.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 241,
        "story_id": 79,
        "conclusion": "Robert Lewandowski plays for Bayern Munchen.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 6,
        "story_id": 2,
        "conclusion": "Montana is home to the city of Missoula.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 848,
        "story_id": 330,
        "conclusion": "John is engaged.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 966,
        "story_id": 363,
        "conclusion": "If the mixture contains only one element or contains carbon, then the mixture is neither a chemical compound nor an alkane.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 306,
        "story_id": 101,
        "conclusion": "Ailton was not loaned out to a football club.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 134,
        "story_id": 46,
        "conclusion": "Aurochs are extinct.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 906,
        "story_id": 343,
        "conclusion": "1984 is not a streaming service.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 323,
        "story_id": 107,
        "conclusion": "Heinrich Schmidt was German or Russian or both.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 2,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1316,
        "story_id": 456,
        "conclusion": "If Yuri does not leap straight into the air, then Yuri is an American professional basketball player.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 958,
        "story_id": 361,
        "conclusion": "Peter is notably tidy.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 242,
        "story_id": 79,
        "conclusion": "Robert Lewandowski is a star.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 527,
        "story_id": 183,
        "conclusion": "Peter is shorter than a man in Michael's class.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 7,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 244,
        "story_id": 80,
        "conclusion": "Harry Potter was published by New Vessel Press.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 820,
        "story_id": 322,
        "conclusion": "KO is a stock and a growth stock.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1015,
        "story_id": 380,
        "conclusion": "If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 928,
        "story_id": 350,
        "conclusion": "A design by Max is evocative and dreamy.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1313,
        "story_id": 456,
        "conclusion": "Yuri is an American national.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 171,
        "story_id": 58,
        "conclusion": "Walden contains knowledge.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1033,
        "story_id": 386,
        "conclusion": "If colorectal cancer is a kind of bile duct cancer or a form of Cholangiocarcinoma, then colorectal cancer is a kind of bile duct cancer and a kind of mild flu.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 927,
        "story_id": 350,
        "conclusion": "A design by Max is a brutalist building.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 1270,
        "story_id": 441,
        "conclusion": "If Tom is not both a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 688,
        "story_id": 245,
        "conclusion": "Sir Digby\u2019s nemesis does not win.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 8,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 411,
        "story_id": 140,
        "conclusion": "Steinhauer was not the winner of the 1992 du Maurier Classic.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 5,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 189,
        "story_id": 64,
        "conclusion": "Dani Shapiro is a novel writer.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 8,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 935,
        "story_id": 352,
        "conclusion": "If the Harvard Weekly Book club is a private company, then it either has legal obligations or is created under law.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 657,
        "story_id": 232,
        "conclusion": "Beijing hosted both the 2008 Summer Olympics and the Winter Olympics.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 547,
        "story_id": 191,
        "conclusion": "Machine translation is a language understanding task.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 172,
        "story_id": 58,
        "conclusion": "Harry is smarter than before.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 443,
        "story_id": 152,
        "conclusion": "John flies to LGA airport.",
        "ground_truth": "False",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 3,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 665,
        "story_id": 234,
        "conclusion": "Pierson College is a residential college at Yale.",
        "ground_truth": "True",
        "prediction": "Unknown",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 4,
        "modified_premises": "[No premises provided]"
      },
      {
        "example_id": 2,
        "story_id": 0,
        "conclusion": "Joey is a wild turkey.",
        "ground_truth": "Unknown",
        "prediction": "Unknown",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1,
        "num_original_premises": 6,
        "modified_premises": "[No premises provided]"
      }
    ],
    "multilogieval": [
      {
        "logic_type": "nm",
        "depth": "d5",
        "rule": "d5_1",
        "question": "Can we conclude if a Tiger does not purr then a Dog does not have a tail?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d5",
        "rule": "CD_C_DS_MP_MP",
        "question": "If there was no noise level up, were the police called to intervene?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d5",
        "rule": "d5_1",
        "question": "Can we conclude if Hot Chocolate is not aromatic then Tea can be sweetened?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d5",
        "rule": "d5_1",
        "question": "Can we conclude if the chocolate cake is not enjoyed by customers then the cookie is not delicious?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d1",
        "rule": "reasoning_about_exceptions_1",
        "question": "Can we conclude Tonga is a popular tourist destination and exactly one of Fiji or Samoa is not a popular tourist destination?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d2",
        "rule": "REII_MP",
        "question": "Can we conclude John purchased a textbook?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d2",
        "rule": "CD_DS",
        "question": "Given that Olivia did not make new friends in her book club, is it true that she discovered new book genres?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d5",
        "rule": "HS_MT_DS_MP_MP",
        "question": "If James cannot run farther, then can he run faster speeds?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d2",
        "rule": "DRD_MP",
        "question": "Can we conclude the blue car has heated seats?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d5",
        "rule": "BD_C_DS_MP_MP",
        "question": "If Kim's coworker invited her for drinks, did Kim go to shopping?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d2",
        "rule": "BD_DS",
        "question": "If Ashley was not alert all morning, did she take medicine to help her sleep the night before?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d5",
        "rule": "d5_1",
        "question": "Can we conclude if Sarah does not achieve success in the team then Alex has leadership skills?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d4",
        "rule": "CD_DS_MP_MP",
        "question": "Priya's plants did not grow well. Then did they wilt and die?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d3",
        "rule": "BD_C_DS",
        "question": "If Jessica ate a healthy breakfast, then did Sam get a good grade on the test?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d4",
        "rule": "d4_2",
        "question": "Can we conclude if the person with a degree is qualified then the teacher does not have expertise?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d4",
        "rule": "d4_1",
        "question": "Can we conclude if a library is not conducive to studying then Bob has a laptop?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d3",
        "rule": "d3_1",
        "question": "Can we conclude if Sarah does not get excited, then the other car has high performance?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d3",
        "rule": "DMT_CO_MT",
        "question": "Either Sam did not struggle on the test or he did not get a bad grade. Did Sam study enough for the exam?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d4",
        "rule": "d4_2",
        "question": "Can we conclude if company S uses sustainable practices, then company Q does not implement recycling programs?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d4",
        "rule": "BD_DS_MT_MT",
        "question": "If the cafe is not busy, then did Jane finish her work early?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d1",
        "rule": "HS",
        "question": "Given that Alex studies hard for his biology exam, will he likely get a good grade on the exam?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d5",
        "rule": "d5_1",
        "question": "Can we conclude if Mary does not excel in laboratory work then Jerry does not excel academically?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d1",
        "rule": "MP",
        "question": "Will the team likely develop a good product?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d1",
        "rule": "DMT",
        "question": "Does it entail that there is at least one professor for whom either being highly educated is not true or being an excellent teacher is not true or both?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d2",
        "rule": "CD_DS",
        "question": "If I did not get the job, then was I not selected?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d1",
        "rule": "DD",
        "question": "Does it entail that for Alex, who is learning music, either they do not learn to play the guitar or they do not take singing lessons?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d2",
        "rule": "HS_MP",
        "question": "If Mike trains his new puppy, will it behave properly?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d1",
        "rule": "reasoning_about_exceptions_2",
        "question": "does this entail that exactly one species of bat is active during the day?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d3",
        "rule": "DMT_CO_MT",
        "question": "Jay either did not go to the mechanic or he did not check the manual. Did Jay see the check engine light illuminated?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d1",
        "rule": "CO",
        "question": "Does it entail that if an animal stays healthy on the farm, then it reproduces and lives longer?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d3",
        "rule": "CD_C_DS",
        "question": "If Sam did not stay up late working on a paper, did he study hard for the exam?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d3",
        "rule": "d3_2",
        "question": "Can we conclude if a city's residents do not need to stay hydrated, then winter does not have specific activities?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d3",
        "rule": "CD_C_DS",
        "question": "If we did not watch a movie inside, then did we play catch outside?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d3",
        "rule": "BD_C_DS",
        "question": "If Ryan took out the trash, then did Lucy have free time after school?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d4",
        "rule": "I_MT_DMT_DS",
        "question": "The gardener watered the plants sufficiently, but the vegetable plants did not thrive. Did the gardener plant the seeds at the correct depth?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d5",
        "rule": "BD_C_DS_MP_MP",
        "question": "If The oven temperature reaches 375\u00b0FF, then does Alex enjoy the cake?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d1",
        "rule": "reasoning_about_priority",
        "question": "If john's evidence is more reliable than sarah's, does this entail that the package was delivered yesterday?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d4",
        "rule": "CD_C_DS_MP",
        "question": "If I did not miss the game, then was I ecstatic over the results?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d4",
        "rule": "BD_DS_MT_DS",
        "question": "Mary did not stock up on groceries, then did prices go up at the supermarket recently?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d2",
        "rule": "BD_DS",
        "question": "Mark didn't connect with potential customers. Did he explain product benefits?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d4",
        "rule": "BD_DS_MT_DS",
        "question": "If the grass is not wet, were the hoses put away for winter?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d2",
        "rule": "DD_DS",
        "question": "If I got a good night's sleep, did I drink coffee this morning?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d1",
        "rule": "reasoning_about_exceptions_2",
        "question": "does this imply that exactly one dog doesn't stay indoors?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d3",
        "rule": "d3_1",
        "question": "Can we conclude if hive H1 does not produce sweet honey, then Plant Y does not produce colorful flowers?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d3",
        "rule": "HS_CD_DS",
        "question": "The house did not become dark. Were the electronics not working?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "fol",
        "depth": "d2",
        "rule": "DD_DS",
        "question": "Mary watered her houseplants regularly. Is it true that she talked gently to her pets?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d5",
        "rule": "BD_C_DS_MP_MP",
        "question": "If Ashley's friend invited her to a concert, then did Ashley feel recharged?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "nm",
        "depth": "d2",
        "rule": "REI_MT",
        "question": "Can we conclude the vans are electric?",
        "ground_truth": "No",
        "prediction": "No",
        "correct": true,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d4",
        "rule": "BD_DS_MT_DS",
        "question": "If Sam did not study at the library, did he pull an all-nighter?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      },
      {
        "logic_type": "pl",
        "depth": "d1",
        "rule": "DMT",
        "question": "Does it entail that either the students did not use the right brush techniques or did not mix the correct paint colors or both?",
        "ground_truth": "Yes",
        "prediction": "No",
        "correct": false,
        "mode": "keep_none",
        "keep_n": 1
      }
    ]
  },
  "folio_accuracy": 0.34,
  "folio_total": 50,
  "folio_correct": 17,
  "multilogieval_accuracy": 0.34,
  "multilogieval_total": 50,
  "multilogieval_correct": 17
}